
@online{21com,
  title = {A Comparison of Semiparametric Approaches to Evaluate Composite Endpoints in Heart Failure Trials - {{Toenges}} - - {{Statistics}} in {{Medicine}} - {{Wiley Online Library}}},
  date = {2021},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.9149?af=R},
  urldate = {2021-07-31},
  keywords = {multiple-endpoints,rct,recurrent-events,shared-parameter,shared-parameter-models}
}

@article{aal76non,
  title = {Nonparametric Inference in Connection with Multiple Decrement Models},
  author = {Aalen, Odd O.},
  date = {1976},
  journaltitle = {Scan J Stat},
  volume = {3},
  pages = {15--27},
  citeulike-article-id = {13263667},
  posted-at = {2014-07-14 14:09:20},
  priority = {0},
  keywords = {counting-process,cumulative-hazard-estimator}
}

@article{aal78non,
  title = {Nonparametric Inference for a Family of Counting Processes},
  author = {Aalen, Odd O.},
  date = {1978},
  journaltitle = {Appl Stat},
  volume = {6},
  pages = {701--726},
  citeulike-article-id = {13263668},
  posted-at = {2014-07-14 14:09:20},
  priority = {0},
  keywords = {counting-process,cumulative-hazard-estimator}
}

@article{aal93fur,
  title = {Further Results on the Non-Parametric Linear Regression Model in Survival Analysis},
  author = {Aalen, Odd O.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {1569--1588},
  citeulike-article-id = {13263669},
  posted-at = {2014-07-14 14:09:20},
  priority = {0},
  keywords = {bootstrap,graphical-survival-analysis,martingale,ph-model,residuals}
}

@article{aal95ana,
  title = {Analysis of Dependent Survival Data Applied to Lifetimes of Amalgam Fillings},
  author = {Aalen, Odd O. and Bjertness, Espen and Sønju, Torleif},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1819--1829},
  citeulike-article-id = {13263670},
  posted-at = {2014-07-14 14:09:20},
  priority = {0},
  keywords = {multiple-events,multivariate-failure-time-data}
}

@article{abe01ran,
  title = {Rank-Based Procedures for Linear Models: {{Applications}} to Pharmaceutical Science Data},
  author = {Abebe, Asheber and Crimin, Kimberly and McKean, Joseph W. and Haas, Joseph V. and Vidmar, Thomas J.},
  date = {2001},
  journaltitle = {Drug Info J},
  volume = {35},
  pages = {947--971},
  citeulike-article-id = {13265223},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  note = {Wilcoxon scores; robust models; R web interface; distribution-free; nonparametric; web-based software; statistical computing}
}

@article{abr94sim,
  title = {Simple {{Bayesian}} Analysis in Clinical Trials: {{A}} Tutorial},
  author = {Abrams, Keith and Ashby, Deborah and Errington, Doug},
  date = {1994},
  journaltitle = {Controlled Clin Trials},
  volume = {15},
  pages = {349--359},
  citeulike-article-id = {13263671},
  posted-at = {2014-07-14 14:09:20},
  priority = {0},
  keywords = {bayesian-inference,study-design}
}

@article{abr96tim,
  title = {Time-Dependent Hazard Ratio: {{Modeling}} and Hypothesis Testing with Applications in Lupus Nephritis},
  author = {Abrahamowicz, Michal and MacKenzie, Todd and Esdaile, John M.},
  date = {1996},
  journaltitle = {JAMA},
  volume = {91},
  pages = {1432--1439},
  citeulike-article-id = {13263672},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {assessing-ph,hazard-ratio-function,interaction-between-predictor-and-spline-of-time}
}

@book{acepack,
  title = {Acepack: Ace and Avas for Selecting Regression Transformations},
  author = {Spector, Phil and Friedman, Jerome and Tibshirani, Robert and Lumley, Thomas},
  date = {2010},
  url = {http://CRAN.R-project.org/package=acepack},
  citeulike-article-id = {13265837},
  citeulike-linkout-0 = {http://CRAN.R-project.org/package=acepack},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  annotation = {R package version 1.3-3.0}
}

@book{ada95ris,
  title = {Risk},
  author = {Adams, John},
  date = {1995},
  publisher = {{UCL Press Limited}},
  location = {{London}},
  citeulike-article-id = {13263673},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {automobile-safety,commensurability,cost-benefit,global-warming,risk-assessment,risk-displacement},
  note = {risk P. 214-5: How to manage risk - Remember, everyone else is seeking to manage risk too. - They are all guessing; if they knew for certain, they would not be dealing with risk. - Their guesses are strongly influenced by their beliefs. - Their behaviour is strongly influenced by their guesses,~ and tends to reinforce their beliefs. - It is the behaviour of others, and the behaviour of nature, that constitute your risk environment. - Safety interventions that do not alter people's propensity to take risks will be frustrated by responses that re-establish the level of risk with which people were originally content. - In the absence of reductions in people's propensity to take risks, safety interventions will redistribute the burden or risk, not reduce it. - Potential safety benefits tend to get consumed as performance benefits. - For the forseeable future, nature will retain most of her secrets, and science will continue to invent new risks. - Human behaviour will always be unpredictable because it will always be responsive to human behaviour - including your behaviour. - It will never be possible to capture "objective risk", however powerful your computer, because the computer's predictions will be used to guide behaviour intended to influence that which is predicted. -~ In the dance of the risk thermostats, the music never stops.}
}

@article{adapt06Des,
  title = {Special Issue on Adaptive Design},
  author = {{Various}},
  date = {2006},
  journaltitle = {Drug Info J},
  volume = {40},
  number = {4},
  pages = {421--473},
  citeulike-article-id = {13265535},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {adaptive-design,dose-response,implementation,logistics,seamless-ii-iii-designs,terminology}
}

@article{adapt06Des2,
  title = {Special Issue on Adaptive Design},
  author = {{Various}},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  number = {19},
  citeulike-article-id = {13265536},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {adaptive-design,decision-theoretic-sample-size-determination,fda}
}

@article{adc97sam,
  title = {Sample Size Determination: A Review},
  author = {Adcock, C. J.},
  date = {1997},
  journaltitle = {The Statistician},
  volume = {46},
  pages = {261--283},
  citeulike-article-id = {13265277},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {average-coverage-criterion,bayes,bayes-factors,bayesian-inference,bayesian-sample-size-estimation,mcnemars-test,multinomial-distribution,sample-size}
}

@article{adl21adj,
  title = {Adjusting for {{Nonadherence}} or {{Stopping Treatments}} in {{Randomized Clinical Trials}}},
  author = {Adler, Amanda I. and Latimer, Nicholas R.},
  date = {2021-05-25},
  journaltitle = {JAMA},
  volume = {325},
  number = {20},
  pages = {2110--2111},
  issn = {0098-7484},
  doi = {10.1001/jama.2021.2433},
  url = {https://doi.org/10.1001/jama.2021.2433},
  urldate = {2021-05-29},
  abstract = {Randomized clinical trials allocate individuals to different treatments, or, more generally, to interventions and comparators, to determine whether one is better than another. However, after having been randomized to a given intervention, some study participants may not adhere to the assigned protocol. Treatment nonadherence may result from study participants crossing over to the other randomized treatments, taking nontrial medications, or not adhering to the study protocol. All of these situations introduce postrandomization problems that may have to be accounted for in the analysis of data from the trial.},
  keywords = {adherence,compliance,rct,reporting,reporting-clinical-trials,teaching-mds}
}

@article{aga21rob,
  title = {On {{Robustness}} of {{Principal Component Regression}}},
  author = {Agarwal, Anish and Shah, Devavrat and Shen, Dennis and Song, Dogyoon},
  date = {2021-05-12},
  journaltitle = {Journal of the American Statistical Association},
  volume = {0},
  number = {0},
  pages = {1--15},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2021.1928513},
  url = {https://doi.org/10.1080/01621459.2021.1928513},
  urldate = {2021-07-21},
  abstract = {Principal component regression (PCR) is a simple, but powerful and ubiquitously utilized method. Its effectiveness is well established when the covariates exhibit low-rank structure. However, its ability to handle settings with noisy, missing, and mixed-valued, that is, discrete and continuous, covariates is not understood and remains an important open challenge. As the main contribution of this work, we establish the robustness of PCR, without any change, in this respect and provide meaningful finite-sample analysis. To do so, we establish that PCR is equivalent to performing linear regression after preprocessing the covariate matrix via hard singular value thresholding (HSVT). As a result, in the context of counterfactual analysis using observational data, we show PCR is equivalent to the recently proposed robust variant of the synthetic control method, known as robust synthetic control (RSC). As an immediate consequence, we obtain finite-sample analysis of the RSC estimator that was previously absent. As an important contribution to the synthetic controls literature, we establish that an (approximate) linear synthetic control exists in the setting of a generalized factor model, or latent variable model; traditionally in the literature, the existence of a synthetic control needs to be assumed to exist as an axiom. We further discuss a surprising implication of the robustness property of PCR with respect to noise, that is, PCR can learn a good predictive model even if the covariates are tactfully transformed to preserve differential privacy. Finally, this work advances the state-of-the-art analysis for HSVT by establishing stronger guarantees with respect to the l2,∞ -norm rather than the Frobenius norm as is commonly done in the matrix estimation literature, which may be of interest in its own right.},
  keywords = {data-reduction,incomplete-principal-components-regression,pca,robustness,unsupervised-learning},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2021.1928513}
}

@article{agr00sim,
  title = {Simple and Effective Confidence Intervals for Proportions and Differences in Proportions Result from Adding Two Successes and Two Failures},
  author = {Agresti, Alan and Caffo, Brian},
  date = {2000},
  journaltitle = {Am Statistician},
  volume = {54},
  pages = {280--288},
  citeulike-article-id = {13265166},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {adjusted-wald-interval,guaranteed-vs-best-average-coverage,wilson-interval}
}

@article{agr01exa,
  title = {Exact Inference for Categorical Data: Recent Advances and Continuing Controversies},
  author = {Agresti, Alan},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2709--2722},
  citeulike-article-id = {13265226},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {exact-methods,excellent-review-article,odds-ratios,proportions}
}

@article{agr08sim,
  title = {Simultaneous Confidence Intervals for Comparing Binomial Parameters},
  author = {Agresti, Alan and Bini, Matilde and Bertaccini, Bruno and Ryu, Euijung},
  date = {2008},
  journaltitle = {Biometrics},
  volume = {64},
  pages = {1270--1275},
  citeulike-article-id = {13265725},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {binomial-k-sample-problem,bonferroni-method,difference-of-proportions,odds-ratio,proportions,score-test,simultaneous-confidence-intervals,studentized-range-distribution,tukey-multiple-comparisons}
}

@article{agr89,
  title = {A Survey of Models for Repeated Ordered Categorical Response Data},
  author = {Agresti, A.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {1209--1224},
  citeulike-article-id = {13263674},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {logistic-ordinal-model,multivariate-analysis}
}

@article{agr97mod,
  title = {A Model for Repeated Measurements of a Multivariate Binary Response},
  author = {Agresti, Alan},
  date = {1997},
  journaltitle = {J Am Stat Assoc},
  volume = {92},
  pages = {315--321},
  citeulike-article-id = {13263675},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {multivariate-binary-response,repeated-measurements,serial-measurements}
}

@article{agr98app,
  title = {Approximate Is Better than “Exact” for Interval Estimation of Binomial Proportions},
  author = {Agresti, Alan and Coull, Brent A.},
  date = {1998},
  journaltitle = {Am Statistician},
  volume = {52},
  pages = {119--126},
  citeulike-article-id = {13263676},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {confidence-interval,inherent-conservative-of-exact-methods,method-for-averaging-coverage-probabilities-over-p,one-sample-binomial,overlaps-with-new98one,wilson-score-interval-is-best}
}

@book{agresti,
  title = {Categorical Data Analysis},
  author = {Agresti, Alan},
  date = {2002},
  edition = {second},
  publisher = {{Wiley}},
  location = {{Hoboken, NJ}},
  citeulike-article-id = {13265963},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{ahm15new,
  title = {A New Method of Applying Randomised Control Study Data to the Individual Patient: {{A}} Novel Quantitative Patient-Centred Approach to Interpreting Composite End Points.},
  author = {Ahmad, Yousif and Nijjer, Sukhjinder and Cook, Christopher M. and El-Harasis, Majd and Graby, John and Petraco, Ricardo and Kotecha, Tushar and Baker, Christopher S. and Malik, Iqbal S. and Bellamy, Michael F. and Sethi, Amarjit and Mikhail, Ghada W. and Al-Bustami, Mahmud and Khan, Masood and Kaprielian, Raffi and Foale, Rodney A. and Mayet, Jamil and Davies, Justin E. and Francis, Darrel P. and Sen, Sayan},
  date = {2015-09},
  journaltitle = {Int J Cardiol},
  volume = {195},
  eprint = {26048380},
  eprinttype = {pmid},
  pages = {216--224},
  issn = {1874-1754},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26048380},
  abstract = {Modern randomised controlled trials typically use composite endpoints. This is only valid if each endpoint is equally important to patients but few trials document patient preference and seek the relative importance of components of combined endpoints. If patients weigh endpoints differentially, our interpretation of trial data needs to be refined. We derive a quantitative, structured tool to determine the relative importance of each endpoint to patients. We then apply this tool to data comparing angioplasty with drug-eluting stents to bypass surgery. The survey was administered to patients undergoing cardiac catheterisation. A meta-analysis comparing coronary artery bypass grafting (CABG) to percutaneous coronary interventuin (PCI) was then performed using (a) standard MACE and (b) patient-centred MACE. Patients considered stroke worse than death (stroke 102.3 ± 19.6\%, p {$<$} 0.01), and MI and repeat revascularisation less severe than death (61.9 ± 26.8\% and 41.9 ± 25.4\% respectively p {$<$} 0.01 for both). 7 RCTs (5251 patients) were eligible. Meta-analysis demonstrated that standard MACE occurs more frequently with PCI than surgery (OR 1.44; 95\% CI 1.10 to 1.87; p = 0.007). Re-analysis using patient-centred MACE found no significant difference between PCI and CABG (OR 1.22, 95\% CI 0.97 to 1.53; p = 0.10). Patients do not consider the constituent endpoints of MACE equal. We derive a novel patient-centred metric that recognises and quantifies the differences attributed to each endpoint. When patient preference data are applied to contemporary trial results, there is no significant difference between PCI and CABG. Responses from individual patients in clinic could be used to give individual patients a recommendation that is truly personalised. Copyright  2015 Elsevier Ireland Ltd. All rights reserved.},
  citeulike-article-id = {14500138},
  citeulike-attachment-1 = {ahm14new.pdf; /pdf/user/harrelfe/article/14500138/1124511/ahm14new.pdf; 9c8c5f2974918670939c2615b3a1a82900310a3b},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26048380},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26048380},
  day = {15},
  posted-at = {2017-12-10 12:45:39},
  priority = {3},
  keywords = {multiple-endpoints,utilities}
}

@article{ahn94tre,
  title = {Tree-Structured Proportional Hazards Regression Modeling},
  author = {Ahn, Hongshik and Loh, Wei-Yin},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  pages = {471--485},
  citeulike-article-id = {13263677},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {bootstrap,cart,cross-validation,mayo-pbc-data,non-regression,survival-analysis,tree-models}
}

@article{ahn95sam,
  title = {Sample Size Determination for Comparing More than Two Survival Distributions},
  author = {Ahnn, Sang and Anderson, Stewart J.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2273--2282},
  citeulike-article-id = {13263678},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {k-sample-problem,sample-size,study-design,survival-analysis}
}

@article{ait57gen,
  title = {The Generalization of Probit Analysis to the Case of Multiple Responses},
  author = {Aitchison, J. and Silvey, S. D.},
  date = {1957},
  journaltitle = {Biometrika},
  volume = {44},
  pages = {131--140},
  citeulike-article-id = {13265964},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  note = {first paper to describe ordinal response model and that the Hessian has a bordered tridiagonal structure}
}

@article{aka97pow,
  title = {Power of Logrank Test and {{Cox}} Regression Model in Clinical Trials with Heterogeneous Samples},
  author = {Akazawa, Kouhei and Nakamura, Tsuyoshi and Palesch, Yuko},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {583--597},
  citeulike-article-id = {13263679},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {baseline-characteristics,covariable-adjustment,loss-of-power-of-unadjusted-tests,model-identification,model-misspecification,quantifying-prognostic-spectrum-of-adjustors,simulation-setup}
}

@article{akr90,
  title = {The Rank Transform Method in Some Two-Factor Designs},
  author = {Mg, Akritas},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {73--78},
  citeulike-article-id = {13263680},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {distribution-free-methods}
}

@article{akw17hea,
  title = {Heart {{Failure Incidence}} and {{Mortality}} in the {{Southern Community Cohort Study}}},
  author = {Akwo, Elvis A. and Kabagambe, Edmond K. and Wang, Thomas J. and Harrell, Frank E. and Blot, William J. and Mumma, Michael and Gupta, Deepak K. and Lipworth, Loren},
  date = {2017-03},
  journaltitle = {Circ Heart Fail},
  volume = {10},
  number = {3},
  eprint = {28255010},
  eprinttype = {pmid},
  issn = {1941-3297},
  doi = {10.1161/CIRCHEARTFAILURE.116.003553},
  abstract = {BACKGROUND: There is a paucity of data on heart failure (HF) incidence among low-income and minority populations. Our objective was to investigate HF incidence and post-HF survival by race and sex among low-income adults in the southeastern United States. METHODS AND RESULTS: Participants were 27\,078 white and black men and women enrolled during 2002 to 2009 in the SCCS (Southern Community Cohort Study) who had no history of HF and were receiving Centers for Medicare and Medicaid Services. Incident HF diagnoses through December 31, 2010 were ascertained using International Classification of Diseases 9th Revision codes 428.x via linkage with Centers for Medicare and Medicaid Services research files. Most participants were black (68.8\%), women (62.6\%), and earned {$<\$$}15\,000/y (69.7\%); mean age was 55.5 (10.4) years. Risk factors for HF were common: hypertension (62.5\%), diabetes mellitus (26.5\%), myocardial infarction (8.6\%), and obesity (44.8\%). Over a median follow-up of 5.2 years, 4341 participants were diagnosed with HF. The age-standardized incidence rates were 34.8, 37.3, 34.9, and 35.6 /1000 person-years in white women, white men, black men, and black women, respectively, remarkably higher than previously reported. Among HF cases, 952 deaths occurred over a median follow-up of 2.3 years. Men had lower survival; hazard ratios and 95\% confidence intervals were 1.63 (1.27-2.08), 1.38 (1.11-1.72), and 0.90 (0.73-1.12) for white men, black men, and black women compared with white women. CONCLUSIONS: In this low-income population, HF incidence was higher for all race-sex groups than previously reported in other cohorts. The SCCS is a unique resource to investigate determinants of HF risk in a segment of the population underrepresented in other existing cohorts.},
  langid = {english},
  pmcid = {PMC5365148}
}

@article{akw18nei,
  title = {Neighborhood {{Deprivation Predicts Heart Failure Risk}} in a {{Low-Income Population}} of {{Blacks}} and {{Whites}} in the {{Southeastern United States}}},
  author = {Akwo, Elvis A. and Kabagambe, Edmond K. and Harrell, Frank E. and Blot, William J. and Bachmann, Justin M. and Wang, Thomas J. and Gupta, Deepak K. and Lipworth, Loren},
  date = {2018-01},
  journaltitle = {Circ: Cardiovasc Qual Outcomes},
  volume = {11},
  number = {1},
  pages = {e004052+},
  publisher = {American Heart Association, Inc.},
  issn = {1941-7713},
  doi = {10.1161/circoutcomes.117.004052},
  url = {http://dx.doi.org/10.1161/circoutcomes.117.004052},
  citeulike-article-id = {14514307},
  citeulike-attachment-1 = {akw18nei.pdf; /pdf/user/harrelfe/article/14514307/1126606/akw18nei.pdf; 8f3860d22281b6306c7ccb874b56db3a22bd4a24},
  citeulike-linkout-0 = {http://dx.doi.org/10.1161/circoutcomes.117.004052},
  citeulike-linkout-1 = {http://circoutcomes.ahajournals.org/content/11/1/e004052.abstract},
  citeulike-linkout-2 = {http://circoutcomes.ahajournals.org/content/11/1/e004052.full.pdf},
  day = {01},
  posted-at = {2018-01-10 03:55:48},
  priority = {2},
  keywords = {collaboration}
}

@article{akw18neia,
  title = {Neighborhood {{Deprivation Predicts Heart Failure Risk}} in a {{Low-Income Population}} of {{Blacks}} and {{Whites}} in the {{Southeastern United States}}},
  author = {Akwo, Elvis A. and Kabagambe, Edmond K. and Harrell, Frank E. and Blot, William J. and Bachmann, Justin M. and Wang, Thomas J. and Gupta, Deepak K. and Lipworth, Loren},
  date = {2018-01},
  journaltitle = {Circ Cardiovasc Qual Outcomes},
  volume = {11},
  number = {1},
  eprint = {29317456},
  eprinttype = {pmid},
  pages = {e004052},
  issn = {1941-7705},
  doi = {10.1161/CIRCOUTCOMES.117.004052},
  abstract = {BACKGROUND: Recent data suggest that neighborhood socioeconomic environment predicts heart failure (HF) hospital readmissions. We investigated whether neighborhood deprivation predicts risk of incident HF beyond individual socioeconomic status in a low-income population. METHODS AND RESULTS: Participants were 27 078 whites and blacks recruited during 2002 to 2009 in the SCCS (Southern Community Cohort Study), who had no history of HF and were using Centers for Medicare or Medicaid Services. Incident HF diagnoses through December 31, 2010, were ascertained using International Classification of Diseases, Ninth Revision, codes 428.x via linkage with Centers for Medicare or Medicaid Services research files. Participant residential information was geocoded and census tract determined by a spatial join to the US Census Bureau TIGER/Line Shapefiles. The neighborhood deprivation index was constructed using principal components analysis based on census tract-level socioeconomic variables. Cox models with Huber-White cluster sandwich estimator of variance were used to investigate the association between neighborhood deprivation index and HF risk. The study sample was predominantly middle aged (mean, 55.5 years), black (69\%), female (63\%), low income (70\% earned {$<\$$}15 000/y), and {$>$}50\% of participants lived in the most deprived neighborhoods (third neighborhood deprivation index tertile). Over median follow-up of 5.2 years, 4300 participants were diagnosed with HF. After adjustment for demographic, lifestyle, and clinical factors, a 1 interquartile increase in neighborhood deprivation index was associated with a 12\% increase in risk of HF (hazard ratio, 1.12; 95\% confidence interval, 1.07-1.18), and 4.8\% of the variance in HF risk (intraclass correlation coefficient, 4.8; 95\% confidence interval, 3.6-6.4) was explained by neighborhood deprivation. CONCLUSIONS: In this low-income population, scant neighborhood resources compound the risk of HF above and beyond individual socioeconomic status and traditional cardiovascular risk factors. Improvements in community resources may be a significant axis for curbing the burden of HF.},
  langid = {english},
  pmcid = {PMC5769153},
  keywords = {collaboration,epidemiology}
}

@article{al-18fra,
  title = {Fractional {{Flow Reserve}} and {{Instantaneous Wave-Free Ratio}} as {{Predictors}} of the {{Placebo-Controlled Response}} to {{Percutaneous Coronary Intervention}} in {{Stable Single-Vessel Coronary Artery Disease}}},
  author = {Al-Lamee, Rasha and Howard, James P. and Shun-Shin, Matthew J. and Thompson, David and Dehbi, Hakim-Moulay and Sen, Sayan and Nijjer, Sukhjinder and Petraco, Ricardo and Davies, John and Keeble, Thomas and Tang, Kare and Malik, Iqbal S. and Cook, Christopher and Ahmad, Yousif and Sharp, Andrew S. P. and Gerber, Robert and Baker, Christopher and Kaprielian, Raffi and Talwar, Suneel and Assomull, Ravi and Cole, Graham and Keenan, Niall G. and Kanaganayagam, Gajen and Sehmi, Joban and Wensel, Roland and Harrell, Frank E. and Mayet, Jamil and Thom, Simon A. and Davies, Justin E. and Francis, Darrel P.},
  date = {2018-10-23},
  journaltitle = {Circulation},
  url = {https://www.ahajournals.org/doi/10.1161/CIRCULATIONAHA.118.033801},
  urldate = {2018-10-23},
  abstract = {Background: There are no data on how fractional flow reserve (FFR) and instantaneous wave-free ratio (iFR) are associated with the placebo-controlled efficacy of percutaneous coronary intervention (PCI) in stable single-vessel coronary artery disease. Methods: We report the association between prerandomization invasive physiology within ORBITA (Objective Randomised Blinded Investigation With Optimal Medical Therapy of Angioplasty in Stable Angina), a placebo-controlled trial of patients who have stable angina with angiographically severe single-vessel coronary disease clinically eligible for PCI. Patients underwent prerandomization research FFR and iFR assessment. The operator was blinded to these values. Assessment of response variables, treadmill exercise time, stress echocardiography score, symptom frequency, and angina severity were performed at prerandomization and blinded follow-up. Effects were calculated by analysis of covariance. The ability of FFR and iFR to predict placebo-controlled changes in...},
  langid = {english},
  keywords = {collaboration,cv,interaction,rct,rct-interpretation,spline-examples}
}

@article{al-18fraa,
  title = {Fractional {{Flow Reserve}} and {{Instantaneous Wave-Free Ratio}} as {{Predictors}} of the {{Placebo-Controlled Response}} to {{Percutaneous Coronary Intervention}} in {{Stable Single-Vessel Coronary Artery Disease}}},
  author = {Al-Lamee, Rasha and Howard, James P. and Shun-Shin, Matthew J. and Thompson, David and Dehbi, Hakim-Moulay and Sen, Sayan and Nijjer, Sukhjinder and Petraco, Ricardo and Davies, John and Keeble, Thomas and Tang, Kare and Malik, Iqbal S. and Cook, Christopher and Ahmad, Yousif and Sharp, Andrew S. P. and Gerber, Robert and Baker, Christopher and Kaprielian, Raffi and Talwar, Suneel and Assomull, Ravi and Cole, Graham and Keenan, Niall G. and Kanaganayagam, Gajen and Sehmi, Joban and Wensel, Roland and Harrell, Frank E. and Mayet, Jamil and Thom, Simon A. and Davies, Justin E. and Francis, Darrel P.},
  date = {2018-10-23},
  journaltitle = {Circulation},
  volume = {138},
  number = {17},
  eprint = {29789302},
  eprinttype = {pmid},
  pages = {1780--1792},
  issn = {1524-4539},
  doi = {10.1161/CIRCULATIONAHA.118.033801},
  abstract = {BACKGROUND: There are no data on how fractional flow reserve (FFR) and instantaneous wave-free ratio (iFR) are associated with the placebo-controlled efficacy of percutaneous coronary intervention (PCI) in stable single-vessel coronary artery disease. METHODS: We report the association between prerandomization invasive physiology within ORBITA (Objective Randomised Blinded Investigation With Optimal Medical Therapy of Angioplasty in Stable Angina), a placebo-controlled trial of patients who have stable angina with angiographically severe single-vessel coronary disease clinically eligible for PCI. Patients underwent prerandomization research FFR and iFR assessment. The operator was blinded to these values. Assessment of response variables, treadmill exercise time, stress echocardiography score, symptom frequency, and angina severity were performed at prerandomization and blinded follow-up. Effects were calculated by analysis of covariance. The ability of FFR and iFR to predict placebo-controlled changes in response variables was tested by using regression modeling. RESULTS: Invasive physiology data were available in 196 patients (103 PCI and 93 placebo). At prerandomization, the majority had Canadian Cardiovascular Society class II or III symptoms (150/196, 76.5\%). Mean FFR and iFR were 0.69±0.16 and 0.76±0.22, respectively; 97\% had ≥1 positive ischemia tests. The estimated effect of PCI on between-arm prerandomization-adjusted total exercise time was 20.7 s (95\% confidence interval [CI], -4.0 to 45.5; P=0.100) with no interaction of FFR ( Pinteraction=0.318) or iFR ( Pinteraction=0.523). PCI improved stress echocardiography score more than placebo (1.07 segment units; 95\% CI, 0.70-1.44; P{$<$}0.00001). The placebo-controlled effect of PCI on stress echocardiography score increased progressively with decreasing FFR ( Pinteraction{$<$}0.00001) and decreasing iFR ( Pinteraction{$<$}0.00001). PCI did not improve angina frequency score significantly more than placebo (odds ratio, 1.64; 95\% CI, 0.96-2.80; P=0.072) with no detectable evidence of interaction with FFR ( Pinteraction=0.849) or iFR ( Pinteraction=0.783). However, PCI resulted in more patient-reported freedom from angina than placebo (49.5\% versus 31.5\%; odds ratio, 2.47; 95\% CI, 1.30-4.72; P=0.006) but neither FFR ( Pinteraction=0.693) nor iFR ( Pinteraction=0.761) modified this effect. CONCLUSIONS: In patients with stable angina and severe single-vessel disease, the blinded effect of PCI was more clearly seen by stress echocardiography score and freedom from angina than change in treadmill exercise time. Moreover, the lower the FFR or iFR, the greater the magnitude of stress echocardiographic improvement caused by PCI. CLINICAL TRIAL REGISTRATION: URL: https://www.clinicaltrials.gov . Unique identifier: NCT02062593.},
  langid = {english},
  keywords = {collaboration,cv}
}

@article{al-19dob,
  title = {Dobutamine {{Stress Echocardiography Ischemia}} as a {{Predictor}} of the {{Placebo-Controlled Efficacy}} of {{Percutaneous Coronary Intervention}} in {{Stable Coronary Artery Disease}}: {{The Stress Echocardiography-Stratified Analysis}} of {{ORBITA}}},
  shorttitle = {Dobutamine {{Stress Echocardiography Ischemia}} as a {{Predictor}} of the {{Placebo-Controlled Efficacy}} of {{Percutaneous Coronary Intervention}} in {{Stable Coronary Artery Disease}}},
  author = {Al-Lamee, Rasha K. and Shun-Shin, Matthew J. and Howard, James P. and Nowbar, Alexandra N. and Rajkumar, Christopher and Thompson, David and Sen, Sayan and Nijjer, Sukhjinder and Petraco, Ricardo and Davies, John and Keeble, Thomas and Tang, Kare and Malik, Iqbal and Bual, Nina and Cook, Christopher and Ahmad, Yousif and Seligman, Henry and Sharp, Andrew S. P. and Gerber, Robert and Talwar, Suneel and Assomull, Ravi and Cole, Graham and Keenan, Niall G. and Kanaganayagam, Gajen and Sehmi, Joban and Wensel, Roland and Harrell, Frank E. and Mayet, Jamil and Thom, Simon and Davies, Justin E. and Francis, Darrel P.},
  date = {2019-12-10},
  journaltitle = {Circulation},
  volume = {140},
  number = {24},
  eprint = {31707827},
  eprinttype = {pmid},
  pages = {1971--1980},
  issn = {1524-4539},
  doi = {10.1161/CIRCULATIONAHA.119.042918},
  abstract = {BACKGROUND: Dobutamine stress echocardiography is widely used to test for ischemia in patients with stable coronary artery disease. In this analysis, we studied the ability of the prerandomization stress echocardiography score to predict the placebo-controlled efficacy of percutaneous coronary intervention (PCI) within the ORBITA trial (Objective Randomised Blinded Investigation With Optimal Medical Therapy of Angioplasty in Stable Angina). METHODS: One hundred eighty-three patients underwent dobutamine stress echocardiography before randomization. The stress echocardiography score is broadly the number of segments abnormal at peak stress, with akinetic segments counting double and dyskinetic segments counting triple. The ability of prerandomization stress echocardiography to predict the placebo-controlled effect of PCI on response variables was tested by using regression modeling. RESULTS: At prerandomization, the stress echocardiography score was 1.56±1.77 in the PCI arm (n=98) and 1.61±1.73 in the placebo arm (n=85). There was a detectable interaction between prerandomization stress echocardiography score and the effect of PCI on angina frequency score with a larger placebo-controlled effect in patients with the highest stress echocardiography score (Pinteraction=0.031). With our sample size, we were unable to detect an interaction between stress echocardiography score and any other patient-reported response variables: freedom from angina (Pinteraction=0.116), physical limitation (Pinteraction=0.461), quality of life (Pinteraction=0.689), EuroQOL 5 quality-of-life score (Pinteraction=0.789), or between stress echocardiography score and physician-assessed Canadian Cardiovascular Society angina class (Pinteraction=0.693), and treadmill exercise time (Pinteraction=0.426). CONCLUSIONS: The degree of ischemia assessed by dobutamine stress echocardiography predicts the placebo-controlled efficacy of PCI on patient-reported angina frequency. The greater the downstream stress echocardiography abnormality caused by a stenosis, the greater the reduction in symptoms from PCI. CLINICAL TRIAL REGISTRATION: URL: https://www.clinicaltrials.gov. Unique identifier: NCT02062593.},
  langid = {english},
  pmcid = {PMC6903430},
  keywords = {collaboration,cv}
}

@online{al18ass,
  title = {Association Is Not Causation: Treatment Effects Cannot Be Estimated from Observational Data in Heart Failure | {{Kopernio}}},
  shorttitle = {Association Is Not Causation},
  author = {et {al}, C. J. Rush},
  date = {2018},
  url = {https://kopernio.com/viewer?doi=10.1093%2Feurheartj%2Fehy407&token=WzMwMjM5MywiMTAuMTA5My9ldXJoZWFydGovZWh5NDA3Il0.YNHKrn-mK27hCUSAxH6uoJDcnJU},
  urldate = {2020-07-06},
  abstract = {Download PDF of Association is not causation: treatment effects cannot be estimated from observational data in heart failure published in European Heart Journal},
  langid = {english},
  keywords = {bias,observation-study,treatment-comparisons}
}

@article{ala18sho,
  title = {Should a Propensity Score Model Be Super? {{The}} Utility of Ensemble Procedures for Causal Adjustment},
  shorttitle = {Should a Propensity Score Model Be Super?},
  author = {Alam, Shomoita and Moodie, Erica E. M. and Stephens, David A.},
  date = {2018},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8075},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8075},
  urldate = {2018-12-31},
  abstract = {In investigations of the effect of treatment on outcome, the propensity score is a tool to eliminate imbalance in the distribution of confounding variables between treatment groups. Recent work has suggested that Super Learner, an ensemble method, outperforms logistic regression in nonlinear settings; however, experience with real-data analyses tends to show overfitting of the propensity score model using this approach. We investigated a wide range of simulated settings of varying complexities including simulations based on real data to compare the performances of logistic regression, generalized boosted models, and Super Learner in providing balance and for estimating the average treatment effect via propensity score regression, propensity score matching, and inverse probability of treatment weighting. We found that Super Learner and logistic regression are comparable in terms of covariate balance, bias, and mean squared error (MSE); however, Super Learner is computationally very expensive thus leaving no clear advantage to the more complex approach. Propensity scores estimated by generalized boosted models were inferior to the other two estimation approaches. We also found that propensity score regression adjustment was superior to either matching or inverse weighting when the form of the dependence on the treatment on the outcome is correctly specified.},
  langid = {english},
  keywords = {covariable-adjustment,covariate-adjustment,machine-learning,propensity}
}

@book{alb07bay,
  title = {Bayesian {{Computation}} with {{R}}},
  author = {Albert, Jim},
  date = {2007},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265620},
  posted-at = {2014-07-14 14:10:00},
  priority = {0}
}

@article{alb07imp,
  title = {Imputation Approaches for Estimating Diagnostic Accuracy for Multiple Tests from Partially Verified Designs},
  author = {Albert, Paul S.},
  date = {2007},
  journaltitle = {Biometrics},
  volume = {63},
  pages = {947--957},
  citeulike-article-id = {13265625},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {diagnosis,diagnostic-accuracy,gold-standard,latent-class-model,mean-imputation,multiple-imputation,multiple-tests,partial-verification,prevalence,semilatent-class-models,sensitivity,specificity,verification-bias}
}

@article{alb93tea,
  title = {Teaching {{Bayesian}} Statistics Using Sampling Methods and {{MINITAB}}},
  author = {Albert, James H.},
  date = {1993},
  journaltitle = {Am Statistician},
  volume = {47},
  pages = {182--191},
  citeulike-article-id = {13263681},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {bayesian-inference,sampling-importance-resampling,teaching,weighted-bootstrap}
}

@article{alb94mar,
  title = {A {{Markov Model}} for {{Sequences}} of {{Ordinal Data}} from a {{Relapsing-Remitting Disease}}},
  author = {Albert, Paul S.},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  number = {1},
  eprint = {2533196},
  eprinttype = {jstor},
  pages = {51--60},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006-341X},
  doi = {10.2307/2533196},
  abstract = {Many chronic diseases follow a course with multiple relapses into periods with severe symptoms alternating with periods of remission; experimental allergic encephalomyelitis, the animal model for multiple sclerosis, is an example of such a disease. A finite Markov chain is proposed as a model for analyzing sequences of ordinal data from a relapsing-remitting disease. The proposed model is one in which the state space is expanded to include information about the relapsing-remitting status as well as the ordinal severity score, and a reparameterization is suggested that reduces the number of parameters needed to be estimated. The Markov model allows for a wide range of relapsing-remitting behavior, provides an understanding of the stochastic nature of the disease process, and allows for efficient estimation of important characteristics of the disease course (such as mean first passage times, occupation times, and steady-state probabilities). These methods are applied to data from a study of the effect of a treatment (transforming growth factor-β1) on experimental allergic encephalomyelitis.},
  keywords = {markov-model,ordinal,serial},
  note = {Joint model for relapse and disease severity.~ Not clear why this needs to be two models.~ For equally spaced measurements.}
}

@article{alb97gen,
  title = {A Generalized Estimating Equation Approach for Modeling Random Length Binary Vector Data},
  author = {Albert, Paul S. and Follmann, Dean A. and Barnhart, Huiman X.},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {1116--1124},
  citeulike-article-id = {13263682},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {compound-endpoints,correlated-binary-data,gee,joint-modeling-of-severity-and-frequency,shared-parameter-models}
}

@article{alb99tut,
  title = {Tutorial in Biostatistics: {{Longitudinal}} Data Analysis (Repeated Measures) in Clinical Trials},
  author = {Albert, Paul S.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1707--1732},
  citeulike-article-id = {13263683},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {repeated-measures,serial-data,teaching,tutorial}
}

@article{alh92com,
  title = {On the Computation of Likelihood Ratio and Score Test Based Confidence Intervals in Generalized Linear Models},
  author = {Alho, Juha M.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {923--930},
  citeulike-article-id = {13263684},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@article{ali09fac,
  title = {Factors Influencing the Statistical Power of Complex Data Analysis Protocols for Molecular Signature Development from Microarray Data},
  author = {Aliferis, Constantin F. and Statnikov, Alexander and Tsamardinos, Ioannis and Schildcrout, Jonathan S. and Shepherd, Bryan E. and Harrell, Frank E.},
  date = {2009},
  journaltitle = {PLoS ONE},
  volume = {4},
  number = {3},
  citeulike-article-id = {13265726},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  note = {refutation of mic05pre}
}

@article{ali96pro,
  title = {A Proportional Hazards Model for Arbitrarily Censored and Truncated Data},
  author = {Alioum, Ahmadou and Commenges, Daniel},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {512--524},
  citeulike-article-id = {13263685},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {interval-censoring,ph-model,right-truncation}
}

@article{alk97app,
  title = {Application of a Continuous-Time {{Markov}} Chain to a Preclnical Study},
  author = {al- Khalidi, Hussein R. and Schnell, Daniel J.},
  options = {useprefix=true},
  date = {1997},
  journaltitle = {Drug Info J},
  volume = {31},
  pages = {607--613},
  citeulike-article-id = {13263686},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {arrhythmia,continuous-time-markov-chain,limiting-behavior,markov-chain,teaching,transition-probability}
}

@article{all00day,
  title = {A Day in the Life of a {{Medicaid}} Fraud Statistician},
  author = {Allen, Terry},
  date = {2000-23},
  journaltitle = {Stats},
  number = {29},
  pages = {20--21},
  citeulike-article-id = {13265160},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {fraud},
  note = {graphics;We've found that well-executed graphics sometimes can help to avoid the time and expense of a trial. By summarizing the data into a clear picture, a number of graphics have convinced doctors and their attorneys to settle their cases out of court. The power of statistical graphics was emphasized for us in one situation when our investigators confronted a physician with his fraudulent billing pattern displayed in an easy-to-understand visual. The doctor became so upset that he started to hyperventilate and fainted. Our investigators found themselves in the peculiar position of having to revive the doctor in his own office before he could discuss his upcoded billings.}
}

@book{all01mis,
  title = {Missing {{Data}}},
  author = {Allison, Paul D.},
  date = {2001},
  series = {Sage {{University Papers Series}} on {{Quantitative Applications}} in the {{Social Sciences}}, 07-136},
  publisher = {{Sage}},
  location = {{Thousand Oaks CA}},
  citeulike-article-id = {13265694},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {missing-data,multiple-imputation}
}

@article{alo16tut,
  title = {Tutorial on Statistical Considerations on Subgroup Analysis in Confirmatory Clinical Trials},
  author = {Alosh, Mohamed and Huque, Mohammad F. and Bretz, Frank and D'Agostino, Ralph B.},
  date = {2017-04},
  journaltitle = {Stat Med},
  volume = {36},
  number = {8},
  pages = {1334--1360},
  issn = {02776715},
  doi = {10.1002/sim.7167},
  url = {http://dx.doi.org/10.1002/sim.7167},
  citeulike-article-id = {14219611},
  citeulike-attachment-1 = {alo16tut.pdf; /pdf/user/harrelfe/article/14219611/1093601/alo16tut.pdf; f48f4dd7a933d48941428e88b2d104178c0d08be},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7167},
  day = {15},
  posted-at = {2016-12-04 13:30:06},
  priority = {2},
  keywords = {rct,subgroup-analysis,tutorial}
}

@article{alr07cas,
  title = {Case Complexity Scores in Congenital Heart Surgery: {{A}} Comparative Study of the {{Aristotal Basic Complexity}} Score and the {{Risk Adjustment}} in {{Congenital Heart Surgery}} ({{RACHS-1}}) System},
  author = {Al-Radi, Osman O. and Harrell, Frank E. and Caldarone, Christopher A. and McCrindle, Brian W. and Jacobs, Jeffrep P. and Williams, M. Gail and Van Arsdell, Glen S. and Williams, William G.},
  date = {2007},
  journaltitle = {J Thorac Cardiovasc Surg},
  volume = {133},
  pages = {865--874},
  citeulike-article-id = {13265566},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {adequacy-index,clinical-prediction-rule},
  note = {use of probability of more concordance and likelihood ratio χ² for testing differences in discrimination;adequacy index shown with nice charts, adjusted and unadjusted for background variables}
}

@article{alt00wha,
  title = {What Do We Mean by Validating a Prognostic Model?},
  author = {Altman, Douglas G. and Royston, Patrick},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {453--473},
  citeulike-article-id = {13265116},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {model-validation},
  note = {simple separation index;examples of validation of multiple clinical models;validation criteria}
}

@article{alt02how,
  title = {How Statistical Expertise Is Used in Medical Research},
  author = {Altman, Douglas G. and Goodman, Steven N. and Schroter, Sara},
  date = {2002},
  journaltitle = {JAMA},
  volume = {287},
  pages = {2817--2820},
  citeulike-article-id = {13265291},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {general,teaching-mds},
  note = {"Statistical input to medical research is widely recommended but inconsistently obtained. Individuals providing such expertise are often not involved until the analysis of data and many go unrecognized by either authorship or acknowledgement."; no association between authorship by methodologist and whether methodologist was paid for her contribution; research without assistance by methodologist had a greater chance of being rejected by the editor (0.71 vs 0.57) and possibly a lower chance of being accepted for publication (0.07 vs 0.11); epidemiologists more likely to be co-authors than biostatisticians;analysis presented of what stage methodologists first got involved with the research}
}

@article{alt04ven,
  title = {Ventilation Imaging of the Lung: Comparison of Hyperpolarized Helium-3 {{MR}} Imaging with {{Xe-133}} Scintigraphy.},
  author = {Altes, T. A. and Rehm, P. K. and Harrell, F. and Salerno, M. and Daniel, T. M. and De Lange, E. E.},
  date = {2004},
  journaltitle = {Acad Rad},
  volume = {11},
  number = {7},
  pages = {729--34},
  url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks&dbfrom=pubmed&retmode=ref&id=15217589},
  citeulike-article-id = {13265383},
  citeulike-linkout-0 = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks&#38;dbfrom=pubmed&#38;retmode=ref&#38;id=15217589},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{alt18res,
  title = {Response to "{{Why}} All Randomized Controlled Trials Produce Biased Results"},
  author = {Althouse, Andrew D. and Abebe, Kaleab Z. and Collins, Gary S. and Harrell, Frank E.},
  date = {2018-11},
  journaltitle = {Ann Med},
  volume = {50},
  number = {7},
  eprint = {30122065},
  eprinttype = {pmid},
  pages = {545--548},
  issn = {1365-2060},
  doi = {10.1080/07853890.2018.1514529},
  langid = {english},
  keywords = {ltte}
}

@article{alt21rec,
  title = {Recommendations for {{Statistical Reporting}} in {{Cardiovascular Medicine}}: {{A Special Report From}} the {{American Heart Association}}},
  shorttitle = {Recommendations for {{Statistical Reporting}} in {{Cardiovascular Medicine}}},
  author = {Althouse, Andrew D. and Below, Jennifer E. and Claggett, Brian L. and Cox, Nancy J. and de Lemos, James A. and Deo, Rahul C. and Duval, Sue and Hachamovitch, Rory and Kaul, Sanjay and Keith, Scott W. and Secemsky, Eric and Teixeira-Pinto, Armando and Roger, Veronique L. and {null}, null},
  options = {useprefix=true},
  date = {2021-07-27},
  journaltitle = {Circulation},
  volume = {144},
  number = {4},
  pages = {e70-e91},
  doi = {10.1161/CIRCULATIONAHA.121.055393},
  url = {https://www.ahajournals.org/doi/10.1161/CIRCULATIONAHA.121.055393},
  urldate = {2022-01-11},
  abstract = {Statistical analyses are a crucial component of the biomedical research process and are necessary to draw inferences from biomedical research data. The application of sound statistical methodology is a prerequisite for publication in the American Heart Association (AHA) journal portfolio. The objective of this document is to summarize key aspects of statistical reporting that might be most relevant to the authors, reviewers, and readership of AHA journals. The AHA Scientific Publication Committee convened a task force to inventory existing statistical standards for publication in biomedical journals and to identify approaches suitable for the AHA journal portfolio. The experts on the task force were selected by the AHA Scientific Publication Committee, who identified 12 key topics that serve as the section headers for this document. For each topic, the members of the writing group identified relevant references and evaluated them as a resource to make the standards summarized herein. Each section was independently reviewed by an expert reviewer who was not part of the task force. Expert reviewers were also permitted to comment on other sections if they chose. Differences of opinion were adjudicated by consensus. The standards presented in this report are intended to serve as a guide for high-quality reporting of statistical analyses methods and results.},
  keywords = {bayes,guidelines,reporting,reporting-statistical-results,teaching-mds}
}

@article{alt70the,
  title = {Theory for the Measurement of Competing Risks in Animal Experiments},
  author = {Altschuler, B.},
  date = {1970},
  journaltitle = {Math Biosci},
  volume = {6},
  pages = {1--11},
  citeulike-article-id = {13263687},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@article{alt86not,
  title = {A Note on the Uncertainty of a Survival Probability Estimated from {{Cox}}'s Regression Model},
  author = {Altman, Douglas G. and Andersen, Per K.},
  date = {1986},
  journaltitle = {Biometrika},
  volume = {73},
  pages = {722--724},
  citeulike-article-id = {13263688},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  note = {approximation to variance of estimated survival probabilities from Cox model}
}

@article{alt89,
  title = {Bootstrap Investigation of the Stability of a {{Cox}} Regression Model},
  author = {Altman, D. G. and Andersen, P. K.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {771--783},
  citeulike-article-id = {13263689},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {model-uncertainty,validation}
}

@article{alt90ran,
  title = {Randomization and Baseline Comparison in Clinical Trials},
  author = {Altman, D. G. and Doré, C. J.},
  date = {1990},
  journaltitle = {Lancet},
  volume = {335},
  pages = {149--153},
  citeulike-article-id = {13263690},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {baseline-imbalance,rct}
}

@article{alt91cat,
  title = {Categorising Continuous Covariates (Letter to the Editor)},
  author = {Altman, D. G.},
  date = {1991},
  journaltitle = {Brit J Cancer},
  volume = {64},
  pages = {975},
  citeulike-article-id = {13263691},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {cutpoints,dichotomizing-continuous-variables,teaching-mds}
}

@article{alt94dan,
  title = {Dangers of Using `optimal' Cutpoints in the Evaluation of Prognostic Factors},
  author = {Altman, D. G. and Lausen, B. and Sauerbrei, W. and Schumacher, M.},
  date = {1994},
  journaltitle = {J Nat Cancer Inst},
  volume = {86},
  pages = {829--835},
  citeulike-article-id = {13263692},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {cutpoints,dichotomizing-continuous-variables,teaching-mds}
}

@article{alt94pra,
  title = {Practical Problems in Fitting a Proportional Hazards Model to Data with Updated Measurements of the Covariates},
  author = {Altman, Douglas G. and De Stavola, Bianca L.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {301--341},
  citeulike-article-id = {13263693},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {cox-model,statistical-software,tdc}
}

@article{alt95abs,
  title = {Absence of Evidence Is Not Evidence of Absence},
  author = {Altman, D. G. and Bland, J. M.},
  date = {1995},
  journaltitle = {BMJ},
  volume = {311},
  pages = {485},
  citeulike-article-id = {13263694},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {interpretation-of-negative-or-nonsignificant-findings,statistical-significance,teaching-mds}
}

@article{alt95rev,
  title = {Review of Survival Analyses Published in Cancer Journals},
  author = {Altman, D. G. and De Stavola, B. L. and Love, S. B. and Stepniewska, K. A.},
  date = {1995},
  journaltitle = {Brit J Cancer},
  volume = {72},
  pages = {511--518},
  citeulike-article-id = {13263695},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {reporting,reporting-statistical-results,survival-analysis,teaching-mds}
}

@article{alt98sub,
  title = {Suboptimal Analysis Using `optimal' Cutpoints},
  author = {Altman, Douglas G.},
  date = {1998},
  journaltitle = {Brit J Cancer},
  volume = {78},
  pages = {556--557},
  citeulike-article-id = {13265377},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {categorization,cutpoints,dichotomizing-continuous-variables,teaching-mds}
}

@article{alz06int,
  title = {An {{Introduction}} to {{S}} and the {{Hmisc}} and {{Design Libraries}}},
  author = {Alzola, Carlos F. and Harrell, Frank E.},
  date = {2006},
  url = {https://hbiostat.org/R/doc/sintro.pdf}
}

@article{amb02sel,
  title = {Selection Bias in Gene Extraction on the Basis of Microarray Gene-Expression Data},
  author = {Ambroise, Christophe and McLachlan, Geoffrey J.},
  date = {2002-05},
  journaltitle = {PNASs},
  volume = {99},
  number = {10},
  eprint = {11983868},
  eprinttype = {pmid},
  pages = {6562--6566},
  publisher = {National Academy of Sciences},
  location = {Laboratoire Heudiasyc, Unité Mixte de Recherche/Centre National de la Recherche Scientifique 6599, 60200 Compiègne, France.},
  issn = {1091-6490},
  doi = {10.1073/pnas.102102699},
  url = {http://dx.doi.org/10.1073/pnas.102102699},
  abstract = {In the context of cancer diagnosis and treatment, we consider the problem of constructing an accurate prediction rule on the basis of a relatively small number of tumor tissue samples of known type containing the expression data on very many (possibly thousands) genes. Recently, results have been presented in the literature suggesting that it is possible to construct a prediction rule from only a few genes such that it has a negligible prediction error rate. However, in these results the test error or the leave-one-out cross-validated error is calculated without allowance for the selection bias. There is no allowance because the rule is either tested on tissue samples that were used in the first instance to select the genes being used in the rule or because the cross-validation of the rule is not external to the selection process; that is, gene selection is not performed in training the rule at each stage of the cross-validation process. We describe how in practice the selection bias can be assessed and corrected for by either performing a cross-validation or applying the bootstrap external to the selection process. We recommend using 10-fold rather than leave-one-out cross-validation, and concerning the bootstrap, we suggest using the so-called .632+ bootstrap error estimate designed to handle overfitted prediction rules. Using two published data sets, we demonstrate that when correction is made for the selection bias, the cross-validated error is no longer zero for a subset of only a few genes.},
  citeulike-article-id = {118632},
  citeulike-attachment-1 = {amb02sel.pdf; /pdf/user/harrelfe/article/118632/1010488/amb02sel.pdf; 9c2bec7994fe1cb65e8fa8c84ede0b3f5ab36149},
  citeulike-linkout-0 = {http://dx.doi.org/10.1073/pnas.102102699},
  citeulike-linkout-1 = {http://www.pnas.org/content/99/10/6562.abstract},
  citeulike-linkout-2 = {http://www.pnas.org/content/99/10/6562.full.pdf},
  citeulike-linkout-3 = {http://www.pnas.org/cgi/content/abstract/99/10/6562},
  citeulike-linkout-4 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC124442/},
  citeulike-linkout-5 = {http://view.ncbi.nlm.nih.gov/pubmed/11983868},
  citeulike-linkout-6 = {http://www.hubmed.org/display.cgi?uids=11983868},
  day = {14},
  pmcid = {PMC124442},
  posted-at = {2015-03-22 18:50:36},
  priority = {2},
  keywords = {bad-biomarker-research,bad-science,bad-statistics,model-uncertainty,selection-bias,univariable-screening},
  note = {Relied on an improper accuracy score (proportion classified correct) so had to use the .632 bootstrap unnecessarily}
}

@article{amb02sim,
  title = {Simplifying a Prognostic Model: A Simulation Study Based on Clinical Data.},
  author = {Ambler, Gareth and Brady, Anthony R. and Royston, Patrick},
  date = {2002-12},
  journaltitle = {Stat Med},
  volume = {21},
  number = {24},
  eprint = {12483768},
  eprinttype = {pmid},
  pages = {3803--3822},
  publisher = {John Wiley & Sons, Ltd.},
  issn = {0277-6715},
  doi = {10.1002/sim.1422},
  url = {http://dx.doi.org/10.1002/sim.1422},
  abstract = {Prognostic models are designed to predict a clinical outcome in individuals or groups of individuals with a particular disease or condition. To avoid bias many researchers advocate the use of full models developed by prespecifying predictors. Variable selection is not employed and the resulting models may be large and complicated. In practice more parsimonious models that retain most of the prognostic information may be preferred. We investigate the effect on various performance measures, including mean square error and prognostic classification, of three methods for estimating full models (including penalized estimation and Tibshirani's lasso) and consider two methods (backwards elimination and a new proposal called stepdown) for simplifying full models. Simulation studies based on two medical data sets suggest that simplified models can be found that perform nearly as well as, or sometimes even better than, full models. Optimizing the Akaike information criterion appears to be appropriate for choosing the degree of simplification.},
  citeulike-article-id = {9055286},
  citeulike-attachment-1 = {ambler₀2ₛimplifying₉76387.pdf; /pdf/user/harrelfe/article/9055286/976387/ambler₀2ₛimplifying₉76387.pdf; 4d9bbbb6bbc0da404250b95dced4af9c52c31c60},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.1422},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/12483768},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=12483768},
  day = {30},
  posted-at = {2014-07-19 15:11:24},
  priority = {0},
  keywords = {aic,model-approximation,model-simplification,penalization,pre-conditioning,prognosis,roc,variable-selection},
  note = {ordinary backward stepdown worked well when there was a large fraction of truly irrelevant predictors}
}

@article{amb08est,
  title = {Estimates of Clinically Useful Measures in Competing Risks Survival Analysis},
  author = {Ambrogi, Federico and Biganzoli, Elia and Boracchi, Patrizia},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {6407--6425},
  citeulike-article-id = {13265762},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {clinically-useful-measures,competing-risks,generalized-estimating-equations,gethdata,prostate-cancer-dataset,pseudo-values,transformation-model}
}

@article{ami08gra,
  title = {Graphical Approaches to the Analysis of Safety Data from Clinical Trials},
  author = {Amit, Ohad and Heiberger, Richard M. and Lane, Peter W.},
  date = {2008},
  journaltitle = {Pharm Stat},
  volume = {7},
  pages = {20--35},
  url = {http://www3.interscience.wiley.com/journal/114129388/abstract},
  citeulike-article-id = {13265689},
  citeulike-linkout-0 = {http://www3.interscience.wiley.com/journal/114129388/abstract},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {adverse-events,aes,graphics,pharmaceutical-safety}
}

@book{amvotes,
  title = {America {{Votes}} 20: {{A Handbook}} of {{Contemporary American Election Statistics}}},
  editor = {Scammon, Richard M. and McGillivray, Alice V. and Cook, Rhodes},
  date = {1992},
  publisher = {{Congressional Quarterly}},
  location = {{Washington, DC}},
  citeulike-article-id = {13265165},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  annotation = {ISBN 0-87187-558-6. Hardbound.\$155.00}
}

@article{and20ana,
  title = {Analysis of Time-to-Event for Observational Studies: {{Guidance}} to the Use of Intensity Models},
  shorttitle = {Analysis of Time-to-Event for Observational Studies},
  author = {Andersen, Per Kragh and Perme, Maja Pohar and van Houwelingen, Hans C. and Cook, Richard J. and Joly, Pierre and Martinussen, Torben and Taylor, Jeremy M. G. and Abrahamowicz, Michal and Therneau, Terry M.},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8757},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8757},
  urldate = {2020-10-12},
  abstract = {This paper provides guidance for researchers with some mathematical background on the conduct of time-to-event analysis in observational studies based on intensity (hazard) models. Discussions of basic concepts like time axis, event definition and censoring are given. Hazard models are introduced, with special emphasis on the Cox proportional hazards regression model. We provide check lists that may be useful both when fitting the model and assessing its goodness of fit and when interpreting the results. Special attention is paid to how to avoid problems with immortal time bias by introducing time-dependent covariates. We discuss prediction based on hazard models and difficulties when attempting to draw proper causal conclusions from such models. Finally, we present a series of examples where the methods and check lists are exemplified. Computational details and implementation using the freely available R software are documented in Supplementary Material. The paper was prepared as part of the STRATOS initiative.},
  langid = {english},
  keywords = {observational-study,survival,tdc,teaching,teaching-mds},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8757}
}

@article{and81reg,
  title = {Regression, Discrimination and Measurement Models for Ordered Categorical Variables},
  author = {Anderson, J. A. and Philips, P. R.},
  date = {1981},
  journaltitle = {Appl Stat},
  volume = {30},
  pages = {22--31},
  citeulike-article-id = {13263697},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {measurement-scale,ordinal-logistic-model,ordinal-response}
}

@article{and82cox,
  title = {Cox's Regression Model for Counting Processes: {{A}} Large Sample Study},
  author = {Andersen, P. K. and Gill, R. D.},
  date = {1982},
  journaltitle = {Ann Stat},
  volume = {10},
  pages = {1100--1120},
  citeulike-article-id = {13263698},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@article{and82two,
  title = {A Two-Step Regression Model for Hazard Functions},
  author = {Anderson, J. A. and Senthilselvan, A.},
  date = {1982},
  journaltitle = {Appl Stat},
  volume = {31},
  pages = {44--51},
  citeulike-article-id = {13263699},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@article{and84reg,
  title = {Regression and Ordered Categorical Variables},
  author = {Anderson, J. A.},
  date = {1984},
  journaltitle = {J Roy Stat Soc B},
  volume = {46},
  pages = {1--30},
  citeulike-article-id = {13263700},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {extensions-to-ordinal-logistic-model,ordinal-logistic-model,ordinal-response}
}

@article{and87con,
  title = {Conditional Power Calculations as an Aid in the Decision Whether to Continue a Clinical Trial},
  author = {Andersen, Per K.},
  date = {1987},
  journaltitle = {Controlled Clin Trials},
  volume = {8},
  pages = {67--74},
  citeulike-article-id = {13265657},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {censored-survival-data,conditional-confidence-intervals,conditional-power,rct,stochastic-curtailment}
}

@article{and95mod,
  title = {Model Misspecification in Proportional Hazards Regression},
  author = {Anderson, Garnet L. and Fleming, Thomas R.},
  date = {1995},
  journaltitle = {Biometrika},
  volume = {82},
  pages = {527--541},
  citeulike-article-id = {13263701},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {covariate-adjustment,model-identification,model-misspecification,rct,treatment-effects-in-cox-model,unadjusted-estimates}
}

@article{and99tes,
  title = {Testing for Centre Effects in Multi-Centre Survival Studies: {{A}} Monte Carlo Comparison of Fixed and Random Effects Tests},
  author = {Andersen, Per K. and Klein, John P. and Zhang, Mei-Jie},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1489--1500},
  citeulike-article-id = {13263702},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {center-effects,fixed-vs-random-effects,frailty-model,ignoring-center-effects-biases-treatment-effect,multi-center-rct,see-sar96hie}
}

@article{ang95two,
  title = {Two-Stage Least Squares Estimation of Average Causal Effects in Models with Variable Treatment Intensity},
  author = {Angrist, Joshua D. and Imbens, Guido W.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {431--442},
  citeulike-article-id = {13263703},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {causal-inference,instrumental-variables,propensity-score,two-stage-models}
}

@article{ano19app,
  title = {Approaches to Treatment Effect Heterogeneity in the Presence of Confounding},
  author = {Anoke, Sarah C. and Normand, Sharon-Lise and Zigler, Corwin M.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8143},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8143},
  urldate = {2019-04-01},
  abstract = {The literature on causal effect estimation tends to focus on the population mean estimand, which is less informative as medical treatments are becoming more personalized and there is increasing awareness that subpopulations of individuals may experience a group-specific effect that differs from the population average. In fact, it is possible that there is underlying systematic effect heterogeneity that is obscured by focusing on the population mean estimand. In this context, understanding which covariates contribute to this treatment effect heterogeneity (TEH) and how these covariates determine the differential treatment effect (TE) is an important consideration. Towards such an understanding, this paper briefly reviews three approaches used in making causal inferences and conducts a simulation study to compare these approaches according to their performance in an exploratory evaluation of TEH when the heterogeneous subgroups are not known a priori. Performance metrics include the detection of any heterogeneity, the identification and characterization of heterogeneous subgroups, and unconfounded estimation of the TE within subgroups. The methods are then deployed in a comparative effectiveness evaluation of drug-eluting versus bare-metal stents among 54 099 Medicare beneficiaries in the continental United States admitted to a hospital with acute myocardial infarction in 2008.},
  langid = {english},
  keywords = {hte}
}

@article{ans73gra,
  title = {Graphs in Statistical Analysis},
  author = {Anscombe, F. J.},
  date = {1973},
  journaltitle = {Am Statistician},
  volume = {27},
  pages = {17--21},
  citeulike-article-id = {13263704},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {graphics,teaching-mds}
}

@article{ant04inf,
  title = {Inference on Correlated Discrimination Measures in Survival Analysis: A Nonparametric Approach},
  author = {Antolini, L. and Nam, B. H. and D'Agostino, R. B.},
  date = {2004},
  journaltitle = {Comm Stat Th Meth},
  volume = {33},
  pages = {2117--2136},
  citeulike-article-id = {13265425},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  note = {used U-statistic theory to get a variance estimate for the C index;not clear if assumed no early censoring}
}

@article{ant05tim,
  title = {A Time-Dependent Discrimination Index for Survival Data},
  author = {Antolini, Laura and Boracchi, Patrizia and Biganzoli, Elia},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {3927--3944},
  citeulike-article-id = {13265455},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {c-index,discrimination,nonparametric,predictive-accuracy,roc,tdc}
}

@article{ant10com,
  title = {Compound Optimal Allocation for Individual and Collective Ethics in Binary Clinical Trials},
  author = {Antognini, Alessandro B. and Giovagnoli, Alessandra},
  date = {2010},
  journaltitle = {Biometrika},
  volume = {97},
  number = {4},
  pages = {935--946},
  citeulike-article-id = {13265869},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {collective-ethics,individual-ethics,rct}
}

@article{ant11cov,
  title = {The Covariate-Adaptive Biased Coin Design for Balancing Clinical Trials in the Presence of Prognostic Factors},
  author = {Baldi Antognini, A. and Zagoraiou, M.},
  date = {2011},
  journaltitle = {Biometrika},
  volume = {98},
  number = {3},
  eprint = {http://biomet.oxfordjournals.org/content/98/3/519.full.pdf+html},
  pages = {519--535},
  doi = {10.1093/biomet/asr021},
  url = {http://biomet.oxfordjournals.org/content/98/3/519.abstract},
  abstract = {The present paper deals with sequential designs intended to balance the allocations of two competing treatments in the presence of prognostic factors. After giving a theoretical framework on the optimality of balanced designs that can arise when covariates are taken into account, we propose a new family of covariate-adaptive randomized designs that represents higher order approximation to balance treatments, both globally and also across covariates. We derive the theoretical properties of the suggested designs in terms of loss of precision and predictability. The performance of this proposal is illustrated through a simulation study and compared with those of other procedures suggested in the literature.},
  citeulike-article-id = {13265895},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/asr021},
  citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/98/3/519.abstract},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {balance,covariate-adaptive-design,efrons-biased-coin,stratified-randomization}
}

@article{ara19use,
  title = {The Use of Weight Adjusted for Height Rather than Body Mass Index to Assess Growth Trajectory: {{Results}} from a Population-Based Cohort},
  shorttitle = {The Use of Weight Adjusted for Height Rather than Body Mass Index to Assess Growth Trajectory},
  author = {Araújo, Joana and Ramos, Elisabete and Mishra, Gita D. and Severo, Milton},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {5},
  pages = {855--865},
  issn = {1097-0258},
  doi = {10.1002/sim.8007},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8007},
  urldate = {2019-02-15},
  abstract = {We compared different growth models parameterizations regarding (i) adjustment of weight-for-height, as denoted by body mass index (BMI); (ii) adjustment for different covariates, ie, age or height; and (iii) the use of different smoothing methods, ie, polynomial, fractional polynomial, or linear splines. A total of 11 459 measurements of weight and height from 719 participants were used, obtained from the EPITeen cohort at 13, 17, and 21 years, and extracted from child health books. The individual growth curves were modeled using mixed-effects polynomial, fractional polynomial, and linear splines, and each model parameterization included as covariate age or height. The goodness-of-fit of the model parametrizations was compared using the relative squared error (RSE) and the relative absolute error (RAE). The adjustment of weight-for-height as denoted by BMI was found to be biased, especially for extreme values of height and presented the worst fit indexes from all model parameterizations tested (RSE = 12.46\%; RAE = 22.63\%). Regardless of the smoothing method, the weight-for-height retrieved the best fit indexes in comparison to the adjustment for age. With regard to the smoothing methods and comparing weight-for-height model parameterizations, the fractional polynomial model performed better (RSE = 0.75\%; RAE = 5.70\%), followed by linear splines (RSE = 0.77\%; RAE = 5.82\%), and conventional polynomial (RSE = 0.91\%; RAE = 6.82\%). Therefore, growth modeling in pediatric age should be based on the modeling of weight-for-height because the use of BMI leaves residual confounding for height. Regarding the smoothing methods, although differences were relatively small, the fractional polynomials performed better in comparison to conventional polynomials and linear splines.},
  langid = {english},
  keywords = {bmi,measurement}
}

@article{arc20min,
  title = {Minimum Sample Size for External Validation of a Clinical Prediction Model with a Continuous Outcome},
  author = {Archer, Lucinda and Snell, Kym I. E. and Ensor, Joie and Hudda, Mohammed T. and Collins, Gary S. and Riley, Richard D.},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8766},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8766},
  urldate = {2020-11-06},
  abstract = {Clinical prediction models provide individualized outcome predictions to inform patient counseling and clinical decision making. External validation is the process of examining a prediction model's performance in data independent to that used for model development. Current external validation studies often suffer from small sample sizes, and subsequently imprecise estimates of a model's predictive performance. To address this, we propose how to determine the minimum sample size needed for external validation of a clinical prediction model with a continuous outcome. Four criteria are proposed, that target precise estimates of (i) R2 (the proportion of variance explained), (ii) calibration-in-the-large (agreement between predicted and observed outcome values on average), (iii) calibration slope (agreement between predicted and observed values across the range of predicted values), and (iv) the variance of observed outcome values. Closed-form sample size solutions are derived for each criterion, which require the user to specify anticipated values of the model's performance (in particular R2) and the outcome variance in the external validation dataset. A sensible starting point is to base values on those for the model development study, as obtained from the publication or study authors. The largest sample size required to meet all four criteria is the recommended minimum sample size needed in the external validation dataset. The calculations can also be applied to estimate expected precision when an existing dataset with a fixed sample size is available, to help gauge if it is adequate. We illustrate the proposed methods on a case-study predicting fat-free mass in children.},
  langid = {english},
  keywords = {sample-size,validation},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8766}
}

@article{arj88,
  title = {A Graphical Method for Assessing Goodness of Fit in {{Cox}}'s Proportional Hazards Model},
  author = {Arjas, E.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {204--212},
  citeulike-article-id = {13263705},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {cox-model-graphical-methods,testing-proportional-hazards}
}

@article{arj96non,
  title = {Non-Parametric {{Bayesian}} Approach to Hazard Regression: {{A}} Case Study with a Large Number of Missing Covariate Values},
  author = {Arjas, Elja and Liu, Liping},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1757--1770},
  citeulike-article-id = {13263706},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {bayesian-inference,missing-covariables,non-parametric-hazard-function-estimation,non-ph}
}

@article{ark95cov,
  title = {The Covariance Decomposition of the Probability Score and Its Use in Evaluating Prognostic Estimates},
  author = {Arkes, H. R. and Dawson, N. V. and Speroff, T. and Harrell, F. E. and Alzola, C. and Phillips, R. and Desbiens, N. and Oye, R. K. and Knaus, W. and Connors, A. F. and Investigators, The S.},
  date = {1995},
  journaltitle = {Med Decis Mak},
  volume = {15},
  pages = {120--131},
  citeulike-article-id = {13263707},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@book{arm71,
  title = {Statistical {{Methods}} in {{Medical Research}}},
  author = {Armitage, P.},
  date = {1971},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13263708},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@book{arm87,
  title = {Statistical {{Methods}} in {{Medical Research}}},
  author = {Armitage, P. and Berry, G.},
  date = {1987},
  edition = {Second},
  publisher = {{Blackwell}},
  location = {{Oxford}},
  citeulike-article-id = {13263710},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {measurement}
}

@article{arm89,
  title = {Ordinal Regression Models for Epidemiologic Data},
  author = {Armstrong, B. G. and Sloan, M.},
  date = {1989},
  journaltitle = {Am J Epi},
  volume = {129},
  pages = {191--204},
  citeulike-article-id = {13263709},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {logistic-ordinal-model},
  annotation = {See letter to editor by Peterson}
}

@article{arn15dev,
  title = {Development and Internal Validation of a Pediatric Acute Asthma Prediction Rule for Hospitalization.},
  author = {Arnold, Donald H. and Gebretsadik, Tebeb and Moons, Karel G. and Harrell, Frank E. and Hartert, Tina V.},
  date = {2015},
  journaltitle = {J Allergy Clin Immun},
  volume = {3},
  number = {2},
  eprint = {25609324},
  eprinttype = {pmid},
  pages = {228--235},
  issn = {2213-2201},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25609324},
  abstract = {Clinicians have difficulty predicting need for hospitalization of children with acute asthma exacerbations. The objective of this study was to develop and internally validate a multivariable asthma prediction rule (APR) to inform hospitalization decision making in children aged 5-17 years with acute asthma exacerbations. Between April 2008 and February 2013 we enrolled a prospective cohort of patients aged 5-17 years with asthma who presented to our pediatric emergency department with acute exacerbations. Predictors for APR modeling included 15 demographic characteristics, asthma chronic control measures, and pulmonary examination findings in participants at the time of triage and before treatment. The primary outcome variable for APR modeling was need for hospitalization (length of stay {$>$}24 h for those admitted to hospital or relapse for those discharged). A secondary outcome was the hospitalization decision of the clinical team. We used penalized maximum likelihood multiple logistic regression modeling to examine the adjusted association of each predictor variable with the outcome. Backward step-down variable selection techniques were used to yield reduced-form models. Data from 928 of 933 participants were used for prediction rule modeling, with median [interquartile range] age 8.8 [6.9, 11.2] years, 61\% male, and 59\% African-American race. Both full (penalized) and reduced-form models for each outcome calibrated well, with bootstrap-corrected c-indices of 0.74 and 0.73 for need for hospitalization and 0.81 in each case for hospitalization decision. The APR predicts the need for hospitalization of children with acute asthma exacerbations using predictor variables available at the time of presentation to an emergency department. Copyright  2014 American Academy of Allergy, Asthma \& Immunology. Published by Elsevier Inc. All rights reserved.},
  citeulike-article-id = {14102492},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25609324},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25609324},
  posted-at = {2016-07-26 21:20:43},
  priority = {2},
  keywords = {clinical-prediction,collaboration}
}

@article{aro15vit,
  title = {Vitamin {{D}} Therapy in Individuals with Prehypertension or Hypertension: The {{DAYLIGHT}} Trial.},
  author = {Arora, Pankaj and Song, Yanna and Dusek, Jeffery and Plotnikoff, Gregory and Sabatine, Marc S. and Cheng, Susan and Valcour, Andre and Swales, Heather and Taylor, Beth and Carney, Erin and Guanaga, Derek and Young, Joseph R. and Karol, Courtney and Torre, Michael and Azzahir, Atum and Strachan, Semerit M. and O'Neill, Dillon C. and Wolf, Myles and Harrell, Frank and Newton-Cheh, Christopher and Wang, Thomas J.},
  date = {2015-01},
  journaltitle = {Circ},
  volume = {131},
  number = {3},
  eprint = {25359163},
  eprinttype = {pmid},
  pages = {254--262},
  issn = {1524-4539},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25359163},
  abstract = {A large body of epidemiological and experimental evidence suggests that vitamin D deficiency may promote hypertension. This raises the possibility that vitamin D supplementation could be a simple intervention to reduce blood pressure, but data from prospective, randomized trials are limited. A double-blind, randomized, controlled trial was conducted at 4 sites in the United States. We enrolled 534 individuals 18 to 50 years of age with low vitamin D status (25-hydroxyvitamin D levels ≤25 ng/mL) and systolic blood pressure of 120 to 159 mm Hg. Participants were randomized to high-dose (4000 IU/d) versus low-dose (400 IU/d) oral vitamin D3 for 6 months. The primary end point was change in mean 24-hour systolic blood pressure. Secondary end points included change in ambulatory diastolic blood pressure and clinic systolic and diastolic blood pressures. The median age was 38 years, and 62\% of participants were men. Forty-six percent of participants were white, and 48\% were black. The median 25-hydroxyvitamin D level at baseline was 15.3 ng/mL. Four-hundred fifty-five participants (85\%) had at least 1 follow-up blood pressure measurement; 383 participants (72\%) completed the full 6-month study. At the end of the study, there was no significant difference in the primary end point (change in mean 24-hour systolic blood pressure, -0.8 versus -1.6 mm Hg in the high-dose and low-dose arms; P=0.71) or in any of the secondary end points. Furthermore, there was no evidence of association between change in 25-hydroxyvitamin D and change in 24-hour systolic blood pressure at 6 months (Spearman correlation coefficient, -0.05, P=0.34). Results were consistent across prespecified subgroups. Vitamin D supplementation did not reduce blood pressure in individuals with prehypertension or stage I hypertension and vitamin D deficiency. Our findings suggest that the association between vitamin D status and elevated blood pressure noted in observational studies is not causal. http://www.clinicaltrials.gov. Unique identifier: NCT01240512.  2014 American Heart Association, Inc.},
  citeulike-article-id = {14102496},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25359163},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25359163},
  day = {20},
  posted-at = {2016-07-26 21:26:27},
  priority = {2},
  keywords = {collaboration,rct}
}

@article{asapval,
  title = {The {{ASA}}'s {{Statement}} on p-{{Values}}: {{Context}}, {{Process}}, and {{Purpose}}},
  author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
  date = {2016-04},
  journaltitle = {Am Statistician},
  volume = {70},
  number = {2},
  pages = {129--133},
  publisher = {Taylor & Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.2016.1154108},
  url = {http://dx.doi.org/10.1080/00031305.2016.1154108},
  citeulike-article-id = {13971481},
  citeulike-attachment-1 = {asapval.pdf; /pdf/user/harrelfe/article/13971481/1090791/asapval.pdf; 5219a3ac9a935cd8b4c81cd6b8df0339cbf12e1e},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00031305.2016.1154108},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/00031305.2016.1154108},
  day = {2},
  posted-at = {2016-11-05 13:09:16},
  priority = {0},
  keywords = {hypothesis-testing,p-values}
}

@article{ash06bay,
  title = {Bayesian Statistics in Medicine: {{A}} 25 Year Review},
  author = {Ashby, Deborah},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {3589--3631},
  citeulike-article-id = {13265537},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {bayesian-methods,multiple-uses-of-bayes,review}
}

@article{ash16ina,
  title = {Inadequacy of 3-Month {{Oswestry Disability Index}} Outcome for Assessing Individual Longer-Term Patient Experience after Lumbar Spine Surgery.},
  author = {Asher, Anthony L. and Chotai, Silky and Devin, Clinton J. and Speroff, Theodore and Harrell, Frank E. and Nian, Hui and Dittus, Robert S. and Mummaneni, Praveen V. and Knightly, John J. and Glassman, Steven D. and Bydon, Mohamad and Archer, Kristin R. and Foley, Kevin T. and McGirt, Matthew J.},
  date = {2016-08},
  journaltitle = {J Neurosurg: Spine},
  volume = {25},
  number = {2},
  eprint = {26989974},
  eprinttype = {pmid},
  pages = {170--180},
  issn = {1547-5646},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26989974},
  abstract = {OBJECTIVE Prospective longitudinal outcomes registries are at the center of evidence-driven health care reform. Obtaining real-world outcomes data at 12 months can be costly and challenging. In the present study, the authors analyzed whether 3-month outcome measurements sufficiently represent 12-month outcomes for patients with degenerative lumbar disease undergoing surgery. METHODS Data from 3073 patients undergoing elective spine surgery for degenerative lumbar disease were entered into a prospective multicenter registry (N(2)QOD). Baseline, 3-month, and 12-month follow-up Oswestry Disability Index (ODI) scores were recorded. The absolute differences between actual 12- and 3-month ODI scores was evaluated. Additionally, the authors analyzed the absolute difference between actual 12-month ODI scores and a model-predicted 12-month ODI score (the model used patients' baseline characteristics and actual 3-month scores). The minimal clinically important difference (MCID) for ODI of 12.8 points and the substantial clinical benefit (SCB) for ODI of 18.8 points were used based on the previously published values. The concordance rate of achieving MCID and SCB for ODI at 3-and 12-months was computed. RESULTS The 3-month ODI scores differed from 12-month scores by an absolute difference of 11.9 ± 10.8, and predictive modeling estimations of 12-month ODI scores differed from actual 12-month scores by a mean (± SD) of 10.7 ± 9.0 points (p = 0.001). Sixty-four percent of patients (n = 1982) achieved an MCID for ODI at 3 months in comparison with 67\% of patients (n = 2088) by 12 months; 51\% (n = 1731) and 61\% (n = 1860) of patients achieved SCB for ODI at 3 months and 12 months, respectively. Almost 20\% of patients had ODI scores that varied at least 20 points (the point span of an ODI functional category) between actual 3- and 12-month values. In the aggregate analysis of achieving MCID, 77\% of patients were concordant and 23\% were discordant in achieving or not achieving MCID at 3 and 12 months. The discordance rates of achieving or not achieving MCID for ODI were in the range of 19\% to 27\% for all diagnoses and treatments (decompression with and without fusion). The positive and negative predictive value of 3-months ODI to predict 12-month ODI was 86\% and 60\% for MCID and 82\% and 67\% for SCB. CONCLUSIONS Based on their findings, the authors conclude the following: 1) Predictive methods for functional outcome based on early patient experience (i.e., baseline and/or 3-month data) should be used to help evaluate the effectiveness of procedures in patient populations, rather than serving as a proxy for long-term individual patient experience. 2) Prospective longitudinal registries need to span at least 12 months to determine the effectiveness of spine care at the individual patient and practitioner level.},
  citeulike-article-id = {14229679},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26989974},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26989974},
  posted-at = {2016-12-18 16:48:36},
  priority = {2},
  keywords = {qod}
}

@article{ash16pre,
  title = {Predictive {{Model}} for {{Return}} to {{Work After Elective Surgery}} for {{Lumbar Degenerative Disease}}: {{An Analysis From National Neurosurgery Quality Outcomes Database Registry}}.},
  author = {Asher, Anthony L. and Chotai, Silky and Devin, Clinton J. and Archer-Swygert, Kristen and Parker, Scott L. and Bydon, Mohamad and Hui, Nian and Harrell, Frank and Speroff, Theodore and Dittus, Robert and Philips, Sharon and Shaffrey, Christopher I. and Foley, Kevin T. and McGirt, Matthew J. and {N2QOD Investigator Group}},
  date = {2016-08},
  journaltitle = {Neurosurgery},
  volume = {63 Suppl 1},
  eprint = {27399427},
  eprinttype = {pmid},
  issn = {1524-4040},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/27399427},
  abstract = {The current costs associated with spine care are unsustainable. The productivity loss and time away from work in gainfully employed patients contributes greatly to the financial burden. Therefore, it is vital to identify the factors associated with returning to work after lumbar spine surgery. We present a predictive model of ability to return to work (RTW) after lumbar spine surgery for degenerative spine disease. Total 4694 patients undergoing elective spine surgery for degenerative lumbar disease who were employed were entered into a prospective multicenter registry (N2QOD). Baseline and 3-month postoperative patient-reported outcomes: Oswestry Disability Index (ODI), EQ-5D, NRS back and leg pain were recorded. The time to RTW was defined as the period between operation time and date of returning to work. A multivariable Cox proportional hazards regression model, including an array of preoperative factors, was fitted for RTW. The model performance was measured by the c-index. Eighty-two percent of patients (n = 3855) returned to work within 3 -months postoperatively. The risk-adjusted predictors of lower likelihood of RTW were preoperatively employed but not working at the time of presentation, those occupied with manual labor, on worker's compensation, on liability insurance, baseline ODI and NRS-BP scores, female sex, African American race, history of diabetes mellitus, and higher ASA grades. The likelihood of RTW within 3 months was higher in patients with higher education level compared with those with less than high school level education. The c-index of our model performance was 0.71. We present a novel predictive model for probability of RTW after lumbar spine surgery. Spine care providers can use this model to educate patients and encourage them in shared decision making regarding the RTW outcome. This will result in better communication between patients and clinicians and improve recovery expectations, which will ultimately increase the likelihood of a positive RTW trajectory.},
  citeulike-article-id = {14105713},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/27399427},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=27399427},
  posted-at = {2016-08-01 15:48:40},
  priority = {2},
  keywords = {qod}
}

@article{ash17ana,
  title = {An Analysis from the {{Quality Outcomes Database}}, {{Part}} 2. {{Predictive}} Model for Return to Work after Elective Surgery for Lumbar Degenerative Disease},
  author = {Asher, Anthony L. and Devin, Clinton J. and Archer, Kristin R. and Chotai, Silky and Parker, Scott L. and Bydon, Mohamad and Nian, Hui and Harrell, Frank E. and Speroff, Theodore and Dittus, Robert S. and Philips, Sharon E. and Shaffrey, Christopher I. and Foley, Kevin T. and McGirt, Matthew J.},
  date = {2017-10},
  journaltitle = {J Neurosurg Spine},
  volume = {27},
  number = {4},
  eprint = {28498069},
  eprinttype = {pmid},
  pages = {370--381},
  issn = {1547-5646},
  doi = {10.3171/2016.8.SPINE16527},
  abstract = {OBJECTIVE Current costs associated with spine care are unsustainable. Productivity loss and time away from work for patients who were once gainfully employed contributes greatly to the financial burden experienced by individuals and, more broadly, society. Therefore, it is vital to identify the factors associated with return to work (RTW) after lumbar spine surgery. In this analysis, the authors used data from a national prospective outcomes registry to create a predictive model of patients' ability to RTW after undergoing lumbar spine surgery for degenerative spine disease. METHODS Data from 4694 patients who underwent elective spine surgery for degenerative lumbar disease, who had been employed preoperatively, and who had completed a 3-month follow-up evaluation, were entered into a prospective, multicenter registry. Patient-reported outcomes-Oswestry Disability Index (ODI), numeric rating scale (NRS) for back pain (BP) and leg pain (LP), and EQ-5D scores-were recorded at baseline and at 3 months postoperatively. The time to RTW was defined as the period between operation and date of returning to work. A multivariable Cox proportional hazards regression model, including an array of preoperative factors, was fitted for RTW. The model performance was measured using the concordance index (c-index). RESULTS Eighty-two percent of patients (n = 3855) returned to work within 3 months postoperatively. The risk-adjusted predictors of a lower likelihood of RTW were being preoperatively employed but not working at the time of presentation, manual labor as an occupation, worker's compensation, liability insurance for disability, higher preoperative ODI score, higher preoperative NRS-BP score, and demographic factors such as female sex, African American race, history of diabetes, and higher American Society of Anesthesiologists score. The likelihood of a RTW within 3 months was higher in patients with higher education level than in those with less than high school-level education. The c-index of the model's performance was 0.71. CONCLUSIONS This study presents a novel predictive model for the probability of returning to work after lumbar spine surgery. Spine care providers can use this model to educate patients and encourage them in shared decision-making regarding the RTW outcome. This evidence-based decision support will result in better communication between patients and clinicians and improve postoperative recovery expectations, which will ultimately increase the likelihood of a positive RTW trajectory.},
  langid = {english},
  keywords = {collaboration}
}

@article{ash17pat,
  title = {Patient Characteristics of Smokers Undergoing Lumbar Spine Surgery: An Analysis from the {{Quality Outcomes Database}}},
  shorttitle = {Patient Characteristics of Smokers Undergoing Lumbar Spine Surgery},
  author = {Asher, Anthony L. and Devin, Clinton J. and McCutcheon, Brandon and Chotai, Silky and Archer, Kristin R. and Nian, Hui and Harrell, Frank E. and McGirt, Matthew and Mummaneni, Praveen V. and Shaffrey, Christopher I. and Foley, Kevin and Glassman, Steven D. and Bydon, Mohamad},
  date = {2017-12},
  journaltitle = {J Neurosurg Spine},
  volume = {27},
  number = {6},
  eprint = {28960162},
  eprinttype = {pmid},
  pages = {661--669},
  issn = {1547-5646},
  doi = {10.3171/2017.4.SPINE16984},
  abstract = {OBJECTIVE In this analysis the authors compare the characteristics of smokers to nonsmokers using demographic, socioeconomic, and comorbidity variables. They also investigate which of these characteristics are most strongly associated with smoking status. Finally, the authors investigate whether the association between known patient risk factors and disability outcome is differentially modified by patient smoking status for those who have undergone surgery for lumbar degeneration. METHODS A total of 7547 patients undergoing degenerative lumbar surgery were entered into a prospective multicenter registry (Quality Outcomes Database [QOD]). A retrospective analysis of the prospectively collected data was conducted. Patients were dichotomized as smokers (current smokers) and nonsmokers. Multivariable logistic regression analysis fitted for patient smoking status and subsequent measurement of variable importance was performed to identify the strongest patient characteristics associated with smoking status. Multivariable linear regression models fitted for 12-month Oswestry Disability Index (ODI) scores in subsets of smokers and nonsmokers was performed to investigate whether differential effects of risk factors by smoking status might be present. RESULTS In total, 18\% (n = 1365) of patients were smokers and 82\% (n = 6182) were nonsmokers. In a multivariable logistic regression analysis, the factors significantly associated with patients' smoking status were sex (p {$<$} 0.0001), age (p {$<$} 0.0001), body mass index (p {$<$} 0.0001), educational status (p {$<$} 0.0001), insurance status (p {$<$} 0.001), and employment/occupation (p = 0.0024). Patients with diabetes had lowers odds of being a smoker (p = 0.0008), while patients with coronary artery disease had greater odds of being a smoker (p = 0.044). Patients' propensity for smoking was also significantly associated with higher American Society of Anesthesiologists (ASA) class (p {$<$} 0.0001), anterior-alone surgical approach (p = 0.018), greater number of levels (p = 0.0246), decompression only (p = 0.0001), and higher baseline ODI score (p {$<$} 0.0001). In a multivariable proportional odds logistic regression model, the adjusted odds ratio of risk factors and direction of improvement in 12-month ODI scores remained similar between the subsets of smokers and nonsmokers. CONCLUSIONS Using a large, national, multiinstitutional registry, the authors described the profile of patients who undergo lumbar spine surgery and its association with their smoking status. Compared with nonsmokers, smokers were younger, male, nondiabetic, nonobese patients presenting with leg pain more so than back pain, with higher ASA classes, higher disability, less education, more likely to be unemployed, and with Medicaid/uninsured insurance status. Smoking status did not affect the association between these risk factors and 12-month ODI outcome, suggesting that interventions for modifiable risk factors are equally efficacious between smokers and nonsmokers.},
  langid = {english},
  keywords = {collaboration}
}

@article{ash19com,
  title = {Comparison of {{Outcomes Following Anterior}} vs {{Posterior Fusion Surgery}} for {{Patients With Degenerative Cervical Myelopathy}}: {{An Analysis From Quality Outcomes Database}}},
  shorttitle = {Comparison of {{Outcomes Following Anterior}} vs {{Posterior Fusion Surgery}} for {{Patients With Degenerative Cervical Myelopathy}}},
  author = {Asher, Anthony L. and Devin, Clinton J. and Kerezoudis, Panagiotis and Chotai, Silky and Nian, Hui and Harrell, Frank E. and Sivaganesan, Ahilan and McGirt, Matthew J. and Archer, Kristin R. and Foley, Kevin T. and Mummaneni, Praveen V. and Bisson, Erica F. and Knightly, John J. and Shaffrey, Christopher I. and Bydon, Mohamad},
  date = {2019-04-01},
  journaltitle = {Neurosurgery},
  volume = {84},
  number = {4},
  eprint = {29741718},
  eprinttype = {pmid},
  pages = {919--926},
  issn = {1524-4040},
  doi = {10.1093/neuros/nyy144},
  abstract = {BACKGROUND: The choice of anterior vs posterior approach for degenerative cervical myelopathy that spans multiple segments remains controversial. OBJECTIVE: To compare the outcomes following the 2 approaches using multicenter prospectively collected data. METHODS: Quality Outcomes Database (QOD) for patients undergoing surgery for 3 to 5 level degenerative cervical myelopathy was analyzed. The anterior group (anterior cervical discectomy [ACDF] or corpectomy [ACCF] with fusion) was compared with posterior cervical fusion. Outcomes included: patient reported outcomes (PROs): neck disability index (NDI), numeric rating scale (NRS) of neck pain and arm pain, EQ-5D, modified Japanese Orthopedic Association score for myelopathy (mJOA), and NASS satisfaction questionnaire; hospital length of stay (LOS), 90-d readmission, and return to work (RTW). Multivariable regression models were fitted for outcomes. RESULTS: Of total 245 patients analyzed, 163 patients underwent anterior surgery (ACDF-116, ACCF-47) and 82 underwent posterior surgery. Patients undergoing an anterior approach had lower odds of having higher LOS (P {$<$} .001, odds ratio 0.16, 95\% confidence interval 0.08-0.30). The 12-mo NDI, EQ-5D, NRS, mJOA, and satisfaction scores as well as 90-d readmission and RTW did not differ significantly between anterior and posterior groups. CONCLUSION: Patients undergoing anterior approaches for 3 to 5 level degenerative cervical myelopathy had shorter hospital LOS compared to those undergoing posterior decompression and fusion. Also, patients in both groups exhibited similar long-term PROs, readmission, and RTW rates. Further investigations are needed to compare the differences in longer term reoperation rates and functional outcomes before the clinical superiority of one approach over the other can be established.},
  langid = {english},
  keywords = {collaboration}
}

@article{ash19eff,
  title = {Effect of {{Modified Japanese Orthopedic Association Severity Classifications}} on {{Satisfaction With Outcomes}} 12 {{Months After Elective Surgery}} for {{Cervical Spine Myelopathy}}},
  author = {Asher, Anthony L. and Devin, Clinton J. and Weisenthal, Benjamin M. and Pennings, Jacquelyn and Khan, Inamullah and Archer, Kristin R. and Sivaganesan, Ahilan and Chotai, Silky and Bydon, Mohamad and Nian, Hui and Harrell, Frank E. and McGirt, Matthew J. and Mummaneni, Praveen and Bisson, Erica F. and Shaffrey, Christopher and Foley, Kevin T. and {for QOD Vanguard Sites}},
  date = {2019-06-01},
  journaltitle = {Spine (Phila Pa 1976)},
  volume = {44},
  number = {11},
  eprint = {30475334},
  eprinttype = {pmid},
  pages = {801--808},
  issn = {1528-1159},
  doi = {10.1097/BRS.0000000000002946},
  abstract = {STUDY DESIGN: This study retrospectively analyzes prospectively collected data. OBJECTIVE: Here, we aim to determine the influence of preoperative and 12-month modified Japanese Orthopedic Association (mJOA) on satisfaction and understand the change in mJOA severity classification after surgical management of degenerative cervical myelopathy (DCM). SUMMARY OF BACKGROUND DATA: DCM is a progressive degenerative spine disease resulting from cervical cord compression. The natural progression of DCM is variable; some patients experience periods of stability, while others rapidly deteriorate following disease onset. The mJOA is commonly used to grade and categorize myelopathy symptoms, but its association with postoperative satisfaction has not been previously explored. METHODS: The quality and outcomes database (QOD) was queried for patients undergoing elective surgery for DCM. Patients were divided into mild (≥14), moderate (9 to 13), or severe ({$<$}9) categories on the mJOA scores. A McNemar-Bowker test was used to assess whether a significant proportion of patients changed mJOA category between preoperative and 12 months postoperative. A multivariable proportional odds ordinal logistic regression model was fitted with 12-month satisfaction as the outcome of interest. RESULTS: We identified 1963 patients who underwent elective surgery for DCM and completed 12-months follow-ups. Comparing mJOA severity level preoperatively and at 12 months revealed that 55\% remained in the same category, 37\% improved, and 7\% moved to a worse category. After adjusting for baseline and surgery-specific variables, the 12-month mJOA category had the highest impact on patient satisfaction (P{$\mkern1mu<\mkern1mu$}0.001). CONCLUSION: Patient satisfaction is an indispensable tool for measuring quality of care after spine surgery. In this sample, 12-month mJOA category, regardless of preop mJOA, was significantly correlated with satisfaction. Given these findings, it is important to advise patients of the probability that surgery will change their mJOA severity classification and the changes required to achieve postoperative satisfaction. LEVEL OF EVIDENCE: 3.},
  langid = {english},
  keywords = {collaboration}
}

@article{ash19pre,
  title = {Predictors of Patient Satisfaction Following 1- or 2-Level Anterior Cervical Discectomy and Fusion: Insights from the {{Quality Outcomes Database}}},
  shorttitle = {Predictors of Patient Satisfaction Following 1- or 2-Level Anterior Cervical Discectomy and Fusion},
  author = {Asher, Anthony L. and Devin, Clinton J. and Kerezoudis, Panagiotis and Nian, Hui and Alvi, Mohammed Ali and Khan, Inamullah and Sivaganesan, Ahilan and Harrell, Frank E. and Archer, Kristin R. and Bydon, Mohamad},
  date = {2019-08-30},
  journaltitle = {J Neurosurg Spine},
  eprint = {31470402},
  eprinttype = {pmid},
  pages = {1--9},
  issn = {1547-5646},
  doi = {10.3171/2019.6.SPINE19426},
  abstract = {OBJECTIVE: Patient satisfaction with treatment outcome is gaining an increasingly important role in assessing the value of surgical spine care delivery. Nationwide data evaluating the predictors of patient satisfaction in elective cervical spine surgery are lacking. The authors sought to decipher the impacts of the patient, surgical practice, and surgeon on satisfaction with outcome following anterior cervical discectomy and fusion (ACDF). METHODS: The authors queried the Quality Outcomes Database for patients undergoing 1- to 2-level ACDF for degenerative spine disease since 2013. Patient satisfaction with the surgical outcome as measured by the North American Spine Society (NASS) scale comprised the primary outcome. A multivariable proportional odds logistic regression model was constructed with adjustments for baseline patient characteristics and surgical practice and surgeon characteristics as fixed effects. RESULTS: A total of 4148 patients (median age 54 years, 48\% males) with complete 12-month NASS satisfaction data were analyzed. Sixty-seven percent of patients answered that "surgery met their expectations" (n = 2803), while 20\% reported that they "did not improve as much as they had hoped but they would undergo the same operation for the same results" (n = 836). After adjusting for a multitude of patient-specific as well as hospital- and surgeon-related factors, the authors found baseline Neck Disability Index (NDI) score, US geographic region of hospital, patient race, insurance status, symptom duration, and Workers' compensation status to be the most important predictors of patient satisfaction. The discriminative ability of the model was satisfactory (c-index 0.66, overfitting-corrected estimate 0.64). CONCLUSIONS: The authors' results found baseline NDI score, patient race, insurance status, symptom duration, and Workers' compensation status as well as the geographic region of the hospital to be the most important predictors of long-term patient satisfaction after a 1- to 2-level ACDF. The findings of the present analysis further reinforce the role of preoperative discussion with patients on setting treatment goals and realistic expectations.},
  langid = {english},
  keywords = {collaboration}
}

@article{ash89,
  title = {The Ordered Logistic Regression Model in Psychiatry: {{Rising}} Prevalence of Dementia in Old People's Homes},
  author = {Ashby, D. and West, C. R. and Ames, D.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {1317--1326},
  citeulike-article-id = {13263711},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {logistic-ordinal-model}
}

@article{asi96che,
  title = {Checklist of Information for Inclusion in Reports of Clinical Trials},
  author = {{The Asilomar Working Group on Recommendations for Reporting of Clinical Trials in the Biomedical Literature}},
  date = {1996},
  journaltitle = {Ann Int Med},
  volume = {124},
  pages = {741--743},
  doi = {10.7326/0003-4819-124-8-199604150-00007},
  url = {http://dx.doi.org/10.7326/0003-4819-124-8-199604150-00007},
  citeulike-article-id = {13263712},
  citeulike-linkout-0 = {http://dx.doi.org/10.7326/0003-4819-124-8-199604150-00007},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {clinical-trials,rct,reporting,statistical-results,teaching-mds}
}

@article{ass16cli,
  title = {Clinical and {{Biological Insights Into Combined Post-}} and {{Pre-Capillary Pulmonary Hypertension}}},
  author = {Assad, Tufik R. and Hemnes, Anna R. and Larkin, Emma K. and Glazer, Andrew M. and Xu, Meng and Wells, Quinn S. and Farber-Eger, Eric H. and Sheng, Quanhu and Shyr, Yu and Harrell, Frank E. and Newman, John H. and Brittain, Evan L.},
  date = {2016-12},
  journaltitle = {J Am Coll Cardiol},
  volume = {68},
  number = {23},
  pages = {2525--2536},
  issn = {07351097},
  doi = {10.1016/j.jacc.2016.09.942},
  url = {http://dx.doi.org/10.1016/j.jacc.2016.09.942},
  citeulike-article-id = {14244631},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jacc.2016.09.942},
  posted-at = {2017-01-02 14:06:22},
  priority = {2},
  keywords = {collaboration}
}

@article{ass16hem,
  title = {Hemodynamic Evidence of Vascular Remodeling in Combined Post- and Precapillary Pulmonary Hypertension},
  author = {Assad, Tufik R. and Brittain, Evan L. and Wells, Quinn S. and Farber-Eger, Eric H. and Halliday, Stephen J. and Doss, Laura N. and Xu, Meng and Wang, Li and Harrell, Frank E. and Yu, Chang and Robbins, Ivan M. and Newman, John H. and Hemnes, Anna R.},
  date = {2016-07},
  journaltitle = {Pulmonary Circ},
  volume = {6},
  number = {3},
  pages = {313--321},
  publisher = {The University of Chicago Press},
  doi = {10.1086/688516},
  url = {http://dx.doi.org/10.1086/688516},
  abstract = {AbstractAlthough commonly encountered, patients with combined postcapillary and precapillary pulmonary hypertension (Cpc-PH) have poorly understood pulmonary vascular properties. The product of pulmonary vascular resistance and compliance, resistance-compliance (RC) time, is a measure of pulmonary vascular physiology. While RC time is lower in postcapillary PH than in precapillary PH, the RC time in Cpc-PH and the effect of pulmonary wedge pressure (PWP) on RC time are unknown. We tested the hypothesis that Cpc-PH has an RC time that resembles that in pulmonary arterial hypertension (PAH) more than that in isolated postcapillary PH (Ipc-PH). We analyzed the hemodynamics of 282 consecutive patients with PH referred for right heart catheterization (RHC) with a fluid challenge from 2004 to 2013 (cohort A) and 4,382 patients who underwent RHC between 1998 and 2014 for validation (cohort B). Baseline RC time in Cpc-PH was higher than that in Ipc-PH and lower than that in PAH in both cohorts (P {$<$} 0.001). In cohort A, RC time decreased after fluid challenge in patients with Ipc-PH but not in those with PAH or Cpc-PH (P {$<$} 0.001). In cohort B, the inverse relationship of pulmonary vascular compliance and resistance, as well as that of RC time and PWP, in Cpc-PH was similar to that in PAH and distinct from that in Ipc-PH. Our findings demonstrate that patients with Cpc-PH have pulmonary vascular physiology that resembles that of patients with PAH more than that of Ipc-PH patients. Further study is warranted to identify determinants of vascular remodeling and assess therapeutic response in this subset of PH.},
  citeulike-article-id = {14150633},
  citeulike-linkout-0 = {http://dx.doi.org/10.1086/688516},
  citeulike-linkout-1 = {http://www.journals.uchicago.edu/doi/abs/10.1086/688516},
  day = {14},
  posted-at = {2016-10-03 01:33:17},
  priority = {2},
  keywords = {collaboration}
}

@article{ass17pro,
  title = {Prognostic {{Effect}} and {{Longitudinal Hemodynamic Assessment}} of {{Borderline Pulmonary Hypertension}}},
  author = {Assad, Tufik R. and Maron, Bradley A. and Robbins, Ivan M. and Xu, Meng and Huang, Shi and Harrell, Frank E. and Farber-Eger, Eric H. and Wells, Quinn S. and Choudhary, Gaurav and Hemnes, Anna R. and Brittain, Evan L.},
  date = {2017-12-01},
  journaltitle = {JAMA Cardiol},
  volume = {2},
  number = {12},
  eprint = {29071338},
  eprinttype = {pmid},
  pages = {1361--1368},
  issn = {2380-6591},
  doi = {10.1001/jamacardio.2017.3882},
  abstract = {Importance: Pulmonary hypertension (PH) is diagnosed by a mean pulmonary arterial pressure (mPAP) value of at least 25 mm Hg during right heart catheterization (RHC). While several studies have demonstrated increased mortality in patients with mPAP less than that threshold, little is known about the natural history of borderline PH. Objective: To test the hypothesis that patients with borderline PH have decreased survival compared with patients with lower mPAP and frequently develop overt PH and to identify clinical correlates of borderline PH. Design, Setting, and Participants: Retrospective cohort study from 1998 to 2014 at Vanderbilt University Medical Center, comprising all patients undergoing routine RHC for clinical indication. We extracted demographics, clinical data, invasive hemodynamics, echocardiography, and vital status for all patients. Patients with mPAP values of 18 mm Hg or less, 19 to 24 mm Hg, and at least 25 mm Hg were classified as reference, borderline PH, and PH, respectively. Exposures: Mean pulmonary arterial pressure. Main Outcome and Measures: Our primary outcome was all-cause mortality after adjusting for clinically relevant covariates in a Cox proportional hazards model. Our secondary outcome was the diagnosis of overt PH in patients initially diagnosed with borderline PH. Both outcomes were determined prior to data analysis. Results: We identified 4343 patients (mean [SD] age, 59 [15] years, 51\% women, and 86\% white) among whom the prevalence of PH and borderline PH was 62\% and 18\%, respectively. Advanced age, features of the metabolic syndrome, and chronic heart and lung disease were independently associated with a higher likelihood of borderline PH compared with reference patients in a logistic regression model. After adjusting for 34 covariates in a Cox proportional hazards model, borderline PH was associated with increased mortality compared with reference patients (hazard ratio, 1.31; 95\% CI, 1.04-1.65; P\,=\,.001). The hazard of death increased incrementally with higher mPAP, without an observed threshold. In the 70 patients with borderline PH who underwent a repeated RHC, 43 (61\%) had developed overt PH, with a median increase in mPAP of 5 mm Hg (interquartile range, -1 to 11 mm Hg; P\,{$<$}\,.001). Conclusions and Relevance: Borderline PH is common in patients undergoing RHC and is associated with significant comorbidities, progression to overt PH, and decreased survival. Small increases in mPAP, even at values currently considered normal, are independently associated with increased mortality. Prospective studies are warranted to determine whether early intervention or closer monitoring improves clinical outcomes in these patients.},
  langid = {english},
  pmcid = {PMC5814998},
  keywords = {collaboration,cv}
}

@article{ath07ear,
  title = {Early Evidence-Based Medicine: {{Clues}} on Statistical Analysis in Medicine from {{Galen}}'s Writings},
  author = {Athanasios, Diamandopoulos A. and Pavlos, Goudas C. and Theodoros, Kassimatis I.},
  date = {2007},
  journaltitle = {Am Statistician},
  volume = {61},
  pages = {154--158},
  citeulike-article-id = {13265582},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {ebm,evidence-based-medicine,history-of-statistics}
}

@article{atk80,
  title = {A Note on the Generalized Information Criterion for Choice of a Model},
  author = {Atkinson, A. C.},
  date = {1980},
  journaltitle = {Biometrika},
  volume = {67},
  pages = {413--418},
  citeulike-article-id = {13263713},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {aic}
}

@article{att21the,
  title = {Therapeutic {{Anticoagulation}} with {{Heparin}} in {{Noncritically Ill Patients}} with {{Covid-19}}},
  author = {ATTACC Investigators},
  date = {2021-08-04},
  journaltitle = {New England Journal of Medicine},
  volume = {0},
  number = {0},
  pages = {null},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa2105911},
  url = {https://doi.org/10.1056/NEJMoa2105911},
  urldate = {2021-08-07},
  keywords = {bayes,rct,teaching-mds},
  annotation = {\_eprint: https://doi.org/10.1056/NEJMoa2105911}
}

@article{aub21bay,
  title = {A {{Bayesian}} Approach for Event Predictions in Clinical Trials with Time-to-Event Outcomes},
  author = {Aubel, Paul and Antigny, Marine and Fougeray, Ronan and Dubois, Frédéric and Saint-Hilary, Gaëlle},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9186},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9186},
  urldate = {2021-09-21},
  abstract = {In clinical trials with time-to-event outcome as the primary endpoint, the end of study date is often based on the number of observed events, which drives the statistical power and the sample size calculation. It is of great value for study sponsors to have a good understanding of the recruitment process and the event milestones to manage the logistical tasks, which require a considerable amount of resources. The objective of the proposed statistical approach is to predict, as accurately as possible, the timing of an analysis planned once a target number of events is collected. The method takes into account the enrollment, the time to event, and the time to censor processes, using Weibull models in a Bayesian framework. We also consider a possible delay in the event reporting by the investigators, and covariates may also be included. Several metrics can be obtained, such as the probability of study completion at specific timepoints or the credible interval of the date of study completion. The approach was applied to oncology trials, with progression-free survival as primary outcome. A retrospective analysis shows the accuracy of the approach on these examples, as well as the benefit of updating the predictive probability of study completion as data are accumulating or new information becomes available. We also evaluated the performances of the proposed method in a comprehensive simulation study.},
  langid = {english},
  keywords = {bayes,implementation,prediction,rct,recruitment},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9186}
}

@article{aus03com,
  title = {Comparing Hierarchical Modeling with Traditional Logistic Regression Analysis among Patients Hospitalized with Acute Myocardial Infarction: {{Should}} We Be Analyzing Cardiovascular Outcomes Data Differently?},
  author = {Austin, Peter C. and Tu, Jack V. and Alter, David A.},
  date = {2003},
  journaltitle = {Am Heart J},
  volume = {145},
  pages = {27--35},
  citeulike-article-id = {13265308},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  note = {Multilevel model takes intra-cluster correlations into account and results in wider confidence intervals of fixed effects;Editorial, p. 16 by EL DeLong}
}

@article{aus05use,
  title = {Tutorial in {{Biostatistics}}:{{The}} Use of Quantile Regression in Health Care Research: A Case Study Examining Gender Differences in the Timeliness of Thrombolytic Therapy},
  author = {Austin, Peter C. and Tu, Jack V. and Daly, Paul A. and Alter, David A.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {791--816},
  citeulike-article-id = {13265399},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {acute-mi,cox-ph-model,log-transformation,quantile-regression,regression-models,thrombolysis-waiting-time}
}

@article{aus06com,
  title = {A Comparison of Propensity Score Methods: {{A}} Case-Study Estimating the Effectiveness of Post-{{AMI}} Statin Use},
  author = {Austin, Peter C. and Mamdani, Muhammad M.},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {2084--2106},
  citeulike-article-id = {13265481},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {acute-myocardial-infarction,mi,pharmacoepidemiology,propensity-score,residual-confounding,statins},
  note = {propensity adjustment using covariate adjustment;effect on hypothesis tests, relative and absolute effects;residual confounding remained after stratifying by quintiles of propensity;Q-Q plots were more sensitive for showing imbalances;non-collapsibility of odds ratios;matched pairs yielded estimates closer to the null because of this;allowing propensity effect on Y to be quadratic affected the result}
}

@article{aus07com,
  title = {A Comparison of Regression Trees, Logistic Regression, Generalized Additive Models, and Multivariate Adaptive Regression Splines for Predicting {{AMI}} Mortality},
  author = {Austin, Peter C.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {2937--2957},
  citeulike-article-id = {13265589},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {cart,generalized-additive-models,logistic-regression,mi,ordinary-logistic-models-performed-well,poor-performance-of-recursive-partitioning,predictive-modeling,recursive-partitioning,validation}
}

@article{aus07per,
  title = {The Performance of Different Propensity Score Methods for Estimating Marginal Odds Ratios},
  author = {Austin, Peter C.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3078--3094},
  citeulike-article-id = {13265602},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {bias,matching,matching-can-have-lower-mse-than-covariate-adjustment,observational-study,propensity-score,simulation}
}

@article{aus08boo,
  title = {Bootstrap Model Selection Had Similar Performance for Selecting Authentic and Noise Variables Compared to Backward Variable Elimination: A Simulation Study},
  author = {Austin, Peter C.},
  date = {2008},
  journaltitle = {J Clin Epi},
  volume = {61},
  pages = {1009--1017},
  citeulike-article-id = {13265695},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  note = {"in general, a bootstrap model selection method had comparable performance to conventional backward variable elimination for identifying the true regression model. In most settings, both methods performed poorly at correctly identifying the correct regression model."}
}

@article{aus08per,
  title = {The Performance of Different Propensity-Score Methods for Estimating Relative Risks},
  author = {Austin, Peter C.},
  date = {2008},
  journaltitle = {J Clin Epi},
  volume = {61},
  pages = {537--545},
  citeulike-article-id = {13265663},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {comparison,propensity-score,review},
  note = {MSE and bias of relative risk;quintile stratification vs. matching;covariate adjustment;"propensity-score matching resulted in estimates with less bias than did stratification on the quintiles of the propensity score, but stratification on the quintiles of the propensity score resulted in estimates with greater precision."}
}

@article{aus10log,
  title = {Logistic Regression Had Superior Performance Compared with Regression Trees for Predicting In-Hospital Mortality in Patients Hospitalized with Heart Failure},
  author = {Austin, Peter C. and Tu, Jack V. and Lee, Douglas S.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {1145--1155},
  citeulike-article-id = {13265843},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {brier-score,chf,classification-tree,gam,generalized-additive-model,generalized-r2,logistic-regression,predictive-model,recursive-partitioning,validation},
  note = {ROC areas for logistic models varied from 0.747 to 0.775 whereas they varied from 0.620-0.651 for recursive partitioning;repeated data simulation showed large variation in tree structure}
}

@article{aus10sub,
  title = {A Substantial and Confusing Variation Exists in Handling of Baseline Covariates in Randomized Controlled Trials: A Review of Trials Published in Leading Medical Journal},
  author = {Austin, P. C. and Manca, A. and Zwarenstein, M. and Juurlink, D. N. and Stanbrook, M. B.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {142--153},
  doi = {10.1016/j.jclinepi.2009.06.002},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2009.06.002},
  citeulike-article-id = {13265828},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2009.06.002},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {ancova,baseline-adjustment,clinical-trials,covariate-adjustment,rct},
  note = {silliness of testing baseline imbalance in RCTs;letter to the editor by Berger 63:939-940, with a strong and convincing response by the authors 63:940-941}
}

@article{aus12gen,
  title = {Generating Survival Times to Simulate {{Cox}} Proportional Hazards Models with Time-Varying Covariates},
  author = {Austin, Peter C.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {29},
  pages = {3946--3958},
  doi = {10.1002/sim.5452},
  url = {http://dx.doi.org/10.1002/sim.5452},
  abstract = {Simulations and Monte Carlo methods serve an important role in modern statistical research. They allow for an examination of the performance of statistical procedures in settings in which analytic and mathematical derivations may not be feasible. A key element in any statistical simulation is the existence of an appropriate data-generating process: one must be able to simulate data from a specified statistical model. We describe data-generating processes for the Cox proportional hazards model with time-varying covariates when event times follow an exponential, Weibull, or Gompertz distribution. We consider three types of time-varying covariates: first, a dichotomous time-varying covariate that can change at most once from untreated to treated (e.g., organ transplant); second, a continuous time-varying covariate such as cumulative exposure at a constant dose to radiation or to a pharmaceutical agent used for a chronic condition; third, a dichotomous time-varying covariate with a subject being able to move repeatedly between treatment states (e.g., current compliance or use of a medication). In each setting, we derive closed-form expressions that allow one to simulate survival times so that survival times are related to a vector of fixed or time-invariant covariates and to a single time-varying covariate. We illustrate the utility of our closed-form expressions for simulating event times by using Monte Carlo simulations to estimate the statistical power to detect as statistically significant the effect of different types of binary time-varying covariates. This is compared with the statistical power to detect as statistically significant a binary time-invariant covariate.},
  citeulike-article-id = {13265952},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5452},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {exponential-distribution,gompertz-distribution,power-and-sample-size-calculation,proportional-hazards-model,simulation-setup,simulations,survival-analysis,tdc,weibull-distribution},
  annotation = {Corrections, 32:1078;2013; see also 32:898;2013}
}

@article{aus14eve,
  title = {Events per Variable ({{EPV}}) and the Relative Performance of Different Strategies for Estimating the out-of-Sample Validity of Logistic Regression Models.},
  author = {Austin, Peter C. and Steyerberg, Ewout W.},
  date = {2017-04},
  journaltitle = {Stat Meth Med Res},
  volume = {26},
  number = {2},
  eprint = {25411322},
  eprinttype = {pmid},
  pages = {796--808},
  issn = {1477-0334},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25411322},
  abstract = {We conducted an extensive set of empirical analyses to examine the effect of the number of events per variable (EPV) on the relative performance of three different methods for assessing the predictive accuracy of a logistic regression model: apparent performance in the analysis sample, split-sample validation, and optimism correction using bootstrap methods. Using a single dataset of patients hospitalized with heart failure, we compared the estimates of discriminatory performance from these methods to those for a very large independent validation sample arising from the same population. As anticipated, the apparent performance was optimistically biased, with the degree of optimism diminishing as the number of events per variable increased. Differences between the bootstrap-corrected approach and the use of an independent validation sample were minimal once the number of events per variable was at least 20. Split-sample assessment resulted in too pessimistic and highly uncertain estimates of model performance. Apparent performance estimates had lower mean squared error compared to split-sample estimates, but the lowest mean squared error was obtained by bootstrap-corrected optimism estimates. For bias, variance, and mean squared error of the performance estimates, the penalty incurred by using split-sample validation was equivalent to reducing the sample size by a proportion equivalent to the proportion of the sample that was withheld for model validation. In conclusion, split-sample validation is inefficient and apparent performance is too optimistic for internal validation of regression-based prediction models. Modern validation methods, such as bootstrap-based optimism correction, are preferable. While these findings may be unsurprising to many statisticians, the results of the current study reinforce what should be considered good statistical practice in the development and validation of clinical prediction models.},
  citeulike-article-id = {13474592},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25411322},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25411322},
  day = {19},
  posted-at = {2015-04-13 21:00:48},
  priority = {2},
  keywords = {events-per-variable,external-validation,validation}
}

@article{aus14gra,
  title = {Graphical Assessment of Internal and External Calibration of Logistic Regression Models by Using Loess Smoothers.},
  author = {Austin, Peter C. and Steyerberg, Ewout W.},
  date = {2014-02},
  journaltitle = {Stat Med},
  volume = {33},
  number = {3},
  eprint = {24002997},
  eprinttype = {pmid},
  pages = {517--535},
  issn = {1097-0258},
  doi = {10.1002/sim.5941},
  url = {http://dx.doi.org/10.1002/sim.5941},
  abstract = {Predicting the probability of the occurrence of a binary outcome or condition is important in biomedical research. While assessing discrimination is an essential issue in developing and validating binary prediction models, less attention has been paid to methods for assessing model calibration. Calibration refers to the degree of agreement between observed and predicted probabilities and is often assessed by testing for lack-of-fit. The objective of our study was to examine the ability of graphical methods to assess the calibration of logistic regression models. We examined lack of internal calibration, which was related to misspecification of the logistic regression model, and external calibration, which was related to an overfit model or to shrinkage of the linear predictor. We conducted an extensive set of Monte Carlo simulations with a locally weighted least squares regression smoother (i.e., the loess algorithm) to examine the ability of graphical methods to assess model calibration. We found that loess-based methods were able to provide evidence of moderate departures from linearity and indicate omission of a moderately strong interaction. Misspecification of the link function was harder to detect. Visual patterns were clearer with higher sample sizes, higher incidence of the outcome, or higher discrimination. Loess-based methods were also able to identify the lack of calibration in external validation samples when an overfit regression model had been used. In conclusion, loess-based smoothing methods are adequate tools to graphically assess calibration and merit wider application.},
  citeulike-article-id = {12772094},
  citeulike-attachment-1 = {aus14gra.pdf; /pdf/user/harrelfe/article/12772094/980963/aus14gra.pdf; 2d5f899ea2f29c2526697772320a2a6cfad0b06f},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5941},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/24002997},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=24002997},
  day = {10},
  posted-at = {2014-08-18 00:12:55},
  priority = {0},
  keywords = {calibration,nonparametric-calibration-curve,predictive-accuracy}
}

@article{aus17acc,
  title = {Accounting for Competing Risks in Randomized Controlled Trials: A Review and Recommendations for Improvement},
  author = {Austin, Peter C. and Fine, Jason P.},
  date = {2017-01},
  journaltitle = {Stat Med},
  pages = {n/a},
  doi = {10.1002/sim.7215},
  url = {http://dx.doi.org/10.1002/sim.7215},
  abstract = {In studies with survival or time-to-event outcomes, a competing risk is an event whose occurrence precludes the occurrence of the primary event of interest. Specialized statistical methods must be used to analyze survival data in the presence of competing risks. We conducted a review of randomized controlled trials with survival outcomes that were published in high-impact general medical journals. Of 40 studies that we identified, 31 (77.5\%) were potentially susceptible to competing risks. However, in the majority of these studies, the potential presence of competing risks was not accounted for in the statistical analyses that were described. Of the 31 studies potentially susceptible to competing risks, 24 (77.4\%) reported the results of a Kaplan–Meier survival analysis, while only five (16.1\%) reported using cumulative incidence functions to estimate the incidence of the outcome over time in the presence of competing risks. The former approach will tend to result in an overestimate of the incidence of the outcome over time, while the latter approach will result in unbiased estimation of the incidence of the primary outcome over time. We provide recommendations on the analysis and reporting of randomized controlled trials with survival outcomes in the presence of competing risks.  2017 The Authors. Stat Med published by John Wiley \& Sons Ltd.},
  citeulike-article-id = {14258025},
  citeulike-attachment-1 = {aus17acc.pdf; /pdf/user/harrelfe/article/14258025/1098533/aus17acc.pdf; fb765b1d1156c22243fa0c194d0a9e6d20abefcd},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7215},
  day = {1},
  posted-at = {2017-01-19 13:53:26},
  priority = {4},
  keywords = {competing-risks,epub-replace,rct,survival-analysis}
}

@article{aus19int,
  title = {The {{Integrated Calibration Index}} ({{ICI}}) and Related Metrics for Quantifying the Calibration of Logistic Regression Models},
  author = {Austin, Peter C. and Steyerberg, Ewout W.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {21},
  pages = {4051--4065},
  issn = {1097-0258},
  doi = {10.1002/sim.8281},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8281},
  urldate = {2019-08-10},
  abstract = {Assessing the calibration of methods for estimating the probability of the occurrence of a binary outcome is an important aspect of validating the performance of risk-prediction algorithms. Calibration commonly refers to the agreement between predicted and observed probabilities of the outcome. Graphical methods are an attractive approach to assess calibration, in which observed and predicted probabilities are compared using loess-based smoothing functions. We describe the Integrated Calibration Index (ICI) that is motivated by Harrell's Emax index, which is the maximum absolute difference between a smooth calibration curve and the diagonal line of perfect calibration. The ICI can be interpreted as weighted difference between observed and predicted probabilities, in which observations are weighted by the empirical density function of the predicted probabilities. As such, the ICI is a measure of calibration that explicitly incorporates the distribution of predicted probabilities. We also discuss two related measures of calibration, E50 and E90, which represent the median and 90th percentile of the absolute difference between observed and predicted probabilities. We illustrate the utility of the ICI, E50, and E90 by using them to compare the calibration of logistic regression with that of random forests and boosted regression trees for predicting mortality in patients hospitalized with a heart attack. The use of these numeric metrics permitted for a greater differentiation in calibration than was permissible by visual inspection of graphical calibration curves.},
  langid = {english},
  keywords = {calibration,validation}
}

@article{aus19inta,
  title = {The {{Integrated Calibration Index}} ({{ICI}}) and Related Metrics for Quantifying the Calibration of Logistic Regression Models},
  author = {Austin, Peter C. and Steyerberg, Ewout W.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8281},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8281},
  urldate = {2019-07-04},
  abstract = {Assessing the calibration of methods for estimating the probability of the occurrence of a binary outcome is an important aspect of validating the performance of risk-prediction algorithms. Calibration commonly refers to the agreement between predicted and observed probabilities of the outcome. Graphical methods are an attractive approach to assess calibration, in which observed and predicted probabilities are compared using loess-based smoothing functions. We describe the Integrated Calibration Index (ICI) that is motivated by Harrell's Emax index, which is the maximum absolute difference between a smooth calibration curve and the diagonal line of perfect calibration. The ICI can be interpreted as weighted difference between observed and predicted probabilities, in which observations are weighted by the empirical density function of the predicted probabilities. As such, the ICI is a measure of calibration that explicitly incorporates the distribution of predicted probabilities. We also discuss two related measures of calibration, E50 and E90, which represent the median and 90th percentile of the absolute difference between observed and predicted probabilities. We illustrate the utility of the ICI, E50, and E90 by using them to compare the calibration of logistic regression with that of random forests and boosted regression trees for predicting mortality in patients hospitalized with a heart attack. The use of these numeric metrics permitted for a greater differentiation in calibration than was permissible by visual inspection of graphical calibration curves.},
  langid = {english},
  keywords = {calibration,calibration-curve,logistic,validation}
}

@article{aus20gra,
  title = {Graphical Calibration Curves and the Integrated Calibration Index ({{ICI}}) for Survival Models},
  author = {Austin, Peter C. and Harrell, Frank E. and van Klaveren, David},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8570},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8570},
  urldate = {2020-06-17},
  abstract = {In the context of survival analysis, calibration refers to the agreement between predicted probabilities and observed event rates or frequencies of the outcome within a given duration of time. We aimed to describe and evaluate methods for graphically assessing the calibration of survival models. We focus on hazard regression models and restricted cubic splines in conjunction with a Cox proportional hazards model. We also describe modifications of the Integrated Calibration Index, of E50 and of E90. In this context, this is the average (respectively, median or 90th percentile) absolute difference between predicted survival probabilities and smoothed survival frequencies. We conducted a series of Monte Carlo simulations to evaluate the performance of these calibration measures when the underlying model has been correctly specified and under different types of model mis-specification. We illustrate the utility of calibration curves and the three calibration metrics by using them to compare the calibration of a Cox proportional hazards regression model with that of a random survival forest for predicting mortality in patients hospitalized with heart failure. Under a correctly specified regression model, differences between the two methods for constructing calibration curves were minimal, although the performance of the method based on restricted cubic splines tended to be slightly better. In contrast, under a mis-specified model, the smoothed calibration curved constructed using hazard regression tended to be closer to the true calibration curve. The use of calibration curves and of these numeric calibration metrics permits for a comprehensive comparison of the calibration of competing survival models.},
  langid = {english},
  keywords = {calibration,censored-data,survival,validation},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8570}
}

@article{aus20graa,
  title = {Graphical Calibration Curves and the Integrated Calibration Index ({{ICI}}) for Survival Models},
  author = {Austin, Peter C. and Harrell, Frank E. and van Klaveren, David},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8570},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8570},
  urldate = {2020-06-21},
  abstract = {In the context of survival analysis, calibration refers to the agreement between predicted probabilities and observed event rates or frequencies of the outcome within a given duration of time. We aimed to describe and evaluate methods for graphically assessing the calibration of survival models. We focus on hazard regression models and restricted cubic splines in conjunction with a Cox proportional hazards model. We also describe modifications of the Integrated Calibration Index, of E50 and of E90. In this context, this is the average (respectively, median or 90th percentile) absolute difference between predicted survival probabilities and smoothed survival frequencies. We conducted a series of Monte Carlo simulations to evaluate the performance of these calibration measures when the underlying model has been correctly specified and under different types of model mis-specification. We illustrate the utility of calibration curves and the three calibration metrics by using them to compare the calibration of a Cox proportional hazards regression model with that of a random survival forest for predicting mortality in patients hospitalized with heart failure. Under a correctly specified regression model, differences between the two methods for constructing calibration curves were minimal, although the performance of the method based on restricted cubic splines tended to be slightly better. In contrast, under a mis-specified model, the smoothed calibration curved constructed using hazard regression tended to be closer to the true calibration curve. The use of calibration curves and of these numeric calibration metrics permits for a comprehensive comparison of the calibration of competing survival models.},
  langid = {english},
  keywords = {calibration,predictive-accuracy,rms,validation},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8570}
}

@article{aus20grab,
  title = {Graphical Calibration Curves and the Integrated Calibration Index ({{ICI}}) for Survival Models},
  author = {Austin, Peter C. and Harrell, Frank E. and van Klaveren, David},
  options = {useprefix=true},
  date = {2020-09-20},
  journaltitle = {Stat Med},
  volume = {39},
  number = {21},
  eprint = {32548928},
  eprinttype = {pmid},
  pages = {2714--2742},
  issn = {1097-0258},
  doi = {10.1002/sim.8570},
  abstract = {In the context of survival analysis, calibration refers to the agreement between predicted probabilities and observed event rates or frequencies of the outcome within a given duration of time. We aimed to describe and evaluate methods for graphically assessing the calibration of survival models. We focus on hazard regression models and restricted cubic splines in conjunction with a Cox proportional hazards model. We also describe modifications of the Integrated Calibration Index, of E50 and of E90. In this context, this is the average (respectively, median or 90th percentile) absolute difference between predicted survival probabilities and smoothed survival frequencies. We conducted a series of Monte Carlo simulations to evaluate the performance of these calibration measures when the underlying model has been correctly specified and under different types of model mis-specification. We illustrate the utility of calibration curves and the three calibration metrics by using them to compare the calibration of a Cox proportional hazards regression model with that of a random survival forest for predicting mortality in patients hospitalized with heart failure. Under a correctly specified regression model, differences between the two methods for constructing calibration curves were minimal, although the performance of the method based on restricted cubic splines tended to be slightly better. In contrast, under a mis-specified model, the smoothed calibration curved constructed using hazard regression tended to be closer to the true calibration curve. The use of calibration curves and of these numeric calibration metrics permits for a comprehensive comparison of the calibration of competing survival models.},
  langid = {english},
  pmcid = {PMC7497089},
  keywords = {calibration,methodology,validation}
}

@article{aus21fin,
  title = {Fine-{{Gray}} Subdistribution Hazard Models to Simultaneously Estimate the Absolute Risk of Different Event Types: {{Cumulative}} Total Failure Probability May Exceed 1},
  shorttitle = {Fine-{{Gray}} Subdistribution Hazard Models to Simultaneously Estimate the Absolute Risk of Different Event Types},
  author = {Austin, Peter C. and Steyerberg, Ewout W. and Putter, Hein},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9023},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9023},
  urldate = {2021-05-10},
  abstract = {The Fine-Gray subdistribution hazard model has become the default method to estimate the incidence of outcomes over time in the presence of competing risks. This model is attractive because it directly relates covariates to the cumulative incidence function (CIF) of the event of interest. An alternative is to combine the different cause-specific hazard functions to obtain the different CIFs. A limitation of the subdistribution hazard approach is that the sum of the cause-specific CIFs can exceed 1 (100\%) for some covariate patterns. Using data on 9479 patients hospitalized with acute myocardial infarction, we estimated the cumulative incidence of both cardiovascular death and non-cardiovascular death for each patient. We found that when using subdistribution hazard models, approximately 5\% of subjects had an estimated risk of 5-year all-cause death (obtained by combining the two cause-specific CIFs obtained from subdistribution hazard models) that exceeded 1. This phenomenon was avoided by using the two cause-specific hazard models. We provide a proof that the sum of predictions exceeds 1 is a fundamental problem with the Fine-Gray subdistribution hazard model. We further explored this issue using simulations based on two different types of data-generating process, one based on subdistribution hazard models and other based on cause-specific hazard models. We conclude that care should be taken when using the Fine-Gray subdistribution hazard model in situations with wide risk distributions or a high cumulative incidence, and if one is interested in the risk of failure from each of the different event types.},
  langid = {english},
  keywords = {competing-risk,cumulative-incidence-function,multiple-endpoints},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9023}
}

@article{aus21usi,
  title = {Using Fractional Polynomials and Restricted Cubic Splines to Model Non-Proportional Hazards or Time-Varying Covariate Effects in the {{Cox}} Regression Model},
  author = {Austin, Peter C. and Fang, Jiming and Lee, Douglas S.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9259},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9259},
  urldate = {2021-11-24},
  abstract = {The Cox proportional hazards model is used extensively in clinical and epidemiological research. A key assumption of this model is that of proportional hazards. A variable satisfies the proportional hazards assumption if the effect of that variable on the hazard function is constant over time. When the proportional hazards assumption is violated for a given variable, a common approach is to modify the model so that the regression coefficient associated with the given variable is assumed to be a linear function of time (or of log-time), rather than being constant or fixed. However, this is an unnecessarily restrictive assumption. We describe two different methods to allow a regression coefficient, and thus the hazard ratio, in a Cox model to vary as a flexible function of time. These methods use either fractional polynomials or restricted cubic splines to model the log-hazard ratio as a function of time. We illustrate the utility of these methods using data on 12 705 patients who presented to a hospital emergency department with a primary diagnosis of heart failure. We used a Cox model to assess the association between elevated cardiac troponin at presentation and the hazard of death after adjustment for an extensive set of covariates. SAS code for implementing the restricted cubic spline approach is provided, while an existing Stata function allows for the use of fractional polynomials.},
  langid = {english},
  keywords = {cox-model,fractional-polynomial,spline,tdc,time-dependent-effects},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9259}
}

@article{aus22gra,
  title = {Graphical Calibration Curves and the Integrated Calibration Index ({{ICI}}) for Competing Risk Models},
  author = {Austin, Peter C. and Putter, Hein and Giardiello, Daniele and van Klaveren, David},
  options = {useprefix=true},
  date = {2022-01-17},
  journaltitle = {Diagnostic and Prognostic Research},
  volume = {6},
  number = {1},
  pages = {2},
  issn = {2397-7523},
  doi = {10.1186/s41512-021-00114-6},
  url = {https://doi.org/10.1186/s41512-021-00114-6},
  urldate = {2022-01-19},
  abstract = {Assessing calibration—the agreement between estimated risk and observed proportions—is an important component of deriving and validating clinical prediction models. Methods for assessing the calibration of prognostic models for use with competing risk data have received little attention.},
  keywords = {Calibration,Competing risks,Model validation,Random forests,Survival analysis,Time-to-event model}
}

@article{aus82eff,
  title = {Effect of Myocardium at Risk on Outcome after Coronary Artery Occlusion and Release},
  author = {Austin, M. and Wenger, T. L. and Harrell FE, F. and Strauss, H. C.},
  date = {1982},
  journaltitle = {Am J Physiol},
  volume = {243},
  pages = {340--345},
  citeulike-article-id = {13263714},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@article{azz94log,
  title = {Logistic Regression for Autocorrelated Data with Application to Repeated Measures},
  author = {Azzalini, A.},
  date = {1994},
  journaltitle = {Biometrika},
  volume = {81},
  number = {4},
  eprint = {/oup/backfile/content\_public/journal/biomet/81/4/10.1093/biomet/81.4.767/2/81-4-767.pdf},
  pages = {767--775},
  doi = {10.1093/biomet/81.4.767},
  url = {+ http://dx.doi.org/10.1093/biomet/81.4.767},
  citeulike-article-id = {14413457},
  citeulike-attachment-1 = {azz94log.pdf; /pdf/user/harrelfe/article/14413457/1115540/azz94log.pdf; 756c07ab51f065630cc1f5ec267153565bdaa110},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/81.4.767},
  citeulike-linkout-1 = {+ http://dx.doi.org/10.1093/biomet/81.4.767},
  posted-at = {2017-08-12 22:56:09},
  priority = {2},
  keywords = {binary-logistic-model,correlated-binary-data,longitudinal-binary-data,markov-model,serial-data},
  note = {See section 3.1 where the authors imply that if there are gaps in measurements one can merely replace 1-step transition probabilities with gap-step probabilities.
\par
The paper's aim is to reparameterize the model so that an effect is on the unconditional (on previous times) probability Y=1.~ The author did not comment on the fact that one can use the simple parameterization and uncondition the estimates to get marginal quantities.}
}

@article{bac21how,
  title = {How to Choose a Time Zero for Patients in External Control Arms},
  author = {Backenroth, Daniel},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2107},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2107},
  urldate = {2021-03-05},
  abstract = {When a sponsor carries out a single-arm trial of a novel oncology compound, it may wish to assess the efficacy of the compound via comparison of overall survival to an external control arm, constructed using patients included in some retrospective registry. If efficacy of the novel compound is compared to efficacy of physician's choice of chemotherapy, patients in the retrospective registry might qualify for inclusion in the external control arm at multiple different points in time, when they receive different chemotherapy treatments. For example, a patient might qualify at the start of their second, third and fourth lines of therapy. From the start of which line of therapy should this patient's survival be compared to survival of participants in the single-arm trial? Some sponsors have elected to include patients in the external control arm from the last available line of therapy in the retrospective database. Another possibility is to randomly select a line of therapy for each external control arm patient from among those available. In this paper, we show, via probabilistic arguments and also via simulation based on real data, that both of these methods give rise to a bias in favor of the single-arm trial. We further show that this bias can be avoided by instead including external control arm patients multiple times in the external control arm, once for each time they receive qualifying treatment.},
  langid = {english},
  keywords = {ehr,observational-study,time-origin},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2107}
}

@article{bai06pre,
  title = {Prediction by Supervised Principal Components},
  author = {Bair, Eric and Hastie, Trevor and Paul, Debashis and Tibshirani, Robert},
  date = {2006},
  journaltitle = {J Am Stat Assoc},
  volume = {101},
  pages = {119--137},
  citeulike-article-id = {13265464},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  note = {supervised principal components;data reduction;screens variables for correlation with Y exceeding a threshold and does principal components on the remaining variables;compared to gene shaving and partial least squares;claimed that PLS did not perform as well}
}

@article{bai08ens,
  title = {Ensuring Trial Validity by Data Quality Assurance and Diversification of Monitoring Methods},
  author = {Baigent, C. and Harrell, F. E. and Buyse, M. and Emberson, J. R. and Altman, D. G.},
  date = {2008},
  journaltitle = {Clin Trials},
  volume = {5},
  pages = {49--55},
  citeulike-article-id = {13265651},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {clinical-trial-executing,data-quality,rct,trial-monitoring}
}

@article{bai77pro,
  title = {A Proposal for the Analysis of Kidney Graft Survival},
  author = {Bailey, R. C. and Homer, L. D. and Summe, J. P.},
  date = {1977},
  journaltitle = {Transplantation},
  volume = {24},
  pages = {309--315},
  citeulike-article-id = {13263715},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {non-proportional-hazards,parametric-survival-models}
}

@article{bai88gui,
  title = {Guidelines for Statistical Reporting in Articles in Medical Journals},
  author = {Bailar III, John C. and Mosteller, Frederick},
  date = {1988},
  journaltitle = {Ann Int Med},
  volume = {108},
  pages = {266--273},
  citeulike-article-id = {13263716},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {general,reporting,statistical-results,teaching-mds}
}

@article{bai95lar,
  title = {A Larger Perspective},
  author = {Bailar III, John C.},
  date = {1995},
  journaltitle = {Am Statistician},
  volume = {49},
  pages = {10--11},
  citeulike-article-id = {13263717},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {statistics-in-society,teaching-statisticians}
}

@book{bai95med,
  title = {Medical {{Uses}} of {{Statistics}}},
  author = {Bailar III, John C. and Mosteller, Frederick},
  date = {1995},
  edition = {Second},
  publisher = {{NEJM Books}},
  location = {{Boston}},
  citeulike-article-id = {13263718},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {general,teaching-mds}
}

@article{baj99non,
  title = {Nonparametric Two-Sample Comparisons of Changes on Ordinal Responses},
  author = {Bajorski, Peter and Petkau, John},
  date = {1999},
  journaltitle = {J Am Stat Assoc},
  volume = {94},
  pages = {970--978},
  citeulike-article-id = {13263719},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {change,ordinal},
  note = {analysis of change in ordinal response variable}
}

@article{bak14how,
  title = {How to Interpret a Small Increase in {{AUC}} with an Additional Risk Prediction Marker: Decision Analysis Comes Through},
  author = {Baker, Stuart G. and Schuit, Ewoud and Steyerberg, Ewout W. and Pencina, Michael J. and Vickers, Andew and Moons, Karel G. M. and Mol, Ben W. J. and Lindeman, Karen S.},
  date = {2014-09},
  journaltitle = {Stat Med},
  volume = {33},
  number = {22},
  pages = {3946--3959},
  doi = {10.1002/sim.6195},
  url = {http://dx.doi.org/10.1002/sim.6195},
  abstract = {An important question in the evaluation of an additional risk prediction marker is how to interpret a small increase in the area under the receiver operating characteristic curve (AUC). Many researchers believe that a change in AUC is a poor metric because it increases only slightly with the addition of a marker with a large odds ratio. Because it is not possible on purely statistical grounds to choose between the odds ratio and AUC, we invoke decision analysis, which incorporates costs and benefits. For example, a timely estimate of the risk of later non-elective operative delivery can help a woman in labor decide if she wants an early elective cesarean section to avoid greater complications from possible later non-elective operative delivery. A basic risk prediction model for later non-elective operative delivery involves only antepartum markers. Because adding intrapartum markers to this risk prediction model increases AUC by 0.02, we questioned whether this small improvement is worthwhile. A key decision-analytic quantity is the risk threshold, here the risk of later non-elective operative delivery at which a patient would be indifferent between an early elective cesarean section and usual care. For a range of risk thresholds, we found that an increase in the net benefit of risk prediction requires collecting intrapartum marker data on 68 to 124 women for every correct prediction of later non-elective operative delivery. Because data collection is non-invasive, this test tradeoff of 68 to 124 is clinically acceptable, indicating the value of adding intrapartum markers to the risk prediction model.},
  citeulike-article-id = {13325623},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6195},
  day = {30},
  posted-at = {2014-11-29 16:07:14},
  priority = {2},
  keywords = {c-index,clinical-decision-making,predictive-accuracy,roc-area}
}

@article{bak19max,
  title = {Maximum Likelihood Estimation with Missing Outcomes: {{From}} Simplicity to Complexity},
  shorttitle = {Maximum Likelihood Estimation with Missing Outcomes},
  author = {Baker, Stuart G.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {22},
  pages = {4453--4474},
  issn = {1097-0258},
  doi = {10.1002/sim.8319},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8319},
  urldate = {2019-09-08},
  abstract = {Many clinical or prevention studies involve missing or censored outcomes. Maximum likelihood (ML) methods provide a conceptually straightforward approach to estimation when the outcome is partially missing. Methods of implementing ML methods range from the simple to the complex, depending on the type of data and the missing-data mechanism. Simple ML methods for ignorable missing-data mechanisms (when data are missing at random) include complete-case analysis, complete-case analysis with covariate adjustment, survival analysis with covariate adjustment, and analysis via propensity-to-be-missing scores. More complex ML methods for ignorable missing-data mechanisms include the analysis of longitudinal dropouts via a marginal model for continuous data or a conditional model for categorical data. A moderately complex ML method for categorical data with a saturated model and either ignorable or nonignorable missing-data mechanisms is a perfect fit analysis, an algebraic method involving closed-form estimates and variances. A complex and flexible ML method with categorical data and either ignorable or nonignorable missing-data mechanisms is the method of composite linear models, a matrix method requiring specialized software. Except for the method of composite linear models, which can involve challenging matrix specifications, the implementation of these ML methods ranges in difficulty from easy to moderate.},
  langid = {english},
  keywords = {missing,mle,mle-with-missing-data}
}

@article{bak95eva,
  title = {Evaluating Multiple Diagnostic Tests with Partial Verification},
  author = {Baker, Stuart G.},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {330--337},
  citeulike-article-id = {13263720},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {diagnosis,verification-bias,workup-bias}
}

@article{bak99eco,
  title = {Economic Analysis in Clinical Trials: {{Practical}} Considerations},
  author = {Baker, Andrew M. and Arnold, Renée J. and Kaniecki, Diana J.},
  date = {1999},
  journaltitle = {Drug Info J},
  volume = {33},
  pages = {1053--1060},
  citeulike-article-id = {13263721},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {analysis-of-cost,cost-items,economics-in-clinical-trials,study-design}
}

@article{bal19bay,
  title = {Bayesian {{Causality}}},
  author = {Baldi, Pierre and Shahbaba, Babak},
  date = {2019-08-12},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--9},
  issn = {0003-1305},
  doi = {10.1080/00031305.2019.1647876},
  url = {https://doi.org/10.1080/00031305.2019.1647876},
  urldate = {2019-08-30},
  abstract = {Although no universally accepted definition of causality exists, in practice one is often faced with the question of statistically assessing causal relationships in different settings. We present a uniform general approach to causality problems derived from the axiomatic foundations of the Bayesian statistical framework. In this approach, causality statements are viewed as hypotheses, or models, about the world and the fundamental object to be computed is the posterior distribution of the causal hypotheses, given the data and the background knowledge. Computation of the posterior, illustrated here in simple examples, may involve complex probabilistic modeling but this is no different than in any other Bayesian modeling situation. The main advantage of the approach is its connection to the axiomatic foundations of the Bayesian framework, and the general uniformity with which it can be applied to a variety of causality settings, ranging from specific to general cases, or from causes of effects to effects of causes.},
  keywords = {bayes,causal-inference,causal-model,causality}
}

@article{bal97bou,
  title = {Bounds on Treatment Effects from Studies with Imperfect Compliance},
  author = {Balke, Alexander and Pearl, Judea},
  date = {1997},
  journaltitle = {J Am Stat Assoc},
  volume = {92},
  pages = {1171--1176},
  citeulike-article-id = {13263722},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {bound-on-treatment-effect,compliance,rct}
}

@article{bam75,
  title = {The Area above the Ordinal Dominance Graph and the Area below the Receiver Operating Characteristic Graph},
  author = {Bamber, D.},
  date = {1975},
  journaltitle = {J Mathe Psych},
  volume = {12},
  pages = {387--415},
  citeulike-article-id = {13263723},
  posted-at = {2014-07-14 14:09:21},
  priority = {0},
  keywords = {c-index,diagnosis,discrimination,roc,teaching-mds,wilcoxon-mann-whitney}
}

@article{ban00est,
  title = {Estimating Medical Costs with Censored Data},
  author = {Bang, Heejung and Tsiatis, Anastasios A.},
  date = {2000},
  journaltitle = {Biometrika},
  volume = {87},
  pages = {329--343},
  citeulike-article-id = {13265134},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {analysis-of-cost,censoring}
}

@article{ban02med,
  title = {Median Regression with Censored Cost Data},
  author = {Bang, Heejung and Tsiatis, Anastasios A.},
  date = {2002},
  journaltitle = {Biometrics},
  volume = {58},
  pages = {643--649},
  citeulike-article-id = {13265293},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {analysis-of-cost-data,censoring,cost-analysis,estimating-equation,median-regression,quantile-regression,simulated-annealing,survival-analysis}
}

@article{ban05per,
  title = {A Permutation Test Sensitive to Differences in Areas for Comparing {{ROC}} Curves from a Paired Design},
  author = {Bandos, Andriy I. and Rockette, Howard D. and Gur, David},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2873--2893},
  citeulike-article-id = {13265442},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {non-parametric,paired-design,permutation-test,roc-area}
}

@article{ban44bia,
  title = {On {{Biases}} in {{Estimation Due}} to the {{Use}} of {{Preliminary Tests}} of {{Significance}}},
  author = {Bancroft, T. A.},
  date = {1944},
  journaltitle = {The Annals of Mathematical Statistics},
  volume = {15},
  number = {2},
  eprint = {2236199},
  eprinttype = {jstor},
  pages = {190--204},
  issn = {0003-4851},
  keywords = {model-uncertainty,pre-test}
}

@incollection{ban85,
  title = {Nomograms},
  booktitle = {Encyclopedia of {{Statistical Sciences}}},
  author = {Banks, J.},
  editor = {Kotz, S. and Johnson, N. L.},
  date = {1985},
  volume = {6},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13263724},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@article{bar02ove,
  title = {Overall Concordance Correlation Coefficient for Evaluating Agreement among Multiple Observers},
  author = {Barnhart, Huiman X. and Haber, Michael and Song, Jingli},
  date = {2002},
  journaltitle = {Biometrics},
  volume = {58},
  pages = {1020--1027},
  citeulike-article-id = {13265302},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {agreement,cluster-bootstrap,gee,inter-observer-variability,observer-agreement,overall-concordance-coefficient,reproducibility,u-statistic},
  note = {problem with ordinary correlation coefficient; relation between overall index and weighted average of all pairwise indexes; confidence interval for index; multiple observers}
}

@article{bar04imp,
  title = {Imputations of Missing Values in Practice: {{Results}} from Imputations of Serum Cholesterol in 28 Cohort Studies},
  author = {Barzi, Federica and Woodward, Mark},
  date = {2004},
  journaltitle = {Am J Epi},
  volume = {160},
  pages = {34--45},
  citeulike-article-id = {13265381},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {bias,cholesterol,coronary-disease,hazard-rate,imputation,meta-analysis,missing-data,mortality,multiple-imputation,review},
  note = {excellent review article for multiple imputation;list of variables to include in imputation model;"Imputation models should ideally include all covariates that are related to the missing data mechanism, have distributions that differ between the respondents and nonrespondents, are associated with cholesterol, and will be included in the analyses of the final complete data sets";detailed comparison of results (cholesterol effect and confidence limits) for various imputation methods}
}

@article{bar06eva,
  title = {Evaluation of Sample Size and Power for Multi-Arm Survival Trials Allowing for Non-Uniform Accrual, Non-Proportional Hazards, Loss to Follow-up and Cross-Over},
  author = {{Barthel} and Babiker, A. and Royston, P. and Parmar, M. K. B.},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {2521--2542},
  doi = {10.1002/sim.2517},
  url = {http://dx.doi.org/10.1002/sim.2517},
  citeulike-article-id = {13265482},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2517},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {clinical-trials,non-ph,nonadherence,power,rct,sample-size,survival-analysis}
}

@article{bar06mul,
  title = {Multiple Imputation Techniques in Small Sample Clinical Trials},
  author = {Barnes, Sunni A. and Lindborg, Stacy R. and Seaman, John W.},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {233--245},
  citeulike-article-id = {13265457},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {locf,multiple-imputation,predictive-mean-matching},
  note = {bad performance of LOCF including high bias and poor confidence interval coverage;simulation setup;longitudinal data;serial data;RCT;dropout;assumed missing at random (MAR);approximate Bayesian bootstrap;Bayesian least squares;missing data;nice background summary;new completion score method based on fitting a Poisson model for the number of completed clinic visits and using donors and approximate Bayesian bootstrap}
}

@article{bar11ana,
  title = {The Analysis of Ordinal Time-Series Data via a Transition ({{Markov}}) Model},
  author = {Bartimote-Aufflick, Kathryn and Thomson, Peter C.},
  date = {2011-09-01},
  journaltitle = {Journal of Applied Statistics},
  volume = {38},
  number = {9},
  pages = {1883--1897},
  publisher = {{Taylor \& Francis}},
  issn = {0266-4763},
  doi = {10.1080/02664763.2010.529885},
  url = {https://doi.org/10.1080/02664763.2010.529885},
  urldate = {2021-01-03},
  abstract = {While standard techniques are available for the analysis of time-series (longitudinal) data, and for ordinal (rating) data, not much is available for the combination of the two, at least in a readily-usable form. However, this data type is common place in the natural and health sciences where repeated ratings are recorded on the same subject. To analyse these data, this paper considers a transition (Markov) model where the rating of a subject at one time depends explicitly on the observed rating at the previous point of time by incorporating the previous rating as a predictor variable. Complications arise with adequate handling of data at the first observation (t=1), as there is no prior observation to use as a predictor. To overcome this, it is postulated the existence of a rating at time t=0; however it is treated as ‘missing data’ and the expectation–maximisation algorithm used to accommodate this. The particular benefits of this method are shown for shorter time series.},
  keywords = {markov-model,ordinal,serial,transition-model},
  annotation = {\_eprint: https://doi.org/10.1080/02664763.2010.529885},
  note = {Imputation and E-M for handling missing first observation; does not cover other missings or irregular time points
\par
Emphasis of paper is on the case where the first observation of Y is a response, and one wants to impute the time zero state.
\par
Points to Diggle et al 2nd edition 2002 as primary reference for Markov ordinal models.
\par
Discusses interacting covariates with previous state but doesn't use that in their examples.}
}

@article{bar11ass,
  title = {Assessment of the {{Framingham}} Risk Factors among {{ED}} Patients with Newly Diagnosed Atrial Fibrillation},
  author = {Barrett, T. W. and Storrow, A. B. and Jenkins, C. A. and Harrell, F. E. and Amdahl, J. and Russ, S. and Slovis, C. M. and Darbar, D.},
  date = {2012-01},
  journaltitle = {Am J Emerg Med},
  volume = {30},
  number = {1},
  pages = {151--7},
  citeulike-article-id = {13265861},
  posted-at = {2014-07-14 14:10:06},
  priority = {0}
}

@article{bar11atr,
  title = {Atrial Fibrillation and Flutter Outcomes and Risk Determination ({{AFFORD}}): {{Design}} and Rationale},
  author = {Barrett, T. W. and Storrow, A. B. and Jenkins, C. A. and Harrell, F. E. and Miller, K. F. and Moser, K. M. and Russ, S. and Roden, D. M. and {Darbar}},
  date = {2011},
  journaltitle = {J Cardiology},
  volume = {58},
  pages = {124--130},
  doi = {10.1016/j.jjcc.2011.06.007},
  url = {http://dx.doi.org/10.1016/j.jjcc.2011.06.007},
  citeulike-article-id = {13265911},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jjcc.2011.06.007},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@article{bar11cli,
  title = {A Clinical Prediction Model to Estimate Risk for 30-Day Adverse Events in Emergency Department Patients with Symptomatic Atrial Fibrillation.},
  author = {Barrett, Tyler W. and Martin, Amy R. and Storrow, Alan B. and Jenkins, Cathy A. and Harrell, Frank E. and Russ, Stephan and Roden, Dan M. and Darbar, Dawood},
  date = {2011-01},
  journaltitle = {Ann Emerg Med},
  volume = {57},
  number = {1},
  pages = {1--12},
  doi = {10.1016/j.annemergmed.2010.05.031},
  url = {http://dx.doi.org/10.1016/j.annemergmed.2010.05.031},
  abstract = {Atrial fibrillation affects more than 2 million people in the United States and accounts for nearly 1\% of emergency department (ED) visits. Physicians have little information to guide risk stratification of patients with symptomatic atrial fibrillation and admit more than 65\%. Our aim is to assess whether data available in the ED management of symptomatic atrial fibrillation can estimate a patient's risk of experiencing a 30-day adverse event.We systematically reviewed the electronic medical records of all ED patients presenting with symptomatic atrial fibrillation between August 2005 and July 2008. Predefined adverse outcomes included 30-day ED return visit, unscheduled hospitalization, cardiovascular complication, or death. We performed multivariable logistic regression to identify predictors of 30-day adverse events. The model was validated with 300 bootstrap replications.During the 3-year study period, 914 patients accounted for 1,228 ED visits. Eighty patients were excluded for non-atrial-fibrillation-related complaints and 2 patients had no follow-up recorded. Of 832 eligible patients, 216 (25.9\%) experienced at least 1 of the 30-day adverse events. Increasing age (odds ratio [OR] 1.20 per decade; 95\% confidence interval [CI] 1.06 to 1.36 per decade), complaint of dyspnea (OR 1.57; 95\% CI 1.12 to 2.20), smokers (OR 2.35; 95\% CI 1.47 to 3.76), inadequate ventricular rate control (OR 1.58; 95\% CI 1.13 to 2.21), and patients receiving β-blockers (OR 1.44; 95\% CI 1.02 to 2.04) were independently associated with higher risk for adverse events. C-index was 0.67.In ED patients with symptomatic atrial fibrillation, increased age, inadequate ED ventricular rate control, dyspnea, smoking, and β-blocker treatment were associated with an increased risk of a 30-day adverse event.},
  citeulike-article-id = {13265812},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.annemergmed.2010.05.031},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {age-factors,aged,atrial-fibrillation,complications-diagnosis-therapy,emergency-service,female,hospital,humans,logistic-models,male,middle-aged,models,probability,retrospective-studies,risk-factors,sex-factors,statistics----numerical-data,theoretical,time-factors}
}

@article{bar15aff,
  title = {The {{AFFORD}} Clinical Decision Aid to Identify Emergency Department Patients with Atrial Fibrillation at Low Risk for 30-Day Adverse Events.},
  author = {Barrett, Tyler W. and Storrow, Alan B. and Jenkins, Cathy A. and Abraham, Robert L. and Liu, Dandan and Miller, Karen F. and Moser, Kelly M. and Russ, Stephan and Roden, Dan M. and Harrell, Frank E. and Darbar, Dawood},
  date = {2015-03},
  journaltitle = {Am J Cardio},
  volume = {115},
  number = {6},
  eprint = {25633190},
  eprinttype = {pmid},
  pages = {763--770},
  issn = {1879-1913},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25633190},
  abstract = {There is wide variation in the management of patients with atrial fibrillation (AF) in the emergency department (ED). We aimed to derive and internally validate the first prospective, ED-based clinical decision aid to identify patients with AF at low risk for 30-day adverse events. We performed a prospective cohort study at a university-affiliated tertiary-care ED. Patients were enrolled from June 9, 2010, to February 28, 2013, and followed for 30 days. We enrolled a convenience sample of patients in ED presenting with symptomatic AF. Candidate predictors were based on ED data available in the first 2 hours. The decision aid was derived using model approximation (preconditioning) followed by strong bootstrap internal validation. We used an ordinal outcome hierarchy defined as the incidence of the most severe adverse event within 30 days of the ED evaluation. Of 497 patients enrolled, stroke and AF-related death occurred in 13 (3\%) and 4 ({$<$}1\%) patients, respectively. The decision aid included the following: age, triage vitals (systolic blood pressure, temperature, respiratory rate, oxygen saturation, supplemental oxygen requirement), medical history (heart failure, home sotalol use, previous percutaneous coronary intervention, electrical cardioversion, cardiac ablation, frequency of AF symptoms), and ED data (2 hours heart rate, chest radiograph results, hemoglobin, creatinine, and brain natriuretic peptide). The decision aid's c-statistic in predicting any 30-day adverse event was 0.7 (95\% confidence interval 0.65, 0.76). In conclusion, in patients with AF in the ED, Atrial Fibrillation and Flutter Outcome Risk Determination provides the first evidence-based decision aid for identifying patients who are at low risk for 30-day adverse events and candidates for safe discharge. Copyright  2015 Elsevier Inc. All rights reserved.},
  citeulike-article-id = {14102491},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25633190},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25633190},
  day = {15},
  posted-at = {2016-07-26 21:18:56},
  priority = {2},
  keywords = {clinical-prediction-rule,collaboration,emergency-medicine-research}
}

@article{bar19com,
  title = {Comparative {{Accuracy}} of {{Diagnosis}} by {{Collective Intelligence}} of {{Multiple Physicians}} vs {{Individual Physicians}}},
  author = {Barnett, Michael L. and Boddupalli, Dhruv and Nundy, Shantanu and Bates, David W.},
  date = {2019-03-01},
  journaltitle = {JAMA Netw Open},
  volume = {2},
  number = {3},
  pages = {e190096-e190096},
  doi = {10.1001/jamanetworkopen.2019.0096},
  url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2726709},
  urldate = {2019-03-03},
  abstract = {{$<$}h3{$>$}Importance{$<$}/h3{$><$}p{$>$}The traditional approach of diagnosis by individual physicians has a high rate of misdiagnosis. Pooling multiple physicians’ diagnoses (collective intelligence) is a promising approach to reducing misdiagnoses, but its accuracy in clinical cases is unknown to date.{$<$}/p{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To assess how the diagnostic accuracy of groups of physicians and trainees compares with the diagnostic accuracy of individual physicians.{$<$}/p{$><$}h3{$>$}Design, Setting, and Participants{$<$}/h3{$><$}p{$>$}Cross-sectional study using data from the Human Diagnosis Project (Human Dx), a multicountry data set of ranked differential diagnoses by individual physicians, graduate trainees, and medical students (users) solving user-submitted, structured clinical cases. From May 7, 2014, to October 5, 2016, groups of 2 to 9 randomly selected physicians solved individual cases. Data analysis was performed from March 16, 2017, to July 30, 2018.{$<$}/p{$><$}h3{$>$}Main Outcomes and Measures{$<$}/h3{$><$}p{$>$}The primary outcome was diagnostic accuracy, assessed as a correct diagnosis in the top 3 ranked diagnoses for an individual; for groups, the top 3 diagnoses were a collective differential generated using a weighted combination of user diagnoses with a variety of approaches. A version of the McNemar test was used to account for clustering across repeated solvers to compare diagnostic accuracy.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Of the 2069 users solving 1572 cases from the Human Dx data set, 1228 (59.4\%) were residents or fellows, 431 (20.8\%) were attending physicians, and 410 (19.8\%) were medical students. Collective intelligence was associated with increasing diagnostic accuracy, from 62.5\% (95\% CI, 60.1\%-64.9\%) for individual physicians up to 85.6\% (95\% CI, 83.9\%-87.4\%) for groups of 9 (23.0\% difference; 95\% CI, 14.9\%-31.2\%;\emph{P} \&lt; .001). The range of improvement varied by the specifications used for combining groups’ diagnoses, but groups consistently outperformed individuals regardless of approach. Absolute improvement in accuracy from individuals to groups of 9 varied by presenting symptom from an increase of 17.3\% (95\% CI, 6.4\%-28.2\%;\emph{P} = .002) for abdominal pain to 29.8\% (95\% CI, 3.7\%-55.8\%;\emph{P} = .02) for fever. Groups from 2 users (77.7\% accuracy; 95\% CI, 70.1\%-84.6\%) to 9 users (85.5\% accuracy; 95\% CI, 75.1\%-95.9\%) outperformed individual specialists in their subspecialty (66.3\% accuracy; 95\% CI, 59.1\%-73.5\%;\emph{P} \&lt; .001 vs groups of 2 and 9).{$<$}/p{$><$}h3{$>$}Conclusions and Relevance{$<$}/h3{$><$}p{$>$}A collective intelligence approach was associated with higher diagnostic accuracy compared with individuals, including individual specialists whose expertise matched the case diagnosis, across a range of medical cases. Given the few proven strategies to address misdiagnosis, this technique merits further study in clinical settings.{$<$}/p{$>$}},
  langid = {english},
  keywords = {accuracy,diagnosis,diagnostic-accuracy,predictive-accuracy,teaching-mds}
}

@article{bar19dep,
  title = {Dependence Modeling for Recurrent Event Times Subject to Right-Censoring with {{D-vine}} Copulas},
  author = {Barthel, Nicole and Geerdens, Candida and Czado, Claudia and Janssen, Paul},
  date = {2019},
  journaltitle = {Biometrics},
  volume = {75},
  number = {2},
  pages = {439--451},
  issn = {1541-0420},
  doi = {10.1111/biom.13014},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13014},
  urldate = {2019-08-30},
  abstract = {In many time-to-event studies, the event of interest is recurrent. Here, the data for each sample unit correspond to a series of gap times between the subsequent events. Given a limited follow-up period, the last gap time might be right-censored. In contrast to classical analysis, gap times and censoring times cannot be assumed independent, i.e., the sequential nature of the data induces dependent censoring. Also, the number of recurrences typically varies among sample units leading to unbalanced data. To model the association pattern between gap times, so far only parametric margins combined with the restrictive class of Archimedean copulas have been considered. Here, taking the specific data features into account, we extend existing work in several directions: we allow for nonparametric margins and consider the flexible class of D-vine copulas. A global and sequential (one- and two-stage) likelihood approach are suggested. We discuss the computational efficiency of each estimation strategy. Extensive simulations show good finite sample performance of the proposed methodology. It is used to analyze the association of recurrent asthma attacks in children. The analysis reveals that a D-vine copula detects relevant insights, on how dependence changes in strength and type over time.},
  langid = {english},
  keywords = {censoring,copula,recurrent-events}
}

@article{bar77,
  title = {Comparitive Step-up and Composite Tests for Selecting Prognostic Indicators Associated with Survival},
  author = {Bartolucci, A. A. and Fraser, M. D.},
  date = {1977},
  journaltitle = {Biometrical J},
  volume = {19},
  pages = {437--448},
  citeulike-article-id = {13263726},
  posted-at = {2014-07-14 14:09:21},
  priority = {0}
}

@book{bar82com,
  title = {Comparative {{Statistical Inference}}},
  author = {Barnett, V.},
  date = {1982},
  edition = {Second},
  publisher = {{Wiley}},
  citeulike-article-id = {13263727},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,comparison,prior},
  note = {This is a nice comparative account of frequentist and Bayesian methods. In particular, it contains a chapter on the various approaches to prior specification}
}

@article{bar88,
  title = {Residuals for Relative Risk Regression},
  author = {Barlow, W. E. and Prentice, R. L.},
  date = {1988},
  journaltitle = {Biometrika},
  volume = {75},
  pages = {65--74},
  citeulike-article-id = {13263728},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model,testing-proportional-hazards}
}

@article{bar89typ,
  title = {Type {{A}} Behavior and Survival: {{A}} Follow-up Study of 1,467 Patients with Coronary Artery Disease},
  author = {Barefoot, J. C. and Peterson, B. L. and Harrell, F. E. and Hlatky, M. A. and Pryor, D. B. and Haney, T. L. and Blumenthal, J. A. and Siegler, I. C. and Williams, R. B.},
  date = {1989},
  journaltitle = {Am J Card},
  volume = {64},
  pages = {427--432},
  citeulike-article-id = {13263729},
  posted-at = {2014-07-14 14:09:22},
  priority = {0}
}

@article{bar99sma,
  title = {Small-Sample Degrees of Freedom with Multiple Imputation},
  author = {Barnard, John and Rubin, Donald B.},
  date = {1999},
  journaltitle = {Biometrika},
  volume = {86},
  pages = {948--955},
  citeulike-article-id = {13265090},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  note = {improved t-distribution d.f. after multiple imputation}
}

@article{bau08ada,
  title = {Adaptive Designs: {{Looking}} for a Needle in the Haystack: {{A}} New Challenge in Medical Research},
  author = {Bauer, Peter},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {1565--1580},
  citeulike-article-id = {13265673},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {adaptive-design,false-discovery-rate,feasibility,large-number-of-hypotheses,optimality,pilot-designs,prediction-scores,weighting},
  note = {many sample size reestimation procedures violate the sufficiency principle and weight different observations differently;absurd results can be obtained, e.g., rejecting the test while the overall mean has the wrong sign;nice review}
}

@article{bau10dis,
  title = {Discovery of Complex Pathways from Observational Data},
  author = {Baurley, James W. and Conti, David V. and Gauderman, James and Thomas, Duncan C.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  number = {19},
  pages = {1998--2011},
  citeulike-article-id = {13265864},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {discovery,pathways,topology}
}

@article{bea96mul,
  title = {Multi-Level Models for Repeated Measurement Data: {{Application}} to Quality of Life Data in Clinical Trials},
  author = {Beacon, Heather J. and Thompson, Simon G.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2717--2732},
  citeulike-article-id = {13263730},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {hierarchical-models,multi-level-models,quality-of-life,random-effects,repeated-measurements}
}

@article{beb18pro,
  title = {Properties of Composite Time to First Event versus Joint Marginal Analyses of Multiple Outcomes},
  author = {Ionut, Bebu and John, Lachin},
  journaltitle = {Stat Med},
  volume = {0},
  number = {0},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7849},
  doi = {10.1002/sim.7849},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7849},
  abstract = {Many clinical studies (eg, cardiovascular outcome trials) investigate the effect of an intervention on multiple event time outcomes. The most common method of analysis is a so-called ” composite” analysis of a composite outcome defined as the time to the first component event. Other approaches have been proposed, including the win ratio (or win difference) for ordered outcomes and the application of the Wei-Lachin test. Herein, we assess the influence of the marginal and joint distributions of the component events, and their correlation structures, on the operating characteristics of these methods for the analysis of multiple events. The operating characteristics are investigated using a bivariate exponential model with a shared frailty, under which these properties are obtained in closed form. While the composite time-to-first-event analysis provides an unbiased test of the hypothesis of equality of the distribution of the time to first event, we show that it can provide a biased test of the joint null hypothesis of equal marginal hazards when the correlation of event times differs between groups. The same applies to the win ratio. However, the operating characteristics of the Wei-Lachin or other tests of the joint equality of the marginal hazards are unaffected. Furthermore, when the correlations are equal, the Wei-Lachin test is more powerful to detect a difference in marginal hazards than the composite analysis test. Careful consideration of the properties of the various methods for analysis of composite outcome measures are in order before adopting one as primary analysis in a clinical study.},
  citeulike-article-id = {14609539},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7849},
  citeulike-linkout-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7849},
  posted-at = {2018-06-30 01:32:12},
  priority = {3},
  keywords = {composite-endpoints,multiple-endpoints,rct},
  note = {win ratio; time to first event test is biased when correlation of event times differs between groups}
}

@article{bec87,
  title = {Analysis of Data from The},
  author = {Becker, R. A. and {Denby} and McGill, R. and Wilks, A. R.},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {169--186},
  citeulike-article-id = {13263731},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {distribution-free-methods,function-optimization}
}

@article{bec87dyn,
  title = {Dynamic Graphics for Data Analysis ({{C}}/{{R}}: P383-395)},
  author = {Becker, Richard A. and Cleveland, William S. and Wilks, Allan R.},
  date = {1987},
  journaltitle = {Stat Sci},
  volume = {2},
  pages = {355--383},
  citeulike-article-id = {13263732},
  posted-at = {2014-07-14 14:09:22},
  priority = {0}
}

@article{bec92con,
  title = {The Concept of Residual Confounding in Regression Models and Some Applications},
  author = {Belcher, Heiko},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1747--1758},
  citeulike-article-id = {13263733},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {categorizing-continuous-variables,confounding,cutpoints,information-loss,teaching-mds}
}

@article{bed19dat,
  title = {Data Reduction Prior to Inference: {{Are}} There Consequences of Comparing Groups Using a t-Test Based on Principal Component Scores?},
  shorttitle = {Data Reduction Prior to Inference},
  author = {Bedrick, Edward J.},
  date = {2019},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13159},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13159},
  urldate = {2019-11-16},
  abstract = {Researchers often use a two-step process to analyze multivariate data. First, dimensionality is reduced using a technique such as principal component analysis, followed by a group comparison using a t-test or analysis of variance. Although this practice is often discouraged, the statistical properties of this procedure are not well understood, starting with the hypothesis being tested. We suggest that this approach might be considering two distinct hypotheses, one of which is a global test of no differences in the mean vectors, and the other being a focused test of a specific linear combination where the coefficients have been estimated from the data. We study the asymptotic properties of the two-sample t-statistic for these two scenarios, assuming a nonsparse setting. We show that the size of the global test agrees with the presumed level but that the test has poor power. In contrast, the size of the focused test can be arbitrarily distorted with certain mean and covariance structures. A simple method is provided to correct the size of the focused test. Data analyses and simulations are used to illustrate the results. Recommendations on the use of this two-step method and the related use of principal components for prediction are provided.},
  langid = {english},
  keywords = {data-reduction,pca},
  note = {t-test on PC1}
}

@article{bed96new,
  title = {A New Perspective on Priors for Generalized Linear Models},
  author = {Bedrick, Edward J. and Christensen, Ronald and Johnson, Wesley},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {1450--1460},
  citeulike-article-id = {13263734},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,choice-of-prior-distribution,conditional-mean-priors,data-augmentation}
}

@article{bed97bay,
  title = {Bayesian Binomial Regression: {{Predicting}} Survival at a Trauma Center},
  author = {Bedrick, Edward J. and Christensen, Ronald and Johnson, Wesley},
  date = {1997},
  journaltitle = {Am Statistician},
  volume = {51},
  pages = {211--218},
  citeulike-article-id = {13263735},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,case-deletion-of-augmented-prior-data-to-analyze-sensitivity-to-choice-of-prior,choice-of-prior,conditional-mean-priors,data-augmentation,logistic-model,simulation-of-posterior}
}

@article{bee20eme,
  title = {The Emerging Landscape of Health Research Based on Biobanks Linked to Electronic Health Records: {{Existing}} Resources, Statistical Challenges, and Potential Opportunities},
  shorttitle = {The Emerging Landscape of Health Research Based on Biobanks Linked to Electronic Health Records},
  author = {Beesley, Lauren J. and Salvatore, Maxwell and Fritsche, Lars G. and Pandit, Anita and Rao, Arvind and Brummett, Chad and Willer, Cristen J. and Lisabeth, Lynda D. and Mukherjee, Bhramar},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8445},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8445},
  urldate = {2019-12-20},
  abstract = {Biobanks linked to electronic health records provide rich resources for health-related research. With improvements in administrative and informatics infrastructure, the availability and utility of data from biobanks have dramatically increased. In this paper, we first aim to characterize the current landscape of available biobanks and to describe specific biobanks, including their place of origin, size, and data types. The development and accessibility of large-scale biorepositories provide the opportunity to accelerate agnostic searches, expedite discoveries, and conduct hypothesis-generating studies of disease-treatment, disease-exposure, and disease-gene associations. Rather than designing and implementing a single study focused on a few targeted hypotheses, researchers can potentially use biobanks' existing resources to answer an expanded selection of exploratory questions as quickly as they can analyze them. However, there are many obvious and subtle challenges with the design and analysis of biobank-based studies. Our second aim is to discuss statistical issues related to biobank research such as study design, sampling strategy, phenotype identification, and missing data. We focus our discussion on biobanks that are linked to electronic health records. Some of the analytic issues are illustrated using data from the Michigan Genomics Initiative and UK Biobank, two biobanks with two different recruitment mechanisms. We summarize the current body of literature for addressing these challenges and discuss some standing open problems. This work complements and extends recent reviews about biobank-based research and serves as a resource catalog with analytical and practical guidance for statisticians, epidemiologists, and other medical researchers pursuing research using biobanks.},
  langid = {english},
  keywords = {ehr}
}

@article{beg00use,
  title = {On the Use of Surrogate End Points in Randomized Trials (with Discussion)},
  author = {Begg, Colin B. and Leung, Denis H. Y.},
  date = {2000},
  journaltitle = {J Roy Stat Soc A},
  volume = {163},
  pages = {15--28},
  citeulike-article-id = {13265107},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {problems-with-prentice-criterion,problems-with-using-estimated-risk-as-and-endpoint,rct,surrogate-endpoint}
}

@article{beg90sig,
  title = {Significance Tests of Covariate Imbalance in Clinical Trials},
  author = {Begg, C. B.},
  date = {1990},
  journaltitle = {Controlled Clin Trials},
  volume = {11},
  pages = {223--225},
  citeulike-article-id = {13263736},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {baseline-imbalance,rct}
}

@article{beg96imp,
  title = {Improving the Quality of Reporting of Randomized Controlled Trials. {{The Consort}} Statement},
  author = {Begg, C. and Cho, M. and Eastwook, S. and Horton, R. and Moher, D. and Olkin, I. and {Em Et Al}},
  date = {1996},
  journaltitle = {JAMA},
  volume = {276},
  pages = {637--639},
  citeulike-article-id = {13263737},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {clinical-trials,rct,reporting,statistical-results,teaching-mds}
}

@article{bel21det,
  title = {The Detailed Clinical Objectives Approach to Designing Clinical Trials and Choosing Estimands},
  author = {Bell, James and Hamilton, Alan and Sailer, Oliver and Voss, Florian},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2129},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2129},
  urldate = {2021-05-20},
  abstract = {Objective setting is a necessary early step in the development of a clinical trial. ICH E9(R1) notes that the clinical objectives of a trial lead directly to the choice of estimands but barely discusses objectives themselves. Indeed, there is very little guidance anywhere in literature about objectives in clinical trials. This article identifies the substantial overlap between description of estimands and high quality definitions of objectives. It consequently shows that the estimand is decided by the precise choice of trial objective, and that therefore estimand decisions should be made at the objective level. The Detailed Clinical Objectives approach is proposed to support this. It emphasises clarity, specificity and a clinical focus when choosing and documenting objectives. Template text and examples are included to provide guidance on how it can be used in real trials. Finally, we describe objective-driven trial design, emphasising how strong objective setting establishes an important foundation for rigorous trial design discussions, logistical and operational decision-making during trial preparations, and clear communication of results and conclusions at the end of the trial. Highlighting the distinctions between objectives and estimands, we note how an objective-based framework can build on the ICH E9(R1) estimand framework to address many of its unanswered questions.},
  langid = {english},
  keywords = {design,endpoints,estimand,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2129}
}

@book{bel80,
  title = {Regression {{Diagnostics}}: {{Identifying Influential Data}} and {{Sources}} of {{Collinearity}}},
  author = {Belsley, D. A. and Kuh, E. and Welsch, R. E.},
  date = {1980},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13263738},
  posted-at = {2014-07-14 14:09:22},
  priority = {0}
}

@book{bel91con,
  title = {Conditioning {{Diagnostics}}: {{Collinearity}} and {{Weak Data}} in {{Regression}}},
  author = {Belsley, David A.},
  date = {1991},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13263739},
  posted-at = {2014-07-14 14:09:22},
  priority = {0}
}

@article{ben00cal,
  title = {Calculating Ordinal Regression Models in {{SAS}} and {{S-Plus}}},
  author = {Bender, Ralf and Benner, Axel},
  date = {2000},
  journaltitle = {Biometrical J},
  volume = {42},
  pages = {677--699},
  citeulike-article-id = {13265258},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {continuation-ratio-model,cr,ordinal-regression,ordinal-response,po,proportional-odds-model,r,review},
  note = {extensive use of Design library}
}

@article{ben05gen,
  title = {Generating Survival Times to Simulate {{Cox}} Proportional Hazards Models},
  author = {Bender, Ralf and Augustin, Thomas and Blettner, Maria},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {1713--1723},
  citeulike-article-id = {13265424},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {censoring,cox-model,simulating-survival-times,simulation-setup},
  annotation = {errata 25:1978-1979}
}

@article{ben12aga,
  title = {Against Quantiles: Categorization of Continuous Variables in Epidemiologic Research, and Its Discontents},
  author = {Bennette, Caroline and Vickers, Andrew},
  date = {2012-02},
  journaltitle = {BMC Med Res Methodol},
  volume = {12},
  number = {1},
  eprint = {22375553},
  eprinttype = {pmid},
  pages = {21+},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-12-21},
  url = {http://dx.doi.org/10.1186/1471-2288-12-21},
  abstract = {Quantiles are a staple of epidemiologic research: in contemporary epidemiologic practice, continuous variables are typically categorized into tertiles, quartiles and quintiles as a means to illustrate the relationship between a continuous exposure and a binary outcome. In this paper we argue that this approach is highly problematic and present several potential alternatives. We also discuss the perceived drawbacks of these newer statistical methods and the possible reasons for their slow adoption by epidemiologists. The use of quantiles is often inadequate for epidemiologic research with continuous variables.},
  citeulike-article-id = {10398554},
  citeulike-attachment-1 = {ben12aga.pdf; /pdf/user/harrelfe/article/10398554/1105032/ben12aga.pdf; 30d8b922169fca1fda79552f2539c4c5b4a6a32f},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2288-12-21},
  citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3353173/},
  citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22375553},
  citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22375553},
  day = {29},
  pmcid = {PMC3353173},
  posted-at = {2017-03-18 15:24:49},
  priority = {0},
  keywords = {categorization,cutpoints,dichotomization,epidemiology,teaching-mds},
  note = {terrific graphical examples; nice display of outcome heterogeneity within quantile groups of PSA}
}

@article{ben18gen,
  title = {A {{Gentle Introduction}} to the {{Comparison Between Null Hypothesis Testing}} and {{Bayesian Analysis}}: {{Reanalysis}} of {{Two Randomized Controlled Trials}}},
  shorttitle = {A {{Gentle Introduction}} to the {{Comparison Between Null Hypothesis Testing}} and {{Bayesian Analysis}}},
  author = {Bendtsen, Marcus},
  date = {2018},
  journaltitle = {Journal of Medical Internet Research},
  volume = {20},
  number = {10},
  pages = {e10873},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/10873},
  url = {https://www.jmir.org/2018/10/e10873/},
  urldate = {2020-03-16},
  abstract = {The debate on the use and misuse of  P  values has risen and fallen throughout their almost century-long existence in scientific discovery. Over the past few years, the debate has again received front-page attention, particularly through the public reminder by the American Statistical Association on how  P  values should be used and interpreted. At the core of the issue lies a fault in the way that scientific evidence is dichotomized and research is subsequently reported, and this fault is exacerbated by researchers giving license to statistical models to do scientific inference. This paper highlights a different approach to handling the evidence collected during a randomized controlled trial, one that does not dichotomize, but rather reports the evidence collected. Through the use of a coin flipping experiment and reanalysis of real-world data, the traditional approach of testing null hypothesis significance is contrasted with a Bayesian approach. This paper is meant to be understood by those who rely on statistical models to draw conclusions from data, but are not statisticians and may therefore not be able to grasp the debate that is primarily led by statisticians.  [J Med Internet Res 2018;20(10):e10873]},
  langid = {english},
  keywords = {bayes,teaching,teaching-mds},
  note = {Using priors forces us to be more specific and explicit about what we mean when we say that something is unknown... the Bayesian approach does not attempt to identify a fixed value for the parameters and dichotomize the world into significant and nonsignificant, but rather relies on the researcher to do the scientific inference and not to delegate this obligation to the statistical model... the NHST approach is rooted in the idea of being able to redo the experiment many times (so as to get a sampling distribution).~ Even if we can rely on theoretical results to get this sampling distribution without actually going back in time and redoing the experiment, the underlying idea can be somewhat problematic.~ What do we mean by redoing an experiment? Can we redo a randomized controlled trial while keeping all things equal and recruiting a new sample from the study population?... Once we remove ourselves from the dichotomization of evidence, other things start to take precedence: critically assessing the models chosen, evaluating the quality of the data, interpreting the real-world impact of the results, etc.}
}

@article{ben20imp,
  title = {Improving {{Precision}} and {{Power}} in {{Randomized Trials}} for {{COVID-19 Treatments Using Covariate Adjustment}}, for {{Binary}}, {{Ordinal}}, and {{Time-to-Event Outcomes}}},
  author = {Benkeser, David and Díaz, Iván and Luedtke, Alex and Segal, Jodi and Scharfstein, Daniel and Rosenblum, Michael},
  date = {2020-06-11},
  journaltitle = {medRxiv},
  eprint = {32577668},
  eprinttype = {pmid},
  doi = {10.1101/2020.04.19.20069922},
  abstract = {Time is of the essence in evaluating potential drugs and biologics for the treatment and prevention of COVID-19. There are currently over 400 clinical trials (phase 2 and 3) of treatments for COVID-19 registered on clinicaltrials.gov. Covariate adjustment is a statistical analysis method with potential to improve precision and reduce the required sample size for a substantial number of these trials. Though covariate adjustment is recommended by the U.S. Food and Drug Administration and the European Medicines Agency, it is underutilized, especially for the types of outcomes (binary, ordinal and time-to-event) that are common in COVID-19 trials. To demonstrate the potential value added by covariate adjustment in this context, we simulated two-arm, randomized trials comparing a hypothetical COVID-19 treatment versus standard of care, where the primary outcome is binary, ordinal, or time-to-event. Our simulated distributions are derived from two sources: longitudinal data on over 500 patients hospitalized at Weill Cornell Medicine New York Presbyterian Hospital, and a Centers for Disease Control and Prevention (CDC) preliminary description of 2449 cases. We found substantial precision gains from using covariate adjustment--equivalent to 9-21\% reductions in the required sample size to achieve a desired power--for a variety of estimands (targets of inference) when the trial sample size was at least 200. We provide an R package and practical recommendations for implementing covariate adjustment. The estimators that we consider are robust to model misspecification.},
  langid = {english},
  pmcid = {PMC7302221}
}

@article{ben21fir,
  title = {The First-Order {{Markov}} Conditional Linear Expectation Approach for Analysis of Longitudinal Data},
  author = {Bender, Shaun and Gamerman, Victoria and Reese, Peter P. and Gray, Daniel Lloyd and Li, Yimei and Shults, Justine},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8883},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8883},
  urldate = {2021-02-12},
  abstract = {We consider longitudinal discrete data that may be unequally spaced in time and may exhibit overdispersion, so that the variance of the outcome variable is inflated relative to its assumed distribution. We implement an approach that extends generalized linear models for analysis of longitudinal data and is likelihood based, in contrast to generalized estimating equations (GEE) that are semiparametric. The method assumes independence between subjects; first-order antedependence within subjects; exponential family distributions for the first outcome on each subject and for the subsequent conditional distributions; and linearity of the expectations of the conditional distributions. We demonstrate application of the method in an analysis of seizure counts and in a study to evaluate the performance of transplant centers. Simulations for both studies demonstrate the benefits of the proposed likelihood based approach; however, they also demonstrate better than anticipated performance for GEE.},
  langid = {english},
  keywords = {autoregressive-correlation-structure,gee,markov,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8883}
}

@article{ben82eff,
  title = {Effective Sample Size for Tests of Censored Survival Data},
  author = {Benedetti, Jacqueline K. and Liu, Ping-Yu and Sather, Harland N. and Seinfeld, Jack and Epton, Michael A.},
  date = {1982},
  journaltitle = {Biometrika},
  volume = {69},
  pages = {343--349},
  citeulike-article-id = {13263740},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {censored-data,general,sample-size}
}

@article{ben82effa,
  title = {Effective Sample Size for Tests of Censored Survival Data},
  author = {BENEDETTI, JACQUELINE K. and LIU, PING-YU and SATHER, HARLAND N. and SEINFELD, JACK and EPTON, MICHAEL A.},
  date = {1982-08-01},
  journaltitle = {Biometrika},
  volume = {69},
  number = {2},
  pages = {343--349},
  issn = {0006-3444},
  doi = {10.1093/biomet/69.2.343},
  url = {https://doi.org/10.1093/biomet/69.2.343},
  urldate = {2022-03-17},
  abstract = {When survival experience of two groups is compared in the presence of arbitrary right censoring, the effective sample size for determining the power of the test used is usually taken to be the number of uncensored observations. This convention is examined through a Monte Carlo study. Empirical powers of the generalized Savage test and generalized Wilcoxon test with uncensored data are compared to those with censored data containing approximately the same number of uncensored observations. Large sample relative efficiencies are calculated for a Lehmann family of alternatives. It is shown that, depending on the underlying distribution and censoring mechanism, censored observations can add appreciably to the power of either test.},
  keywords = {effective-sample-size,survival}
}

@article{ben95cov,
  title = {Covariance Structure Analysis: {{Statistical}} Practice, Theory, Directions},
  author = {Bentler, P. M. and Dodgeon, P.},
  date = {1995},
  journaltitle = {Ann Rev Psychol},
  volume = {47},
  pages = {541--570},
  citeulike-article-id = {13263741},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {distribution-free-structural-equation-models,may-be-1996}
}

@article{ber01ada,
  title = {Adaptive Trials and {{Bayesian}} Statistics in Drug Development (with Discussion)},
  author = {Berry, Donald A.},
  date = {2001},
  journaltitle = {Biopharm Rep ASA},
  volume = {9},
  number = {2},
  pages = {1--11},
  citeulike-article-id = {13265268},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {adaptive-design,bayesian-methods,drug-development,play-the-winner,rct,seamless-designs},
  note = {excellent motivation for use of Bayesian methods in clinical trials;seamless Phase II-Phase II trials; comments by Chi, Hung, O'Neill;trial vs. process;holdup from using more adaptive designs is more due to logistics/blinding than to frequentist methods (from discussants)}
}

@article{ber02imp,
  title = {Improving the Information Content of Categorical Clinical Trial Endpoints},
  author = {Berger, Vance W.},
  date = {2002},
  journaltitle = {Controlled Clin Trials},
  volume = {23},
  pages = {502--514},
  citeulike-article-id = {13265294},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {binary-endpoint,composite-endpoint,fusability-of-outcomes,multiple-endpoints,multiple-outcomes,rct,study-design}
}

@article{ber04acc,
  title = {Accounting for Multiplicities in Assessing Drug Safety: {{A}} Three-Level Hierarchical Mixture Model},
  author = {Berry, Scott M. and Berry, Donald A.},
  date = {2004},
  journaltitle = {Biometrics},
  volume = {60},
  pages = {418--426},
  citeulike-article-id = {13265378},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {clinical-safety,drug-safety-analysis,mixture-model,multiple-comparisons,pharmaceutical-safety,pharmaceutical-trial,rct},
  note = {borrowing information within organ system and across organ systems;AEs;adverse events;talk given studying this method at JSM2004 by jayanti\_gupta@merck.com}
}

@article{ber04bay,
  title = {Bayesian {{Statistics}} and the {{Efficiency}} and {{Ethics}} of {{Clinical Trials}}},
  author = {Berry, Donald A.},
  date = {2004-02},
  journaltitle = {Statist. Sci.},
  volume = {19},
  number = {1},
  pages = {175--187},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/088342304000000044},
  url = {https://projecteuclid.org/euclid.ss/1089808281},
  urldate = {2019-12-21},
  abstract = {The Bayesian approach is being used increasingly in medical research. The flexibility of the Bayesian approach allows for building designs of clinical trials that have good properties of any desired sort. Examples include maximizing effective treatment of patients in the trial, maximizing information about the slope of a dose–response curve, minimizing costs, minimizing the number of patients treated, minimizing the length of the trial and combinations of these desiderata. They also include standard frequentist operating characteristics when these are important considerations. Posterior probabilities are updated via Bayes’ theorem on the basis of accumulating data. These are used to effect modifications of the trial’s course, including stopping accrual, extending accrual beyond that originally planned, dropping treatment arms, adding arms, etc. An important aspect of the approach I advocate is modeling the relationship between a trial’s primary endpoint and early indications of patient performance—auxiliary endpoints. This has several highly desirable consequences. One is that it improves the efficiency of adaptive trials because information is available sooner than otherwise.},
  langid = {english},
  mrnumber = {MR2086326},
  zmnumber = {1057.62096},
  keywords = {adaptive,bayes,ethics,rct,sequential}
}

@article{ber06bay,
  title = {Bayesian Clinical Trials},
  author = {Berry, Donald A.},
  date = {2006},
  journaltitle = {Nat Rev},
  volume = {5},
  pages = {27--36},
  citeulike-article-id = {13265478},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {bayesian-methods,rct,review,teaching-mds},
  annotation = {Editorial, p. 3},
  note = {excellent review of Bayesian approaches in clinical trials; "The greatest virtue of the traditional approach may be its extreme rigour and narrowness of focus to the experiment at hand, but a side effect of this virtue is inflexibility, which in turn limits innovation in the design and analysis of clinical trials. ... The set of `other possible results' depends on the experimental design. ... Everything that is known is taken as given and all probabilities are calculated conditionally on known values. ... in contrast to the frequentist approach, only the probabilities of the observed results matter. ... The continuous learning that is possible in the Bayesian approach enables investigators to modify trials in midcourse. ... it is possible to learn from small samples, depending on the results, ... it is possible to adapt to what is learned to enable better treatment of patients. ... subjectivity in prior distributions is explicit and open to examination (and critique) by all. ... The Bayesian approach has several advantages in drug development. One is the process of updating knowledge gradually rather than restricting revisions in study design to large, discrete steps measured in trials or phases."}
}

@article{ber07bag,
  title = {The Bagged Median and the Bagged Mean},
  author = {Berrendero, J. R.},
  date = {2007},
  journaltitle = {Am Statistician},
  volume = {61},
  number = {4},
  pages = {325--330},
  citeulike-article-id = {13265642},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {bagging,bootstrap,breakdown-point,hodges-lehmann-estimate,robustness},
  note = {use of size of samples with replacement as tuning constant for efficiency vs. robustness}
}

@article{ber08usi,
  title = {Using Tensor Product Splines in Modeling Exposure--Time--Response Relationships: {{Application}} to the {{Colorado Plateau Uranium Miners}} Cohort},
  author = {Berhane, Kiros and Hauptmann, Michael and Langholz, Bryan},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {5484--5496},
  citeulike-article-id = {13265712},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {latency,nested-case-control,occupational-exposure,relative-risk,tensor-spline},
  note = {discusses taking product of all univariate spline basis functions}
}

@article{ber17int,
  title = {Interrupted Time Series Regression for the Evaluation of Public Health Interventions: A Tutorial},
  shorttitle = {Interrupted Time Series Regression for the Evaluation of Public Health Interventions},
  author = {Bernal, James Lopez and Cummins, Steven and Gasparrini, Antonio},
  date = {2017-02-01},
  journaltitle = {International Journal of Epidemiology},
  volume = {46},
  number = {1},
  pages = {348--355},
  issn = {0300-5771},
  doi = {10.1093/ije/dyw098},
  url = {https://doi.org/10.1093/ije/dyw098},
  urldate = {2021-04-18},
  abstract = {Interrupted time series (ITS) analysis is a valuable study design for evaluating the effectiveness of population-level health interventions that have been implemented at a clearly defined point in time. It is increasingly being used to evaluate the effectiveness of interventions ranging from clinical therapy to national public health legislation. Whereas the design shares many properties of regression-based approaches in other epidemiological studies, there are a range of unique features of time series data that require additional methodological considerations. In this tutorial we use a worked example to demonstrate a robust approach to ITS analysis using segmented regression. We begin by describing the design and considering when ITS is an appropriate design choice. We then discuss the essential, yet often omitted, step of proposing the impact model a priori. Subsequently, we demonstrate the approach to statistical analysis including the main segmented regression model. Finally we describe the main methodological issues associated with ITS analysis: over-dispersion of time series data, autocorrelation, adjusting for seasonal trends and controlling for time-varying confounders, and we also outline some of the more complex design adaptations that can be used to strengthen the basic ITS design.},
  keywords = {interrupted-time-series}
}

@article{ber21ass,
  title = {Assessing the Calibration of Subdistribution Hazard Models in Discrete Time},
  author = {Berger, Moritz and Schmid, Matthias},
  date = {2021},
  journaltitle = {Canadian Journal of Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1708-945X},
  doi = {10.1002/cjs.11633},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.11633},
  urldate = {2021-08-16},
  abstract = {The generalization performance of a risk prediction model can be evaluated by its calibration, which measures the agreement between predicted and observed outcomes on external validation data. Here, we propose methods for assessing the calibration of discrete time-to-event models in the presence of competing risks. Specifically, we consider the class of discrete subdistribution hazard models, which directly relate the cumulative incidence function of one event of interest to a set of covariates. We apply the methods to a prediction model for the development of nosocomial pneumonia. Simulation studies show that the methods are strong tools for calibration assessment even in scenarios with a high censoring rate and/or a large number of discrete time points.},
  langid = {english},
  keywords = {calibration,calibration-accuracy,competing-risk,subdistribution-hazard},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cjs.11633}
}

@book{ber81gra,
  title = {Graphics and {{Graphic Information-Processing}}},
  author = {Bertin, Jacques},
  date = {1981},
  publisher = {{de Gruyter}},
  location = {{Berlin}},
  citeulike-article-id = {13265230},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {graphics},
  annotation = {Translated by William Berg and Paul Scott, original work pubished 1977}
}

@book{ber83sem,
  title = {Semiology of {{Graphics}}: {{Diagrams Network Maps}}},
  author = {Bertin, Jacques},
  date = {1983},
  publisher = {{University of Wisconsin Press}},
  location = {{Madison WI}},
  citeulike-article-id = {13265231},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {graphics},
  annotation = {Translated by William Berg, original work published 1967}
}

@book{ber85sta,
  title = {Statistical {{Decision Theory}} and {{Bayesian Analysis}}},
  author = {Berger, James O.},
  date = {1985},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13263742},
  posted-at = {2014-07-14 14:09:22},
  priority = {0}
}

@article{ber86rob,
  title = {Robust {{Bayes}} and {{Empirical Bayes Analysis}} with ε-{{Contaminated Priors}}},
  author = {Berger, James and Berliner, L. Mark},
  date = {1986},
  journaltitle = {The Annals of Statistics},
  volume = {14},
  number = {2},
  eprint = {2241230},
  eprinttype = {jstor},
  pages = {461--486},
  issn = {0090-5364},
  abstract = {For Bayesian analysis, an attractive method of modelling uncertainty in the prior distribution is through use of ε-contamination classes, i.e., classes of distributions which have the form π = (1 - ε)π0 + ε q, π0 being the base elicited prior, q being a "contamination," and ε reflecting the amount of error in π0 that is deemed possible. Classes of contaminations that are considered include (i) all possible contaminations, (ii) all symmetric, unimodal contaminations, and (iii) all contaminations such that π is unimodal. Two issues in robust Bayesian analysis are studied. The first is that of determining the range of posterior probabilities of a set as π ranges over the ε-contamination class. The second, more extensively studied, issue is that of selecting, in a data dependent fashion, a "good" prior distribution (the Type-II maximum likelihood prior) from the ε-contamination class, and using this prior in the subsequent analysis. Relationships and applications to empirical Bayes analysis are also discussed.},
  keywords = {bayes,prior}
}

@article{ber87com,
  title = {Computing for Incomplete Repeated Measures},
  author = {{Berk}},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {385--398},
  citeulike-article-id = {13263743},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {multivariate-analysis,teaching}
}

@article{ber87eff,
  title = {Effective Microcomputer Statistical Software},
  author = {Kn, Berk},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {222--228},
  citeulike-article-id = {13263744},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {miscellaneous,statistical-computation-algorithms}
}

@article{ber87int,
  title = {Interim Analysis in Clinical Trials: {{The}} Role of the Likelihood Principle},
  author = {Berry, Donald A.},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {117--122},
  doi = {10.1080/00031305.1987.10475458},
  url = {http://dx.doi.org/10.1080/00031305.1987.10475458},
  citeulike-article-id = {13263745},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00031305.1987.10475458},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,conditionalism,sequential-monitoring,study-design}
}

@article{ber87log,
  title = {Logarithmic Transformations in {{ANOVA}}},
  author = {Berry, Donald A.},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {439--456},
  citeulike-article-id = {13263746},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {count-data,log-normal-distribution,pvcs,residuals,robustness},
  note = {choosing c in transforming by taking log(x+c)}
}

@article{ber87tes,
  title = {Testing a Point Null Hypothesis: {{The}} Irreconcilability of {{P-values}} and Evidence},
  author = {Berger, J. and Sellke, T.},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {112--139},
  citeulike-article-id = {13263747},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,evidence,p-value,point-null-hypothesis}
}

@article{ber87tesa,
  title = {Testing {{Precise Hypotheses}}},
  author = {Berger, James O. and Delampady, Mohan},
  date = {1987-08},
  journaltitle = {Statistical Science},
  volume = {2},
  number = {3},
  pages = {317--335},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177013238},
  url = {https://projecteuclid.org/journals/statistical-science/volume-2/issue-3/Testing-Precise-Hypotheses/10.1214/ss/1177013238.full},
  urldate = {2022-04-06},
  abstract = {Testing of precise (point or small interval) hypotheses is reviewed, with special emphasis placed on exploring the dramatic conflict between conditional measures (Bayes factors and posterior probabilities) and the classical P-value (or observed significance level). This conflict is highlighted by finding lower bounds on the conditional measures over wide classes of priors, in normal and binomial situations, lower bounds, which are much larger than the P-value; this leads to the recommendation of several alternatives to P-values. Results are also given concerning the validity of approximating an interval null by a point null. The overall discussion features critical examination of issues such as the probability of objective testing and the possibility of testing from confidence sets.},
  keywords = {bayes,p-value},
  note = {Quote from Section 4.6:
\par
Some statisticians argue that the implied logic concerning a small P-value is compelling: “Either H0 is true and a rare event has occurred, or H0 is false.” ~One could again argue against this reasoning as addressing the wrong question, but there is a more obvious major flaw: the “rare event” whose probability is being calculated under H0 is \emph{not} the event of observing the actual data x0, but the event E = \{possible data x: |T(x)| {$>$}= |T(x0)|\}. ~The inclusion of all data “more extreme” than the actual x0 is a curious step, and one which we have seen no remotely convincing justification. … the “logic of surprise” cannot differentiate between x0 and E …}
}

@incollection{ber88mul,
  title = {Multiple Comparisons, Multiple Tests, and Data Dredging: {{A Bayesian}} Perspective},
  booktitle = {Bayesian {{Statistics}}},
  author = {Berry, Donald A.},
  editor = {Bernardo, J. M. and DeGroot, M. H. and Lindley, D. V. and Smith, A. F. M.},
  date = {1988},
  volume = {3},
  pages = {79--94},
  publisher = {{Oxford University Press}},
  citeulike-article-id = {13263748},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,data-dredging,multiple-comparisons,multiple-tests},
  note = {if want to dredge data to generate hypotheses one still needs another dataset to test the hypotheses}
}

@article{ber88sta,
  title = {Statistical Analysis and the Illusion of Objectivity ({{Letters}} to Editor p. 430-433)},
  author = {Berger, James O. and Berry, Donald A.},
  date = {1988},
  journaltitle = {Am Scientist},
  volume = {76},
  pages = {159--165},
  citeulike-article-id = {13263749},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,p-values}
}

@article{ber90mon,
  title = {Monitoring Accumulating Data in a Clinical Trial},
  author = {Berry, Donald A.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {1197--1211},
  doi = {10.2307/2531771},
  url = {http://dx.doi.org/10.2307/2531771},
  citeulike-article-id = {13263750},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2531771},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {monitoring,rct,sequential,sequential-methods,study-design-and-stopping-rules}
}

@article{ber90sub,
  title = {Subgroup Analyses (Letter)},
  author = {Berry, Donald A.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {1227--1230},
  citeulike-article-id = {13263751},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {miscellaneous,study-design-and-stopping-rules}
}

@article{ber91ana,
  title = {Analysis of Failure Time Data with Ordinal Categories of Response},
  author = {Berridge, D. M. and Whitehead, J.},
  date = {1991},
  journaltitle = {Stat Med},
  volume = {10},
  pages = {1703--1710},
  doi = {10.1002/sim.4780101108},
  url = {http://dx.doi.org/10.1002/sim.4780101108},
  citeulike-article-id = {13263752},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780101108},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {time-and-severity-of-event}
}

@article{ber94bay,
  title = {Bayesian Analysis of Survival on Multiple Time Scales},
  author = {Berzuini, Carlo and Clayton, David},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {823--838},
  citeulike-article-id = {13263753},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {survival-analysis,time-origin}
}

@article{ber94dec,
  title = {Decision Making during a Phase {{III}} Randomized Controlled Trial},
  author = {Berry, Donald A. and Wolff, Mark C. and Sack, David},
  date = {1994},
  journaltitle = {Controlled Clin Trials},
  volume = {15},
  pages = {360--378},
  doi = {10.1016/0197-2456(94)90033-7},
  url = {http://dx.doi.org/10.1016/0197-2456(94)90033-7},
  citeulike-article-id = {13263754},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0197-2456(94)90033-7},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayes,bayesian-inference,rct,study-design}
}

@article{ber95see,
  title = {Seeing a Curve in Multiple Regression},
  author = {Berk, Kenneth N. and Booth, David E.},
  date = {1995},
  journaltitle = {Technometrics},
  volume = {37},
  pages = {385--398},
  citeulike-article-id = {13263755},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {partial-residual}
}

@book{ber96bay,
  title = {Bayesian {{Biostatistics}}},
  author = {Berry, Donald A. and Stangl, D. K.},
  date = {1996},
  publisher = {{Marcel Dekker}},
  location = {{New York}},
  citeulike-article-id = {13263758},
  posted-at = {2014-07-14 14:09:22},
  priority = {0}
}

@article{ber96bio,
  title = {Bioequivalence Trials, Intersection-Union Tests and Equivalence Confidence Sets (with Discussion)},
  author = {Berger, Roger L. and Hsu, Jason C.},
  date = {1996},
  journaltitle = {Stat Sci},
  volume = {11},
  pages = {283--319},
  citeulike-article-id = {13263756},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bioequivalence,equivalence-testing}
}

@book{ber96sta,
  title = {Statistics: {{A Bayesian Perspective}}},
  author = {Berry, Donald A.},
  date = {1996},
  publisher = {{Duxbury Press}},
  location = {{Belmont, CA}},
  citeulike-article-id = {13263757},
  posted-at = {2014-07-14 14:09:22},
  priority = {0}
}

@article{ber97tea,
  title = {Teaching Elementary {{Bayesian}} Statistics with Real Applications in Science},
  author = {Berry, Donald A.},
  date = {1997},
  journaltitle = {Am Statistician},
  volume = {51},
  pages = {241--246},
  citeulike-article-id = {13263759},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,scientific-approach,teaching}
}

@article{ber97uni,
  title = {Unified Frequentist and {{Bayesian}} Testing of a Precise Hypothesis (with Discussion)},
  author = {Berger, J. O. and Boukai, B. and Wang, Y.},
  date = {1997},
  journaltitle = {Stat Sci},
  volume = {12},
  pages = {133--160},
  citeulike-article-id = {13263760},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,misinterpretation-of-p-values},
  note = {"no decision" region;error probability;Bayes factor;likelihood ratio;"in situations ... involving testing a precise null hypothesis, a P-value of 0.05 essentially does not provide any evidence against the null hypothesis";for a one-sample problem where the data are normally distributed with known variance and unknown mean~ and H\_0: =\_0 vs. H\_1:~  \_0, P=0.05 may correspond to a probability of H\_0 being true of 0.5}
}

@article{bes76dev,
  title = {Development of a {{Crohn}}'s Disease Activity Index},
  author = {Best, William R. and Becktel, J. M. and Singleton, J. W. and Kern, F.},
  date = {1976},
  journaltitle = {Gastroent},
  volume = {70},
  pages = {439--444},
  citeulike-article-id = {13265733},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  note = {development of CDAI}
}

@article{bes96bay,
  title = {Bayesian Analysis of Realistically Complex Models},
  author = {Best, N. G. and Spiegelhalter, D. J. and Thomas, A. and Brayne, C. E. G.},
  date = {1996},
  journaltitle = {J Roy Stat Soc A},
  volume = {159},
  pages = {323--342},
  citeulike-article-id = {13263761},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-methods,conditional-independence,gibbs-sampling,graphical-models,informative-dropout,random-effects-model,repeated-ordinal-categorical-responses}
}

@article{bet97loc,
  title = {Local Estimation of Smooth Curves for Longitudinal Data},
  author = {Betensky, Rebecca A.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2429--2445},
  citeulike-article-id = {13263762},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {gam,local-regression,longitudinal-data,nice-examples-of-serial-data,serial-data}
}

@article{bet99ext,
  title = {An Extension of {{Kendall}}'s Coefficient of Concordance to Bivariate Interval Censored Data},
  author = {Betensky, Rebecca A. and Finkelstein, Dianne M.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {3101--3109},
  citeulike-article-id = {13263763},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bivariate-survival-data,interval-censoring,nonparametric-index-of-association}
}

@article{beu05dir,
  title = {Direct Likelihood Analysis versus Simple Forms of Imputation for Missing Data in Randomized Clinical Trials},
  author = {Beunckens, Caroline and Molenberghs, Geert and Kenward, Michael G.},
  date = {2005},
  journaltitle = {Clin Trials},
  volume = {2},
  pages = {379--386},
  citeulike-article-id = {13265450},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {dropouts,locf,longitudinal-data,rct,serial-data},
  note = {bias in LOCF; mixed models used for likelihood analysis}
}

@article{bey08eas,
  title = {An Easy Mathematical Proof Showed That Time-Dependent Bias Inevitably Leads to Biased Effect Estimation},
  author = {Beyersmann, Jan and Gastmeier, Petra and Wolkewitz, Martin and Schumacher, Martin},
  date = {2008},
  journaltitle = {J Clin Epi},
  volume = {61},
  pages = {1216--1221},
  citeulike-article-id = {13265710},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {hospital-infection,length-bias,survival-analysis,survival-bias,time-dependent-exposure}
}

@article{bey09sim,
  title = {Simulating Competing Risks Data in Survival Analysis},
  author = {Beyersmann, Jan and Latouche, Aurelien and Buchholz, Anika and Schumacher, Martin},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {956--971},
  citeulike-article-id = {13265729},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {case-specific-hazard,competing-risks,latent-failure-time,model-misspecification,multistate-model,simulation-setup,subdistribution-hazard,survival-analysis}
}

@article{bey13pla,
  title = {Planning and Evaluating Clinical Trials with Composite Time-to-First-Event Endpoints in a Competing Risk Framework},
  author = {Rauch, G. and Beyersmann, J.},
  date = {2013-09},
  journaltitle = {Stat Med},
  volume = {32},
  number = {21},
  pages = {3595--3608},
  doi = {10.1002/sim.5798},
  url = {http://dx.doi.org/10.1002/sim.5798},
  abstract = {Composite endpoints combine several events of interest within a single variable. These are often time-to-first-event data, which are analyzed via survival analysis techniques. To demonstrate the significance of an overall clinical benefit, it is sufficient to assess the test problem formulated for the composite. However, the effect observed for the composite does not necessarily reflect the effects for the components. Therefore, it would be desirable that the sample size for clinical trials using composite endpoints provides enough power not only to detect a clinically relevant superiority for the composite but also to address the components in an adequate way. The single components of a composite endpoint assessed as time-to-first-event define competing risks. We consider multiple test problems based on the cause-specific hazards of competing events to address the problem of analyzing both a composite endpoint and its components. Thereby, we use sequentially rejective test procedures to reduce the power loss to a minimum. We show how to calculate the sample size for the given multiple test problem by using a simply applicable simulation tool in SAS. Our ideas are illustrated by two clinical study examples.},
  citeulike-article-id = {13448173},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5798},
  day = {20},
  posted-at = {2014-11-29 17:02:02},
  priority = {2},
  keywords = {competing-risks,composite-endpoints,multiple-endpoints,rct,study-design}
}

@article{beydes,
  title = {Design Aspects of {{COVID-19}} Treatment Trials: {{Improving}} Probability and Time of Favorable Events},
  shorttitle = {Design Aspects of {{COVID-19}} Treatment Trials},
  author = {Beyersmann, Jan and Friede, Tim and Schmoor, Claudia},
  journaltitle = {Biometrical Journal},
  volume = {n/a},
  number = {n/a},
  issn = {1521-4036},
  doi = {10.1002/bimj.202000359},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000359},
  urldate = {2021-11-03},
  abstract = {As a reaction to the pandemic of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), a multitude of clinical trials for the treatment of SARS-CoV-2 or the resulting corona disease 2019 (COVID-19) are globally at various stages from planning to completion. Although some attempts were made to standardize study designs, this was hindered by the ferocity of the pandemic and the need to set up clinical trials quickly. We take the view that a successful treatment of COVID-19 patients (i) increases the probability of a recovery or improvement within a certain time interval, say 28 days; (ii) aims to expedite favorable events within this time frame; and (iii) does not increase mortality over this time period. On this background, we discuss the choice of endpoint and its analysis. Furthermore, we consider consequences of this choice for other design aspects including sample size and power and provide some guidance on the application of adaptive designs in this particular context.},
  langid = {english},
  keywords = {compound-endpoints,covid19,design,multiple-endpoints,outcome-assessment,outcomes,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000359},
  note = {Most comprehensive dissection of competing risk analysis for time to recovery.~ Shows that TTR interpretation is extremely complex.
\par
Mentions that TTR does not have a way to handle death after recovery.
\par
Covers "average" improvement or recovery times with insertion of infinity.
\par
Section 3.4: "... the interpretation of probabilities is arguably more accessible.~ One possible outcome could be the probability to be alive after recovery...".~ References sch20ext which using continuous time transition models.
\par
p. 12: See 2nd full paragraph which illustrates why "any competing events analysis is incomplete without a look at the competing event".
\par
p. 14 2nd and 3rd full paragraphs: "... no large difference in the calculated sample size for the subdistribution hazard ratio ... as compared to the calculated sample size for the odds ratio of the binary endpoint ...".~ "When no competing events are present, it had been shown by Annesi et al (1989) that the efficiency of an analysis with logistic regression is high as compare to an analysis with the Cox regression in the situation of a low event rate." ... "~ Then refers to an ordinal analysis at one time point, and mentions that ordinal analysis may require smaller sample size and gives an example.~
\par
Section 5 3rd paragraph: "The presence of competing outcomes raises the question of the potential need to account for multiple testing.~ Recall that a successful trial would prove superiority for the favorable event and at least no effect or noninferiority for the competing event.~
\par
The paper uses terrible notation.}
}

@article{bic95wha,
  title = {What Academia Needs},
  author = {Bickel, Peter J.},
  date = {1995},
  journaltitle = {Am Statistician},
  volume = {49},
  pages = {5--6},
  citeulike-article-id = {13263764},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {teaching-statisticians}
}

@article{bie13las,
  title = {A Lasso for Hierarchical Interactions},
  author = {Bien, Jacob and Taylor, Jonathan and Tibshirani, Robert},
  date = {2013},
  journaltitle = {Appl Stat},
  volume = {41},
  number = {3},
  pages = {1111--1141},
  doi = {10.1214/13-AOS1096},
  url = {http://dx.doi.org/10.1214/13-AOS1096},
  citeulike-article-id = {13265991},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/13-AOS1096},
  posted-at = {2014-07-14 14:10:09},
  priority = {0}
}

@article{big97inc,
  title = {Incorporating Variability in Estimates of Heterogeneity in the Random Effects Model in Meta-Analysis},
  author = {Biggerstaff, B. J. and Tweedie, R. L.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {753--768},
  citeulike-article-id = {13263765},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {across-study-variation,dersimonian-and-laird-model,meta-analysis}
}

@article{big98fee,
  title = {Feed Forward Neural Networks for the Analysis of Censored Survival Data: {{A}} Partial Logistic Regression Approach},
  author = {Biganzoli, Elia and Boracchi, Patrizia and Mariani, Luigi and Marubini, Ettore},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1169--1186},
  citeulike-article-id = {13263766},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {discrete-cox-model,discrete-hazard-model,neural-networks,repeated-measures-logistic-model,survival-analysis},
  note = {using neural network to obtain smoothed hazards from grouped survival data}
}

@article{bil06fun,
  title = {Functional {{Data Analysis}} of {{Protein Expression}} in {{Matrix-Assisted Laser Desorption}}/{{Ionization Time-of-Flight Mass Spectrometry}}},
  author = {Billheimer, D.},
  date = {2006},
  journaltitle = {in review},
  citeulike-article-id = {13265502},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{bil96sem,
  title = {A Semiparametric Extension of the {{Mann-Whitney}} Test for Randomly Truncated Data},
  author = {Bilker, Warren B. and Wang, Meo-Cheng},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {10--20},
  citeulike-article-id = {13263767},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {right-truncation}
}

@article{bin08emp,
  title = {Empirical Study of the Dependence of the Results of Multivariable Flexible Survival Analyses on Model Selection Strategy},
  author = {Binquet, C. and Abrahamowicz, M. and Mahboubi, A. and Jooste, V. and Faivre, J. and Bonithon-Kopp, C. and Quantin, C.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {6470--6488},
  citeulike-article-id = {13265763},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {flexible-survival-model,gastric-cancer,model-selection-strategy,splines}
}

@article{bin21ori,
  title = {On the {{Origin}} of {{Sensitivity}} and {{Specificity}}},
  author = {Binney, Nicholas and Hyde, Christopher and Bossuyt, Patrick M.},
  date = {2021-03-16},
  journaltitle = {Annals of Internal Medicine},
  publisher = {{American College of Physicians}},
  doi = {10.7326/M20-5028},
  url = {https://www.acpjournals.org/doi/abs/10.7326/M20-5028},
  urldate = {2021-03-20},
  abstract = {Today, sensitivity and specificity are thought of as attributes of many diagnostic tests. This article discusses the history of use of these terms, which is rooted in early 20th-century immunology.},
  langid = {english},
  keywords = {diagnosis,history,sensitivity,specificity}
}

@article{bin92fit,
  title = {Fitting {{Cox}}'s Proportional Hazards Models from Survey Data},
  author = {Binder, David A.},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {139--147},
  citeulike-article-id = {13263768},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {complex-sample-surveys,maximum-likelihood,see-lin00fit}
}

@article{bjo05out,
  title = {Outcome and Prognostic Markers in Severe Drug-Induced Liver Disease},
  author = {Björnsson, E. and Olsson, R.},
  date = {2005},
  journaltitle = {Hepatology},
  volume = {42},
  pages = {481--489},
  citeulike-article-id = {13265452},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {clinical-safety,hepatotoxity,liver-function,liver-toxicity,pharmaceutical-safety},
  note = {related liver abnormalities to outcome using logistic regression}
}

@article{bla08agr,
  title = {Agreement between Methods of Measurement with Multiple Observations per Individual},
  author = {Bland, J. M. and Altman, D. G.},
  date = {2007},
  journaltitle = {J Biopharm Stat},
  volume = {17},
  number = {4},
  pages = {571--582},
  citeulike-article-id = {13265783},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {observer-agreement,observer-variability}
}

@article{bla11com,
  title = {Comparisons against Baseline within Randomised Groups Are Often Used and Can Be Highly Misleading},
  author = {Bland, J. Martin and Altman, Douglas G.},
  date = {2011-12},
  journaltitle = {Trials},
  volume = {12},
  number = {1},
  pages = {264},
  doi = {10.1186/1745-6215-12-264},
  url = {https://doi.org/10.1186/1745-6215-12-264},
  abstract = {In randomised trials, rather than comparing randomised groups directly some researchers carry out a significance test comparing a baseline with a final measurement separately in each group. We give several examples where this has been done. We use simulation to demonstrate that the procedure is invalid and also show this algebraically. This approach is biased and invalid, producing conclusions which are, potentially, highly misleading. The actual alpha level of this procedure can be as high as 0.50 for two groups and 0.75 for three. Randomised groups should be compared directly by two-sample methods and separate tests against baseline are highly misleading.},
  citeulike-article-id = {14475433},
  citeulike-attachment-1 = {bland₁1<sub>c</sub>omparisons₁122627.pdf; /pdf/user/harrelfe/article/14475433/1122627/bland₁1<sub>c</sub>omparisons₁122627.pdf; bf47eb2856cf8ec2b2b2a997603a3c39e48d7509},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/1745-6215-12-264},
  citeulike-linkout-1 = {https://doi.org/10.1186/1745-6215-12-264},
  day = {22},
  posted-at = {2017-11-13 13:21:11},
  priority = {2},
  keywords = {change,rct}
}

@article{bla20pro,
  title = {Propensity Scores Using Missingness Pattern Information: A Practical Guide},
  shorttitle = {Propensity Scores Using Missingness Pattern Information},
  author = {Blake, Helen A. and Leyrat, Clémence and Mansfield, Kathryn E. and Seaman, Shaun and Tomlinson, Laurie A. and Carpenter, James and Williamson, Elizabeth J.},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8503},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8503},
  urldate = {2020-02-28},
  abstract = {Electronic health records are a valuable data source for investigating health-related questions, and propensity score analysis has become an increasingly popular approach to address confounding bias in such investigations. However, because electronic health records are typically routinely recorded as part of standard clinical care, there are often missing values, particularly for potential confounders. In our motivating study—using electronic health records to investigate the effect of renin-angiotensin system blockers on the risk of acute kidney injury—two key confounders, ethnicity and chronic kidney disease stage, have 59\% and 53\% missing data, respectively. The missingness pattern approach (MPA), a variant of the missing indicator approach, has been proposed as a method for handling partially observed confounders in propensity score analysis. In the MPA, propensity scores are estimated separately for each missingness pattern present in the data. Although the assumptions underlying the validity of the MPA are stated in the literature, it can be difficult in practice to assess their plausibility. In this article, we explore the MPA's underlying assumptions by using causal diagrams to assess their plausibility in a range of simple scenarios, drawing general conclusions about situations in which they are likely to be violated. We present a framework providing practical guidance for assessing whether the MPA's assumptions are plausible in a particular setting and thus deciding when the MPA is appropriate. We apply our framework to our motivating study, showing that the MPA's underlying assumptions appear reasonable, and we demonstrate the application of MPA to this study.},
  langid = {english},
  keywords = {imputation,missing,propensity},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8503}
}

@article{bla85sep,
  title = {Separating the {{Brier}} Score into Calibration and Refinement Components: {{A}} Graphical Exposition},
  author = {Blattenberger, Gail and Lad, Frank},
  date = {1985},
  journaltitle = {Am Statistician},
  volume = {39},
  pages = {26--32},
  citeulike-article-id = {13263769},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {brier-score,predictive-accuracy}
}

@incollection{bla86,
  title = {Analysis of Death (Survival Analysis) and Other Time-Related Events},
  booktitle = {Current {{Status}} of {{Clinical Cardiology}}},
  author = {Blackstone, E. H.},
  editor = {Macartney, F. J.},
  date = {1986},
  pages = {55--101},
  publisher = {{MTP Press Limited}},
  location = {{Lancaster, UK}},
  citeulike-article-id = {13263770},
  posted-at = {2014-07-14 14:09:22},
  priority = {0}
}

@article{bla86dec,
  title = {The Decomposition of Time-Varying Hazard into Phases, Each Incorporating a Separate Stream of Concomitant Information},
  author = {Blackstone, E. H. and Naftel, D. C. and Turner, M. E.},
  date = {1986},
  journaltitle = {J Am Stat Assoc},
  volume = {81},
  pages = {615--624},
  citeulike-article-id = {13263771},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {non-ph,parametric-survival-models}
}

@article{bla86sta,
  title = {Statistical Methods for Assessing Agreement between Two Methods of Clinical Measurement},
  author = {Bland, J. M. and Altman, D. G.},
  date = {1986},
  journaltitle = {Lancet},
  volume = {0},
  pages = {307--310},
  citeulike-article-id = {13263772},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {measurement,research-methods}
}

@article{bla88,
  title = {Latent Variable Models for the Analysis of Medical Data with Repeated Measures of Binary Variables},
  author = {{Blackwood}},
  date = {1988},
  journaltitle = {Stat Med},
  volume = {7},
  pages = {975--981},
  citeulike-article-id = {13263773},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{bla92use,
  title = {On the Use of the Generalized t and Generalized Rank-Sum Statistics in Medical Research},
  author = {Blair, R. C. and Morel, J. G.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {491--501},
  citeulike-article-id = {13263774},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {nonparametrics}
}

@article{ble03ext,
  title = {External Validation Is Necessary in Prediction Research: {{A}} Clinical Example},
  author = {Bleeker, S. E. and Moll, H. A. and Steyerberg, E. W. and Donders, A. R. T. and Derkson-Lubsen, G. and Grobbee, D. E. and Moons, K. G. M.},
  date = {2003},
  journaltitle = {J Clin Epi},
  volume = {56},
  pages = {826--832},
  citeulike-article-id = {13265354},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  note = {"For relatively small data sets, internal validation of prediction models by bootstrap techniques may not be sufficient and indicative for the model's performance in future patients. External validation is essential before implementing prediction models in clinical practice. ... only pure sampling variability is considered with bootstrap techniques, and changes in the patient population are not";cite on RMS web page;validation criteria}
}

@article{ble93inf,
  title = {Influence of Model-Building Strategies on the Results of a Case-Control Study},
  author = {Blettner, Maria and Sauerbrei, Willi},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {1325--1338},
  citeulike-article-id = {13263775},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {modeling-strategies,study-design}
}

@article{ble98sem,
  title = {A Semiparametric {{Bayesian}} Approach to the Random Effects Model},
  author = {Kleinman, Ken P. and Ibrahim, Joseph G.},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {921--938},
  citeulike-article-id = {13263776},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {bayesian-inference,dirichlet-prior-for-random-effects,random-effects}
}

@article{blo00usi,
  title = {Using Generalized Linear Models to Assess Medical Care Costs},
  author = {Blough, David K. and Ramsey, Scott D.},
  date = {2000},
  journaltitle = {Hlth Serv Outcomes Res Meth},
  volume = {1},
  pages = {185--202},
  citeulike-article-id = {13265151},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {cost-data,gamma-distribution,general-linear-model,heteroscedasticity,skewness}
}

@article{blo89,
  title = {Empirical Comparison of Approaches to Forming Strata},
  author = {Bloch, Daniel A. and Segal, Mark R.},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {897--905},
  citeulike-article-id = {13263777},
  posted-at = {2014-07-14 14:09:22},
  priority = {0},
  keywords = {cart-vs-logistic-regression-with-real-data,distribution-free-methods,general,predictive-methods}
}

@article{blu02lik,
  title = {Likelihood Methods for Measuring Statistical Evidence},
  author = {Blume, J. D.},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  number = {17},
  pages = {2563--2599},
  citeulike-article-id = {13265738},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@article{blu03wha,
  title = {What Your Statistician Never Told You about {{P-values}}},
  author = {Blume, J. D. and Peipert, J. F.},
  date = {2003},
  journaltitle = {J Am Assoc Gyn Laparoscopists},
  volume = {10},
  number = {4},
  pages = {439--444},
  citeulike-article-id = {13265739},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@article{blu07,
  title = {Statistical Evidence for {{GLM}} Parameters: A Robust Likelihood Approach},
  author = {Blume, J. D. and Su, L. and Acosta, L. and McGarvey, S.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  number = {15},
  pages = {2919--2936},
  citeulike-article-id = {13265741},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@article{blu08how,
  title = {How Often {{Likelihood}} Ratios Are Misleading in Sequential Trials},
  author = {Blume, J. D.},
  date = {2008},
  journaltitle = {Comm Stat Th Meth},
  volume = {37},
  number = {8},
  pages = {1193--1206},
  citeulike-article-id = {13265740},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@incollection{blu11lik,
  title = {Likelihood and Its Evidential Framework},
  booktitle = {Handbook of the {{Philosophy}} of {{Science}}: {{Philosophy}} of {{Statistics}}},
  author = {Blume, Jeffrey D.},
  editor = {Gabbay, Dov M. and Woods, John},
  date = {2011},
  pages = {493--511},
  publisher = {{North Holland}},
  location = {{San Diego}},
  citeulike-article-id = {14016555},
  citeulike-attachment-1 = {blu11lik.pdf; /pdf/user/harrelfe/article/14016555/1064777/blu11lik.pdf; c8e2200254c490a7cf93d0339efc119cdc8f08de},
  posted-at = {2016-04-20 03:52:08},
  priority = {1},
  keywords = {likelihood}
}

@article{boe04nul,
  title = {Null Bar and Null Zone Are Better than the Error Bar to Compare Group Means in Graphs},
  author = {Boers, Maarten},
  date = {2004-07-01},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {57},
  number = {7},
  pages = {712--715},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2003.05.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0895435604000800},
  urldate = {2021-07-20},
  abstract = {The problem Conventional graphs often include error bars around the group means. Regardless of what these bars depict, they are uninformative as to whether a difference between the groups is statistically significant. The solution This article suggests plotting the null bar or null zone: that is, the range or area in which the means of the two groups fall if the null hypothesis of no difference cannot be rejected. The bar and zone are simply derived from the confidence interval around the difference, obtained from the t-test.},
  langid = {english},
  keywords = {confidence-bands,graphics}
}

@article{bon08sim,
  title = {Simultaneous Regression Shrinkage, Variable Selection, and Supervised Clustering of Predictors with {{OSCAR}}},
  author = {Bondell, Howard D. and Reich, Brian J.},
  date = {2008},
  journaltitle = {Biometrics},
  volume = {64},
  pages = {115--123},
  citeulike-article-id = {13265669},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {correlation,groups-variables-into-predictive-clusters,matlab-software-available,penalization,predictive-group,shrinkage,simultaneous-variable-selection-and-shrinkage,supervised-clustering,variable-selection}
}

@article{bon10non,
  title = {Noncrossing Quantile Regression Curve Estimation},
  author = {Bondell, Howard D. and Reich, Brian J. and Wang, Huixia},
  date = {2010},
  journaltitle = {Biometrika},
  volume = {97},
  number = {4},
  pages = {825--838},
  citeulike-article-id = {13265870},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {covariate-space,crossing-quantile-curves,quantile-regression,restriction}
}

@article{bon16gra,
  title = {Graphical and Numerical Diagnostic Tools to Assess Suitability of Multiple Imputations and Imputation Models},
  author = {Bondarenko, Irina and Raghunathan, Trivellore},
  date = {2016-07},
  journaltitle = {Stat Med},
  volume = {35},
  number = {17},
  pages = {3007--3020},
  issn = {02776715},
  doi = {10.1002/sim.6926},
  url = {http://dx.doi.org/10.1002/sim.6926},
  citeulike-article-id = {14218256},
  citeulike-attachment-1 = {bon16gra.pdf; /pdf/user/harrelfe/article/14218256/1093465/bon16gra.pdf; 4d28c519af1c95c938392f9af6d03c47935a39a7},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6926},
  day = {30},
  posted-at = {2016-12-01 14:14:34},
  priority = {2},
  keywords = {diagnostics,missing-data}
}

@article{bon87,
  title = {Logistic Regression for Dependent Binary Observations},
  author = {Bonney, G. E.},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {951--973},
  citeulike-article-id = {13263778},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{boo07new,
  title = {New Confidence Bounds for {{QT}} Studies},
  author = {Boos, Dennis D. and Hoffman, David and Kringle, Robert and Zhang, Ji},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3801--3817},
  citeulike-article-id = {13265617},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {arrhythmia,corrected-qt,crossover-study,ecg,parallel-design,pharmaceutical-safety,qt-prolongation,repolarization}
}

@article{boo92gen,
  title = {On Generalized Score Tests},
  author = {Boos, Dennis D.},
  date = {1992},
  journaltitle = {Ann Math Stat},
  volume = {46},
  pages = {327--333},
  citeulike-article-id = {13263779},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {maximum-likelihood}
}

@article{boo98mon,
  title = {Monte {{Carlo}} Approximation of Bootstrap Variances},
  author = {Booth, James G. and Sarkar, Somnath},
  date = {1998},
  journaltitle = {Am Statistician},
  volume = {52},
  pages = {354--357},
  citeulike-article-id = {13263780},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {bootstrap,bounds,cv,number-of-bootstrap-resamples,relative-error-resample-size},
  note = {number of resamples required to estimate variances, quantiles; 800 resamples may be required to guarantee with 0.95 confidence that the relative error of a variance estimate is 0.1;Efron's original suggestions for as low as 25 resamples were based on comparing stability of bootstrap estimates to sampling error, but small relative effects can significantly change P-values;number of bootstrap resamples}
}

@book{boot,
  title = {An {{Introduction}} to the {{Bootstrap}}},
  author = {Efron, Bradley and Tibshirani, Robert},
  date = {1993},
  publisher = {{Chapman and Hall}},
  location = {{New York}},
  citeulike-article-id = {13263781},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {bootstrap}
}

@article{bor07gen,
  title = {A Generalized Concept of Power Helped to Choose Optimal Endpoints in Clinical Trials},
  author = {Borm, George F. and van der Wilt, Gert J. and Kremer, Jan A. M. and Zielhuis, Gerhard A.},
  options = {useprefix=true},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {375--381},
  citeulike-article-id = {13265570},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {composite-endpoints,confidence-interval,multiple-endpoints,power,rct,sample-size,statistical-design},
  note = {power of a study as opposed to power of a test}
}

@article{bor07sta,
  title = {Statistical Decisionmaking without Math},
  author = {Bordley, Robert},
  date = {2007},
  journaltitle = {Chance},
  volume = {20},
  number = {3},
  pages = {39--44},
  citeulike-article-id = {13265623},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {decision-theory,graphics,statistical-decision-theory}
}

@article{bor94cas,
  title = {The Case for Confidence Intervals in Controlled Clinical Trials},
  author = {Borenstein, Michael},
  date = {1994},
  journaltitle = {Controlled Clin Trials},
  volume = {15},
  pages = {411--428},
  citeulike-article-id = {13263782},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {confidence-function,confidence-intervals,p-value-function,p-values,study-design,study-interpretation,teaching-mds}
}

@article{bor94pla,
  title = {Planning for Precision in Survival Studies},
  author = {Borenstein, Michael},
  date = {1994},
  journaltitle = {J Clin Epi},
  volume = {47},
  pages = {1277--1285},
  citeulike-article-id = {13263783},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {precision,sample-size,study-decision}
}

@article{bot10log,
  title = {Logistic Quantile Regression for Bounded Outcomes},
  author = {Bottai, Matteo and Cai, Bo and McKeown, Robert E.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {309--317},
  citeulike-article-id = {13265798},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {bounded-outcomes,conditional-quantiles,logistic-quantile-regression,quantile-regression,robust-regression,transformations},
  note = {assumes more than ordinality;claimed to be useful for U-- and J--shaped distributions of Y;based on a rescaling Y to a 0-1 scale from the min to the max Y value}
}

@article{bou88pro,
  title = {Prognostic Value of the Simplified Selvester {{QRS}} Score in Patients with Coronary Artery Disease},
  author = {Bounous EP, R. M. and Harrell, F. E. and Hinohara, T. and Mark, D. B. and Ideker, R. E. and Selvester, R. H. and Wagner, G. S.},
  date = {1988},
  journaltitle = {J Am Coll Cardiol},
  volume = {11},
  pages = {35--41},
  citeulike-article-id = {13263784},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bou88sur,
  title = {Surgical Survival Benefits for Coronary Disease Patients with Left Ventricular Dysfunction},
  author = {Bounous, E. P. and Mark, D. B. and Pollock, B. G. and Hlatky, M. A. and Harrell, F. E. and Lee, K. L. and Rankin, J. S. and Wechsler, A. S. and Pryor, D. B. and Califf, R. M.},
  date = {1988},
  journaltitle = {Circ},
  volume = {78(Suppl I)},
  pages = {151--157},
  citeulike-article-id = {13263785},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bou95pro,
  title = {Problems with Instrumental Variables Estimation When the Correlation between the Instruments and the Endogenous Explanatory Variables Is Weak},
  author = {Bound, John and Jaeger, David A. and Baker, Regina M.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {443--450},
  citeulike-article-id = {13263786},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {confounding,instrumental-variables}
}

@article{bow21con,
  title = {Connecting {{Instrumental Variable}} Methods for Causal Inference to the {{Estimand Framework}}},
  author = {Bowden, Jack and Bornkamp, Björn and Glimm, Ekkehard and Bretz, Frank},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9143},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9143},
  urldate = {2021-07-22},
  abstract = {Causal inference methods are gaining increasing prominence in pharmaceutical drug development in light of the recently published addendum on estimands and sensitivity analysis in clinical trials to the E9 guideline of the International Council for Harmonisation. The E9 addendum emphasises the need to account for post-randomization or ‘intercurrent’ events that can potentially influence the interpretation of a treatment effect estimate at a trial's conclusion. Instrumental Variables (IV) methods have been used extensively in economics, epidemiology, and academic clinical studies for ‘causal inference,’ but less so in the pharmaceutical industry setting until now. In this tutorial article we review the basic tools for causal inference, including graphical diagrams and potential outcomes, as well as several conceptual frameworks that an IV analysis can sit within. We discuss in detail how to map these approaches to the Treatment Policy, Principal Stratum and Hypothetical ‘estimand strategies’ introduced in the E9 addendum, and provide details of their implementation using standard regression models. Specific attention is given to discussing the assumptions each estimation strategy relies on in order to be consistent, the extent to which they can be empirically tested and sensitivity analyses in which specific assumptions can be relaxed. We finish by applying the methods described to simulated data closely matching two recent pharmaceutical trials to further motivate and clarify the ideas.},
  langid = {english},
  keywords = {causal-inference,causality,estimand,instrumental-variable},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9143}
}

@book{bow95mea,
  title = {Measuring {{Disease}}: {{A Review}} of {{Disease-Specific Quality}} of {{Life Measurement Scales}}},
  author = {Bowling, Ann},
  date = {1995},
  publisher = {{Open University Press}},
  location = {{Buckingham, Philadelphia}},
  citeulike-article-id = {13263787},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {qol},
  annotation = {reviewed SM 15:1067-8; 1996}
}

@article{bow96gra,
  title = {Graphical Comparison of Nonparametric Curves},
  author = {Bowman, Adrian and Young, Stuart},
  date = {1996},
  journaltitle = {Appl Stat},
  volume = {45},
  pages = {83--98},
  citeulike-article-id = {13263788},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {reference-bands},
  note = {confidence band for y1-y2 on graph for y1,y2 - seems to only work for symmetric CLs}
}

@book{box73bay,
  title = {Bayesian {{Inference}} in {{Statistical Analysis}}},
  author = {Box, George E. P. and Tiao, George C.},
  date = {1973},
  publisher = {{Addison-Wesley}},
  location = {{Reading, MA}},
  citeulike-article-id = {13263789},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{boy12est,
  title = {Estimation of Treatment Effect under Non-Proportional Hazards and Conditionally Independent Censoring},
  author = {Boyd, Adam P. and Kittelson, John M. and Gillen, Daniel L.},
  date = {2012},
  journaltitle = {Statistics in Medicine},
  volume = {31},
  number = {28},
  pages = {3504--3515},
  issn = {1097-0258},
  doi = {10.1002/sim.5440},
  url = {https://www.onlinelibrary.wiley.com/doi/abs/10.1002/sim.5440},
  urldate = {2020-12-16},
  abstract = {In clinical trials with time-to-event outcomes, it is common to estimate the marginal hazard ratio from the proportional hazards model, even when the proportional hazards assumption is not valid. This is unavoidable from the perspective that the estimator must be specified a priori if probability statements about treatment effect estimates are desired. Marginal hazard ratio estimates under non-proportional hazards are still useful, as they can be considered to be average treatment effect estimates over the support of the data. However, as many have shown, under non-proportional hazard, the ‘usual’ unweighted marginal hazard ratio estimate is a function of the censoring distribution, which is not normally considered to be scientifically relevant when describing the treatment effect. In addition, in many practical settings, the censoring distribution is only conditionally independent (e.g., differing across treatment arms), which further complicates the interpretation. In this paper, we investigate an estimator of the hazard ratio that removes the influence of censoring and propose a consistent robust variance estimator. We compare the coverage probability of the estimator to both the usual Cox model estimator and an estimator proposed by Xu and O'Quigley (2000) when censoring is independent of the covariate. The new estimator should be used for inference that does not depend on the censoring distribution. It is particularly relevant to adaptive clinical trials where, by design, censoring distributions differ across treatment arms. Copyright © 2012 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {censoring,cox-model,ph,rct,survival,weighted-mle},
  annotation = {\_eprint: https://www.onlinelibrary.wiley.com/doi/pdf/10.1002/sim.5440}
}

@article{bra00ree,
  title = {Reengineering a Database for Clinical Trials Management: {{Lessons}} for System Architects},
  author = {Brandth, Cynthia A. and Nadkarni, Prakash and Marenco, Luis and Karras, Bryant T. and Lu, Charles and Schacter, Lee and Fisk, John M. and Miller, Perry L.},
  date = {2000},
  journaltitle = {Controlled Clin Trials},
  volume = {21},
  pages = {440--461},
  citeulike-article-id = {13265239},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {clinical-data-management,discussion-of-client-side-scripting,metadata,used-microsoft-active-server-pages}
}

@article{bra02rec,
  title = {Recursive Combination Tests},
  author = {Brannath, W. and Posch, M. and Bauer, P.},
  date = {2002},
  journaltitle = {J Am Stat Assoc},
  volume = {97},
  pages = {236--244},
  citeulike-article-id = {13265515},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{bra03seq,
  title = {Sequential Tests for Noninferiority and Superiority},
  author = {Brannath, W. and Bauer, P. and Maurer, W. and Posch, M.},
  date = {2003},
  journaltitle = {Biometrics},
  volume = {59},
  pages = {106--114},
  citeulike-article-id = {13265506},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{bra08acc,
  title = {Accurate Parametric Inference for Small Samples},
  author = {Brazzale, Alessandra R. and Davison, Anthony C.},
  date = {2008},
  journaltitle = {Stat Sci},
  volume = {23},
  number = {4},
  pages = {465--484},
  citeulike-article-id = {13265807},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {conditional-inference,conservatism-of-exact-approaches,fragility-of-exact-approaches,heteroscedasticity,logistic-regression,lugannani-rice-formula,mcmc,nonlinear-model,r,r-code,regression-scale-model,saddlepoint-approximation,spline,statistical-computing}
}

@article{bra09con,
  title = {Confirmatory Adaptive Designs with {{Bayesian}} Decision Tools for a Targeted Therapy in Oncology},
  author = {Brannath, Werner and Zuber, Emmanuel and Branson, Michael and Bretz, Frank and Gallo, Paul and Posch, Martin and Racine-Poon, Amy},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {1445--1463},
  citeulike-article-id = {13265757},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {bayesian-adapative-design,biomarker,closure-principle,combination-test,flexible-design,group-sequential-design,posterior-probability,predictive-power,sub-population-selection,time-to-event-data},
  note = {nice display of how to formalize the use of posterior probabilities for deciding the next step in the trial;RCT}
}

@article{bra12eff,
  title = {Effect of {{Dietary Protein Content}} on {{Weight Gain}}, {{Energy Expenditure}}, and {{Body Composition During Overeating}}},
  author = {Bray, George A. and Smith, Steven R. and de Jonge, Lilian and Xie, Hui and Rood, Jennifer and Martin, Corby K. and Most, Marlene and Brock, Courtney and Mancuso, Susan and Redman, Leanne M.},
  options = {useprefix=true},
  date = {2012-01-04},
  journaltitle = {JAMA},
  volume = {307},
  number = {1},
  eprint = {22215165},
  eprinttype = {pmid},
  pages = {47--55},
  issn = {0098-7484},
  doi = {10.1001/jama.2011.1918},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3777747/},
  urldate = {2019-10-02},
  abstract = {Context The role of diet composition in response to overeating and energy dissipation in humans is unclear. Objective To evaluate the effects of overconsumption of low, normal, and high protein diets on weight gain, energy expenditure, and body composition. Design, Setting, and Participants A single-blind, randomized controlled trial of 25 US healthy, weight-stable male and female volunteers, aged 18 to 35 years with a body mass index between 19 and 30. The first participant was admitted to the inpatient metabolic unit in June 2005 and the last in October 2007. Intervention After consuming a weight-stabilizing diet for 13 to 25 days, participants were randomized to diets containing 5\% of energy from protein (low protein), 15\% (normal protein), or 25\% (high protein), which they were overfed during the last 8 weeks of their 10- to 12-week stay in the inpatient metabolic unit. Compared with energy intake during the weight stabilization period, the protein diets provided approximately 40\% more energy intake, which corresponds to 954 kcal/d (95\% CI, 884–1022 kcal/d). Main Outcome Measures Body composition was measured by dual-energy x-ray absorptiometry biweekly, resting energy expenditure was measured weekly by ventilated hood, and total energy expenditure by doubly labeled water prior to the overeating and weight stabilization periods and at weeks 7 to 8. Results Overeating produced significantly less weight gain in the low protein diet group (3.16 kg; 95\% CI, 1.88–4.44 kg) compared with the normal protein diet group (6.05 kg; 95\% CI, 4.84–7.26 kg) or the high protein diet group (6.51 kg; 95\% CI, 5.23–7.79 kg) (P=.002). Body fat increased similarly in all 3 protein diet groups and represented 50\% to more than 90\% of the excess stored calories. Resting energy expenditure, total energy expenditure, and body protein did not increase during overfeeding with the low protein diet. In contrast, resting energy expenditure (normal protein diet: 160 kcal/d [95\% CI, 102–218 kcal/d]; high protein diet: 227 kcal/d [95\% CI, 165–289 kcal/d]) and body protein (lean body mass) (normal protein diet: 2.87 kg [95\% CI, 2.11–3.62 kg]; high protein diet: 3.18 kg [95\% CI, 2.37–3.98 kg]) increased significantly with the normal and high protein diets. Conclusions Among persons living in a controlled setting, calories alone account for the increase in fat; protein affected energy expenditure and storage of lean body mass, but not body fat storage.},
  pmcid = {PMC3777747},
  keywords = {diet,experimental-design,teaching,teaching-mds}
}

@article{bra17myo,
  title = {Myocardial {{T1 Measurement Predicts Beneficial LV Remodeling After Long-Term Heart Failure Therapy}}},
  author = {Bradham, William S. and Bell, Susan P. and Adkisson, Douglas W. and Smith, Holly M. and Harrell, Frank E. and Lawson, Mark A. and Ooi, Henry and Sawyer, Douglas B. and Kronenberg, Marvin W.},
  date = {2017-03},
  journaltitle = {J Card Fail},
  volume = {23},
  number = {3},
  eprint = {27940336},
  eprinttype = {pmid},
  pages = {262--265},
  issn = {1532-8414},
  doi = {10.1016/j.cardfail.2016.11.008},
  abstract = {BACKGROUND: The myocardial longitudinal relaxation time (T1) on cardiac magnetic resonance imaging (CMR) can quantify myocardial fibrosis in the presence or absence of visually detectable late gadolinium (Gd) enhancement (LGE). Mineralocorticoid receptor antagonist (MRA) treatment produces beneficial remodeling in nonischemic dilated cardiomyopathy (NIDCM). We assessed the hypothesis that interstitial myocardial fibrosis measured with the use of CMR predicts left ventricular (LV) beneficial remodeling in NIDCM after heart failure (HF) treatment including MRAs. METHODS AND RESULTS: Twelve patients with NIDCM, on stable beta-blocker and angiotensin-converting enzyme inhibitor/angiotensin receptor-blocking therapy, were studied before and after 6-29 months of treatment with MRAs, by means of CMR assessment of LV structure, function, and T1 from standard Look-Locker sequences (T1LL). All patients had depressed cardiac function, dilated left ventricles, and no visual LGE. After adding MRA to HF treatment, the LV ejection fraction increased and the LV end-systolic volume index (LV end-systolic volume/m2) decreased in all patients (P\,{$<$}\,.0001). This this was inversely proportional to the baseline myocardial T1LL (r\,=\,-0.65; P\,=\,.02). CONCLUSION: Myocardial T1LL, in the absence of visually detectable LGE, was quantitatively related to the degree of beneficial LV remodeling achieved in response to adding MRA to a HF regimen.},
  langid = {english},
  pmcid = {PMC5350022},
  keywords = {collaboration,cv}
}

@article{bra18mot,
  title = {Motivating Sample Sizes in Adaptive {{Phase I}} Trials via {{Bayesian}} Posterior Credible Intervals},
  author = {Braun, Thomas M.},
  journaltitle = {Biom},
  pages = {n/a},
  doi = {10.1111/biom.12872},
  url = {http://dx.doi.org/10.1111/biom.12872},
  abstract = {In contrast with typical Phase III clinical trials, there is little existing methodology for determining the appropriate numbers of patients to enroll in adaptive Phase I trials. And, as stated by Dennis Lindley in a more general context, ” [t]he simple practical question of 'What size of sample should I take' is often posed to a statistician, and it is a question that is embarrassingly difficult to answer.” Historically, simulation has been the primary option for determining sample sizes for adaptive Phase I trials, and although useful, can be problematic and time-consuming when a sample size is needed relatively quickly. We propose a computationally fast and simple approach that uses Beta distributions to approximate the posterior distributions of DLT rates of each dose and determines an appropriate sample size through posterior coverage rates. We provide sample sizes produced by our methods for a vast number of realistic Phase I trial settings and demonstrate that our sample sizes are generally larger than those produced by a competing approach that is based upon the nonparametric optimal design.},
  citeulike-article-id = {14548317},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/biom.12872},
  posted-at = {2018-03-13 19:45:31},
  priority = {2},
  keywords = {adaptive-design,bayes,bayesian-inference,drug-development,sample-size}
}

@article{bra18tim,
  title = {Timing of {{Left Ventricular Remodeling}} in {{Nonischemic Dilated Cardiomyopathy}}},
  author = {Bradham, William S. and Bell, Susan P. and Huang, Shi and Harrell, Frank E. and Adkisson, Douglas W. and Lawson, Mark A. and Sawyer, Douglas B. and Ooi, Henry and Kronenberg, Marvin W.},
  date = {2018-09},
  journaltitle = {Am J Med Sci},
  volume = {356},
  number = {3},
  eprint = {30286821},
  eprinttype = {pmid},
  pages = {262--267},
  issn = {1538-2990},
  doi = {10.1016/j.amjms.2018.06.003},
  abstract = {BACKGROUND: Mineralocorticoid receptor antagonist (MRA) treatment produces beneficial left ventricular (LV) remodeling in nonischemic dilated cardiomyopathy (NIDCM). This study addressed the timing of maximal beneficial LV remodeling in NIDCM when adding MRA. MATERIALS AND METHODS: We studied 12 patients with NIDCM on stable β-blocker and angiotensin-converting enzyme inhibitor/angiotensin receptor-blocking therapy who underwent cardiac magnetic resonance imaging before and after 6-31 months of continuous MRA therapy. RESULTS: At baseline, the LV ejection fraction (LVEF) was 24\% (19-27); median [interquartile range]. The LV end-systolic volume index (LVESVI) was 63 ml (57-76) and the LV stroke volume index (LVSVI) was 19 ml (14-21), all depressed. After adding MRA to the HF regimen, the LVEF increased to 47\% (42-52), with a decrease in LVESVI to 36 ml (33-45) and increase in LVSVI to 36 ml (28-39) (for each, P \,{$<$} 0\,.0001). Using generalized least squares analysis, the maximal beneficial remodeling (defined by maximal increase in LVEF, the maximal decrease in LVESVI and maximal increase in LVSVI) was achieved after approximately 12-16 months of MRA treatment. CONCLUSIONS: Adding MRA to a standard medical regimen for NIDCM resulted in beneficial LV remodeling. The maximal beneficial remodeling was achieved with 12-16 months of MRA therapy. These results have implications for the timing of other advanced therapies, such as placing internal cardioverter-defibrillators.},
  langid = {english},
  pmcid = {PMC7388723},
  keywords = {collaboration,cv}
}

@article{bra21bre,
  title = {Breaking the {{Bayesian Ice}} with {{Preclinical Discovery Biologists}} by {{Predicting Inadequate Animal Enrolment}}},
  author = {Bradstreet, Thomas E.},
  date = {2021-07-03},
  journaltitle = {Statistics in Biopharmaceutical Research},
  volume = {13},
  number = {3},
  pages = {344--354},
  publisher = {{Taylor \& Francis}},
  issn = {null},
  doi = {10.1080/19466315.2020.1799856},
  url = {https://doi.org/10.1080/19466315.2020.1799856},
  urldate = {2021-11-12},
  abstract = {An initial proposal was made to start 30 monkeys in the run-in period of a preclinical translational research study, to have 24 or more animals qualify for randomization in the subsequent treatment period. Based upon data from previous studies, Bayesian posterior prediction indicated that successful enrolment was highly unlikely. At least 67 animals were required to achieve an acceptable posterior predictive probability of success. Importantly, we leveraged these feasibility analyses to introduce our preclinical scientist collaborators to a Bayesian strategy for probability-based decision making. We provided them with a generous helping of graphics to effectively and efficiently illustrate Bayesian concepts and methods. We present our 4P strategy for collaboration with preclinical scientists: patience, persistence, positioning, and privilege. We discuss the alignment of the Bayesian and 4P strategies with goals common to pharmaceutical researchers: scientific innovation; stochastic intelligence and statistical literacy of team members; team collaboration and collegial partnerships; ethical acuity; and fiscal stewardship. Our article is as much about successfully reaching out to preclinical scientists, and introducing them to the Bayesian strategy, as it is about that strategy successfully addressing the animal enrolment question. This article is written at a statistical level accessible to both preclinical scientists and statisticians.},
  keywords = {bayes,prior-elicitation,sequential,teaching-mds},
  annotation = {\_eprint: https://doi.org/10.1080/19466315.2020.1799856}
}

@article{bra88con,
  title = {Confidence Intervals Extract Clinically Useful Information from Data},
  author = {Braitman, L. E.},
  date = {1988},
  journaltitle = {Ann Int Med},
  volume = {108},
  pages = {296--298},
  citeulike-article-id = {13263790},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {confidence-intervals,teaching-mds}
}

@article{bra89ran,
  title = {Randomized, Double-Blind Comparison of Famotidine with Ranitidine in Treatment of Acute, Benign Gastric Ulcer Disease. {{Community-based}} Study Coupled with a Patient Registry},
  author = {Brazer, S. R. and Tyor, M. P. and Pancotto, F. S. and Brice, R. S. and Garbutt, J. T. and Wildermann, N. M. and Harrell, F. E. and Pryor, D. B. and {The Study Group} and Liss, C. L. and Root, J. K. and Humphries, T. J.},
  date = {1989},
  journaltitle = {Dig Dis Sci},
  volume = {34},
  pages = {1047--1052},
  citeulike-article-id = {13263791},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bra90,
  title = {Assessing Proportionality in the Proportional Odds Model for Ordinal Logistic Regression},
  author = {Brant, R.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {1171--1178},
  citeulike-article-id = {13263792},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {logistic-ordinal-model}
}

@article{bra90stu,
  title = {Studies of Gastric Ulcer Disease by Community-Based Gastroenterologists},
  author = {Brazer, S. R. and Tyor, M. P. and Pancetto, F. S. and Nickl, N. J. and Wildermann, N. M. and Harrell, F. E. and {Pryor}},
  date = {1990},
  journaltitle = {Am J Gastroent},
  volume = {85},
  pages = {824--828},
  citeulike-article-id = {13263793},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bra91con,
  title = {Confidence Intervals Assess Both Clinical Significance and Statistical Significance},
  author = {Braitman, L. E.},
  date = {1991},
  journaltitle = {Ann Int Med},
  volume = {114},
  pages = {515--517},
  citeulike-article-id = {13263794},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {clinical-significance,confidence-intervals,statistical-significance,teaching-mds}
}

@article{bra91usi,
  title = {Using Ordinal Logistic Regression to Estimate the Likelihood of Colorectal Neoplasia},
  author = {Brazer, Scott R. and Pancotto, Frank S. and Long III, Thomas T. and Harrell, Frank E. and Lee, Kerry L. and Tyor, Malcolm P. and Pryor, David B.},
  date = {1991},
  journaltitle = {J Clin Epi},
  volume = {44},
  pages = {1263--1270},
  citeulike-article-id = {13263795},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {multivariable-modelling,nomogram,ordinal-logistic-model,ordinal-response,teaching-mds,tutorial}
}

@article{bra96dig,
  title = {Digesting Logistic Regression Results},
  author = {Brant, Rollin},
  date = {1996},
  journaltitle = {Am Statistician},
  volume = {50},
  pages = {117--119},
  citeulike-article-id = {13263796},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {apache,displaying-logistic-models,graphical-methods}
}

@article{bra96pre,
  title = {Predicting Clinical States in Individual Patients},
  author = {Braitman, L. E. and Davidoff, F.},
  date = {1996},
  journaltitle = {Ann Int Med},
  volume = {125},
  pages = {406--412},
  citeulike-article-id = {13263797},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {multivariable-modeling,reporting-statistical-results,teaching-mds}
}

@article{bra98met,
  title = {Metan---an Alternative Meta-Analysis Command},
  author = {Bradburn, Michael J. and Deeks, Jonathan J. and Altman, Douglas G.},
  date = {1998-07},
  journaltitle = {Stata Tech Bull},
  number = {44},
  pages = {4--15},
  citeulike-article-id = {13263798},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {blob-charts,meta-analysis}
}

@article{Brannath04,
  title = {Optimal Conditional Error Functions for the Control of Conditional Power},
  author = {Brannath, W. and {Bauer}},
  date = {2004},
  journaltitle = {Biometrics},
  volume = {60},
  pages = {715--723},
  citeulike-article-id = {13265519},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{bre01sta,
  title = {Statistical Modeling: {{The}} Two Cultures (with Discussion)},
  author = {Breiman, Leo},
  date = {2001},
  journaltitle = {Stat Sci},
  volume = {16},
  pages = {199--231},
  citeulike-article-id = {13265251},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  note = {data models vs. algorithms;Cox's discussion criticizes Breiman for using straw-men oversimplified data models;consulting vs. academia;conflict between accuracy and simplicity;interpretability is not as important as information;nature is a black box anyway;measuring importance of variables by removing or perturbing them;overuse of percent classified correctly}
}

@article{bre10fro,
  title = {From Adaptive Design to Modern Protocol Design for Drug Development: {{Part II}}. {{Success}} Probabilities and Effect Estimates for {{Phase}} 3 Development Programs},
  author = {Bretz, Frank and Wang, Sue-Jane},
  date = {2010},
  journaltitle = {Drug Info J},
  volume = {44},
  pages = {333--342},
  citeulike-article-id = {13265867},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {adaptive-design,clinical-trial-simulation,treatment-selection}
}

@article{bre13anc,
  title = {{{ANCOVA Versus CHANGE From Baseline}} in {{Nonrandomized Studies}}: {{The Difference}}},
  author = {van Breukelen, Gerard J. P.},
  options = {useprefix=true},
  date = {2013-11},
  journaltitle = {Multivar Behav Res},
  volume = {48},
  number = {6},
  pages = {895--922},
  publisher = {Routledge},
  doi = {10.1080/00273171.2013.831743},
  url = {http://dx.doi.org/10.1080/00273171.2013.831743},
  abstract = {The pretest-posttest control group design can be analyzed with the posttest as dependent variable and the pretest as covariate (ANCOVA) or with the difference between posttest and pretest as dependent variable (CHANGE). These 2 methods can give contradictory results if groups differ at pretest, a phenomenon that is known as Lord's paradox. Literature claims that ANCOVA is preferable if treatment assignment is based on randomization or on the pretest and questionable for preexisting groups. Some literature suggests that Lord's paradox has to do with measurement error in the pretest. This article shows two new things: First, the claims are confirmed by proving the mathematical equivalence of ANCOVA to a repeated measures model without group effect at pretest. Second, correction for measurement error in the pretest is shown to lead back to ANCOVA or to CHANGE, depending on the assumed absence or presence of a true group difference at pretest. These two new theoretical results are illustrated with multilevel (mixed) regression and structural equation modeling of data from two studies.},
  citeulike-article-id = {13472026},
  citeulike-attachment-1 = {van<sub>b</sub>reukelen₁3ₐncova₁121106.pdf; /pdf/user/harrelfe/article/13472026/1121106/van<sub>b</sub>reukelen₁3ₐncova₁121106.pdf; 04466de0ad20031f5c74e6c7ee3c32c9e88bef0d},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00273171.2013.831743},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/00273171.2013.831743},
  day = {1},
  posted-at = {2017-10-22 21:31:24},
  priority = {2},
  keywords = {ancova,change,change-from-baseline,change-score}
}

@article{bre74,
  title = {Covariance Analysis of Censored Survival Data},
  author = {Breslow, N. E.},
  date = {1974},
  journaltitle = {Biometrics},
  volume = {30},
  pages = {89--99},
  citeulike-article-id = {13263799},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bre78,
  title = {Estimation of Multiple Relative Risk Functions in Matched Case-Control Studies},
  author = {Breslow, N. E. and Day, N. E. and Halvorsen, K. T. and Prentice, R. L. and Sabai, C.},
  date = {1978},
  journaltitle = {Am J Epi},
  volume = {108},
  pages = {299--307},
  citeulike-article-id = {13263800},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bre79,
  title = {Statistical Methods for Censored Survival Data},
  author = {Breslow, N. E.},
  date = {1979},
  journaltitle = {Env Hlth Perspect},
  volume = {32},
  pages = {181--192},
  citeulike-article-id = {13263801},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@book{bre84cla,
  title = {Classification and {{Regression Trees}}},
  author = {Breiman, Leo and Friedman, Jerome H. and Olshen, Richard A. and Stone, Charles J.},
  date = {1984},
  publisher = {{Wadsworth and Brooks/Cole}},
  location = {{Pacific Grove, CA}},
  citeulike-article-id = {13263802},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bre84two,
  title = {A Two-Sample Censored-Data Rank Test for Acceleration},
  author = {Breslow, N. E. and Edler, L. and Berger, J.},
  date = {1984},
  journaltitle = {Biometrics},
  volume = {40},
  pages = {1049--1062},
  citeulike-article-id = {13263803},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {assessing-ph,survival-analysis}
}

@article{bre85est,
  title = {Estimating Optimal Transformations for Multiple Regression and Correlation (with Discussion)},
  author = {Breiman, L. and Friedman, J. H.},
  date = {1985},
  journaltitle = {J Am Stat Assoc},
  volume = {80},
  pages = {580--619},
  citeulike-article-id = {13263804},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {ace,multivariate-analysis,transformations}
}

@article{bre88log,
  title = {Logistic Regression for Two-Stage Case-Control Data},
  author = {Breslow, N. E. and Cain, K. C.},
  date = {1988},
  journaltitle = {Biometrika},
  volume = {75},
  pages = {11--20},
  citeulike-article-id = {13263805},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {empirical-likelihood-approach,missing-data,study-design}
}

@article{bre90bio,
  title = {Biostatistics and {{Bayes}} (with Discussion)},
  author = {Breslow, Norman},
  date = {1990},
  journaltitle = {Stat Sci},
  volume = {5},
  pages = {269--298},
  citeulike-article-id = {13263806},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {bayesian-inference,bioequivalence,model-selection-p-281,sequential-monitoring}
}

@article{bre92lit,
  title = {The Little Bootstrap and Other Methods for Dimensionality Selection in Regression: {{X-fixed}} Prediction Error},
  author = {Breiman, Leo},
  date = {1992},
  journaltitle = {J Am Stat Assoc},
  volume = {87},
  pages = {738--754},
  citeulike-article-id = {13263807},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bre95bet,
  title = {Better Subset Regression Using the Nonnegative Garrote},
  author = {Breiman, Leo},
  date = {1995},
  journaltitle = {Technometrics},
  volume = {37},
  pages = {373--384},
  citeulike-article-id = {13263808},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {model-selection,penalized-estimation,ridge-regression,scale-invariance,shrinkage,simulation-setup,variable-selection}
}

@report{bre96bor,
  title = {Born Again Trees},
  author = {Breiman, L. and Shang, N.},
  date = {1996},
  institution = {{University of California}},
  location = {{Berkeley}},
  citeulike-article-id = {13263809},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  note = {using trees to decode black box predictors}
}

@article{bre97var,
  title = {Variation of Sensitivity, Specificity, Likelihood Ratios and Predictive Values with Disease Prevalence},
  author = {Brenner, Hermann and Gefeller, Olaf},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {981--991},
  citeulike-article-id = {13263810},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {diagnosis,teaching-mds},
  note = {non-constancy of sensitivity and specificity caused by fact that most diseases represent continuous processes}
}

@article{bri05ass,
  title = {Assessing the Skill of Yes/No Predictions},
  author = {Briggs, William and Ruppert, David},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  pages = {799--807},
  citeulike-article-id = {13265439},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {accuracy,brier-score,expected-loss,mammogram-testing,sensitivity,skill-score,specificity,test-of-dependence}
}

@article{bri08ski,
  title = {The Skill Plot: {{A}} Graphical Technique for Evaluating Continuous Diagnostic Tests (with Discussion)},
  author = {Briggs, William M. and Zaretzki, Russell},
  date = {2008},
  journaltitle = {Biometrics},
  volume = {64},
  pages = {250--261},
  citeulike-article-id = {13265667},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {diagnosis,diagnostic-accuracy,predictive-accuracy,roc-curve,sensitivity,skill-plot,skill-score,specificity},
  note = {"statistics such as the AUC are not especially relevant to someone who must make a decision about a particular x\_c. ... ROC curves lack or obscure several quantities that are necessary for evaluating the operational effectiveness of diagnostic tests. ... ROC curves were first used to check how radio {$<$}i{$>$}receivers{$<$}/i{$>$} (like radar receivers) operated over a range of frequencies. ... This is not how most ROC curves are used now, particularly in medicine. The receiver of a diagnostic measurement ... wants to make a decision based on some x\_c, and is not especially interested in how well he would have done had he used some different cutoff."; in the discussion David Hand states "when integrating to yield the overall AUC measure, it is necessary to decide what weight to give each value in the integration. The AUC implicitly does this using a weighting derived empirically from the data. This is nonsensical. The relative importance of misclassifying a case as a noncase, compared to the reverse, cannot come from the data itself. It must come externally, from considerations of the severity one attaches to the different kinds of misclassifications."; see Lin, Kvam, Lu Stat in Med 28:798-813;2009}
}

@article{bri17sub,
  title = {The {{Substitute}} for P-{{Values}}},
  author = {Briggs, William M.},
  date = {2017-07},
  journaltitle = {JASA},
  volume = {112},
  number = {519},
  pages = {897--898},
  publisher = {Taylor & Francis},
  doi = {10.1080/01621459.2017.1311264},
  url = {http://dx.doi.org/10.1080/01621459.2017.1311264},
  abstract = {If it was not obvious before, after reading McShane and Gal, the conclusion is that p-values should be proscribed. There are no good uses for them; indeed, every use either violates frequentist theory, is fallacious, or is based on a misunderstanding. A replacement for p-values is suggested, based on predictive models.},
  citeulike-article-id = {14479856},
  citeulike-attachment-1 = {bri17sub.pdf; /pdf/user/harrelfe/article/14479856/1123078/bri17sub.pdf; e2946ca2518f20e15d607a0bccb9accb149c2c19},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.2017.1311264},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1311264},
  day = {3},
  posted-at = {2017-11-21 14:33:28},
  priority = {0},
  keywords = {bayesian-inference,p-values,teaching-mds,teaching-statisticians}
}

@article{bri50ver,
  title = {Verification of Forecasts Expressed in Terms of Probability},
  author = {Brier, G. W.},
  date = {1950},
  journaltitle = {Monthly Weather Rev},
  volume = {78},
  pages = {1--3},
  citeulike-article-id = {13263811},
  posted-at = {2014-07-14 14:09:23},
  priority = {0}
}

@article{bri89,
  title = {Sample Sizes for Constructing Confidence Intervals and Testing Hypotheses},
  author = {Bristol, D. R.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {803--811},
  citeulike-article-id = {13263812},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {sample-size-estimation,study-design-and-stopping-rules}
}

@article{bri90,
  title = {Survival Analysis Techniques in Angina Pectoris Trials},
  author = {Bristol, D. R. and Castellana, J. V.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {293--299},
  citeulike-article-id = {13263813},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {measurement,research-methods,survival-analysis-proportional-hazards-model}
}

@article{bri99con,
  title = {Constructing Confidence Intervals for Cost-Effectiveness Ratios: {{An}} Evaluation of Parametric and Non-Parametric Techniques Using {{Monte Carlo}} Simulation},
  author = {Briggs, Andrew H. and Mooney, Christopher Z. and Wonderling, David E.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {3245--3262},
  citeulike-article-id = {13263814},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {analysis-of-cost,bootstrap,c-e-ratio,confidence-intervals-for-cost-effectiveness-ratio,simulation-setup}
}

@article{brms,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  author = {Bürkner, Paul-Christian},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  volume = {80},
  number = {1},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  url = {http://dx.doi.org/10.18637/jss.v080.i01},
  citeulike-article-id = {14573585},
  citeulike-linkout-0 = {http://dx.doi.org/10.18637/jss.v080.i01},
  posted-at = {2018-04-22 23:45:47},
  priority = {2},
  keywords = {bayes,bayesian-inference,bayesian-modeling,stan,statistical-computing}
}

@incollection{bro00bay,
  title = {A {{Bayesian}} Meta-Analysis of Randomized Mega-Trials for the Choice of Thrombolytic Agent in Acute Myocardial Infarction},
  booktitle = {Meta-{{Analysis}} in {{Medicine}} and {{Health Policy}}},
  author = {Brophy, J. and Joseph, L.},
  editor = {Berry, D. and Stangl, D.},
  date = {2000},
  pages = {83--104},
  publisher = {{Marcel Dekker}},
  location = {{New York}},
  citeulike-article-id = {13265203},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {bayesian-analysis,gusto,poolability},
  note = {accounting for differences in treatment delivery; adjusting analyses to explicitly account for the possible effect of accelerated dosing, using a hierarchical Bayesian model with bias corrections. Despite this adjustment, the authors found very similar conclusions as in their previous article, and therefore conclude that this does not fully explain the differences observed in the results of GUSTO compared to previous studies.}
}

@article{bro01int,
  title = {Interval Estimation for a Binomial Proportion (with Discussion)},
  author = {Brown, Lawrence D. and Cai, Tony T. and DasGupta, Anirban},
  date = {2001},
  journaltitle = {Stat Sci},
  volume = {16},
  pages = {101--133},
  citeulike-article-id = {13265233},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {confidence-intervals-for-binomial-proportion,confidence-limits,probability,wilson-interval}
}

@article{bro05sea,
  title = {In Search of Fewer Independent Risk Factors},
  author = {Brotman, Daniel J. and Walker, Esteban and Lauer, Michael S. and O'Brien, Ralph G.},
  date = {2005},
  journaltitle = {Arc Int Med},
  volume = {165},
  pages = {138--145},
  citeulike-article-id = {13265398},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  note = {"independence depends on variables included in the model;noncausal risk factors can be independent risk factors;indirect causal factors may be nonindependent risk factors;therapeutic markers need not be risk factors;randomized controlled trials cannot always distinguish causal from noncausal factors"}
}

@article{bro09wha,
  title = {What Is Statistics? (With Discussion)},
  author = {Brown, Emery N. and Kass, Robert E.},
  date = {2009},
  journaltitle = {Am Statistician},
  volume = {63},
  number = {2},
  pages = {105--123},
  citeulike-article-id = {13265832},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {cross-disciplinary-statistical-research,statistical-education,statistical-paradigm,statistical-thinking},
  note = {"... departments of statistics often act as if they are preparing students to be short-term consultants, able to answer circumscribed methodological questions based on limited contemplation of the context. The short-term consultant model relegates the statistician to a subsidiary position, and suggests that applied statistics consists of handling well-formulated questions, so as to match an accepted method to nearly any kind of data. ... Statistical thinking uses probabilistic descriptions of variability in (1) inductive reasoning and (2) analysis of procedures for data collection, prediction, and scientific inference. ... The essential component that characterizes the discipline is the introduction of probability to describe variation in order to provide a good solution to a problem involving the reduction of data for a specific purpose. ... (we) elaborate our definition of statistical thinking by stating that it involves two principles: 1. Statistical models of regularity and variability in data may be used to express knowledge and uncertainty about a signal in the presence of noise, via inductive reasoning. 2. Statistical methods may be analyzed to determine how well they are likely to perform."}
}

@article{bro12los,
  title = {The Loss of the “{{Titanic}}”},
  author = {Bron, G.},
  date = {1912-05},
  journaltitle = {The Sphere},
  volume = {49},
  pages = {103},
  url = {http://novascotia.ca/archives/virtual/titanic/magazines.asp?ID=56},
  citeulike-article-id = {13409324},
  citeulike-linkout-0 = {http://novascotia.ca/archives/virtual/titanic/magazines.asp?ID=56},
  posted-at = {2014-10-26 22:23:56},
  priority = {0},
  keywords = {graphics,titanic},
  annotation = {The results analysed and shown in a special “Sphere” diagram drawn from the official figures given in the House of Commons},
  note = {The results analysed and shown in a special “Sphere” diagram drawn from the official figures given in the House of Commons}
}

@article{bro16com,
  title = {Composite {{End Points}} in {{Acute Heart Failure Research}}: {{Data Simulations Illustrate}} the {{Limitations}}},
  shorttitle = {Composite {{End Points}} in {{Acute Heart Failure Research}}},
  author = {Brown, Paul M. and Anstrom, Kevin J. and Felker, G. Michael and Ezekowitz, Justin A.},
  date = {2016-11-01},
  journaltitle = {Canadian Journal of Cardiology},
  volume = {32},
  number = {11},
  pages = {1356.e21-1356.e28},
  publisher = {{Elsevier}},
  issn = {0828-282X, 1916-7075},
  doi = {10.1016/j.cjca.2016.02.067},
  url = {https://www.onlinecjc.ca/article/S0828-282X(16)00193-8/abstract},
  urldate = {2020-12-07},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}p{$>$}Composite end points are frequently used in clinical trials of investigational treatments for acute heart failure, eg, to boost statistical power and reduce the overall sample size. By incorporating multiple and varying types of clinical outcomes they provide a test for the overall efficacy of the treatment. Our objective is to compare the performance of popular composite end points in terms of statistical power and describe the uncertainty in these power estimates and issues concerning implementation. We consider several composites that incorporate outcomes of varying types (eg, time to event, categorical, and continuous). Data are simulated for 5 outcomes, and the composites are derived and compared. Power is evaluated graphically while varying the size of the treatment effects, thus describing the sensitivity of power to varying circumstances and eventualities such as opposing effects. The average \emph{z} score offered the most power, although caution should be exercised when opposing effects are anticipated. Results emphasize the importance of an a priori assessment of power and scientific basis for construction, including the weighting of individual outcomes deduced from data simulations. The interpretation of a composite should be made alongside results from the individual components. The average \emph{z} score offers the most power, but this should be considered in the research context and is not without its limitations.{$<$}/p{$>$}},
  langid = {english},
  keywords = {composite-endpoint,multiple-endpoints,rct}
}

@article{bro17com,
  title = {Composite {{End Points}} in {{Clinical Trials}} of {{Heart Failure Therapy}}},
  author = {{Brown Paul M.} and {Ezekowitz Justin A.}},
  date = {2017-01-01},
  journaltitle = {Circulation: Heart Failure},
  volume = {10},
  number = {1},
  pages = {e003222},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCHEARTFAILURE.116.003222},
  url = {https://www.ahajournals.org/doi/full/10.1161/circheartfailure.116.003222},
  urldate = {2020-11-25},
  abstract = {Composite end points are popular outcomes in clinical trials of heart failure therapies. For example, a global rank composite is typically analyzed using a Mann–Whitney U test, and the results are summarized by the mean of ranks and a corresponding P value. The mean of ranks is uninformative, and a clinically meaningful estimate of the treatment effect is needed to communicate study results and facilitate an assessment of heterogeneity (the consistency of the effect across outcomes). The probability index is intuitive for clinicians, easy to calculate, and may be applied to various composites. We suggest a simple and familiar plot to assess heterogeneity across outcomes, which should be routine when analyzing composites. We think that the probability index provides an immediate and simple solution to an overt problem.},
  keywords = {c-index,global-rank,multiple-endpoints,probability-index,rct}
}

@article{bro17mul,
  title = {Multitype {{Events}} and the {{Analysis}} of {{Heart Failure Readmissions}}},
  author = {Brown, Paul M. and Ezekowitz, Justin A.},
  date = {2017-06},
  journaltitle = {Circ: Cardiovasc Qual Outcomes},
  volume = {10},
  number = {6},
  eprint = {28630372},
  eprinttype = {pmid},
  pages = {e003382+},
  publisher = {American Heart Association, Inc.},
  issn = {1941-7713},
  doi = {10.1161/circoutcomes.116.003382},
  url = {http://dx.doi.org/10.1161/circoutcomes.116.003382},
  citeulike-article-id = {14565827},
  citeulike-linkout-0 = {http://dx.doi.org/10.1161/circoutcomes.116.003382},
  citeulike-linkout-1 = {http://circoutcomes.ahajournals.org/content/10/6/e003382.abstract},
  citeulike-linkout-2 = {http://circoutcomes.ahajournals.org/content/10/6/e003382.full.pdf},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/28630372},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=28630372},
  day = {01},
  posted-at = {2018-04-08 14:34:53},
  priority = {2},
  keywords = {multiple-endpoints,rct}
}

@article{bro18exa,
  title = {Examining the {{Influence}} of {{Component Outcomes}} on the {{Composite}} at the {{Design Stage}}},
  author = {{Brown Paul M.} and {Ezekowitz Justin A.}},
  date = {2018-06-01},
  journaltitle = {Circulation: Cardiovascular Quality and Outcomes},
  volume = {11},
  number = {6},
  pages = {e004419},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCOUTCOMES.117.004419},
  url = {https://www.ahajournals.org/doi/10.1161/CIRCOUTCOMES.117.004419},
  urldate = {2020-12-07},
  keywords = {composit-endpoint,influence,multiple-endpoints,rct}
}

@article{bro21pro,
  title = {The Promise and Pitfalls of Composite Endpoints in Sepsis and {{COVID-19}} Clinical Trials},
  author = {Brown, P. M. and Rogne, Tormod and Solligård, Erik},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {20},
  number = {2},
  pages = {413--417},
  issn = {1539-1612},
  doi = {10.1002/pst.2070},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2070},
  urldate = {2021-03-07},
  abstract = {Composite endpoints reveal the tendency for statistical convention to arise locally within subfields. Composites are familiar in cardiovascular trials, yet almost unknown in sepsis. However, the VITAMINS trial in patients with septic shock adopted a composite of mortality and vasopressor-free days, and an ordinal scale describing patient status rapidly became standard in COVID studies. Aware that recent use could incite interest in such endpoints, we are motivated to flag their potential value and pitfalls for sepsis research and COVID studies.},
  langid = {english},
  keywords = {compound-endpoints,covid19,multiple-endpoints,rct,sepsis},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2070}
}

@article{bro66spu,
  title = {Spurious Effects from an Extraneous Variable},
  author = {Bross, Irwin D. J.},
  date = {1966-06},
  journaltitle = {J Chron Dis},
  volume = {19},
  number = {6},
  pages = {637--647},
  issn = {00219681},
  doi = {10.1016/0021-9681(66)90062-2},
  url = {http://dx.doi.org/10.1016/0021-9681(66)90062-2},
  citeulike-article-id = {13898362},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0021-9681(66)90062-2},
  posted-at = {2016-01-05 23:08:41},
  priority = {2},
  keywords = {confounding,epidemiology},
  note = {referenced by fra15reg as providing a measure of confounding+prevalence+outcome association}
}

@incollection{bro74non,
  title = {Nonparametric Tests of Independence for Censored Data, with Applications to Heart Transplant Studies},
  booktitle = {Rel {{Biometry}}},
  author = {Brown, B. W. and Hollander, M. and Korwar, R. M.},
  editor = {Proschan, F. and Serfling, R. J.},
  date = {1974},
  pages = {327--354},
  publisher = {{SIAM}},
  location = {{Philadelphia}},
  citeulike-article-id = {13263815},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  note = {Original idea may have come from efr67two}
}

@article{bro88,
  title = {Reader Reaction: {{Estimating Pr}}({{X}}},
  author = {{Brownie}},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {615--621},
  citeulike-article-id = {13263816},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {distribution-free-methods,predictive-accuracy}
}

@inproceedings{bro88reg,
  title = {Regression Strategies},
  booktitle = {Proceedings of the 20th {{Symposium}} on the {{Interface}} between {{Computer Science}} and {{Statistics}}},
  author = {Brownstone, David},
  date = {1988},
  pages = {74--79},
  publisher = {{American Statistical Association}},
  location = {{Washington, DC}},
  citeulike-article-id = {13263817},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {bootstrapping,predictive-accuracy,validation,variable-selection}
}

@article{bro94thr,
  title = {Thrombolysis from {{P}} Values to Public Health},
  author = {Brophy, James M.},
  date = {1994},
  journaltitle = {Can J Cardiol},
  volume = {10},
  pages = {997--999},
  citeulike-article-id = {13263818},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {gusto,p-values,see-bro00bay,statistical-vs-clinical-significance,t-pa}
}

@article{bro95pla,
  title = {Placing Trials in Context Using {{Bayesian}} Analysis: {{GUSTO}} Revisited by {{Reverend Bayes}}},
  author = {Brophy, James M. and Joseph, Lawrence},
  date = {1995},
  journaltitle = {JAMA},
  volume = {273},
  pages = {871--875},
  citeulike-article-id = {13263819},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {bayesian-inference,gusto,meta-analysis,poolability,see-bro00bay,sensitivity-to-prior,t-pa}
}

@article{bro97bay,
  title = {A {{Bayesian}} Analysis of Regression Models with Continuous Errors with Application to Longitudinal Studies},
  author = {Broemeling, Lyle D. and Cook, Peyton},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {321--332},
  citeulike-article-id = {13263820},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {bayesian-inference,bayesian-modeling,direct-sampling-approach-to-estimating-posterior-density,regression-analysis-of-correlated-data,time-series}
}

@article{bro99asy,
  title = {Asymptotic Power Calculations: {{Description}}, Examples, Computer Code},
  author = {Brown, Barry W. and Lovato, James and Russell, Kathy},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {3137--3151},
  citeulike-article-id = {13263821},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {covariable-effects,power-calculation}
}

@article{bru03int,
  title = {The Intensity-Score Approach to Adjusting for Confounding},
  author = {Brumback, Babette and Greenland, Sander and Redman, Mary and Kiviat, Nancy and Diehr, Paula},
  date = {2003},
  journaltitle = {Biometrics},
  volume = {59},
  pages = {274--285},
  citeulike-article-id = {13265334},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {causal-inference,confounding,differential-access-to-care,dynamic-propensity-score,e-estimation,g-estimation,instrumental-variables,longitudinal-data,marginal-structural-model,observational-data,propensity-score,structural-nested-mean-model,time-dependent-confounding,time-dependent-propensity-score}
}

@article{bru03pre,
  title = {Predicting Kidney Graft Failure Using Time-Dependent Renal Function Covariates},
  author = {de Bruijne, Mattheus H. J. and Sijpkens, Yvo W. J. and Paul, Leendert C. and Westendorp, Rudi G. J. and van Houwelingen, Hans C. and Zwinderman, Aeilko H.},
  options = {useprefix=true},
  date = {2003},
  journaltitle = {J Clin Epi},
  volume = {56},
  pages = {448--455},
  citeulike-article-id = {13265331},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {cox-proportional-hazards-model,graft-failure,reciprocal-of-serum-creatinine,renal-transplantation,tdc}
}

@article{bru08eff,
  title = {On Effect-Measure Modification: {{Relationships}} among Changes in the Relative Risk, Odds Ratio, and Risk Difference},
  author = {Brumback, Babette and Berg, Arthur},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {3453--3465},
  doi = {10.1002/sim.3246},
  url = {http://dx.doi.org/10.1002/sim.3246},
  citeulike-article-id = {13265686},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3246},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {case-control-studies,clinical-trials,cohort-studies,common-outcomes,cross-sectional-studies,effect-measure,heterogeneity,interaction,rct},
  note = {different effect measures can give effect modifications of opposite signs}
}

@article{bru08rob,
  title = {Robust {{Bayesian}} Sample Size Determination in Clinical Trials},
  author = {Brutti, Pierpaolo and De Santis, Fulvio and Gubbiotti, Stefania},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {2290--2306},
  citeulike-article-id = {13265677},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {analysis-and-design-priors,bayesian-power,bayesian-robustness,conditional-and-predictive-power,epsilon-contaminated-priors,evidence,phase-ii-and-phase-iii-clinical-trials,sample-size-determination}
}

@article{bru09mix,
  title = {Mixtures of Prior Distributions for Predictive {{Bayesian}} Sample Size Calculations in Clinical Trials},
  author = {Brutti, Pierpaolo and De Santis, Fulvio and Gubbiotti, Stefania},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {2185--2201},
  citeulike-article-id = {13265772},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {analysis-prior,bayesian-methods,design-prior,normal-approximations,phase-ii-and-iii-clinical-trials,predictive-distribution,sample-size-estimation,sample-size-re-estimation}
}

@article{bru19eff,
  title = {Effect of {{Teaching Bayesian Methods Using Learning}} by {{Concept}} vs {{Learning}} by {{Example}} on {{Medical Students}}’ {{Ability}} to {{Estimate Probability}} of a {{Diagnosis}}: {{A Randomized Clinical Trial}}},
  shorttitle = {Effect of {{Teaching Bayesian Methods Using Learning}} by {{Concept}} vs {{Learning}} by {{Example}} on {{Medical Students}}’ {{Ability}} to {{Estimate Probability}} of a {{Diagnosis}}},
  author = {Brush, John E. and Lee, Mark and Sherbino, Jonathan and Taylor-Fishwick, Judith C. and Norman, Geoffrey},
  date = {2019-12-02},
  journaltitle = {JAMA Netw Open},
  volume = {2},
  number = {12},
  pages = {e1918023-e1918023},
  doi = {10.1001/jamanetworkopen.2019.18023},
  url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2757877},
  urldate = {2019-12-21},
  abstract = {{$<$}h3{$>$}Importance{$<$}/h3{$><$}p{$>$}Clinicians use probability estimates to make a diagnosis. Teaching students to make more accurate probability estimates could improve the diagnostic process and, ultimately, the quality of medical care.{$<$}/p{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To test whether novice clinicians can be taught to make more accurate bayesian revisions of diagnostic probabilities using teaching methods that apply either explicit conceptual instruction or repeated examples.{$<$}/p{$><$}h3{$>$}Design, Setting, and Participants{$<$}/h3{$><$}p{$>$}A randomized clinical trial of 2 methods for teaching bayesian updating and diagnostic reasoning was performed. A web-based platform was used for consent, randomization, intervention, and testing of the effect of the intervention. Participants included 61 medical students at McMaster University and Eastern Virginia Medical School recruited from May 1 to September 30, 2018.{$<$}/p{$><$}h3{$>$}Interventions{$<$}/h3{$><$}p{$>$}Students were randomized to (1) receive explicit conceptual instruction regarding diagnostic testing and bayesian revision (concept group), (2) exposure to repeated examples of cases with feedback regarding posttest probability (experience group), or (3) a control condition with no conceptual instruction or repeated examples.{$<$}/p{$><$}h3{$>$}Main Outcomes and Measures{$<$}/h3{$><$}p{$>$}Students in all 3 groups were tested on their ability to update the probability of a diagnosis based on either negative or positive test results. Their probability revisions were compared with posttest probability revisions that were calculated using the Bayes rule and known test sensitivity and specificity.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Of the 61 participants, 22 were assigned to the concept group, 20 to the experience group, and 19 to the control group. Approximate age was 25 years. Two participants were first-year; 37, second-year; 12, third-year; and 10, fourth-year students. Mean (SE) probability estimates of students in the concept group were statistically significantly closer to calculated bayesian probability than the other 2 groups (concept, 0.4\%; [0.7\%]; experience, 3.5\% [0.7\%]; control, 4.3\% [0.7\%];\emph{P} \&lt; .001). Although statistically significant, the differences between groups were relatively modest, and students in all groups performed better than expected, based on prior reports in the literature.{$<$}/p{$><$}h3{$>$}Conclusions and Relevance{$<$}/h3{$><$}p{$>$}The study showed a modest advantage for students who received theoretical instruction on bayesian concepts. All participants’ probability estimates were, on average, close to the bayesian calculation. These findings have implications for how to teach diagnostic reasoning to novice clinicians.{$<$}/p{$><$}h3{$>$}Trial Registration{$<$}/h3{$><$}p{$>$}ClinicalTrials.gov identifier:NCT04130607{$<$}/p{$>$}},
  langid = {english},
  keywords = {bayes,diagnosis,teaching,teaching-mds}
}

@article{bru21ran,
  title = {Ranks and {{Pseudo-ranks}}—{{Surprising Results}} of {{Certain Rank Tests}} in {{Unbalanced Designs}}},
  author = {Brunner, Edgar and Konietschke, Frank and Bathke, Arne C. and Pauly, Markus},
  date = {2021},
  journaltitle = {International Statistical Review},
  volume = {89},
  number = {2},
  pages = {349--366},
  issn = {1751-5823},
  doi = {10.1111/insr.12418},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12418},
  urldate = {2021-10-13},
  abstract = {Rank-based inference methods are applied in various disciplines, typically when procedures relying on standard normal theory are not justifiable. Various specific rank-based methods have been developed for two and more samples and also for general factorial designs (e.g. Kruskal–Wallis test or Akritas–Arnold–Brunner test). It is the aim of the present paper (1) to demonstrate that traditional rank procedures for several samples or general factorial designs may lead to surprising results in case of unequal sample sizes as compared with equal sample sizes, (2) to explain why this is the case and (3) to provide a way to overcome these disadvantages. Theoretical investigations show that the surprising results can be explained by considering the non-centralities of the test statistics, which may be non-zero for the usual rank-based procedures in case of unequal sample sizes, while they may be equal to 0 in case of equal sample sizes. A simple solution is to consider unweighted relative effects instead of weighted relative effects. The former effects are estimated by means of the so-called pseudo-ranks, while the usual ranks naturally lead to the latter effects. A real data example illustrates the practical meaning of the theoretical discussions.},
  langid = {english},
  keywords = {nonparametric,transitivity,wilcoxon-test},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/insr.12418}
}

@article{bru21win,
  title = {Win Odds: {{An}} Adaptation of the Win Ratio to Include Ties},
  shorttitle = {Win Odds},
  author = {Brunner, Edgar and Vandemeulebroecke, Marc and Mütze, Tobias},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {40},
  number = {14},
  pages = {3367--3384},
  issn = {1097-0258},
  doi = {10.1002/sim.8967},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8967},
  urldate = {2021-09-15},
  abstract = {The win ratio, a recently proposed measure for comparing the benefit of two treatment groups, allows ties in the data but ignores ties in the inference. In this article, we highlight some difficulties that this can lead to, and we propose to focus on the win odds instead, a modification of the win ratio which takes ties into account. We construct hypothesis tests and confidence intervals for the win odds, and we investigate their properties through simulations and in a case study. We conclude that the win odds should be preferred over the win ratio.},
  langid = {english},
  keywords = {multiple-endpoints,wilcoxon-test,win-ratio},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8967},
  note = {Nice information about Wilcoxon test and ties.~
\par
Win ratio provides a larger effect size with more times, even though more ties decreases its precision.~ The win odds is more intuitive and interpretable.}
}

@article{bry04sem,
  title = {Semiparametric Models for Cumulative Incidence Functions},
  author = {Bryant, John and Dignam, James J.},
  date = {2004},
  journaltitle = {Biometrics},
  volume = {69},
  pages = {182--190},
  citeulike-article-id = {13265366},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {cause-specific-hazard,competing-risks,cumulative-incidence-function,martingale,multivariate-counting-processes,subdistribution},
  note = {nonparametric adjustment for competing risk with parametric modeling of event of interest to gain precision}
}

@article{buc60met,
  title = {A Method of Estimation of Missing Values in Multivariate Data Suitable for Use with an Electronic Computer},
  author = {Buck, S. F.},
  date = {1960},
  journaltitle = {J Roy Stat Soc B},
  volume = {22},
  pages = {302--307},
  citeulike-article-id = {13263822},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {missing-data}
}

@article{buc79lin,
  title = {Linear Regression with Censored Data},
  author = {Buckley, Jonathan and James, Ian},
  date = {1979},
  journaltitle = {Biometrika},
  volume = {66},
  pages = {429--36},
  citeulike-article-id = {13263823},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {censored-data,distribution-free-methods,general,least-squares}
}

@article{buc97mod,
  title = {Model Selection: {{An}} Integral Part of Inference},
  author = {Buckland, S. T. and Burnham, K. P. and Augustin, N. H.},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {603--618},
  citeulike-article-id = {13263824},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {aic,bic,model-selection,model-uncertainty},
  note = {weighting models by ratio of likelihoods;BIC "assumes that a true model exists and is low-dimensional";states that if a parameter does not appear in a model, you do not count that model when computing variances (?)}
}

@article{bue97pro,
  title = {Problems in Defining Cutoff Points of Continuous Prognostic Factors: {{Example}} of Tumor Thickness in Primary Cutaneous Melanoma},
  author = {Buettner, Petra and Garbe, Claus and Guggenmoos-Holzmann, Irene},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {1201--1210},
  citeulike-article-id = {13263825},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {cutpoints,teaching-mds},
  note = {choice of cut point depends on marginal distribution of predictor}
}

@article{bue99sub,
  title = {Submitting Biologics Applications to the {{Center}} for {{Biologics Evaluation}} and {{Research}} Electronically},
  author = {Buesing, Mary A. and McSweegan, Edward},
  date = {1999},
  journaltitle = {Drug Info J},
  volume = {33},
  pages = {1--15},
  citeulike-article-id = {13263826},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {documentation-format,electronic-submission-to-fda,pdf}
}

@incollection{bugs,
  title = {{{BUGS}}: {{A}} Program to Perform {{Bayesian}} Inference Using {{Gibbs}} Sampling},
  booktitle = {Bayesian {{Statistics}}},
  author = {Thomas, A. and Spiegelhalter, D. J. and Gilks, W. R.},
  editor = {Bernardo, J. M. and Berger, J. O. and Dawid, A. P. and Smith, A. F. M.},
  date = {1992},
  volume = {4},
  pages = {837--842},
  publisher = {{Clarendon Press}},
  location = {{Oxford, UK}},
  url = {http://www.mrc-bsu.cam.ac.uk/bugs},
  citeulike-article-id = {13263827},
  citeulike-linkout-0 = {http://www.mrc-bsu.cam.ac.uk/bugs},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {bayesian-inference,software}
}

@article{bugs2,
  title = {A Language and Program for Complex {{Bayesian}} Modeling},
  author = {Gilks, W. R. and Thomas, A. and Spiegelhalter, D. J.},
  date = {1994},
  journaltitle = {The Statistician},
  volume = {43},
  pages = {169--177},
  url = {http://www.mrc-bsu.cam.ac.uk/bugs},
  citeulike-article-id = {13263828},
  citeulike-linkout-0 = {http://www.mrc-bsu.cam.ac.uk/bugs},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {bayesian-inference}
}

@article{bul07con,
  title = {Confidence Intervals for Multinomial Logistic Regression in Sparse Data},
  author = {Bull, Shelley B. and Lewinger, Juan P. and Lee, Sophia S. F.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {903--918},
  citeulike-article-id = {13265558},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {asymptotic-bias,bayesian-estimates,bias-reduction},
  note = {better than exact conditional methods when there are continuous covariates;data separation;infinite estimates;Jeffreys prior;odds ratio;polytomous logistic regression;small samples;penalization through the use of Jeffreys prior}
}

@article{bul87,
  title = {The Efficiency of Multinomial Logistic Regression Compared with Multiple Group Discriminant Analysis},
  author = {{Bull}},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {1118--1122},
  citeulike-article-id = {13263829},
  posted-at = {2014-07-14 14:09:23},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model}
}

@article{bul97sur,
  title = {Survival Analysis in Observational Studies},
  author = {Bull, Kate and Spiegelhalter, David},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1041--1074},
  citeulike-article-id = {13263830},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {glossary,informative-censoring,logistic-models-for-survival,multivariable-modeling,observational-study,reporting,survival-analysis,teaching,teaching-mds,time-origin,tutorial,warnings-in-using-time-dependent-covariables-to-analysis-treatment-effects}
}

@article{bul98reg,
  title = {Regression Models for Multiple Outcomes in Large Epidemiologic Studies},
  author = {Bull, Shelley B.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {2179--2197},
  citeulike-article-id = {13263831},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {common-covariable-effects-across-outcomes,empirical-bayes,excellent-graphics,gee,multiple-outcomes,outcomes-research,shrinkage}
}

@book{bur03mod,
  title = {Model {{Selection}} and {{Multimodel Inference}}: {{A Practical Information-Theoretic Approach}}},
  author = {Burnham, Kenneth P. and Anderson, David R.},
  date = {2003-12},
  edition = {2},
  publisher = {{Springer}},
  url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/B000QCQT0C},
  citeulike-article-id = {13498607},
  citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/B000QCQT0C},
  citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/B000QCQT0C},
  citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/B000QCQT0C},
  citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/B000QCQT0C},
  citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/B000QCQT0C/citeulike00-21},
  citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/B000QCQT0C},
  citeulike-linkout-6 = {http://www.worldcat.org/isbn/9780387224565},
  citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN9780387224565},
  citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=9780387224565&index=books&linkCode=qs},
  citeulike-linkout-9 = {http://www.librarything.com/isbn/9780387224565},
  day = {04},
  howpublished = {Kindle Edition},
  posted-at = {2015-01-22 22:16:35},
  priority = {2},
  keywords = {aic,model-selection,variable-selection},
  note = {From http://stats.stackexchange.com/questions/134464/the-best-model-of-an-aicc-based-model-selection-on-a-very-small-sample-has-an-hi/134478?noredirect=1\#comment256033\_134478 :
\par
Even keen proponents of the use of AIC in model selection such as Burnham \& Anderson (2002), Model Selection and Multi-model Inference: A Practical Information-Theoretic Approach, recommend selecting the model with lowest AIC from among a few, theoretically well-founded, candidate models, \& inveigh against data dredging. The issues aren't peculiar to the use of AIC.}
}

@article{bur04sin,
  title = {Single versus Multiple Internal Mammary Artery Grafting for Coronary Artery Bypass: 15-Year Follow-up of a Clinical Practice Trial},
  author = {Burfeind, W. R. and Glower, D. D. and Wechsler, A. S. and Tuttle, R. H. and Shaw, L. K. and Harrell, F. E. and Rankin, J. S.},
  date = {2004},
  journaltitle = {Circ},
  volume = {110(11 Suppl 1)},
  pages = {II27-II35},
  doi = {10.1161/01.CIR.0000138193.51635.6f},
  url = {http://dx.doi.org/10.1161/01.CIR.0000138193.51635.6f},
  citeulike-article-id = {13265429},
  citeulike-linkout-0 = {http://dx.doi.org/10.1161/01.CIR.0000138193.51635.6f},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {cabg,clinical-practice}
}

@article{bur18ord,
  title = {Ordinal {{Regression Models}} in {{Psychology}}: {{A Tutorial}}},
  shorttitle = {Ordinal {{Regression Models}} in {{Psychology}}},
  author = {Bürkner, Paul-Christian and Vuorre, Matti},
  date = {2018-02-28T23:41:26},
  doi = {10.31234/osf.io/x8swp},
  url = {https://psyarxiv.com/x8swp/},
  urldate = {2019-01-07},
  abstract = {Ordinal variables, while extremely common in Psychology, are almost exclusively analysed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this tutorial article, we first explain the three major ordinal model classes; the cumulative, sequential and adjacent category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on stem cell opinions and marriage time courses. Appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in Psychology.},
  keywords = {bayes,ordinal}
}

@article{bur20fle,
  title = {A Flexible Parametric Modelling Framework for Survival Analysis},
  author = {Burke, Kevin and Jones, M. C. and Noufaily, Angela},
  date = {2020},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume = {n/a},
  number = {n/a},
  issn = {1467-9876},
  doi = {10.1111/rssc.12398},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12398},
  urldate = {2020-02-23},
  abstract = {We introduce a general, flexible, parametric survival modelling framework which encompasses key shapes of hazard functions (constant; increasing; decreasing; up then down; down then up) and various common survival distributions (log-logistic; Burr type XII; Weibull; Gompertz) and includes defective distributions (cure models). This generality is achieved by using four distributional parameters: two scale-type parameters—one of which relates to accelerated failure time (AFT) modelling; the other to proportional hazards (PH) modelling—and two shape parameters. Furthermore, we advocate ‘multiparameter regression’ whereby more than one distributional parameter depends on covariates—rather than the usual convention of having a single covariate-dependent (scale) parameter. This general formulation unifies the most popular survival models, enabling us to consider the practical value of possible modelling choices. In particular, we suggest introducing covariates through just one or other of the two scale parameters (covering AFT and PH models), and through a ‘power’ shape parameter (covering more complex non-AFT or non-PH effects); the other shape parameter remains covariate independent and handles automatic selection of the baseline distribution. We explore inferential issues and compare with alternative models through various simulation studies, with particular focus on evidence concerning the need, or otherwise, to include both AFT and PH parameters. We illustrate the efficacy of our modelling framework by using data from lung cancer, melanoma and kidney function studies. Censoring is accommodated throughout.},
  langid = {english},
  keywords = {non-ph,non-proportional-hazards,parametric-survival-model,survival}
}

@article{bur21sem,
  title = {Semi-Parametric Accelerated Failure-Time Model: {{A}} Useful Alternative to the Proportional-Hazards Model in Cancer Clinical Trials},
  shorttitle = {Semi-Parametric Accelerated Failure-Time Model},
  author = {Burzykowski, Tomasz},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2169},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2169},
  urldate = {2021-09-27},
  abstract = {The accelerated failure-time (AFT) model has been long recognized as a useful alternative to the proportional-hazards (PH) model. Semi-parametric AFT model has been known since 1981. Its use has been hampered by the difficulty in solving the estimating equations for the model's coefficients. In recent years, however, important developments have taken place regarding the methods of solving the equations. In this article, we briefly review the developments, focusing mainly on rank-based estimation. We conduct a simulation study that directly focuses on the applicability of the model in the context of (cancer) clinical trials. We also investigate the robustness of the AFT model to the omission of covariates. Finally, we conduct a meta-analysis of multiple clinical trials in gastric cancer to illustrate the benefits of the use of the model in practice.},
  langid = {english},
  keywords = {aft-model,semi-parametric},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2169}
}

@article{bur89,
  title = {A Comparitive Study of Ordinary Cross-Validation, v-Fold Cross-Validation and the Repeated Learning-Testing Methods},
  author = {{Burman}},
  date = {1989},
  journaltitle = {Biometrika},
  volume = {76},
  pages = {503--514},
  citeulike-article-id = {13263832},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {general,predictive-accuracy,predictive-methods}
}

@article{bur92tes,
  title = {Tests of Fit for {{Cox}}'s Regression Model},
  author = {Burke, M. D. and Gombay, E.},
  date = {1992},
  journaltitle = {Prob Math Stat},
  volume = {13},
  pages = {127--137},
  citeulike-article-id = {13263833},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {assessing-ph,test-of-ph}
}

@article{bur94com,
  title = {A Comparison of Certain Bootstrap Confidence Intervals in the {{Cox}} Model},
  author = {Burr, Deborah},
  date = {1994},
  journaltitle = {J Am Stat Assoc},
  volume = {89},
  pages = {1290--1302},
  citeulike-article-id = {13263834},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {bootstrap,confidence-intervals,cox-model,simulation-setup,varieties-of-bootstrap}
}

@article{bur94hel,
  title = {Helping Doctors to Draw Appropriate Inferences from the Analysis of Medical Studies},
  author = {Burton, Paul R.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {1994},
  pages = {1699--1713},
  citeulike-article-id = {13263835},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {bayesian-methods,power}
}

@article{bur97art,
  title = {Artificial Neural Networks Improve the Accuracy of Cancer Survival Prediction},
  author = {Burke, H. B. and Goodman, P. H. and Rosen, D. B. and Henson, D. E. and Weinstein, J. N. and Harrell, F. E. and Marks, J. R. and Winchester, D. P. and Bostwick, D. G.},
  date = {1997},
  journaltitle = {Cancer},
  volume = {79},
  pages = {857--862},
  abstract = {BACKGROUND: The TNM staging system originated as a response to the need for an accurate, consistent, universal cancer outcome prediction system. Since the TNM staging system was introduced in the 1950s, new prognostic factors have been identified and new methods for integrating prognostic factors have been developed. This study compares the prediction accuracy of the TNM staging system with that of artificial neural network statistical models. METHODS: For 5-year survival of patients with breast or colorectal carcinoma, the authors compared the TNM staging system's predictive accuracy with that of artificial neural networks (ANN). The area under the receiver operating characteristic curve, as applied to an independent validation data set, was the measure of accuracy. RESULTS: For the American College of Surgeons' Patient Care Evaluation (PCE) data set, using only the TNM variables (tumor size, number of positive regional lymph nodes, and distant metastasis), the artificial neural network's predictions of the 5-year survival of patients with breast carcinoma were significantly more accurate than those of the TNM staging system (TNM, 0.720; ANN, 0.770; P {$<$} 0.001). For the National Cancer Institute's Surveillance, Epidemiology, and End Results breast carcinoma data set, using only the TNM variables, the artificial neural network's predictions of 10-year survival were significantly more accurate than those of the TNM staging system (TNM, 0.692; ANN, 0.730; P {$<$} 0.01). For the PCE colorectal data set, using only the TNM variables, the artificial neural network's predictions of the 5-year survival of patients with colorectal carcinoma were significantly more accurate than those of the TNM staging system (TNM, 0.737; ANN, 0.815; P {$<$} 0.001). Adding commonly collected demographic and anatomic variables to the TNM variables further increased the accuracy of the artificial neural network's predictions of breast carcinoma survival (0.784) and colorectal carcinoma survival (0.869). CONCLUSIONS: Artificial neural networks are significantly more accurate than the TNM staging system when both use the TNM prognostic factors alone. New prognostic factors can be added to artificial neural networks to increase prognostic accuracy further. These results are robust across different data sets and cancer sites.},
  citeulike-article-id = {13263836},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{bur98ext,
  title = {Extending the Simple Linear Regression Model to Account for Correlated Responses: {{An}} Introduction to Generalized Estimating Equations and Multi-Level Mixed Modelling},
  author = {Burton, Paul and Gurrin, Lyle and Sly, Peter},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1261--1291},
  citeulike-article-id = {13263837},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {gee,hierarchical-model,multi-level-model,study-design,teaching}
}

@article{bus82,
  title = {The Likelihood Ratio, {{Wald}}, and {{Lagrange}} Multiplier Tests: {{An}} Expository Note},
  author = {Buse, A.},
  date = {1982},
  journaltitle = {Am Statistician},
  volume = {36},
  pages = {153--157},
  doi = {10.1080/00031305.1982.10482817},
  url = {https://www.tandfonline.com/doi/10.1080/00031305.1982.10482817},
  keywords = {likelihood-ratio,likelihood-ratio-test,mle,score-test,wald-test},
  note = {Lagrange Multiplier should be Rao efficient score test}
}

@article{buu06ful,
  title = {Fully Conditional Specification in Multivariate Imputation},
  author = {van Buuren, S. and Brand, J. P. L. and Groothuis-Oudshoorn, C. G. M. and Rubin, D. B.},
  options = {useprefix=true},
  date = {2006},
  journaltitle = {J Stat Computation Sim},
  volume = {76},
  number = {12},
  pages = {1049--1064},
  abstract = {The use of the Gibbs sampler with fully conditionally specified models, where the distribution of each variable given the other variables is the starting point, has become a popular method to create imputations in incomplete multivariate data. The theoretical weakness of this approach is that the specified conditional densities can be incompatible, and therefore the stationary distribution to which the Gibbs sampler attempts to converge may not exist. This study investigates practical consequences of this problem by means of simulation. Missing data are created under four different missing data mechanisms. Attention is given to the statistical behavior under compatible and incompatible models. The results indicate that multiple imputation produces essentially unbiased estimates with appropriate coverage in the simple cases investigated, even for the incompatible models. Of particular interest is that these results were produced using only five Gibbs iterations starting from a simple draw from observed marginal distributions. It thus appears that, despite the theoretical weaknesses, the actual performance of conditional model specification for multivariate imputation can be quite good, and therefore deserves further study.},
  citeulike-article-id = {13265724},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {distributional-compatibility,gibbs-sampling,multiple-imputation,multivariate-missing-data,proper-imputation,simulation},
  note = {justification for chained equations alternative to full multivariate modeling}
}

@book{buu12fle,
  title = {Flexible Imputation of Missing Data},
  author = {Buuren, Stef},
  date = {2012},
  publisher = {{Chapman \& Hall/CRC}},
  location = {{Boca Raton, FL}},
  doi = {10.1201/b11826},
  url = {http://dx.doi.org/10.1201/b11826},
  citeulike-article-id = {13265938},
  citeulike-linkout-0 = {http://dx.doi.org/10.1201/b11826},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {imputation,missing-data,r,software}
}

@article{buu99mul,
  title = {Multiple Imputation of Missing Blood Pressure Covariates in Survival Analysis},
  author = {van Buuren, S. and Boshuizen, H. C. and Knook, D. L.},
  options = {useprefix=true},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {681--694},
  citeulike-article-id = {13263839},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {cox-model,good-example-of-missingness-related-to-survival-probability,multiple-imputation}
}

@article{buy00r2,
  title = {{{R}}²: {{A}} Useful Measure of Model Performance When Predicting a Dichotomous Outcome},
  author = {Buyse, Marc},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {271--274},
  citeulike-article-id = {13265095},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  annotation = {Letter to the Editor regarding  Stat Med 18:375--384; 1999}
}

@article{buy21net,
  title = {The {{Net Benefit}} of a Treatment Should Take the Correlation between Benefits and Harms into Account},
  author = {Buyse, Marc and Saad, Everardo D. and Peron, Julien and Chiem, Jean-Christophe and Backer, Mickaël De and Cantagallo, Eva and Ciani, Oriana},
  date = {2021-03-24},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.03.018},
  url = {https://www.jclinepi.com/article/S0895-4356(21)00094-9/abstract},
  urldate = {2021-03-29},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}\textbf{:} The assessment of benefits and harms from experimental treatments often ignores the association between outcomes. Generalized pairwise comparisons (GPC) can be used to assess the Net Benefit of treatment in a randomized trial accounting for that association.{$<$}/p{$><$}h3{$>$}Study Design and Settings{$<$}/h3{$><$}p{$>$}\textbf{:} We use GPC to analyze a fictitious trial of treatment versus control, with a binary efficacy outcome (response) and a binary toxicity outcome, as well as data from two actual randomized trials in oncology. In all cases, we compute the Net Benefit for scenarios with different orders of priority between response and toxicity, and a range of odds ratios (ORs) for the association between outcomes.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}\textbf{:} The GPC Net Benefit was quite different from the benefit/harm computed using marginal treatment effects on response and toxicity. In the fictitious trial using response as first priority, treatment had an unfavorable Net Benefit if OR{$<$}1, but favorable if OR{$>$}1. With OR=1, the Net Benefit was 0. Results changed drastically using toxicity as first priority.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}\textbf{:} Even in a simple situation, marginal treatment effects can be misleading. In contrast, GPC assesses the Net Benefit as a function of the treatment effects on each outcome, the association between outcomes, and individual patient priorities.{$<$}/p{$>$}},
  langid = {english},
  keywords = {multiple-endpoints,net-benefit,rct,toxicity}
}

@article{buy98cri,
  title = {Criteria for the Validation of Surrogate Endpoints in Randomized Experiments},
  author = {Buyse, Marc and Molenbergs, Geert},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {1014--1029},
  citeulike-article-id = {13263840},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {study-design,surrogate-endpoint-criteria}
}

@article{buy99rol,
  title = {The Role of Biostatistics in the Prevention, Detection and Treatment of Fraud in Clinical Trials},
  author = {Buyse, Marc and George, Stephen L. and Evans, Stephen and Geller, Nancy L. and Ranstam, Jonas and Scherrer, Bruno and Lesaffre, Emmanuel and Murray, Gordon and Edler, Lutz and Hutton, Jane and Colton, Theodore and Lachenbruch, Peter and Verma, Babu L.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {3435--3451},
  citeulike-article-id = {13265087},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {benfords-law,digit-preference,statistical-audit}
}

@article{buz08adj,
  title = {Adjusting for Verification Bias in Diagnostic Test Evaluation: {{A Bayesian}} Approach},
  author = {Buzoianu, Manuela and Kadane, Joseph B.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {2453--2473},
  citeulike-article-id = {13265678},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {cad,clinical-decision-making,diagnosis,diagnostic-accuracy,mcmc,missing-data,prior-elicitation,spect,verification-bias,workup-bias}
}

@article{bya80cho,
  title = {The Choice of Treatment for Cancer Patients Based on Covariate Information: {{Application}} to Prostate Cancer},
  author = {Byar, David P. and Green, Sylvan B.},
  date = {1980},
  journaltitle = {Bulletin Cancer, Paris},
  volume = {67},
  pages = {477--488},
  citeulike-article-id = {13263841},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {data-for-teaching}
}

@article{byr10pre,
  title = {Preseason Shoulder Strength Measurements in Professional Baseball Pitchers: Identifying Players at Risk for Injury.},
  author = {Byram, I. R. and Bushnell, B. D. and Dugger, K. and Charron, K. and Harrell, F. E. and Noonan, T. J.},
  date = {2010},
  journaltitle = {Am J Sports Med},
  volume = {38},
  number = {7},
  pages = {1375--1382},
  citeulike-article-id = {13265881},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {baseball,sports-medicine}
}

@book{cab02sta,
  title = {Statistical {{Consulting}}},
  author = {Cabrera, J. and McDougall, A.},
  date = {2002},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265335},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {case-studies,datasets-and-problems,report-writing,s-plus,sas,statistical-consulting,statistics-teaching},
  annotation = {review in Biometrics 59:456-457, June 2003}
}

@article{cae15bri,
  title = {Bridging {{Translation}} by {{Improving Preclinical Study Design}} in {{AKI}}.},
  author = {de Caestecker, Mark and Humphreys, Ben D. and Liu, Kathleen D. and Fissell, William H. and Cerda, Jorge and Nolin, Thomas D. and Askenazi, David and Mour, Girish and Harrell, Frank E. and Pullen, Nick and Okusa, Mark D. and Faubel, Sarah and {ASN AKI Advisory Group}},
  options = {useprefix=true},
  date = {2015-12},
  journaltitle = {Journal of the American Society of Nephrology : JASN},
  volume = {26},
  number = {12},
  eprint = {26538634},
  eprinttype = {pmid},
  pages = {2905--2916},
  issn = {1533-3450},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26538634},
  abstract = {Despite extensive research, no therapeutic interventions have been shown to prevent AKI, accelerate recovery of AKI, or reduce progression of AKI to CKD in patients. This failure in translation has led investigators to speculate that the animal models being used do not predict therapeutic responses in humans. Although this issue continues to be debated, an important concern that has not been addressed is whether improvements in preclinical study design can be identified that might also increase the likelihood of translating basic AKI research into clinical practice using the current models. In this review, we have taken an evidence-based approach to identify common weaknesses in study design and reporting in preclinical AKI research that may contribute to the poor translatability of the findings. We focused on use of N-acetylcysteine or sodium bicarbonate for the prevention of contrast-induced AKI and use of erythropoietin for the prevention of AKI, two therapeutic approaches that have been extensively studied in clinical trials. On the basis of our findings, we identified five areas for improvement in preclinical study design and reporting. These suggested and preliminary guidelines may help improve the quality of preclinical research for AKI drug development. Copyright  2015 by the American Society of Nephrology.},
  citeulike-article-id = {14102486},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26538634},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26538634},
  posted-at = {2016-07-26 21:05:51},
  priority = {2},
  keywords = {experimental-design,reproducibility}
}

@article{cai01sho,
  title = {Should All Trials Have a {{Data Safety}} and {{Monotoring Committee}}?},
  author = {Cairns, John A. and Hallstron, Alfred and Held, Peter},
  date = {2001},
  journaltitle = {Am Heart J},
  volume = {141},
  pages = {156--163},
  citeulike-article-id = {13265177},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  note = {excellent background/teaching article about DSMBs}
}

@article{cai09sim,
  title = {Simultaneous Testing of Grouped Hypotheses: {{Finding}} Needles in Multiple Haystacks},
  author = {Cai, Tony T. and Sun, Wenguang},
  date = {2009},
  journaltitle = {J Am Stat Assoc},
  volume = {104},
  pages = {1467--1481},
  citeulike-article-id = {13265822},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {compound-decision-problem,conditional-local-false-discovery-rate,exchangeability,false-discovery-rate,grouped-hypotheses,large-scale-multiple-testing}
}

@article{cai12rem,
  title = {A Remark on '{{Bayesian}} Predictive Approach to Interim Monitoring in Clinical Trials' by {{A}}. {{Dmitrienko}} and {{M-D}}. {{Wang}}},
  author = {Cai, Gengqian and Zhou, Tianhui},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {16},
  pages = {1774--1776},
  doi = {10.1002/sim.4445},
  url = {http://dx.doi.org/10.1002/sim.4445},
  citeulike-article-id = {13265932},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4445},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {bayes,interim-monitoring,monitoring,predictive-distribution,rct},
  note = {concise equation for normal approximation to Bayesian predictive probability}
}

@article{cai97est,
  title = {Estimating the Mean Hazard Ratio Parameters for Clustered Survival Data with Random Clusters},
  author = {Cai, Jianwen and Zhou, Haibo and Davis, C. E.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2009--2020},
  citeulike-article-id = {13263842},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {cluster-bootstrap,clustered-data,clusters-are-random-sample,interactions-between-cluster-effect-and-covariables,mean-treatment-effect-across-centers,simulation-setup}
}

@article{cal01pro,
  title = {Pronostic Value of Dobutamine Stress Technetium-99m Sestamibi {{SPECT}} Myocardial Perfusion Imaging: Stratification of a High Risk Population},
  author = {Calnon, Dennis A. and McGrath, Paul D. and Doss, Amanda L. and Harrell, Frank E. and Watson, Denny D. and Beller, George A.},
  date = {2001},
  journaltitle = {J Am Coll Cardiol},
  volume = {38},
  pages = {1511--1517},
  citeulike-article-id = {13265210},
  posted-at = {2014-07-14 14:09:51},
  priority = {0}
}

@article{cal02int,
  title = {Integrating Quality into the Cycle of Therapeutic Development},
  author = {Califf, Robert M. and Peterson, Eric D. and Gibbons, Raymond J. and Garson, Arthur and Brindis, Ralph G. and Beller, George A. and Smith, Sidney C.},
  date = {2002},
  journaltitle = {J Am Coll Cardiol},
  volume = {40},
  pages = {1895--1901},
  citeulike-article-id = {13265318},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {clinical-trials,clinical-trials-networks,guidelines,observational-research,outcomes,practice-databases,quality-indicators,rct},
  note = {excellent table 1 with "general principles to consider in the design of clinical trials: treatment effects usually modest; qualitative interactions rare; quantitative interactions common; unanticipated effects universal; combinations are unpredictable; short-term effects do not reliably predict long-term effects; class effect almost impossible to define; most therapies produce a combination of helpful and harmful effects; effective therapies do not usually save mondy, but they are incrementally cost-effective"}
}

@article{cal03tow,
  title = {Toward Protecting the Safety of Participants in Clinical Trials},
  author = {Califf, Robert M. and Morse, Michael A. and Wittes, Janet and Goodman, Steven N. and Nelson, Daniel K. and DeMets, David L. and Iafrate, R. Peter and Sugarman, Jeremy},
  date = {2003},
  journaltitle = {Controlled Clin Trials},
  volume = {24},
  pages = {256--271},
  doi = {10.1016/S0197-2456(03)00005-9},
  url = {http://dx.doi.org/10.1016/S0197-2456(03)00005-9},
  citeulike-article-id = {13265333},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0197-2456(03)00005-9},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {adverse-events,aes,central-review-of-multisite-studies,clinical-safety,clinical-trials,dmc,dsmb,duplication-of-effort,ethics,good-clinical-practices,monitoring,protection,rct,reducing-source-document-paperwork,research-ethics-review-boards,responsibilities-of-dmb,safety,safety-monitoring,sponsor}
}

@article{cal12ext,
  title = {Extending the C-Statistic to Nominal Polytomous Outcomes: The {{Polytomous Discrimination Index}}},
  author = {Van Calster, Ben and Van Belle, Vanya and Vergouwe, Yvonne and Timmerman, Dirk and Van Huffel, Sabine and Steyerberg, Ewout W.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {23},
  pages = {2610--2626},
  doi = {10.1002/sim.5321},
  url = {http://dx.doi.org/10.1002/sim.5321},
  abstract = {Diagnostic problems in medicine are sometimes polytomous, meaning that the outcome has more than two distinct categories. For example, ovarian tumors can be benign, borderline, primary invasive, or metastatic. Extending the main measure of binary discrimination, the c-statistic or area under the ROC curve, to nominal polytomous settings is not straightforward. This paper reviews existing measures and presents the polytomous discrimination index (PDI) as an alternative. The PDI assesses all sets of k cases consisting of one case from each outcome category. For each category i (i\,=\,1,\,...\,,k), it is assessed whether the risk of category i is highest for the case from category i. A score of 1∕k is given per category for which this holds, yielding a set score between 0 and 1 to indicate the level of discrimination. The PDI is the average set score and is interpreted as the probability to correctly identify a case from a randomly selected category within a set of k cases. This probability can be split up by outcome category, yielding k category-specific values that result in the PDI when averaged. We demonstrate the measures on two diagnostic problems (residual mass histology after chemotherapy for testicular cancer; diagnosis of ovarian tumors). We compare the behavior of the measures on theoretical data, showing that PDI is more strongly influenced by simultaneous discrimination between all categories than by partial discrimination between pairs of categories. In conclusion, the PDI is attractive because it better matches the requirements of a measure to summarize polytomous discrimination.},
  citeulike-article-id = {13265946},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5321},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {c-statistic,discrimination,model-performance,polytomous-discrimination-index,polytomous-risk-prediction}
}

@article{cal14cal,
  title = {Calibration of {{Risk Prediction Models}}: {{Impact}} on {{Decision-Analytic Performance}}.},
  author = {Van Calster, Ben and Vickers, Andrew J.},
  date = {2014-08},
  journaltitle = {Med Decis Mak},
  eprint = {25155798},
  eprinttype = {pmid},
  pages = {0272989X14547233+},
  publisher = {SAGE Publications},
  issn = {1552-681X},
  doi = {10.1177/0272989x14547233},
  url = {http://dx.doi.org/10.1177/0272989x14547233},
  abstract = {Decision-analytic measures to assess clinical utility of prediction models and diagnostic tests incorporate the relative clinical consequences of true and false positives without the need for external information such as monetary costs. Net Benefit is a commonly used metric that weights the relative consequences in terms of the risk threshold at which a patient would opt for treatment. Theoretical results demonstrate that clinical utility is affected by a model';s calibration, the extent to which estimated risks correspond to observed event rates. We analyzed the effects of different types of miscalibration on Net Benefit and investigated whether and under what circumstances miscalibration can make a model clinically harmful. Clinical harm is defined as a lower Net Benefit compared with classifying all patients as positive or negative by default. We used simulated data to investigate the effect of overestimation, underestimation, overfitting (estimated risks too extreme), and underfitting (estimated risks too close to baseline risk) on Net Benefit for different choices of the risk threshold. In accordance with theory, we observed that miscalibration always reduced Net Benefit. Harm was sometimes observed when models underestimated risk at a threshold below the event rate (as in underestimation and overfitting) or overestimated risk at a threshold above event rate (as in overestimation and overfitting). Underfitting never resulted in a harmful model. The impact of miscalibration decreased with increasing discrimination. Net Benefit was less sensitive to miscalibration for risk thresholds close to the event rate than for other thresholds. We illustrate these findings with examples from the literature and with a case study on testicular cancer diagnosis. Our findings strengthen the importance of obtaining calibrated risk models.  The Author(s) 2014.},
  citeulike-article-id = {13362270},
  citeulike-linkout-0 = {http://dx.doi.org/10.1177/0272989x14547233},
  citeulike-linkout-1 = {http://mdm.sagepub.com/content/early/2014/08/25/0272989X14547233.abstract},
  citeulike-linkout-2 = {http://mdm.sagepub.com/content/early/2014/08/25/0272989X14547233.full.pdf},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/25155798},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=25155798},
  day = {25},
  posted-at = {2014-09-13 16:15:30},
  priority = {2},
  keywords = {calibration,clinical-decision-making,decision-theory}
}

@article{cal15ris,
  title = {Risk {{Prediction}} for {{Individuals}}.},
  author = {Van Calster, Ben and Steyerberg, Ewout W. and Harrell, Frank H.},
  date = {2015-11},
  journaltitle = {JAMA},
  volume = {314},
  number = {17},
  eprint = {26529169},
  eprinttype = {pmid},
  issn = {1538-3598},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26529169},
  citeulike-article-id = {13851630},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26529169},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26529169},
  day = {3},
  posted-at = {2015-12-01 21:17:51},
  priority = {0},
  keywords = {ltte,probability,risk-prediction}
}

@article{cal16cal,
  title = {A Calibration Hierarchy for Risk Models Was Defined: From Utopia to Empirical Data},
  author = {Van Calster, Ben and Nieboer, Daan and Vergouwe, Yvonne and De Cock, Bavo and Pencina, Michael J. and Steyerberg, Ewout W.},
  date = {2016-06},
  journaltitle = {J Clin Epi},
  volume = {74},
  pages = {167--176},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2015.12.005},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2015.12.005},
  citeulike-article-id = {14350246},
  citeulike-attachment-1 = {cal16cal.pdf; /pdf/user/harrelfe/article/14350246/1108735/cal16cal.pdf; 2de6363a7f13f1e592bbc9c4b4a1e8a3fe551c1e},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2015.12.005},
  posted-at = {2017-05-03 23:38:26},
  priority = {5},
  keywords = {calibration,validation}
}

@article{cal18ind,
  title = {Individual Risk Prediction Using Data beyond the Medical Clinic},
  author = {Califf, Robert M. and Harrell, Frank E.},
  date = {2018-08-13},
  journaltitle = {CMAJ},
  volume = {190},
  number = {32},
  eprint = {30104187},
  eprinttype = {pmid},
  pages = {E947-E948},
  issn = {1488-2329},
  doi = {10.1503/cmaj.180967},
  langid = {english},
  pmcid = {PMC6089946},
  keywords = {prediction}
}

@article{cal21met,
  title = {Methodology over Metrics: {{Current}} Scientific Standards Are a Disservice to Patients and Society},
  shorttitle = {Methodology over Metrics},
  author = {Calster, Ben Van and Wynants, Laure and Riley, Richard D. and van Smeden, Maarten and Collins, Gary S.},
  date = {2021-05-30},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.05.018},
  url = {https://www.jclinepi.com/article/S0895-4356(21)00170-0/abstract},
  urldate = {2021-06-01},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}p{$>$}Covid-19 research made it painfully clear that the scandal of poor medical research, as denounced by Altman in 1994, persists today. The overall quality of medical research remains poor, despite longstanding criticisms. The problems are well known, but the research community fails to properly address them. We suggest most problems stem from an underlying paradox: although methodology is undeniably the backbone of qualitative and responsible research, science consistently undervalues methodology. The focus remains more on the destination (research claims and metrics) than on the journey. Notwithstanding, research should serve society more than the reputation of those involved. While we notice that many initiatives are being established to improve components of the research cycle, these initiatives are too disjointed. The overall system is monolithic and slow to adapt. We assert that a top-down action is needed from journals, universities, funders and governments to break the cycle and put methodology first. These actions should involve the widespread adoption of registered reports, balanced research funding between innovative, incremental and methodological research projects, full recognition and demystification of peer review, mandatory statistical review of reports, adherence to reporting guidelines, and investment in methodological education and research. Currently, the scientific enterprise is doing a major disservice to patients and society.{$<$}/p{$>$}},
  langid = {english},
  keywords = {bad-science,bad-statistical-practice,clinical-prediction,covid19,reproducibility}
}

@article{cal82ass,
  title = {Assessment of the Use of the Age- and Sex-Specific {{U}}.{{S}}. Population as a Control Group for Analysis of Survival in Coronary Artery Disease},
  author = {Califf, R. M. and Lee, K. L. and Harrell, F. E. and Kimm, S. Y. S. and Grufferman, S. and Rosati, R. A.},
  date = {1982},
  journaltitle = {Am J Card},
  volume = {50},
  pages = {1279--1282},
  citeulike-article-id = {13263843},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal82pro,
  title = {Prognostic Implications of Ventricular Arrhythmias during 24 Hour Ambulatory Monitoring in Patients Undergoing Cardiac Catheterization for Coronary Artery Disease},
  author = {Califf, R. M. and McKinnis, R. A. and Burks, J. and Lee, K. L. and Harrell FE, V. S. and Pryor, D. B. and Wagner, G. S. and Rosati, R. A.},
  date = {1982},
  journaltitle = {Am J Card},
  volume = {50},
  pages = {23--31},
  citeulike-article-id = {13263844},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@incollection{cal82pro2,
  title = {The Prognosis in the Presence of Coronary Artery Disease},
  booktitle = {Congestive {{Heart Failure}}: {{Current Research}} and {{Clinical Applications}}},
  author = {Califf, R. M. and Bounous, E. P. and Harrell, F. E. and McCants, C. B. and Lee, K. L. and McKinnis, R. A. and Rosati, R. A.},
  editor = {{Braunwald} and {Mock} and {Watson}},
  date = {1982},
  publisher = {{Grune and Stratton}},
  location = {{New York}},
  citeulike-article-id = {13263845},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal83out,
  title = {Outcome in One-Vessel Coronary Artery Disease},
  author = {Califf, R. M. and Tomabechi, Y. and Lee, K. L. and Phillips, H. and Pryor, D. B. and Harrell, F. E. and Harris, P. J. and Peter, R. H. and Behar, V. S. and Kong, Y. and Rosati, R. A.},
  date = {1983},
  journaltitle = {Circ},
  volume = {67},
  pages = {283--290},
  citeulike-article-id = {13263846},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal83pro,
  title = {Prognostic Value of Ventricular Arrhythmias Associated with Treadmill Exercise Testing in Patients Studied with Cardiac Catheterization for Suspected Ischemic Heart Disease},
  author = {Califf, R. M. and McKinnis, R. A. and McNeer, J. F. and Harrell, F. E. and Lee, K. L. and Pryor DB, R. A. and Harris, P. J. and Rosati, R. A. and Wagner, G. S.},
  date = {1983},
  journaltitle = {J Am Coll Cardiol},
  volume = {2},
  pages = {1060--1067},
  citeulike-article-id = {13263847},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal84lef,
  title = {“{{Left}} Main Equivalent” Coronary Artery Disease: Its Clinical Presentation and Prognostic Significance with Nonsurgical Therapy},
  author = {Califf, R. M. and Conley, M. J. and Behar, V. S. and Harrell, F. E. and Lee, K. L. and Pryor, D. B. and McKinnis, R. A. and Rosati, R. A.},
  date = {1984},
  journaltitle = {Am J Card},
  volume = {53},
  pages = {1489--1495},
  citeulike-article-id = {13263848},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal85,
  title = {Prognostic Value of a Coronary Artery Jeopardy Score},
  author = {Califf, R. M. and Phillips, H. R. and {Others}},
  date = {1985},
  journaltitle = {J Am Coll Cardiol},
  volume = {5},
  pages = {1055--1063},
  citeulike-article-id = {13263849},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {adequacy-index}
}

@article{cal85ran,
  title = {Randomized Trials of Coronary Artery Bypass Surgery: {{Impact}} on Clinical Practice at {{Duke University Medical Center}}},
  author = {Califf, R. M. and Hlatky, M. A. and Mark, D. B. and Lee, K. L. and Harrell, F. E. and Rosati, R. A. and Pryor, D. B.},
  date = {1985},
  journaltitle = {Circ},
  volume = {72 Suppl V},
  pages = {136--144},
  citeulike-article-id = {13263850},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal88cha,
  title = {Changing Efficacy of Coronary Revascularization: Implications for Patient Selection},
  author = {Califf, R. M. and Harrell, F. E. and Lee, K. L. and Rankin, J. S. and Mark, D. B. and Hlatky, M. A. and Muhlbaier, L. H. and Wechsler, A. S. and Jones, R. H. and Oldham, H. N. and Pryor, D. B.},
  date = {1988},
  journaltitle = {Circ},
  volume = {78 Suppl II},
  citeulike-article-id = {13263851},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal88imp,
  title = {Importance of Clinical Measures of Ischemia in the Prognosis of Patients with Documented Coronary Artery Disease},
  author = {Califf, R. M. and Mark, D. B. and Harrell, F. E. and Hlatky, M. A. and Lee, K. L. and Rosati, R. A. and Pryor, D. B.},
  date = {1988},
  journaltitle = {J Am Coll Cardiol},
  volume = {11},
  pages = {20--26},
  citeulike-article-id = {13263852},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal89,
  title = {The Evolution of Medical and Surgical Therapy for Coronary Artery Disease},
  author = {Califf, R. M. and Harrell, F. E. and Lee, K. L. and Rankin, J. S. and {Others}},
  date = {1989},
  journaltitle = {JAMA},
  volume = {261},
  pages = {2077--2086},
  citeulike-article-id = {13263853},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cal97ran,
  title = {A Randomized Controlled Trial of Epoprostenol Therapy for Severe Congestive Heart Failure: {{The Flolan International Randomized Survival Trial}} ({{FIRST}})},
  author = {Califf, R. M. and Adams, K. F. and McKenna, W. J. and Gheorghiade, M. and Uretsky, B. F. and McNulty, S. E. and Darius, H. and Schulman, K. and Zannad, F. and Handberg-Thurmond, E. and Harrell, F. E. and Wheeler, W. and Soler-Soler, J. and Swedberg, K.},
  date = {1997},
  journaltitle = {Am Heart J},
  pages = {44--54},
  doi = {10.1016/S0002-8703(97)70105-4},
  url = {http://dx.doi.org/10.1016/S0002-8703(97)70105-4},
  citeulike-article-id = {13263854},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0002-8703(97)70105-4},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {box-charts,clinical-trials,import,interim-analysis,rct,reporting,stopping-boundaries,teaching-mds},
  note = {reporting results (although several typos);tables with quantiles; odds ratio chart showing lack of differential treatment effect;results of interim analyses, with stopping boundaries}
}

@article{cal97sel,
  title = {Selection of Thrombolytic Therapy for Individual Patients: {{Development}} of a Clinical Model},
  author = {Califf, Robert M. and Woodlief, Lynn H. and Harrell, Frank E. and Lee, Kerry L. and White, Harvey D. and Guerci, Alan and Barbash, Gabriel I. and Simes, R and Weaver, W and Simoons, Maarten L. and Topol, Eric J. and Investigators, The G.},
  date = {1997},
  journaltitle = {Am Heart J},
  volume = {133},
  pages = {630--639},
  citeulike-article-id = {13263855},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {absolute-vs-relative-treatment-effects},
  note = {predicting treatment benefit for individual patients;use of nonparametric smoothers in medical papers}
}

@article{cam07chi,
  title = {Chi-Squared and {{Fisher-Irwin}} Tests of Two-by-Two Tables with Small Sample Recommendations},
  author = {Campbell, Ian},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3661--3675},
  citeulike-article-id = {13265608},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {2x2-table,chi-squared-test,exact-tests,fisher-irwin-test,fishers-exact-test},
  note = {small sample recommendations;latest edition of Armitage's book recommends that continuity adjustments never be used for contingency table chi-square tests;E. Pearson modification of Pearson chi-square test, differing from the original by a factor of (N-1)/N;Cochran noted that the number 5 in "expected frequency less than 5" was arbitrary;findings of published studies may be summarized as follows, for comparative trials:"1. Yate's chi-squared test has type I error rates less than the nominal, often less than half the nominal; 2. The Fisher-Irwin test has type I error rates less than the nominal; 3. K Pearson's version of the chi-squared test has type I error rates closer to the nominal than Yate's chi-squared test and the Fisher-Irwin test, but in some situations gives type I errors appreciably larger than the nominal value; 4. The 'N-1' chi-squared test, behaves like K. Pearson's 'N' version, but the tendency for higher than nominal values is reduced; 5. The two-sided Fisher-Irwin test using Irwin's rule is less conservative than the method doubling the one-sided probability; 6. The mid-P Fisher-Irwin test by doubling the one-sided probability performs better than standard versions of the Fisher-Irwin test, and the mid-P method by Irwin's rule performs better still in having actual type I errors closer to nominal levels."; strong support for the 'N-1' test provided expected frequencies exceed 1;flaw in Fisher test which was based on Fisher's premise that marginal totals carry no useful information;demonstration of their useful information in very small sample sizes;Yate's continuity adjustment of N/2 is a large over correction and is inappropriate;counter arguments exist to the use of randomization tests in randomized trials;calculations of worst cases;overall recommendation: use the 'N-1' chi-square test when all expected frequencies are at least 1, otherwise use the Fisher-Irwin test using Irwin's rule for two-sided tests, taking tables from either tail as likely, or less, as that observed; see letter to the editor by Antonio Andres and author's reply in 27:1791-1796; 2008.}
}

@book{cam63exp,
  title = {Experimental and {{Quasi-Experimental Designs}} for {{Research}}},
  author = {Campbell, Donald T. and Stanley, Julian C.},
  date = {1963},
  publisher = {{Houghton Mifflin}},
  location = {{Boston}},
  citeulike-article-id = {13263856},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {experimental-design,health-services-research,social-science-designs}
}

@article{cam89,
  title = {Classification Efficiency of Multinomial Logistic Regression Relative to Ordinal Logistic Regression},
  author = {{Campbell} and Donner, A.},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {587--591},
  citeulike-article-id = {13263857},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {logistic-ordinal-model}
}

@article{cammea,
  title = {Measuring Effects of Medication Adherence on Time-Varying Health Outcomes Using {{Bayesian}} Dynamic Linear Models},
  author = {Campos, Luis F. and Glickman, Mark E. and Hunter, Kristen B.},
  journaltitle = {Biostatistics},
  doi = {10.1093/biostatistics/kxz059},
  url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz059/5687018},
  urldate = {2019-12-26},
  abstract = {Summary.  One of the most significant barriers to medication treatment is patients’ non-adherence to a prescribed medication regimen. The extent of the impact o},
  langid = {english}
}

@article{can06boo,
  title = {Bootstrap Diagnostics and Remedies},
  author = {Canty, Angelo J. and Davison, Anthony C. and Hinkley, David V. and Venture, Valérie},
  date = {2006},
  journaltitle = {Can J Stat},
  volume = {34},
  pages = {5--27},
  citeulike-article-id = {13265494},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {boostrap-recycling,bootstrap,diagnostics-for-reliability-of-bootstrap-calculations,importance-sampling,inconsistency,jackknife-after-bootstrap,outlier,pivot,resampling,spatial-data,stein-estimator,subsampling,superefficiency,time-series}
}

@article{can20dif,
  title = {Difference-in-{{Difference}} in the {{Time}} of {{Cholera}}: A {{Gentle Introduction}} for {{Epidemiologists}}},
  shorttitle = {Difference-in-{{Difference}} in the {{Time}} of {{Cholera}}},
  author = {Caniglia, Ellen C. and Murray, Eleanor J.},
  date = {2020-12},
  journaltitle = {Curr Epidemiol Rep},
  volume = {7},
  number = {4},
  eprint = {33791189},
  eprinttype = {pmid},
  pages = {203--211},
  issn = {2196-2995},
  doi = {10.1007/s40471-020-00245-2},
  abstract = {Purpose of review: The goal of this article is to provide an introduction to the intuition behind the difference-in-difference method for epidemiologists. We focus on the theoretical aspects of this tool, including the types of questions for which difference-in-difference is appropriate, and what assumptions must hold for the results to be causally interpretable. Recent findings: While currently under-utilized in epidemiologic research, the difference-in-difference method is a useful tool to examine effects of population-level exposures, but relies on strong assumptions. Summary: We use the famous example of John Snow's investigation of the cause of cholera mortality in London to illustrate the difference-in-difference approach and corresponding assumptions. We conclude by arguing that this method deserves a second-look from epidemiologists interested in asking causal questions about the impact of a population-level exposure change on a population-level outcome for the group that experienced the change.},
  langid = {english},
  pmcid = {PMC8006863},
  keywords = {difference-in-difference,observational-data,observational-study,observational-treatment-comparisons}
}

@article{can20difa,
  title = {Difference-in-{{Difference}} in the {{Time}} of {{Cholera}}: A {{Gentle Introduction}} for {{Epidemiologists}}},
  shorttitle = {Difference-in-{{Difference}} in the {{Time}} of {{Cholera}}},
  author = {Caniglia, Ellen C. and Murray, Eleanor J.},
  date = {2020-12-01},
  journaltitle = {Curr Epidemiol Rep},
  volume = {7},
  number = {4},
  pages = {203--211},
  issn = {2196-2995},
  doi = {10.1007/s40471-020-00245-2},
  url = {https://doi.org/10.1007/s40471-020-00245-2},
  urldate = {2021-12-15},
  abstract = {The goal of this article is to provide an introduction to the intuition behind the difference-in-difference method for epidemiologists. We focus on the theoretical aspects of this tool, including the types of questions for which difference-in-difference is appropriate, and what assumptions must hold for the results to be causally interpretable.},
  langid = {english},
  keywords = {design,difference-in-difference,observation-study,observational-study-design,teaching-mds}
}

@article{cap13tre,
  title = {The Trend Odds Model for Ordinal Data},
  author = {Capuano, Ana W. and Dawson, Jeffrey D.},
  date = {2013},
  journaltitle = {Statistics in Medicine},
  volume = {32},
  number = {13},
  pages = {2250--2261},
  issn = {1097-0258},
  doi = {10.1002/sim.5689},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5689},
  urldate = {2021-10-08},
  abstract = {Ordinal data appear in a wide variety of scientific fields. These data are often analyzed using ordinal logistic regression models that assume proportional odds. When this assumption is not met, it may be possible to capture the lack of proportionality using a constrained structural relationship between the odds and the cut-points of the ordinal values. We consider a trend odds version of this constrained model, wherein the odds parameter increases or decreases in a monotonic manner across the cut-points. We demonstrate algebraically and graphically how this model is related to latent logistic, normal, and exponential distributions. In particular, we find that scale changes in these potential latent distributions are consistent with the trend odds assumption, with the logistic and exponential distributions having odds that increase in a linear or nearly linear fashion. We show how to fit this model using SAS Proc NLMIXED and perform simulations under proportional odds and trend odds processes. We find that the added complexity of the trend odds model gives improved power over the proportional odds model when there are moderate to severe departures from proportionality. A hypothetical data set is used to illustrate the interpretation of the trend odds model, and we apply this model to a swine influenza example wherein the proportional odds assumption appears to be violated. Copyright © 2012 John Wiley \& Sons, Ltd.},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.5689}
}

@article{car00boo,
  title = {Bootstrap Confidence Intervals: When, Which, What? {{A}} Practical Guide for Medical Statisticians},
  author = {Carpenter, James and Bithell, John},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {1141--1164},
  citeulike-article-id = {13265126},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {bootstrap,conditional-bootstrap,confidence-intervals,confidence-limits,unconditional-bootstrap},
  note = {unconditional nonparametric bootstrap becomes more equivalent to conditional bootstrap based on regression residuals when full models are fitted}
}

@article{car00reg,
  title = {A Regression-Based Method for Estimating Mean Treatment Cost in the Presence of Right-Censoring},
  author = {Carides, George W. and Heyse, Joseph F. and Iglewicz, Boris},
  date = {2000},
  journaltitle = {Biostatistics},
  volume = {1},
  pages = {299--313},
  citeulike-article-id = {13265179},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {analysis-of-cost-data,censoring,one-sample-problem},
  note = {using trend of cumulative cost vs. survival time on uncensored observations to correct for informative censoring}
}

@article{car01des,
  title = {Designing Linked Micromap Plots for States with Many Counties},
  author = {Carr, Daniel B.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1331--1339},
  citeulike-article-id = {13265191},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {graphics,teaching-mds},
  note = {excellent color graphics;showing mortality and changes in mortality over counties}
}

@article{car02cop,
  title = {Coping with Missing Data in Clinical Trials: {{A}} Model-Based Approach Applied to Asthma Trials},
  author = {Carpenter, James and Pocock, Stuart and Lamm, Carl J.},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {1043--1066},
  citeulike-article-id = {13265274},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {bugs,dropout,graphical-methods-for-displaying-nonrandom-dropout-patterns,repeated-measures}
}

@article{car19pre,
  title = {Prediction of {{Progression-Free Survival}} in {{Patients With Advanced}}, {{Well-Differentiated}}, {{Neuroendocrine Tumors Being Treated With}} a {{Somatostatin Analog}}: {{The GETNE-TRASGU Study}}},
  shorttitle = {Prediction of {{Progression-Free Survival}} in {{Patients With Advanced}}, {{Well-Differentiated}}, {{Neuroendocrine Tumors Being Treated With}} a {{Somatostatin Analog}}},
  author = {Carmona-Bayonas, Alberto and Jiménez-Fonseca, Paula and Lamarca, Ángela and Barriuso, Jorge and Castaño, Ángel and Benavent, Marta and Alonso, Vicente and Riesco-Martínez, María del Carmen and Alonso-Gordoa, Teresa and Custodio, Ana and Sánchez Cánovas, Manuel and Hernando Cubero, Jorge and López, Carlos and Lacasta, Adelaida and Fernández Montes, Ana and Marazuela, Mónica and Crespo, Guillermo and Escudero, Pilar and Diaz, José Ángel and Feliciangeli, Eduardo and Gallego, Javier and Llanos, Marta and Segura, Ángel and Vilardell, Felip and Percovich, Juan Carlos and Grande, Enrique and Capdevila, Jaume and Valle, Juan W. and García-Carbonero, Rocío},
  date = {2019-08-07},
  journaltitle = {JCO},
  volume = {37},
  number = {28},
  pages = {2571--2580},
  issn = {0732-183X},
  doi = {10.1200/JCO.19.00980},
  url = {https://ascopubs.org/doi/full/10.1200/JCO.19.00980},
  urldate = {2019-10-06},
  abstract = {PURPOSESomatostatin analogs (SSAs) are recommended for the first-line treatment of most patients with well-differentiated, gastroenteropancreatic (GEP) neuroendocrine tumors; however, benefit from treatment is heterogeneous. The aim of the current study was to develop and validate a progression-free survival (PFS) prediction model in SSA-treated patients.PATIENTS AND METHODSWe extracted data from the Spanish Group of Neuroendocrine and Endocrine Tumors Registry (R-GETNE). Patient eligibility criteria included GEP primary, Ki-67 of 20\% or less, and first-line SSA monotherapy for advanced disease. An accelerated failure time model was developed to predict PFS, which was represented as a nomogram and an online calculator. The nomogram was externally validated in an independent series of consecutive eligible patients (The Christie NHS Foundation Trust, Manchester, United Kingdom).RESULTSWe recruited 535 patients (R-GETNE, n = 438; Manchester, n = 97). Median PFS and overall survival in the derivation cohort were 28.7 (95\% CI, 23.8 to 31.1) and 85.9 months (95\% CI, 71.5 to 96.7 months), respectively. Nine covariates significantly associated with PFS were primary tumor location, Ki-67 percentage, neutrophil-to-lymphocyte ratio, alkaline phosphatase, extent of liver involvement, presence of bone and peritoneal metastases, documented progression status, and the presence of symptoms when initiating SSA. The GETNE-TRASGU (Treated With Analog of Somatostatin in Gastroenteropancreatic and Unknown Primary NETs) model demonstrated suitable calibration, as well as fair discrimination ability with a C-index value of 0.714 (95\% CI, 0.680 to 0.747) and 0.732 (95\% CI, 0.658 to 0.806) in the derivation and validation series, respectively.CONCLUSIONThe GETNE-TRASGU evidence-based prognostic tool stratifies patients with GEP neuroendocrine tumors receiving SSA treatment according to their estimated PFS. This nomogram may be useful when stratifying patients with neuroendocrine tumors in future trials. Furthermore, it could be a valuable tool for making treatment decisions in daily clinical practice.},
  keywords = {case-studies,survival,teaching,teaching-mds}
}

@article{car21cau,
  title = {Causal Considerations Can Inform the Interpretation of Surprising Associations in Medical Registries},
  author = {Carmona-Bayonas, Alberto and Jiménez-Fonseca, Paula and Gallego, Javier and Msaouel, Pavlos},
  date = {2021-10-28},
  journaltitle = {Cancer Invest},
  eprint = {34709109},
  eprinttype = {pmid},
  pages = {1--27},
  issn = {1532-4192},
  doi = {10.1080/07357907.2021.1999971},
  abstract = {An exploratory analysis of registry data from 2437 patients with advanced gastric cancer revealed a surprising association between astrological birth sign and overall survival (OS) with p\,=\,0.01. After dichotomizing or changing the reference sign, p-values {$<$}0.05 were observed for several birth signs following adjustments for multiple comparisons. Bayesian models with moderately skeptical priors still pointed to these associations. A more plausible causal model, justified by contextual knowledge, revealed that these associations arose from the astrological sign association with seasonality. This case study illustrates how causal considerations can guide analyses through what would otherwise be a hopeless maze of statistical possibilities.},
  langid = {english},
  keywords = {bayes,causal-inference,causality,seasonality,skeptical-prior}
}

@article{car21mis,
  title = {Missing Data: {{A}} Statistical Framework for Practice},
  shorttitle = {Missing Data},
  author = {Carpenter, James R. and Smuk, Melanie},
  date = {2021},
  journaltitle = {Biometrical Journal},
  volume = {63},
  number = {5},
  pages = {915--947},
  issn = {1521-4036},
  doi = {10.1002/bimj.202000196},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000196},
  urldate = {2021-10-21},
  abstract = {Missing data are ubiquitous in medical research, yet there is still uncertainty over when restricting to the complete records is likely to be acceptable, when more complex methods (e.g. maximum likelihood, multiple imputation and Bayesian methods) should be used, how they relate to each other and the role of sensitivity analysis. This article seeks to address both applied practitioners and researchers interested in a more formal explanation of some of the results. For practitioners, the framework, illustrative examples and code should equip them with a practical approach to address the issues raised by missing data (particularly using multiple imputation), alongside an overview of how the various approaches in the literature relate. In particular, we describe how multiple imputation can be readily used for sensitivity analyses, which are still infrequently performed. For those interested in more formal derivations, we give outline arguments for key results, use simple examples to show how methods relate, and references for full details. The ideas are illustrated with a cohort study, a multi-centre case control study and a randomised clinical trial.},
  langid = {english},
  keywords = {missing,multiple-imputation,teaching-mds,teaching-paper},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000196}
}

@book{car83,
  title = {Regression {{Analysis}} of {{Survival Data}} in {{Cancer Chemotherapy}}},
  author = {Carter, W. H. and Wampler, G. L. and Stablein, D. M.},
  date = {1983},
  publisher = {{Marcel Dekker}},
  location = {{New York}},
  citeulike-article-id = {13263858},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{car89,
  title = {Analysis of Rank Measures of Association for Ordinal Data from Longitudinal Studies},
  author = {Carr, G. J. and Hafner, K. B. and Koch, G. G.},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {797--804},
  citeulike-article-id = {13263859},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {logistic-ordinal-model,multivariate-analysis}
}

@article{car89pre,
  title = {Preliminary Report: {{Effect}} of {{Encainide}} and {{Flecainide}} on Mortality in a Randomized Trial of Arrhythmia Suppression after Myocardial Infarction},
  author = {Investigators, Cast},
  date = {1989},
  journaltitle = {NEJM},
  volume = {321},
  number = {6},
  pages = {406--412},
  citeulike-article-id = {13265615},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {cardiac-arrhythmia-suppression-trial,cast}
}

@article{car93mod,
  title = {Modelling Multivariate Binary Data with Alternating Logistic Regressions},
  author = {Carey, Vincent and Zeger, Scott L.},
  date = {1993},
  journaltitle = {Biometrika},
  volume = {80},
  pages = {517--526},
  citeulike-article-id = {13263860},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {clustered-data,logistic-model-extensions,multivariate}
}

@article{car95con,
  title = {Converting Tables to Plots: {{A}} Challenge from {{Iowa State}}},
  author = {Carr, Daniel B. and Nusser, Sarah M.},
  date = {1995-12},
  journaltitle = {Stat Comp Graphics News ASA},
  citeulike-article-id = {13263861},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {converting-table-to-graph,graphics}
}

@report{car96non,
  title = {Nonparametric Estimation of the Parameters of Cost Distributions in the Presence of Right-Censoring},
  author = {Carides, George W. and Heyse, Joseph F.},
  date = {1996},
  institution = {{Merck Research Laboratories}},
  location = {{Blue Bell, PA 19422 USA}},
  citeulike-article-id = {13263863},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {analysis-of-cost-data,economics,informative-censoring,right-censored-cost-data,weighted-kaplan-meier-estimator},
  annotation = {Presented at the Joint Statistical Meetings, Chicago, August 1996}
}

@article{car96nonb,
  title = {Nonparametric Estimation of the Parameters of Cost Distributions in the Presence of Right Censoring},
  author = {Carides, George W. and Heyse, Joseph F.},
  date = {1996},
  journaltitle = {J Hlth Econ},
  citeulike-article-id = {13263862},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {cost-distribution,economic-evaluation,informative-censoring}
}

@article{car97usi,
  title = {Using Hypertext and the Internet for Structure and Management of Observational Studies},
  author = {Carey, Vincent J.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1667--1682},
  citeulike-article-id = {13263864},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {html,hypertext,internet,latex,observational-study-design,sas-to-latex,web}
}

@article{cas20rat,
  title = {Rationale and {{Design}} of {{ORCHID}}: {{A Randomized Placebo-controlled Clinical Trial}} of {{Hydroxychloroquine}} for {{Adults Hospitalized}} with {{COVID-19}}},
  shorttitle = {Rationale and {{Design}} of {{ORCHID}}},
  author = {Casey, Jonathan D. and Johnson, Nicholas J. and Semler, Matthew W. and Collins, Sean P. and Aggarwal, Neil R. and Brower, Roy G. and Chang, Steven Y. and Eppensteiner, John and Filbin, Michael and Gibbs, Kevin W. and Ginde, Adit A. and Gong, Michelle N. and Harrell, Frank and Hayden, Douglas L. and Hough, Catherine L. and Khan, Akram and Leither, Lindsay M. and Moss, Marc and Oldmixon, Cathryn F. and Park, Pauline K. and Reineck, Lora A. and Ringwood, Nancy J. and Robinson, Bryce R. H. and Schoenfeld, David A. and Shapiro, Nathan I. and Steingrub, Jay S. and Torr, Donna K. and Weissman, Alexandra and Lindsell, Christopher J. and Rice, Todd W. and Thompson, B. Taylor and Brown, Samuel M. and Self, Wesley H.},
  date = {2020-09},
  journaltitle = {Ann Am Thorac Soc},
  volume = {17},
  number = {9},
  eprint = {32492354},
  eprinttype = {pmid},
  pages = {1144--1153},
  issn = {2325-6621},
  doi = {10.1513/AnnalsATS.202005-478SD},
  abstract = {The ORCHID (Outcomes Related to COVID-19 treated with Hydroxychloroquine among In-patients with symptomatic Disease) trial is a multicenter, blinded, randomized trial of hydroxychloroquine versus placebo for the treatment of adults hospitalized with coronavirus disease (COVID-19). This document provides the rationale and background for the trial and highlights key design features. We discuss five novel challenges to the design and conduct of a large, multicenter, randomized trial during a pandemic, including 1) widespread, off-label use of the study drug before the availability of safety and efficacy data; 2) the need to adapt traditional procedures for documentation of informed consent during an infectious pandemic; 3) developing a flexible and robust Bayesian analysis incorporating significant uncertainty about the disease, outcomes, and treatment; 4) obtaining indistinguishable drug and placebo without delaying enrollment; and 5) rapidly obtaining administrative and regulatory approvals. Our goals in describing how the ORCHID trial progressed from study conception to enrollment of the first patient in 15 days are to inform the development of other high-quality, multicenter trials targeting COVID-19. We describe lessons learned to improve the efficiency of future clinical trials, particularly in the setting of pandemics. The ORCHID trial will provide high-quality, clinically relevant data on the safety and efficacy of hydroxychloroquine for the treatment of COVID-19 among hospitalized adults.Clinical trial registered with www.clinicaltrials.gov (NCT04332991).},
  langid = {english},
  pmcid = {PMC7462324},
  keywords = {covid19,rct}
}

@article{cas21com,
  title = {{{CommentaryAn}} Introduction to Mediation Analyses of Randomised Controlled Trials},
  author = {Cashin, Aidan G. and Lee, Hopin},
  date = {2021-02-15},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.02.014},
  url = {http://www.jclinepi.com/article/S0895-4356(21)00051-2/abstract},
  urldate = {2021-02-16},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}p{$>$}Mediation analyses of randomised controlled trials can be used to investigate the mechanisms by which health interventions cause outcomes. In this article we provide a brief introduction to mediation analysis in the context of randomised controlled trials. We introduce common target effects, causal assumptions, estimation approaches, and illustrate these concepts using a published mediation analysis of the Systolic Blood Pressure Intervention Trial (SPRINT). Well-conducted mediation analyses of randomised trials can provide meaningful insights to guide clinical and policy decisions.{$<$}/p{$>$}},
  langid = {english},
  keywords = {adherence,compliance,mediation-effect,rct,teaching-mds}
}

@article{cas92exp,
  title = {Explaining the {{Gibbs}} Sampler},
  author = {Casella, George and George, Edward I.},
  date = {1992},
  journaltitle = {Am Statistician},
  volume = {46},
  pages = {167--174},
  citeulike-article-id = {13263865},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {bayesian-inference,data-augmentation,gibbs-sampler,monte-carlo,resampling,teaching}
}

@article{cec96imp,
  title = {The Importance of Work-up (Verification) Bias Correction in Assessing the Accuracy of {{SPECT}} Thallium-201 Testing for the Diagnosis of Coronary Artery Disease},
  author = {Cecil, Michael P. and Kosinski, Andrzej S. and Jones, Michael T. and Taylor, Andrew and Alazraki, Naomi P. and Pettigrew, Roderic I. and Weintraub, William S.},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {735--742},
  citeulike-article-id = {13263866},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {diagnosis,verification-bias,work-up-bias}
}

@article{cep03com,
  title = {Comparison of Logistic Regression versus Propensity Score When the Number of Events Is Low and There Are Multiple Confounders},
  author = {Cepeda, M. S. and Boston, R. and Farrar, J. T. and Strom, B. L.},
  date = {2003},
  journaltitle = {Am J Epi},
  volume = {158},
  eprint = {http://aje.oxfordjournals.org/content/158/3/280.full.pdf+html},
  pages = {280--287},
  doi = {10.1093/aje/kwg115},
  url = {http://aje.oxfordjournals.org/content/158/3/280.abstract},
  abstract = {The aim of this study was to use Monte Carlo simulations to compare logistic regression with propensity scores in terms of bias, precision, empirical coverage probability, empirical power, and robustness when the number of events is low relative to the number of confounders. The authors simulated a cohort study and performed 252,480 trials. In the logistic regression, the bias decreased as the number of events per confounder increased. In the propensity score, the bias decreased as the strength of the association of the exposure with the outcome increased. Propensity scores produced estimates that were less biased, more robust, and more precise than the logistic regression estimates when there were seven or fewer events per confounder. The logistic regression empirical coverage probability increased as the number of events per confounder increased. The propensity score empirical coverage probability decreased after eight or more events per confounder. Overall, the propensity score exhibited more empirical power than logistic regression. Propensity scores are a good alternative to control for imbalances when there are seven or fewer events per confounder; however, empirical power could range from 35\% to 60\%. Logistic regression is the technique of choice when there are at least eight events per confounder.},
  citeulike-article-id = {13265471},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwg115},
  citeulike-linkout-1 = {http://aje.oxfordjournals.org/content/158/3/280.abstract},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  note = {propensity score analysis has advantages to traditional outcome modeling in this case}
}

@article{cer10,
  title = {Special Issue on Comparative Effectiveness Research},
  author = {{Tunis} and {Gatsonis} and {Lauer} and {Normand} and {Rubin}},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  number = {19},
  pages = {1963--1997},
  citeulike-article-id = {13265863},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {cer,comparative-effectiveness-research,rubins-article-is-on-limitations-of-cer-and-goes-into-what-questions-we-ask}
}

@article{ces91goo,
  title = {A Goodness-of-Fit Test for Binary Regression Models, Based on Smoothing Methods},
  author = {le Cessie, S. and van Houwelingen, J. C.},
  options = {useprefix=true},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {1267--1282},
  citeulike-article-id = {13263867},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {global-goodness-of-fit,logistic-regression,smoothers}
}

@article{ces92rid,
  title = {Ridge Estimators in Logistic Regression},
  author = {le Cessie, S. and van Houwelingen, J. C.},
  options = {useprefix=true},
  date = {1992},
  journaltitle = {Appl Stat},
  volume = {41},
  pages = {191--201},
  citeulike-article-id = {13263868},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {logistic-regression,ridge-estimator,shrinkage}
}

@article{ces94log,
  title = {Logistic Regression for Correlated Binary Data},
  author = {le Cessie, S. and van Houwelingen, J. C.},
  options = {useprefix=true},
  date = {1994},
  journaltitle = {Appl Stat},
  volume = {43},
  pages = {95--108},
  citeulike-article-id = {13263869},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {cluster-sampling,correlated-binary-data,logistic-model-extensions}
}

@article{cha01cor,
  title = {Correspondence Analysis with {{R}}},
  author = {Charnomordic, Brigitte and Holmes, Susan},
  date = {2001},
  journaltitle = {Stat Comp Graphics News ASA},
  volume = {12},
  number = {1},
  pages = {19--25},
  citeulike-article-id = {13265245},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {correspondence-analysis,data-reduction,examples,s-language,tutorial}
}

@article{cha04adj,
  title = {Adjustment for Baseline Measurement Error in Randomized Controlled Trials Induces Bias},
  author = {Chan, Siew F and Macaskill, Petra and Irwig, Les and Walter, Stephen D},
  date = {2004-08-01},
  journaltitle = {Controlled Clinical Trials},
  volume = {25},
  number = {4},
  pages = {408--416},
  issn = {0197-2456},
  doi = {10.1016/j.cct.2004.06.001},
  url = {http://www.sciencedirect.com/science/article/pii/S0197245604000455},
  urldate = {2019-09-25},
  abstract = {When estimating the treatment effect in a randomized controlled trial, it is common to have a continuous outcome which is also observed at baseline. These observations are often prone to measurement error, for example due to within-patient variability. Controversy exists in the literature about whether baseline measurement error should be adjusted for in this context. Computer simulations were used to compare the biases in the estimated treatment effect, with and without adjusting for measurement error, and for different levels of observed baseline imbalance. The impacts of sample size (30 per group and 300 per group) and reliability coefficient (0.6, 0.8 and 1) were also assessed. The results show that in randomized controlled trials, the ordinary least squares (OLS) estimator without adjusting for measurement error is unbiased. On the contrary, adjusting for measurement error leads to bias, especially when sample sizes are small and/or measurement error is large. The treatment effect adjusting for measurement error is on average overestimated when the baseline mean of the control group is larger than that of the treated group. It is underestimated when the control group has a smaller baseline mean.},
  keywords = {measurement-error,rct}
}

@article{cha04int,
  title = {Integrating {{Histology}} and {{Mass Spectrometry}}},
  author = {Chaurand, P. and Schwartz, S. A. and Billheimer, D. and Xu, B. J. and Crecelius, A. and Caprioli, R. M.},
  date = {2004},
  journaltitle = {Analytic Chem},
  volume = {76},
  pages = {1145--1155},
  citeulike-article-id = {13265500},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{cha05sum,
  title = {Summarizing Data through a Piecewise Linear Growth Curve Model},
  author = {Chandrasekaran, V. and Gopal, G. and Thomas, A.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {1139--1151},
  citeulike-article-id = {13265403},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {4-number-summary,longitudinal-data,repeated-measures,serial-data,summarizing-within-subject-variability,summary-measures}
}

@article{cha08mul,
  title = {Multivariate Dynamic Model for Ordinal Outcomes},
  author = {Chaubert, F. and Mortier, F. and Saint André, L.},
  date = {2008-09-01},
  journaltitle = {Journal of Multivariate Analysis},
  volume = {99},
  number = {8},
  pages = {1717--1732},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2008.01.011},
  url = {http://www.sciencedirect.com/science/article/pii/S0047259X08000237},
  urldate = {2020-12-22},
  abstract = {Individual or stand-level biomass is not easy to measure. The current methods employed, based on cutting down a representative sample of plantations, make it possible to assess the biomasses for various compartments (bark, dead branches, leaves, …). However, this felling makes individual longitudinal follow-up impossible. In this context, we propose a method to evaluate individual biomasses by compartments when these are ordinals. Biomass is measured visually and observations are therefore not destructive. The technique is based on a probit model redefined in terms of latent variables. A generalization of the univariate case to the multivariate case is then natural and takes into account of dependency between compartment biomasses. These models are then extended to the longitudinal case by developing a Dynamic Multivariate Ordinal Probit Model. The performance of the MCMC algorithm used for the estimation is illustrated by means of simulations built from known biomass models. The quality of the estimates and the impact of certain parameters, are then discussed.},
  langid = {english},
  keywords = {ordinal,serial}
}

@article{cha12clu,
  title = {{{ClustOfVar}}: {{An R}} Package for the Clustering of Variables},
  author = {Chavent, Marie and Kuentz-Simonet, Vanessa and Liquet, Beno\^it and Saracco, Jérôme},
  date = {2012-09},
  journaltitle = {J Stat Software},
  volume = {50},
  number = {13},
  pages = {1--16},
  citeulike-article-id = {13265944},
  day = {22},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {data-reduction,variable-clustering}
}

@article{cha13ran,
  title = {A {{Random Effect Block Bootstrap}} for {{Clustered Data}}},
  author = {Chambers, Raymond and Chandra, Hukum},
  date = {2013},
  journaltitle = {J Comp Graph Stat},
  volume = {22},
  number = {2},
  eprint = {http://amstat.tandfonline.com/doi/pdf/10.1080/10618600.2012.681216},
  pages = {452--470},
  doi = {10.1080/10618600.2012.681216},
  url = {http://amstat.tandfonline.com/doi/abs/10.1080/10618600.2012.681216},
  abstract = {Random effects models for hierarchically dependent data, for example, clustered data, are widely used. A popular bootstrap method for such data is the parametric bootstrap based on the same random effects model as that used in inference. However, it is hard to justify this type of bootstrap when this model is known to be an approximation. In this article, we describe a random effect block bootstrap approach for clustered data that is simple to implement, free of both the distribution and the dependence assumptions of the parametric bootstrap, and is consistent when the mixed model assumptions are valid. Results based on Monte Carlo simulation show that the proposed method seems robust to failure of the dependence assumptions of the assumed mixed model. An application to a realistic environmental dataset indicates that the method produces sensible results. Supplementary materials for the article, including the data used for the application, are available online.},
  citeulike-article-id = {13265970},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/10618600.2012.681216},
  citeulike-linkout-1 = {http://amstat.tandfonline.com/doi/abs/10.1080/10618600.2012.681216},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {bootstrap,cluster-bootstrap,clustered-data,longitudinal,serial}
}

@article{cha14mod,
  title = {A {{Modification}} of a {{Percentile Estimation Procedure Based}} on {{Generalized Polya Urns}}},
  author = {Chandrasekhar, Rameela and Wilding, Gregory E.},
  date = {2014-07},
  journaltitle = {Comm Stat Th Meth},
  volume = {43},
  number = {14},
  pages = {2951--2957},
  publisher = {Taylor & Francis},
  doi = {10.1080/03610926.2012.678137},
  url = {http://dx.doi.org/10.1080/03610926.2012.678137},
  abstract = {Adaptive designs find an important application in the estimation of unknown percentiles for an underlying dose-response curve. A nonparametric adaptive design was suggested by Mugno et~al. (2004) to simultaneously estimate multiple percentiles of an unknown dose-response curve via generalized Polya urns. In this article, we examine the properties of the design proposed by Mugno et~al. (2004) when delays in observing responses are encountered. Using simulations, we evaluate a modification of the design under varying group sizes. Our results demonstrate unbiased estimation with minimal loss in efficiency when compared to the original compound urn design.},
  citeulike-article-id = {14033342},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/03610926.2012.678137},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/03610926.2012.678137},
  day = {18},
  posted-at = {2016-05-11 17:25:02},
  priority = {2},
  keywords = {ctsafac}
}

@article{cha15lik,
  title = {Likelihood-Based Inferences about the Mean Area under a Longitudinal Curve in the Presence of Observations Subject to Limits of Detection.},
  author = {Chandrasekhar, Rameela and Shi, Yi and Hutson, Alan D. and Wilding, Gregory E.},
  date = {2015},
  journaltitle = {Pharm Stat},
  volume = {14},
  number = {3},
  eprint = {25832442},
  eprinttype = {pmid},
  pages = {252--261},
  issn = {1539-1612},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25832442},
  abstract = {Comparison of groups in longitudinal studies is often conducted using the area under the outcome versus time curve. However, outcomes may be subject to censoring due to a limit of detection and specific methods that take informative missingness into account need to be applied. In this article, we present a unified model-based method that accounts for both the within-subject variability in the estimation of the area under the curve as well as the missingness mechanism in the event of censoring. Simulation results demonstrate that our proposed method has a significant advantage over traditionally implemented methods with regards to its inferential properties. A working example from an AIDS study is presented to demonstrate the applicability of our approach.},
  citeulike-article-id = {14033344},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25832442},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25832442},
  posted-at = {2016-05-11 17:26:17},
  priority = {2},
  keywords = {ctsafac}
}

@article{cha15nov,
  title = {A {{Novel Approach}} to {{Testing}} for {{Average Bioequivalence Based}} on {{Modeling}} the {{Within-Period Dependence Structure}}.},
  author = {Chandrasekhar, Rameela and Shi, Yi and Hutson, Alan D. and Wilding, Gregory E.},
  date = {2015},
  journaltitle = {J Biopharm Stat},
  volume = {25},
  number = {6},
  eprint = {25671781},
  eprinttype = {pmid},
  pages = {1320--1338},
  issn = {1520-5711},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25671781},
  abstract = {Bioequivalence trials are commonly conducted to assess therapeutic equivalence between a generic and an innovator brand formulations. In such trials, drug concentrations are obtained repeatedly over time and are summarized using a metric such as the area under the concentration vs. time curve (AUC) for each subject. The usual practice is to then conduct two one-sided tests using these areas to evaluate for average bioequivalence. A major disadvantage of this approach is the loss of information encountered when ignoring the correlation structure between repeated measurements in the computation of areas. In this article, we propose a general linear model approach that incorporates the within-subject covariance structure for making inferences on mean areas. The model-based method can be seen to arise naturally from the reparameterization of the AUC as a linear combination of outcome means. We investigate and compare the inferential properties of our proposed method with the traditional two one-sided tests approach using Monte Carlo simulation studies. We also examine the properties of the method in the event of missing data. Simulations show that the proposed approach is a cost-effective, viable alternative to the traditional method with superior inferential properties. Inferential advantages are particularly apparent in the presence of missing data. To illustrate our approach, a real working example from an asthma study is utilized.},
  citeulike-article-id = {14033343},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25671781},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25671781},
  posted-at = {2016-05-11 17:25:39},
  priority = {2},
  keywords = {ctsafac}
}

@book{cha16pri,
  title = {Principles of {{Scientific Methods}}},
  author = {Chang, Mark},
  date = {2016-04-19},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/b17167},
  url = {https://www.taylorfrancis.com/books/9780429171901},
  urldate = {2019-10-09},
  abstract = {Principles of Scientific Methods focuses on the fundamental principles behind scientific methods. The book refers to "science" in a broad sense, including},
  isbn = {978-0-429-17190-1},
  langid = {english},
  keywords = {experimental-design,scientific-approach}
}

@article{cha18imp,
  title = {Implementing {{Machine Learning}} in {{Health Care}} — {{Addressing Ethical Challenges}}},
  author = {Char, Danton S. and Shah, Nigam H. and Magnus, David},
  date = {2018-03},
  journaltitle = {NEJM},
  volume = {378},
  number = {11},
  pages = {981--983},
  publisher = {Massachusetts Medical Society},
  doi = {10.1056/nejmp1714229},
  url = {http://dx.doi.org/10.1056/nejmp1714229},
  abstract = {Implementing Machine Learning in Health Care We need to consider the ethical challenges inherent in implementing machine learning in health care if its benefits are to be realized. Some of these challenges are straightforward, whereas others have less obvious risks but raise broader ethical concerns.},
  citeulike-article-id = {14549622},
  citeulike-linkout-0 = {http://dx.doi.org/10.1056/nejmp1714229},
  citeulike-linkout-1 = {http://www.nejm.org/doi/abs/10.1056/NEJMp1714229},
  day = {14},
  posted-at = {2018-03-15 12:37:52},
  priority = {2},
  keywords = {ethics,machine-learning}
}

@article{cha19how,
  title = {How to Analyze and Interpret Recurrent Events Data in the Presence of a Terminal Event: {{An}} Application on Readmission after Colorectal Cancer Surgery},
  shorttitle = {How to Analyze and Interpret Recurrent Events Data in the Presence of a Terminal Event},
  author = {Charles‐Nelson, Anaïs and Katsahian, Sandrine and Schramm, Catherine},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8168},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8168},
  urldate = {2019-04-25},
  abstract = {Recurrent events arise when an event occurs many times for a subject. Many models have been developed to analyze these kind of data: the Andersen-Gill's model is one of them as well as the Prentice-William and the Peterson's model, the Wei Lee and Weissfeld's model, or even frailty models, all assuming an independent and noninformative censoring. However, in practice, these assumptions may be violated by the existence of a terminal event that permanently stops the recurrent process (eg, death). Indeed, a patient who experiences an early terminal event is more likely to have a lower number of recurrent events than a patient who experiences a terminal event later. Thus, ignoring terminal events in the analysis may lead to biased results. Many methods have been developed to handle terminal events. In this paper, we describe the existing methods classifying into conditional or marginal methods and compare them in a simulation study to highlight bias in results if an inappropriate method is used, when recurrent events and terminal event are correlated. In addition, we apply the different models on a real dataset to show how results should be interpreted. Finally, we provide recommendations for choosing the appropriate method for analyzing recurrent events in the presence of a terminal event.},
  langid = {english},
  keywords = {multiple-endpoints,rct,recurrent-event-with-competing-risk,recurrent-events,terminating-event}
}

@article{cha20bay,
  title = {A {{Bayesian}} Group Sequential Small n Sequential Multiple-Assignment Randomized Trial},
  author = {Chao, Yan-Cheng and Braun, Thomas M. and Tamura, Roy N. and Kidwell, Kelley M.},
  date = {2020},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume = {n/a},
  number = {n/a},
  issn = {1467-9876},
  doi = {10.1111/rssc.12406},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12406},
  urldate = {2020-04-12},
  abstract = {A small n, sequential, multiple-assignment, randomized trial (called ‘snSMART’) is a small sample multistage design where participants may be rerandomized to treatment on the basis of intermediate end points. This design is motivated by the ‘A randomized multicenter study for isolated skin vasculitis’ trial (NCT02939573): an on-going snSMART design focusing on the evaluation of three drugs for isolated skin vasculitis. By formulating an interim decision rule for removing one of the treatments, we use a Bayesian model and the resulting posterior distributions to provide sufficient evidence that one treatment is inferior to the other treatments before enrolling more participants. By doing so, we can remove the worst performing treatment at an interim analysis and prevent the subsequent participants from receiving the removed treatment. On the basis of simulation results, we have evidence that the treatment response rates can still be unbiasedly and efficiently estimated in our new design, especially for the treatments with higher response rates. In addition, by adjusting the decision rule criteria for the posterior probabilities, we can control the probability of incorrectly removing an effective treatment.},
  langid = {english},
  keywords = {adaptive,bayes,rct,sequential,smart},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssc.12406}
}

@article{cha81met,
  title = {A Method for Assessing the Quality of a Randomized Control Trial},
  author = {Chalmers, Thomas C. and Smith, Harry and Blackburn, Bradley and Silverman, Bernard and Schroeder, Biruta and Reitman, Dinah and Ambroz, Alexander},
  date = {1981},
  journaltitle = {Controlled Clin Trials},
  volume = {2},
  pages = {31--49},
  citeulike-article-id = {13263870},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {clinical-trials,rating-quality-of-studies,rct,reporting}
}

@article{cha85max,
  title = {Maximum Likelihood Methods for Complex Sample Data: {{Logistic}} Regression and Discrete Proportional Hazards Models},
  author = {Chambless, L. E. and Boyle, K. E.},
  date = {1985},
  journaltitle = {Comm Stat A},
  volume = {14},
  pages = {1377--1392},
  citeulike-article-id = {13263871},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {sample-survey,survey-regression,survival-analysis,weighted-maximum-likelihood-estimates}
}

@article{cha90,
  title = {Application of the {{Cox}} Model as a Predictor of Relative Risk of Coronary Heart Disease in the {{Albany Study}}},
  author = {Chang, H. G. H. and Lininger, L. L. and Doyle, J. T. and MacCubbin, P. A. and Rothenberg, R.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {287--292},
  citeulike-article-id = {13263872},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model}
}

@article{cha91,
  title = {Avoiding Statistical Pitfalls (with Discussion)},
  author = {Chatfield, C.},
  date = {1991},
  journaltitle = {Stat Sci},
  volume = {6},
  pages = {240--268},
  citeulike-article-id = {13263873},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cha92not,
  title = {A Note on Linear Rank Tests and {{Gill}} and {{Schumacher}}'s Tests of Proportionality},
  author = {Chappell, Rick},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {199--201},
  citeulike-article-id = {13263875},
  posted-at = {2014-07-14 14:09:24},
  priority = {0}
}

@article{cha94red,
  title = {Reduction in Burden of Illness: {{A}} New Efficacy Measure for Prevention Trials},
  author = {Chang, M. N. and Guess, H. A. and Heyse, J. F.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1807--1814},
  doi = {10.1002/sim.4780131803},
  url = {http://dx.doi.org/10.1002/sim.4780131803},
  citeulike-article-id = {13265754},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780131803},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {burden-of-illness,prevention,rct,study-design},
  note = {by assigning points to various outcomes (e.g., post-infection outcomes in a vaccine trial; non-infected subjects would get a score of zero), simple intent-to-treat analyses may be used to compare two treatments;provides overall net benefit of treatment, avoiding issues of selection bias that might require the use of principal stratification or other causal inference methods;how des one choose the severity scores? (need to check if this could be fixed by using an ordinal logistic model);does not clearly differentiate vaccine effects on preventing infection and effects on post-infection endpoints;Mehrotra has results suggesting principal stratification methods may be more powerful than ITT-based methods (Biometrics 62:893-900;2006)}
}

@article{cha95mod,
  title = {Model Uncertainty, Data Mining and Statistical Inference (with Discussion)},
  author = {Chatfield, C.},
  date = {1995},
  journaltitle = {J Roy Stat Soc A},
  volume = {158},
  pages = {419--466},
  citeulike-article-id = {13263876},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  note = {bias by selecting model because it fits the data well; bias in standard errors;P. 420: ... need for a better balance in the literature and in statistical teaching between~ techniques and problem solving~ strategies. P. 421: It is `well known' to be `logically unsound and practically misleading' (Zhang, 1992) to make inferences as if a model is known to be true when it has, in fact, been selected from the~ same data to be used for estimation purposes. However, although statisticians may admit this privately (Breiman (1992) calls it a `quiet scandal'), they (we) continue to ignore the difficulties because it is not clear what else could or should be done. P. 421: Estimation errors for regression coefficients are usually smaller than errors from failing to take into account model specification. P. 422: Statisticians must stop pretending that model uncertainty does not exist and begin to find ways of coping with it. P. 426: It is indeed strange that we often admit model uncertainty by searching for a best model but then ignore this uncertainty by making inferences and predictions as if certain that the best fitting model is actually true. P. 427: The analyst needs to assess the model selection~ process and not just the best fitting model. P. 432: The use of subset selection methods is well known to introduce alarming biases. P. 433: ... the AIC can be highly biased in data-driven model selection situations. P. 434: Prediction intervals will generally be too narrow. In the discussion, Jamal R. M. Ameen states that a model should be (a) satisfactory in performance relative to the stated objective, (b) logically sound, (c) representative, (d) questionable and subject to on-line interrogation, (e) able to accommodate external or expert information and (f) able to convey information.}
}

@article{cha96est,
  title = {Estimating Confidence Intervals for Cost-Effectiveness Ratios: {{An}} Example from a Randomized Trial},
  author = {Chaudhary, Mohammad A. and Stearns, Sally C.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1447--1458},
  citeulike-article-id = {13263877},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {bootstrap,cost-effectiveness,explanation-of-negative-cost-effectiveness-ratios,fiellers-method}
}

@article{cha97eff,
  title = {Effect of Aging on the Sensitivity of Growth Hormone Secretion to Insulin-like Growth Factor-{{I}} Negative Feedback},
  author = {Chapman, I. M. and Hartman, M. L. and Pezzoli, S. S. and Harrell, F. E. and Hintz, R. L. and Alberti, K. G. and Thorner, M. O.},
  date = {1997},
  journaltitle = {J Clin Endocrin Metab},
  volume = {82},
  pages = {2996--3004},
  citeulike-article-id = {13263878},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {used-cluster-bootstrap-with-simultaneous-confidence-bands}
}

@book{chaBookreg,
  title = {Regression {{Analysis}} by {{Example}}},
  author = {Chatterjee, Samprit and Hadi, Ali S.},
  date = {2012},
  edition = {Fifth},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13263874},
  isbn = {0-470-90584-0},
  posted-at = {2014-07-14 14:09:24},
  priority = {0},
  keywords = {collinearity,general,influence,principal-components,regression,ridge-regression,variable-selection}
}

@article{che07bia,
  title = {Biased Odds Ratios from Dichotomization of Age},
  author = {Chen, Henian and Cohen, Patricia and Chen, Sophie},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3487--3497},
  citeulike-article-id = {13265612},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {categorization,continuous-variables,cutpoint,dichtomization},
  note = {problems with dichotomizing continuous confounder variable;odds ratio;age;confounding;logistic regression;categorization;cutpoint;the further a cutpoint is from the median for the confounder the greater then increase in OR in the exposure}
}

@book{che08han,
  title = {Handbook of {{Data Visualization}}},
  editor = {Chen, Chun-Houh and Härdle, Wolfgang and Unwin, Antony},
  date = {2008},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265690},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {graphics}
}

@article{che14mx,
  title = {A Mixture of Transition Models for Heterogeneous Longitudinal Ordinal Data: With Applications to Longitudinal Bacterial Vaginosis Data},
  author = {Cheon, Kyeongmi and Thoma, Marie E. and Kong, Xiangrong and Albert, Paul S},
  date = {2014-08},
  journaltitle = {Stat Med},
  volume = {33},
  number = {18},
  pages = {3204--3213},
  doi = {10.1002/sim.6151},
  url = {http://dx.doi.org/10.1002/sim.6151},
  abstract = {Markov models used to analyze transition patterns in discrete longitudinal data are based on the limiting assumption that individuals follow the common underlying transition process. However, when one is interested in diseases with different disease or severity subtypes, explicitly modeling subpopulation-specific transition patterns may be appropriate. We propose a model which captures heterogeneity in the transition process through a finite mixture model formulation and provides a framework for identifying subpopulations at different risks. We apply the procedure to longitudinal bacterial vaginosis study data and demonstrate that the model fits the data well. Further, we show that under the mixture model formulation, we can make the important distinction between how covariates affect transition patterns unique to each of the subpopulations and how they affect which subgroup a participant will belong to. Practically, covariate effects on subpopulation-specific transition behavior and those on subpopulation membership can be interpreted as effects on short-term and long-term transition behavior. We further investigate models with higher-order subpopulation-specific transition dependence.},
  citeulike-article-id = {13448117},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6151},
  day = {15},
  posted-at = {2014-11-29 16:17:13},
  priority = {2},
  keywords = {ordinal-response,serial-data,transition-model}
}

@article{che14not,
  title = {A Note on the Relationships between Multiple Imputation, Maximum Likelihood and Fully {{Bayesian}} Methods for Missing Responses in Linear Regression Models.},
  author = {Chen, Qingxia and Ibrahim, Joseph G.},
  date = {2014-07},
  journaltitle = {Statistics and its interface},
  volume = {6},
  number = {3},
  eprint = {25309677},
  eprinttype = {pmid},
  pages = {315--324},
  issn = {1938-7989},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25309677},
  abstract = {Multiple Imputation, Maximum Likelihood and Fully Bayesian methods are the three most commonly used model-based approaches in missing data problems. Although it is easy to show that when the responses are missing at random (MAR), the complete case analysis is unbiased and efficient, the aforementioned methods are still commonly used in practice for this setting. To examine the performance of and relationships between these three methods in this setting, we derive and investigate small sample and asymptotic expressions of the estimates and standard errors, and fully examine how these estimates are related for the three approaches in the linear regression model when the responses are MAR. We show that when the responses are MAR in the linear model, the estimates of the regression coefficients using these three methods are asymptotically equivalent to the complete case estimates under general conditions. One simulation and a real data set from a liver cancer clinical trial are given to compare the properties of these methods when the responses are MAR.},
  citeulike-article-id = {14032319},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25309677},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25309677},
  day = {1},
  posted-at = {2016-05-10 23:04:26},
  priority = {2},
  keywords = {ctsafac}
}

@article{che15com,
  title = {Composite Large Margin Classifiers with Latent Subclasses for Heterogeneous Biomedical Data},
  author = {Chen, Guanhua and Liu, Yufeng and Shen, Dinggang and Kosorok, Michael R.},
  date = {2016},
  journaltitle = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  volume = {9},
  number = {2},
  pages = {75--88},
  publisher = {Wiley Subscription Services, Inc., A Wiley Company},
  doi = {10.1002/sam.11300},
  url = {http://dx.doi.org/10.1002/sam.11300},
  citeulike-article-id = {14033222},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sam.11300},
  posted-at = {2016-05-11 12:58:35},
  priority = {2},
  keywords = {ctsafac}
}

@article{che15qua,
  title = {Quantifying the Average of the Time-Varying Hazard Ratio via a Class of Transformations.},
  author = {Chen, Qingxia and Zeng, Donglin and Ibrahim, Joseph G. and Chen, Ming-Hui H. and Pan, Zhiying and Xue, Xiaodong},
  date = {2015-04},
  journaltitle = {Lifetime Data Anal},
  volume = {21},
  number = {2},
  eprint = {25073864},
  eprinttype = {pmid},
  pages = {259--279},
  issn = {1572-9249},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25073864},
  abstract = {The hazard ratio derived from the Cox model is a commonly used summary statistic to quantify a treatment effect with a time-to-event outcome. The proportional hazards assumption of the Cox model, however, is frequently violated in practice and many alternative models have been proposed in the statistical literature. Unfortunately, the regression coefficients obtained from different models are often not directly comparable. To overcome this problem, we propose a family of weighted hazard ratio measures that are based on the marginal survival curves or marginal hazard functions, and can be estimated using readily available output from various modeling approaches. The proposed transformation family includes the transformations considered by Schemper et al. (Statist Med 28:2473-2489, 2009) as special cases. In addition, we propose a novel estimate of the weighted hazard ratio based on the maximum departure from the null hypothesis within the transformation family, and develop a Kolmogorov[Formula: see text]Smirnov type of test statistic based on this estimate. Simulation studies show that when the hazard functions of two groups either converge or diverge, this new estimate yields a more powerful test than tests based on the individual transformations recommended in Schemper et al. (Statist Med 28:2473-2489, 2009), with a similar magnitude of power loss when the hazards cross. The proposed estimates and test statistics are applied to a colorectal cancer clinical trial.},
  citeulike-article-id = {14032316},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25073864},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25073864},
  posted-at = {2016-05-10 22:58:30},
  priority = {2},
  keywords = {ctsafac}
}

@article{che16too,
  title = {Too Many Covariates and Too Few Cases? - a Comparative Study},
  author = {Chen, Qingxia and Nian, Hui and Zhu, Yuwei and Talbot, H. Keipp and Griffin, Marie R. and Harrell, Frank E.},
  date = {2016-11},
  journaltitle = {Stat Med},
  volume = {35},
  number = {25},
  pages = {4546--4558},
  issn = {02776715},
  doi = {10.1002/sim.7021},
  url = {http://dx.doi.org/10.1002/sim.7021},
  citeulike-article-id = {14218257},
  citeulike-attachment-1 = {che16too.pdf; /pdf/user/harrelfe/article/14218257/1093467/che16too.pdf; 3227b989b9dc8141aeff04faa3e49f67159e8358},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7021},
  day = {10},
  posted-at = {2016-12-01 14:22:08},
  priority = {2},
  keywords = {covariable-adjustment,covariate-adjustment,penalization,penalized-estimation,penalized-mle,propensity-score}
}

@article{che17pro,
  title = {A Profile Likelihood Approach for Longitudinal Data Analysis},
  author = {Chen, Ziqi and Tang, Man-Lai and Gao, Wei},
  date = {2017},
  journaltitle = {Biometrics},
  doi = {10.1111/biom.12712},
  url = {http://dx.doi.org/10.1111/biom.12712},
  abstract = {Inappropriate choice of working correlation structure in generalized estimating equations (GEE) could lead to inefficient parameter estimation while impractical normality assumption in likelihood approach would limit its applicability in longitudinal data analysis. In this article, we propose a profile likelihood method for estimating parameters in longitudinal data analysis via maximizing the estimated likelihood. The proposed method yields consistent and efficient estimates without specifications of the working correlation structure nor the underlying error distribution. Both theoretical and simulation results confirm the satisfactory performance of the proposed method. We illustrate our methodology with a diastolic blood pressure data set.},
  citeulike-article-id = {14345079},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/biom.12712},
  posted-at = {2017-04-26 20:26:06},
  priority = {3},
  keywords = {epub-replace,gee,longitudinal-data,profile-likelihood,robust-methods,serial-data}
}

@article{che19pri,
  title = {Prioritized Concordance Index for Hierarchical Survival Outcomes},
  author = {Cheung, Li C. and Pan, Qing and Hyun, Noorie and Katki, Hormuzd A.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8157},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8157},
  urldate = {2019-04-25},
  abstract = {We propose an extension of Harrell's concordance (C) index to evaluate the prognostic utility of biomarkers for diseases with multiple measurable outcomes that can be prioritized. Our prioritized concordance index measures the probability that, given a random subject pair, the subject with the worst disease status as of a time τ has the higher predicted risk. Our prioritized concordance index uses the same approach as the win ratio, by basing generalized pairwise comparisons on the most severe or clinically important comparable outcome. We use an inverse probability weighting technique to correct for study-specific censoring. Asymptotic properties are derived using U-statistic properties. We apply the prioritized concordance index to two types of disease processes with a rare primary outcome and a more common secondary outcome. Our simulation studies show that when a predictor is predictive of both outcomes, the new concordance index can gain efficiency and power in identifying true prognostic variables compared to using the primary outcome alone. Using the prioritized concordance index, we examine whether novel clinical measures can be useful in predicting risk of type II diabetes in patients with impaired glucose resistance whose disease status can also regress to normal glucose resistance. We also examine the discrimination ability of four published risk models among ever smokers at risk of lung cancer incidence and subsequent death.},
  langid = {english},
  keywords = {c-index,multiple-endpoints,rct}
}

@article{che97pre,
  title = {Predicting {{Survival Probabilities}} with {{Semiparametric Transformation Models}}},
  author = {Cheng, S. C. and Wei, L. J. and Ying, Z.},
  date = {1997-03},
  journaltitle = {JASA},
  volume = {92},
  number = {437},
  pages = {227--235},
  publisher = {Taylor & Francis},
  doi = {10.1080/01621459.1997.10473620},
  url = {http://dx.doi.org/10.1080/01621459.1997.10473620},
  abstract = {Abstract Prediction of survival probabilities for future patients is one of the main goals of fitting survival data with regression models. In this article we consider a large class of semiparametric transformation models, which includes the well-known proportional hazards and proportional odds models, for the analysis of failure time data. Specifically, we propose pointwise and simultaneous confidence interval procedures for the survival probability of future patients with specific covariates. These procedures can be easily implemented through simulation and are illustrated with the data from two well-known clinical studies.},
  citeulike-article-id = {13349281},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1997.10473620},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1997.10473620},
  day = {1},
  posted-at = {2014-09-06 14:28:06},
  priority = {2},
  keywords = {proportional-odds-model,simultaneous-confidence-intervals,survival-analysis},
  note = {simultaneous confidence bands for S(t) for future patients with specified covariables}
}

@article{che98pre,
  title = {Prediction of Cumulative Incidence Function under the Proportional Hazards Model},
  author = {Cheng, S. C. and Fine, Jason P. and Wei, L. J.},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {219--228},
  citeulike-article-id = {13263880},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {competing-risks,confidence-intervals-and-bands,counting-process,martingale},
  note = {cumulative incidence function as a summary for marginal probabilities of each event type}
}

@article{chen12eff,
  title = {Efficient Semiparametric Mean-Association Estimation for Longitudinal Binary Responses},
  author = {Chen, Ziqi and Shi, Ning-Zhong and Gao, Wei and Tang, Man-Lai},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {13},
  pages = {1323--1341},
  doi = {10.1002/sim.4480},
  url = {http://dx.doi.org/10.1002/sim.4480},
  abstract = {Semiparametric methods for longitudinal data with association within subjects have recently received considerable attention. However, existing methods for semiparametric longitudinal binary regression modeling (i) mainly concern mean structures with association parameters treated as nuisance; (ii) generally require a correct specification of the covariance structure for misspecified covariance structure may lead to inefficient mean parameter estimates; and (iii) usually run into computation and estimation problems when the time points are irregularly and possibly subject specific. In this article, we propose a semiparametric logistic regression model, which simultaneously takes into account both the mean and response-association structures (via conditional log-odds ratio) for multivariate longitudinal binary outcomes. Our main interest lies in efficient estimation of both the marginal and association parameters. The estimators of the parameters are obtained via the profile kernel approach. We evaluate the proposed methodology through simulation studies and apply it to a real dataset. Both theoretical and empirical results demonstrate that the proposed method yields highly efficient estimators and performs satisfactorily.},
  citeulike-article-id = {13265928},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4480},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {association-parameter,binary-data,conditional-log-odds-ratio,longitudinal-data,profile-likelihood-estimator,semiparametric-logistic-regression-model}
}

@article{chi02suf,
  title = {Sufficient Dimension Reduction in Regressions with Categorical Predictors},
  author = {Chiaromonte, Francesca and Cook, R. Dennis and Li, Bing},
  date = {2002},
  journaltitle = {Appl Stat},
  volume = {30},
  pages = {475--497},
  citeulike-article-id = {13265292},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {data-reduction,dimension-reduction,sliced-inverse-regression},
  note = {extensions to sliced inverse regression for categorical predictors}
}

@article{chi90,
  title = {The Assessment of Methods of Measurement},
  author = {{Chinn}},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {351--362},
  citeulike-article-id = {13263881},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {comparison-of-two-methods-on-different-scales,comparison-of-two-methods-on-the-same-measurement-scale,diagnosis,measurement,monitoring,reference-ranges,repeatability,research-methods}
}

@article{chi96ant,
  title = {Antihypertensive Effect of Drugs: {{Statistical}} Distribution of the Trough-to-Peak Ratio},
  author = {Chi, Vu X. and Chau, Nguyen P.},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {286--290},
  citeulike-article-id = {13263882},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {pharmaceutical-trial}
}

@article{chmp06gui,
  title = {Guideline on Data Monitoring Committees},
  author = {{Committee for Medicinal Products for Human Use}},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {1639--1645},
  citeulike-article-id = {13265487},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {dmc,dsmb}
}

@book{cho07ada,
  title = {Adaptive {{Design Methods}} in {{Clinical Trials}}},
  author = {Chow, S. C. and Chang, M.},
  date = {2007},
  publisher = {{Chapman \& Hall/CRC}},
  location = {{Boca Raton, Florida}},
  citeulike-article-id = {13265668},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  note = {in book review by Tim Friede in Biometrics 64:314-315; 2008, "In their view clinical trials are rarely carried out the way they were planned and design aspects are changed during the ongoing study through protocol amendments. The criticize the fact that analyses do not usually account for these protocol changes and describe an alternative analysis approach that is valid under a specific model in Chapter 2. Adaptive designs are then a logical consequence of what is happening in practice anyway but with the benefit that design and analysis both adapt to changes."; ExpDesignStudio software mentioned but no information on web}
}

@article{cho12simI,
  title = {A Simulation Study of Predictive Ability Measures in a Survival Model {{I}}: {{Explained}} Variation Measures},
  author = {Choodari-Oskooei, Babak and Royston, Patrick and Parmar, Mahesh K. B.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {23},
  pages = {2627--2643},
  doi = {10.1002/sim.4242},
  url = {http://dx.doi.org/10.1002/sim.4242},
  abstract = {Measures of predictive ability play an important role in quantifying the clinical significance of prognostic factors. Several measures have been proposed to evaluate the predictive ability of survival models in the last two decades, but no single measure is consistently used. The proposed measures can be classified into the following categories: explained variation, explained randomness, and predictive accuracy. The three categories are conceptually different and are based on different principles. Several new measures have been proposed since Schemper and Stare's study in 1996 on some of the existing measures. This paper is the first of two papers that study the proposed measures systematically by applying a set of criteria that a measure of predictive ability should possess in the context of survival analysis. The present paper focuses on the explained variation category, and part II studies the proposed measures in the other categories. Simulation studies are used to examine the performance of five explained variation measures with respect to these criteria, discussing their strengths and shortcomings. Our simulation studies show that the measures proposed by Kent and O'Quigley, R²\_PM, and Royston and Sauerbrei, R²\_D, appear to be the best overall at quantifying predictive ability. However, it should be noted that neither measure is perfect; R²\_PM is sensitive to outliers and R²\_d to (marked) non-normality of the distribution of the prognostic index. The results show that the other measures perform poorly, primarily because they are adversely affected by censoring.},
  citeulike-article-id = {13265948},
  citeulike-attachment-1 = {cho12simI.pdf; /pdf/user/harrelfe/article/13265948/1113130/cho12simI.pdf; 61bfa9b7824eb7317648329b55c3049e749c6aa6},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4242},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {breast-cancer,cox-proportional-hazards-model,explained-variation,predictive-ability,survival-analysis}
}

@article{cho12simII,
  title = {A Simulation Study of Predictive Ability Measures in a Survival Model {{II}}: Explained Randomness and Predictive Accuracy},
  author = {Choodari-Oskooei, B. and Royston, P. and Parmar, Mahesh K. B.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {23},
  pages = {2644--2659},
  doi = {10.1002/sim.5460},
  url = {http://dx.doi.org/10.1002/sim.5460},
  abstract = {Several R²-type measures have been proposed to evaluate the predictive ability of a survival model. In Part I, we classified the measures into four categories and studied the measures in the explained variation category. In this paper, we study the remaining measures in a similar fashion, discussing their strengths and shortcomings. Simulation studies are used to examine the performance of the measures with respect to the criteria we set out in Part I. Our simulation studies showed that among the measures studied in this paper, the measures proposed by Kent and O'Quigley ρ²\_W (and its approximation ρ²\_W,A and Schemper and Kaider R²\_SK perform better with respect to our criteria. However, our investigations showed that ρ²\_W is adversely affected by the distribution of covariate and the presence of influential observations. The results show that the other measures perform poorly, primarily because they are affected either by the degree of censoring or the follow-up period.},
  citeulike-article-id = {13265949},
  citeulike-attachment-1 = {cho12simII.pdf; /pdf/user/harrelfe/article/13265949/1113131/cho12simII.pdf; a705fba5da20d891fe4edadff15b051fc41ade2b},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5460},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {cox-proportional-hazards-model,explained-randomness,predictive-accuracy,survival-analysis}
}

@article{cho14joi,
  title = {Joint Modeling of Longitudinal and Survival Data with Missing and Left-Censored Time-Varying Covariates.},
  author = {Chen, Qingxia and May, Ryan C. and Ibrahim, Joseph G. and Chu, Haitao and Cole, Stephen R.},
  date = {2014-11},
  journaltitle = {Stat Med},
  volume = {33},
  number = {26},
  eprint = {24947785},
  eprinttype = {pmid},
  pages = {4560--4576},
  issn = {1097-0258},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/24947785},
  abstract = {We propose a joint model for longitudinal and survival data with time-varying covariates subject to detection limits and intermittent missingness at random. The model is motivated by data from the Multicenter AIDS Cohort Study (MACS), in which HIV+ subjects have viral load and CD4 cell count measured at repeated visits along with survival data. We model the longitudinal component using a normal linear mixed model, modeling the trajectory of CD4 cell count by regressing on viral load, and other covariates. The viral load data are subject to both left censoring because of detection limits (17\%) and intermittent missingness (27\%). The survival component of the joint model is a Cox model with time-dependent covariates for death because of AIDS. The longitudinal and survival models are linked using the trajectory function of the linear mixed model. A Bayesian analysis is conducted on the MACS data using the proposed joint model. The proposed method is shown to improve the precision of estimates when compared with alternative methods. Copyright  2014 John Wiley \& Sons, Ltd.},
  citeulike-article-id = {14032318},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/24947785},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=24947785},
  day = {20},
  posted-at = {2016-05-10 23:01:58},
  priority = {2},
  keywords = {ctsafac}
}

@article{cho15elu,
  title = {Elucidating the {{Foundations}} of {{Statistical Inference}} with 2 x 2 {{Tables}}},
  author = {Choi, Leena and Blume, Jeffrey D. and Dupont, William D.},
  date = {2015-04},
  journaltitle = {PLoS ONE},
  volume = {10},
  number = {4},
  pages = {e0121263+},
  publisher = {Public Library of Science},
  doi = {10.1371/journal.pone.0121263},
  url = {http://dx.doi.org/10.1371/journal.pone.0121263},
  abstract = {To many, the foundations of statistical inference are cryptic and irrelevant to routine statistical practice. The analysis of 2 x 2 contingency tables, omnipresent in the scientific literature, is a case in point. Fisher's exact test is routinely used even though it has been fraught with controversy for over 70 years. The problem, not widely acknowledged, is that several different p-values can be associated with a single table, making scientific inference inconsistent. The root cause of this controversy lies in the table's origins and the manner in which nuisance parameters are eliminated. However, fundamental statistical principles (e.g., sufficiency, ancillarity, conditionality, and likelihood) can shed light on the controversy and guide our approach in using this test. In this paper, we use these fundamental principles to show how much information is lost when the tables origins are ignored and when various approaches are used to eliminate unknown nuisance parameters. We present novel likelihood contours to aid in the visualization of information loss and show that the information loss is often virtually non-existent. We find that problems arising from the discreteness of the sample space are exacerbated by p-value-based inference. Accordingly, methods that are less sensitive to this discreteness - likelihood ratios, posterior probabilities and mid-p-values - lead to more consistent inferences.},
  citeulike-article-id = {14033215},
  citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0121263},
  day = {7},
  posted-at = {2016-05-11 12:50:32},
  priority = {2},
  keywords = {2x2-table,ctsafac,fishers-exact-test}
}

@article{cho16pop,
  title = {Population {{Pharmacokinetics}} of {{Fentanyl}} in the {{Critically Ill}}*},
  author = {Choi, Leena and Ferrell, Benjamin A. and Vasilevskis, Eduard E. and Pandharipande, Pratik P. and Heltsley, Rebecca and Ely, E. Wesley and Stein, C. Michael and Girard, Timothy D.},
  date = {2016-01},
  journaltitle = {Crit Care Med},
  volume = {44},
  number = {1},
  pages = {64--72},
  issn = {0090-3493},
  doi = {10.1097/ccm.0000000000001347},
  url = {http://dx.doi.org/10.1097/ccm.0000000000001347},
  citeulike-article-id = {14033216},
  citeulike-linkout-0 = {http://dx.doi.org/10.1097/ccm.0000000000001347},
  posted-at = {2016-05-11 12:52:15},
  priority = {2},
  keywords = {ctsafac}
}

@article{cho17eff,
  title = {Effect of Patients' Functional Status on Satisfaction with Outcomes 12 Months after Elective Spine Surgery for Lumbar Degenerative Disease},
  author = {Chotai, Silky and Devin, Clinton J. and Archer, Kristin R. and Bydon, Mohamad and McGirt, Matthew J. and Nian, Hui and Harrell, Frank E. and Dittus, Robert S. and Asher, Anthony L. and {QOD Vanguard Sites}},
  date = {2017-12},
  journaltitle = {Spine J},
  volume = {17},
  number = {12},
  eprint = {28970074},
  eprinttype = {pmid},
  pages = {1783--1793},
  issn = {1878-1632},
  doi = {10.1016/j.spinee.2017.05.027},
  abstract = {BACKGROUND: Comprehensive assessment of quality of care includes patient-reported outcomes, safety of care delivered, and patient satisfaction. The impact of the patient-reported Oswestry Disability Index (ODI) scores at baseline and 12 months on satisfaction with outcomes following spine surgery is not well documented. PURPOSE: This study aimed to determine the impact of patient disability (ODI) scores at baseline and 12 months on satisfaction with outcomes following surgery. STUDY DESIGN: Analysis of prospectively collected longitudinal web-based multicenter data. PATIENT SAMPLE: Patients undergoing elective surgery for degenerative lumbar disease were entered into a prospective multicenter registry. OUTCOME MEASURES: Primary outcome measures were ODI, North American Spine Society satisfaction (NASS) questionnaire. METHODS: Baseline and 12-month ODI scores were recorded. Satisfaction at 12 months after surgery was measured using NASS questionnaire. Multivariable proportional odds logistic regression analysis was conducted to determine the impact of baseline and 12-month ODI on satisfaction with outcomes. RESULTS: Of the total 5,443 patients, 64\% (n=3,460) were satisfied at a level where surgery met their expectations (NASS level 1) at 12 months after surgery. After adjusting for all baseline and surgery-specific variables, the 12-month ODI score had the highest impact (Wald χ2=1,555, 86\% of the total χ2) on achieving satisfaction with outcomes compared with baseline ODI scores (Wald χ2=93, 5\% of the total χ2). The level of satisfaction decreases with increasing 12-month ODI score. Greater change in ODI is required to achieve a better satisfaction level when the patient starts with a higher baseline ODI score. CONCLUSION: Absolute 12-month ODI following surgery had a significant association on satisfaction with outcomes 12 months after surgery. Patients with higher baseline ODI required a larger change in ODI score to achieve satisfaction. No single measure can be used as a sole yardstick to measure quality of care after spine surgery. Satisfaction may be used in conjunction with baseline and 12-month ODI scores to provide an assessment of the quality of spine surgery provided in a patient centric fashion.},
  langid = {english},
  keywords = {collaboration}
}

@article{cho19uti,
  title = {Utility of {{Anxiety}}/{{Depression Domain}} of {{EQ-5D}} to {{Define Psychological Distress}} in {{Spine Surgery}}},
  author = {Chotai, Silky and Khan, Inamullah and Nian, Hui and Archer, Kristin R. and Harrell, Frank E. and Weisenthal, Benjamin M. and Bydon, Mohamad and Asher, Anthony L. and Devin, Clinton J.},
  date = {2019-06},
  journaltitle = {World Neurosurg},
  volume = {126},
  eprint = {30880196},
  eprinttype = {pmid},
  pages = {e1075-e1080},
  issn = {1878-8769},
  doi = {10.1016/j.wneu.2019.02.211},
  abstract = {BACKGROUND: Prospective patient-reported outcomes (PROs) registries are central to emerging evidence-driven reform models. These registries entail significant operator and responder burden to capture PROs data. It is important to limit the number of PROs administered. We sought to determine whether the anxiety/depression domain of EQ-5D could be used to define preoperative psychological distress in patients undergoing elective spine surgery. METHODS: Patients undergoing elective spine surgery and enrolled into a prospective registry were analyzed. The 12-Item Short-Form Health Survey Mental Component Summary, Zung depression scale, Modified Somatic Perception Questionnaire, and EQ-5D were completed. The anxiety/depression domain of EQ-5D was used to define psychological distress; responses were captured as 1) not anxious or depressed, 2) moderately anxious or depressed, or 3) extremely anxious or depressed. Univariate correlation and proportional odds logistic regression analyses were conducted. RESULTS: Of 2470 included patients undergoing elective spine surgery, 45\% (n~= 1109) reported no psychological distress, 47\% (n~= 1168) reported moderate psychological distress, and 8\% (n~= 193) reported extreme psychological distress on EQ-5D. Psychological distress on EQ-5D had positive correlation with Zung depression scale (P {$<$} 0.0001, r~= 0.620) and Modified Somatic Perception Questionnaire (P {$<$} 0.0001, r~= 0.450) and negative correlation with 12-Item Short-Form Health Survey Mental Component Summary (P {$<$} 0.0001, r~=~-0.662). In proportional odds logistic regression models, EQ-5D psychological distress had significant correlations with 12-Item Short-Form Health Survey Mental Component Summary (P {$<$} 0.0001, C-index~= 0.831), Zung depression scale (P {$<$} 0.0001, C-index~= 0.802), and Modified Somatic Perception Questionnaire (P {$<$} 0.0001, C-index~= 0.711). CONCLUSIONS: The anxiety/depression domain of EQ-5D could be used to categorize preoperative psychological distress. Spine registries could use this information to potentially limit the number of validated PROs administered.},
  langid = {english},
  keywords = {collaboration}
}

@article{cho95eff,
  title = {Effect of Non-Random Missing Data Mechanisms in Clinical Trials},
  author = {Choi, S. C. and Lu, I. L.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2675--2684},
  citeulike-article-id = {13263883},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {missing-data,modeling-missing-value-process}
}

@article{chr05tes,
  title = {Testing {{Fisher}}, {{Neyman}}, {{Pearson}}, and {{Bayes}}},
  author = {Christensen, Ronald},
  date = {2005},
  journaltitle = {Am Statistician},
  volume = {59},
  pages = {121--126},
  citeulike-article-id = {13265411},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  note = {"The p value gives an excellent measure of the extent to which the data do not contradict the model.";"The Bayesian analysis gives no special role to the null hypothesis.";in the normal one-sample case, testing H\_0:μ=0 and rejecting H\_0 "could mean that μ 0, or it could mean that the data are not independent, or it could mean that the data are not normal, or it could mean that the variances of the observations are not equal. In other words, rejecting a Fisherian test suggests that something is wrong with the model. It does not specify what is wrong.";"my own classroom presentations have largely abandoned NP ideas when teaching regression, ..., or almost any applied course ... If I could get away with it, I would teach introductory statistics from a Bayesian point of view. The idea of teaching Bayesian statistics to introductory students ... I firmly believe that Bayesian ideas are easier for students to understand than tests and confidence intervals based on the idea of proof by contradiction, which in turn is easier to understand than NP ideas."}
}

@article{chr19sys,
  title = {A Systematic Review Shows No Performance Benefit of Machine Learning over Logistic Regression for Clinical Prediction Models},
  author = {Christodoulou, Evangelia and Ma, Jie and Collins, Gary S. and Steyerberg, Ewout W. and Verbakel, Jan Y. and van Calster, Ben},
  date = {2019-02-11},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  eprint = {30763612},
  eprinttype = {pmid},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2019.02.004},
  url = {https://www.jclinepi.com/article/S0895-4356(18)31081-3/abstract},
  urldate = {2019-02-15},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To compare performance of logistic regression (LR) with machine learning (ML) for clinical prediction modeling. Study design and setting: We conducted a Medline literature search (1/2016 to 8/2017), and extracted comparisons between LR and ML models for binary outcomes. Results: We included 71 out of 927 studies. The median sample size was 1250 (range 72-3,994,872), with 19 predictors considered (range 5-563) and 8 events per predictor (range 0.3-6,697). The most common ML methods were classification trees (30 studies), random forests (28), artificial neural networks (26), and support vector machines (24). Sixty-four (90\%) studies used the area under the receiver operating characteristic curve (AUC) to assess discrimination. Calibration was not addressed in 56 (79\%) studies. We identified 282 comparisons between a LR and ML model (AUC range, 0.52-0.99). For 145 comparisons at low risk of bias, the difference in logit(AUC) between LR and ML was 0.00 (95\% confidence interval, -0.18 to 0.18). For 137 comparisons at high risk of bias, logit(AUC) was 0.34 (0.20 to 0.47) higher for ML. Conclusions: We found no evidence of superior performance of ML over LR for clinical prediction modeling, but improvements in methodology and reporting are needed for studies that compare modeling algorithms.{$<$}/p{$>$}},
  langid = {english},
  keywords = {machine-learning,review}
}

@article{chr21ada,
  title = {Adaptive Sample Size Determination for the Development of Clinical Prediction Models},
  author = {Christodoulou, Evangelia and van Smeden, Maarten and Edlinger, Michael and Timmerman, Dirk and Wanitschek, Maria and Steyerberg, Ewout W. and Van Calster, Ben},
  options = {useprefix=true},
  date = {2021-03-22},
  journaltitle = {Diagnostic and Prognostic Research},
  volume = {5},
  number = {1},
  pages = {6},
  issn = {2397-7523},
  doi = {10.1186/s41512-021-00096-5},
  url = {https://doi.org/10.1186/s41512-021-00096-5},
  urldate = {2021-03-29},
  abstract = {We suggest an adaptive sample size calculation method for developing clinical prediction models, in which model performance is monitored sequentially as new data comes in.},
  keywords = {adaptive,clinical-prediction,rms,sample-size}
}

@article{chr21whe,
  title = {When {{Your Permutation Test}} Is {{Doomed}} to {{Fail}}},
  author = {Christensen, William F. and Zabriskie, Brinley N.},
  date = {2021-03-15},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--11},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2021.1902856},
  url = {https://doi.org/10.1080/00031305.2021.1902856},
  urldate = {2021-04-23},
  abstract = {A two-tailed test comparing the means of two independent populations is perhaps the most commonly used hypothesis test in quantitative research, featured centrally in medical research, A/B testing, and throughout the sciences. When data are skewed, the standard two-tailed t test is not appropriate and the permutation test comparing the two means (or medians) has been a widely recommended alternative, with statistical authors and statistical software packages touting the permutation test’s utility, particularly for small samples. In this presentation, we illustrate that when the two samples are skewed and the sample sizes are unequal, the two-tailed permutation test (as traditionally implemented) can in some cases have power equal to zero, even when the k highest values in the combined data are all found in the group with k observations. Further, in many cases the standard permutation test exhibits decreasing power as the total sample size increases! We illustrate the causes of these perverse properties via both simulation and real-world examples, and we recommend approaches for ameliorating or avoiding these potential problems.},
  keywords = {nonparametric,permutation-test,skewness},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2021.1902856}
}

@article{chu01rec,
  title = {Recent Advancements in the Analysis and Presentation of Safety Data},
  author = {Chuang-Stein, Christy and Le, Vu},
  date = {2001},
  journaltitle = {Drug Info J},
  volume = {35},
  pages = {377--397},
  citeulike-article-id = {13265198},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {analysis-of-drug-safety-data,clinical-safety-parameters,graphical-methods,pharmaceutical}
}

@article{chu87pro,
  title = {Prognostic Effect of Bundle Branch Block Related to Coronary Artery Bypass Grafting},
  author = {Chu, A. and Califf, R. M. and Pryor, D. B. and McKinnis, R. A. and Harrell, F. E. and Lee, K. L. and Curtis, S. E. and Oldham, H. N. and Wagner, G. S.},
  date = {1987},
  journaltitle = {Am J Card},
  volume = {59},
  pages = {798--803},
  citeulike-article-id = {13263884},
  posted-at = {2014-07-14 14:09:25},
  priority = {0}
}

@article{chu92org,
  title = {Organization and Analysis of Safety Data Using a Multivariate Approach},
  author = {Chuang-Stein, C. and Mohberg, N. R. and Musselman, D. M.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1075--1089},
  citeulike-article-id = {13263885},
  posted-at = {2014-07-14 14:09:25},
  priority = {0}
}

@article{chu98lab,
  title = {Laboratory Data in Clinical Trials: {{A}} Statistician's Perspective},
  author = {Chuang-Stein, Christy},
  date = {1998},
  journaltitle = {Controlled Clin Trials},
  volume = {19},
  pages = {167--177},
  citeulike-article-id = {13263886},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {clinical-chemistry,laboratory-data,reference-values,regression-to-the-mean,safety-profile,toxicity}
}

@article{chu98res,
  title = {Resampling Methods for Confidence Intervals in Group Sequential Trials},
  author = {Chuang, Chin-Shan and Lai, Tze L.},
  date = {1998},
  journaltitle = {Biometrika},
  volume = {85},
  pages = {317--332},
  citeulike-article-id = {13263887},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {bootstrap,group-sequential-test}
}

@article{chu98sur,
  title = {Surrogate Endpoints in {{AIDS}} Drug Development: {{Current}} Status (with Discussion by {{Ellenberg}} and {{Gould}})},
  author = {Chuang-Stein, Christy and DeMasi, Ralph},
  date = {1998},
  journaltitle = {Drug Info J},
  volume = {32},
  pages = {439--448},
  citeulike-article-id = {13263888},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {study-design,surrogate-endpoints}
}

@article{cia86str,
  title = {Stratification by Stepwise Regression, Correspondence Analysis and Recursive Partition},
  author = {Ciampi, A. and Thiffault, J. and Nakache, J. P. and Asselain, B.},
  date = {1986},
  journaltitle = {Comp Stat Data Analysis},
  volume = {1986},
  pages = {185--204},
  citeulike-article-id = {13263889},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {cart,correspondence-analysis,multivariate,survival-analysis}
}

@article{cia90,
  title = {Cluster Analysis of an Insulin-Dependent Diabetic Cohort towards the Definition of Clinical Subtypes},
  author = {Ciampi, A. and Schiffrin, A. and Thiffault, J. and {Em Et Al}},
  date = {1990},
  journaltitle = {J Clin Epi},
  volume = {43},
  pages = {701--715},
  citeulike-article-id = {13263890},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {categorical-data,general,predictive-methods}
}

@article{cia95tre,
  title = {Tree-Structured Prediction for Censored Survival Data and the {{Cox}} Model},
  author = {Ciampi, Antonio and Negassa, Abdissa and Lou, Zihyi},
  date = {1995},
  journaltitle = {J Clin Epi},
  volume = {48},
  pages = {675--689},
  citeulike-article-id = {13263891},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {cart,recursive-partitioning,regression-trees,survival-analysis}
}

@article{cib10som,
  title = {Some Factors Predict Successful Short-Term Outcomes in Individuals with Shoulder Pain Receiving Cervicothoracic Manipulation: A Single-Arm Trial.},
  author = {Cibulka, M. T. and Harrell, F. E.},
  date = {2010},
  journaltitle = {Phys Ther},
  volume = {90},
  pages = {26--42},
  doi = {10.2522.ptj.2010.90.4.643},
  url = {http://dx.doi.org/10.2522.ptj.2010.90.4.643},
  citeulike-article-id = {13265800},
  citeulike-linkout-0 = {http://dx.doi.org/10.2522.ptj.2010.90.4.643},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {bad,ltte,multivariable-modeling},
  annotation = {Letter to the editor}
}

@article{cin20mak,
  title = {Making Sense of Sensitivity: Extending Omitted Variable Bias},
  shorttitle = {Making Sense of Sensitivity},
  author = {Cinelli, Carlos and Hazlett, Chad},
  date = {2020},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {n/a},
  number = {n/a},
  issn = {1467-9868},
  doi = {10.1111/rssb.12348},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12348},
  urldate = {2019-12-18},
  abstract = {We extend the omitted variable bias framework with a suite of tools for sensitivity analysis in regression models that does not require assumptions on the functional form of the treatment assignment mechanism nor on the distribution of the unobserved confounders, naturally handles multiple confounders, possibly acting non-linearly, exploits expert knowledge to bound sensitivity parameters and can be easily computed by using only standard regression results. In particular, we introduce two novel sensitivity measures suited for routine reporting. The robustness value describes the minimum strength of association that unobserved confounding would need to have, both with the treatment and with the outcome, to change the research conclusions. The partial R2 of the treatment with the outcome shows how strongly confounders explaining all the residual outcome variation would have to be associated with the treatment to eliminate the estimated effect. Next, we offer graphical tools for elaborating on problematic confounders, examining the sensitivity of point estimates and t-values, as well as ‘extreme scenarios’. Finally, we describe problems with a common ‘benchmarking’ practice and introduce a novel procedure to bound the strength of confounders formally on the basis of a comparison with observed covariates. We apply these methods to a running example that estimates the effect of exposure to violence on attitudes toward peace.},
  langid = {english},
  keywords = {confounding,sensitivity-analysis}
}

@article{cio21gui,
  title = {Guidance for Biostatisticians on Their Essential Contributions to Clinical and Translational Research Protocol Review},
  author = {Ciolino, Jody D. and Spino, Cathie and Ambrosius, Walter T. and Khalatbari, Shokoufeh and Cayetano, Shari Messinger and Lapidus, Jodi A. and Nietert, Paul J. and Oster, Robert A. and Perkins, Susan M. and Pollock, Brad H. and Pomann, Gina-Maria and Price, Lori Lyn and Rice, Todd W. and Tosteson, Tor D. and Lindsell, Christopher J. and Spratt, Heidi},
  year = {2021/ed},
  journaltitle = {Journal of Clinical and Translational Science},
  volume = {5},
  number = {1},
  publisher = {{Cambridge University Press}},
  issn = {2059-8661},
  doi = {10.1017/cts.2021.814},
  url = {https://www.cambridge.org/core/journals/journal-of-clinical-and-translational-science/article/guidance-for-biostatisticians-on-their-essential-contributions-to-clinical-and-translational-research-protocol-review/49B4D365DC2676532BDBDD922298D273#},
  urldate = {2021-10-28},
  abstract = {Rigorous scientific review of research protocols is critical to making funding decisions, and to the protection of both human and non-human research participants. Given the increasing complexity of research designs and data analysis methods, quantitative experts, such as biostatisticians, play an essential role in evaluating the rigor and reproducibility of proposed methods. However, there is a common misconception that a statistician’s input is relevant only to sample size/power and statistical analysis sections of a protocol. The comprehensive nature of a biostatistical review coupled with limited guidance on key components of protocol review motived this work. Members of the Biostatistics, Epidemiology, and Research Design Special Interest Group of the Association for Clinical and Translational Science used a consensus approach to identify the elements of research protocols that a biostatistician should consider in a review, and provide specific guidance on how each element should be reviewed. We present the resulting review framework as an educational tool and guideline for biostatisticians navigating review boards and panels. We briefly describe the approach to developing the framework, and we provide a comprehensive checklist and guidance on review of each protocol element. We posit that the biostatistical reviewer, through their breadth of engagement across multiple disciplines and experience with a range of research designs, can and should contribute significantly beyond review of the statistical analysis plan and sample size justification. Through careful scientific review, we hope to prevent excess resource expenditure and risk to humans and animals on poorly planned studies.},
  langid = {english},
  keywords = {general,protocols,review,review-checklist,study-design,teaching-mds}
}

@article{cla00dyi,
  title = {Dying with Lung Cancer or Chronic Obstructive Pulmonary Disease: {{Insights}} from {{SUPPORT}}},
  author = {Claessens, Michael T. and Lynn, Joanne and Zhong, Zhenshao and Desbiens, Norman A. and Phillips, Russell S. and Wu, Albert W. and Harrell, Frank E. and Connors, Alfred F.},
  date = {2000},
  journaltitle = {J Am Geriatric Soc},
  volume = {48},
  pages = {S146-S153},
  citeulike-article-id = {13265130},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{cla03dev,
  title = {Developing a Prognostic Model in the Presence of Missing Data: An Ovarian Cancer Case Study},
  author = {Clark, Taane G. and Altman, Douglas G.},
  date = {2003},
  journaltitle = {J Clin Epi},
  volume = {56},
  pages = {28--37},
  citeulike-article-id = {13265314},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {design,hmisc,mice,missing-data,multiple-imputation,r},
  note = {reasons for using multiple imputation over likelihood methods; nice background on missing data and multiple imputation}
}

@article{cla08war,
  title = {War, Enmity, and Statistical Tables},
  author = {Clauser, Brian E.},
  date = {2008},
  journaltitle = {Chance},
  volume = {21},
  number = {4},
  pages = {6--11},
  citeulike-article-id = {13265721},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  note = {Karl Pearson produced the Biometrika tables in a format that allowed one to look up the P-value given the t value. In the post World War I British economy, Biometrika was in some financial trouble and they resorted to copyright protection of parts of their publications such as tables. To get around copyright protection, Ronald Fisher restructered the tables to present critical values for t for α=.01, .02, .05, .1, .2, .3, ... .9. This has led to the use of cutoffs for P-values to determine what Fisher called ``significance'', which has led to widespread problems in science and especially to publication bias. See the article by Stigler that follows this article, and its reference to the 1919 paper by Boring.}
}

@article{cla18qua,
  title = {Quantifying the Totality of Treatment Effect with Multiple Event-Time Observations in the Presence of a Terminal Event from a Comparative Clinical Study},
  author = {Claggett, Brian and Tian, Lu and Fu, Haoda and Solomon, Scott D. and Wei, Lee-Jen},
  date = {2018},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.7907},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7907},
  urldate = {2018-08-09},
  abstract = {To evaluate the totality of one treatment's benefit/risk profile relative to an alternative treatment via a longitudinal comparative clinical study, the timing and occurrence of multiple clinical events are typically collected during the patient's follow-up. These multiple observations reflect the patient's disease progression/burden over time. The standard practice is to create a composite endpoint from the multiple outcomes, the timing of the occurrence of the first clinical event, to evaluate the treatment via the standard survival analysis techniques. By ignoring all events after the composite outcome, this type of assessment may not be ideal. Various parametric or semiparametric procedures have been extensively discussed in the literature for the purposes of analyzing multiple event-time data. Many existing methods were developed based on extensive model assumptions. When the model assumptions are not plausible, the resulting inferences for the treatment effect may be misleading. In this article, we propose a simple, nonparametric inference procedure to quantify the treatment effect, which has an intuitive clinically meaningful interpretation. We use the data from a cardiovascular clinical trial for heart failure to illustrate the procedure. A simulation study is also conducted to evaluate the performance of the new proposal.},
  langid = {english},
  keywords = {multiple-endpoints,rct}
}

@article{cla22est,
  title = {Estimands: Bringing Clarity and Focus to Research Questions in Clinical Trials},
  shorttitle = {Estimands},
  author = {Clark, Timothy Peter and Kahan, Brennan C. and Phillips, Alan and White, Ian and Carpenter, James R.},
  date = {2022-01-01},
  journaltitle = {BMJ Open},
  volume = {12},
  number = {1},
  eprint = {34980616},
  eprinttype = {pmid},
  pages = {e052953},
  issn = {2044-6055, 2044-6055},
  doi = {10.1136/bmjopen-2021-052953},
  url = {https://bmjopen.bmj.com/content/12/1/e052953},
  urldate = {2022-01-15},
  abstract = {Precise specification of the research question and associated treatment effect of interest is essential in clinical research, yet recent work shows that they are often incompletely specified. The ICH E9 (R1) Addendum on Estimands and Sensitivity Analysis in Clinical Trials introduces a framework that supports researchers in precisely and transparently specifying the treatment effect they aim to estimate in their clinical trial. In this paper, we present practical examples to demonstrate to all researchers involved in clinical trials how estimands can help them to specify the research question, lead to a better understanding of the treatment effect to be estimated and hence increase the probability of success of the trial.},
  langid = {english},
  keywords = {estimand,intercurrent-event,outcomes,rct}
}

@article{cla22why,
  title = {Why Are Not {{There More Bayesian Clinical Trials}}? {{Perceived Barriers}} and {{Educational Preferences Among Medical Researchers Involved}} in {{Drug Development}}},
  shorttitle = {Why Are Not {{There More Bayesian Clinical Trials}}?},
  author = {Clark, Jennifer and Muhlemann, Natalia and Natanegara, Fanni and Hartley, Andrew and Wenkert, Deborah and Wang, Fei and Harrell, Frank E. and Bray, Ross and {The Medical Outreach Subteam of the Drug Information Association Bayesian Scientific Working Group}},
  date = {2022-01-03},
  journaltitle = {Ther Innov Regul Sci},
  issn = {2168-4804},
  doi = {10.1007/s43441-021-00357-x},
  url = {https://doi.org/10.1007/s43441-021-00357-x},
  urldate = {2022-01-08},
  abstract = {The clinical trials community has been hesitant to adopt Bayesian statistical methods, which are often more flexible and efficient with more naturally interpretable results than frequentist methods. We aimed to identify self-reported barriers to implementing Bayesian methods and preferences for becoming comfortable with them.},
  langid = {english},
  keywords = {bayes,drug-development,teaching-mds}
}

@article{cla88,
  title = {The Analysis of Event History Data: {{A}} Review of Progress and Outstanding Problems},
  author = {{Clayton}},
  date = {1988},
  journaltitle = {Stat Med},
  volume = {7},
  pages = {819--841},
  citeulike-article-id = {13263892},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {general,medical,survival-analysis-regression}
}

@article{cla88rev,
  title = {Review of {{SURVCALC}}},
  author = {Clayton, D.},
  date = {1988},
  journaltitle = {Appl Stat},
  volume = {37},
  pages = {455--456},
  citeulike-article-id = {13263893},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {software-review}
}

@incollection{cla92tre,
  title = {Tree-{{Based Models}}},
  booktitle = {Statistical {{Models}} in {{S}}},
  author = {Clark, Linda A. and Pregibon, Daryl},
  editor = {Chambers, John M. and Hastie, Trevor J.},
  date = {1992},
  pages = {377--419},
  publisher = {{Wadsworth and Brooks/Cole}},
  location = {{Pacific Grove, CA}},
  chapter = {9},
  citeulike-article-id = {13263894},
  posted-at = {2014-07-14 14:09:25},
  priority = {0}
}

@article{cle14rac,
  title = {Racial {{Differences}} in {{Resistance}} to {{P2Y12 Receptor Antagonists}} in {{Type}} 2 {{Diabetic Subjects}}.},
  author = {Cleator, John H. and Duvernay, Matthew T. and Holinstat, Michael and Colowick, Nancy E. and Hudson, Willie J. and Song, Yanna and Harrell, Frank E. and Hamm, Heidi E.},
  date = {2014-10},
  journaltitle = {J Pharm Exp Ther},
  volume = {351},
  number = {1},
  eprint = {25052834},
  eprinttype = {pmid},
  pages = {33--43},
  issn = {1521-0103},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25052834},
  abstract = {Although resistance to the P2Y12 antagonist clopidogrel is linked to altered drug metabolism, some studies suggest that these pharmacokinetic abnormalities only partially account for drug resistance. To circumvent pharmacokinetic complications and target P2Y12 receptor function we applied the direct P2Y12 antagonist 2-methylthio-AMP (2-methylthioadenosine 5'-monophosphate triethylammonium salt) to purified platelets ex vivo. Platelets were purified from healthy and type 2 diabetes mellitus (T2DM) patients and stimulated with thrombin or the selective protease-activated receptor agonists, protease-activated receptor 1-activating peptide (PAR1-AP), or PAR4-AP. Platelet activation as measured by αIIbβ3 activation, and P-selectin expression was monitored in 141 subjects. Our results demonstrate that, compared with healthy subjects, platelets from diabetic patients are resistant to inhibition by 2-methylthio-AMP, demonstrating P2Y12 pharmacodynamic defects among diabetic patients. Inhibition of thrombin-mediated αIIbβ3 activation by 2-methylthio-AMP was lower in diabetic platelets versus healthy platelets. Subgroup analysis revealed a racial difference in the resistance to 2-methylthio-AMP. We found no resistance in platelets from diabetic African Americans; they were inhibited by 2-methylthio-AMP equally as well as platelets from healthy African Americans. In contrast, platelets from Caucasian patients with diabetes were resistant to P2Y12 antagonism compared with healthy Caucasians. Multivariable analysis demonstrated that other variables, such as obesity, age, or gender, could not account for the differential resistance to 2-methylthio-AMP among races. These results suggest that in addition to altered drug metabolism, P2Y12 receptor function itself is altered in the Caucasian diabetic population. The racial difference in platelet function in T2DM is a novel finding, which may lead to differences in treatment as well as new targets for antiplatelet therapy.},
  citeulike-article-id = {13342759},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25052834},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25052834},
  posted-at = {2014-09-01 14:01:18},
  priority = {0},
  keywords = {collaboration,ctsafac,cv}
}

@article{cle79,
  title = {Robust Locally Weighted Regression and Smoothing Scatterplots},
  author = {Cleveland, W. S.},
  date = {1979},
  journaltitle = {J Am Stat Assoc},
  volume = {74},
  pages = {829--836},
  citeulike-article-id = {13263895},
  posted-at = {2014-07-14 14:09:25},
  priority = {0}
}

@article{cle83col,
  title = {A Color-Caused Optical Illusion on a Statistical Graph},
  author = {Cleveland, William S. and McGill, Robert},
  date = {1983},
  journaltitle = {Am Statistician},
  volume = {37},
  pages = {101--105},
  citeulike-article-id = {13263896},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {graphics,optical-illusion}
}

@article{cle84gra,
  title = {Graphical Perception: {{Theory}}, Experimentation, and Application to the Development of Graphical Methods},
  author = {Cleveland, William S. and McGill, Robert},
  date = {1984},
  journaltitle = {J Am Stat Assoc},
  volume = {79},
  pages = {531--554},
  citeulike-article-id = {13263897},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {graphical-perception,graphics,optical-illusion,teaching-mds}
}

@article{cle84sci,
  title = {Graphs in Scientific Publications},
  author = {Cleveland, William S.},
  date = {1984},
  journaltitle = {Am Statistician},
  volume = {38},
  pages = {261--269},
  citeulike-article-id = {13263898},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {graphics,reporting,teaching-mds},
  annotation = {C/R 85v39 p238-9}
}

@article{cle93mod,
  title = {A Model for Studying Display Methods of Statistical Graphics ({{Disc}}: P345-364)},
  author = {Cleveland, William S.},
  date = {1993},
  journaltitle = {J Comp Graph Stat},
  volume = {2},
  pages = {323--343},
  citeulike-article-id = {13263899},
  posted-at = {2014-07-14 14:09:25},
  priority = {0}
}

@book{cle93vis,
  title = {Visualizing {{Data}}},
  author = {Cleveland, William S.},
  date = {1993},
  publisher = {{Hobart Press}},
  location = {{Summit, NJ}},
  citeulike-article-id = {13263900},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {graphics}
}

@book{cle94ele,
  title = {The {{Elements}} of {{Graphing Data}}},
  author = {Cleveland, William S.},
  date = {1994},
  publisher = {{Hobart Press}},
  location = {{Summit, NJ}},
  citeulike-article-id = {13263901},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {graphics,teaching-mds}
}

@article{cluster.rct,
  title = {Special Issue on Cluster Randomized Trials},
  author = {{Various}},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  number = {3},
  citeulike-article-id = {13265182},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {bayesian-model,cluster-randomized-trials,design,sample-size}
}

@article{cna89sur,
  title = {Survival Analysis in Natural History Studies of Disease},
  author = {Cnaan, Avital and Ryan, Louise},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {1255--1268},
  citeulike-article-id = {13263902},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {cox-ph-model,left-truncation,modified-kaplan-meier-estimator}
}

@article{cna97usi,
  title = {Tutorial in {{Biostatistics}}: {{Using}} the General Linear Mixed Model to Analyse Unbalanced Repeated Measures and Longitudinal Data},
  author = {Cnaan, Avital and Laird, Nan M. and Slasor, Peter},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2349--2380},
  citeulike-article-id = {13263903},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {longitudinal-data,mixed-models,serial-data,splines-for-time-trends,teaching}
}

@article{cof88,
  title = {A Random Effects Model for Binary Data from Dependent Samples},
  author = {Coffey, M.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {787--801},
  citeulike-article-id = {13263904},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{coh01per,
  title = {A Perspective from the Press: How to Help Reporters Tell the Truth},
  author = {Cohn, Victor},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1341--1346},
  citeulike-article-id = {13265193},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {clinical-trials,examples-of-misleading-headlines,hierarchy-of-studies,media,nice-overview-of-research,observational-studies,reporters,reporting,teaching-mds}
}

@article{coh94ear,
  title = {The Earth Is Round (p {$<$} .05)},
  author = {Cohen, Jacob},
  date = {1994},
  journaltitle = {Am Psychologist},
  volume = {49},
  number = {12},
  pages = {997--1003},
  issn = {1935-990X},
  doi = {10.1037/0003-066x.49.12.997},
  url = {http://dx.doi.org/10.1037/0003-066x.49.12.997},
  keywords = {misinterpretation-of-p-values,p-values}
}

@article{col00sho,
  title = {Short-Term Prognosis in Severe Adult and Adolescent Malnutrition during Famine},
  author = {Collins, Steve and Myatt, Mark},
  date = {2000},
  journaltitle = {J Am Stat Assoc},
  volume = {284},
  pages = {621--626},
  citeulike-article-id = {13265141},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {algebra,bad-statistics},
  note = {example of bad statistics;adding ORs;suspect validation;lack of probability estimates from model or calibration validation;teaching biostatistical modeling how not to}
}

@article{col00sym,
  title = {Sympercents: Symmetric Percentage Differences on the 100 Log e Scale Simplify the Presentation of Log Transformed Data},
  author = {Cole, T. J.},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {3109--3125},
  citeulike-article-id = {13265161},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {change,measuring-change,quantifying-change,teaching-mds}
}

@article{col12ris,
  title = {Risk Stratification in Acute Heart Failure: {{Rationale}} and Design of the {{STRATIFY}} and {{DECIDE}} Studies},
  author = {Collins, S. P. and Lindsell, C. J. and Jenkins, C. A. and Fe, Harrell and Fermann, G. J. and Miller, K. F. and Roll, S. N. and Sperling, M. I. and Maron, D. J. and Naftilan, A. J. and McPherson, J. A. and Weintraub, N. L. and Sawyer, D. B. and Storrow, A. B.},
  date = {2012-12},
  journaltitle = {Am Heart J},
  volume = {164},
  number = {6},
  pages = {825--834},
  citeulike-article-id = {13265950},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{col14inv,
  title = {An Investigation of the False Discovery Rate and the Misinterpretation of P-Values},
  author = {Colquhoun, David},
  date = {2014-11},
  journaltitle = {Roy Soc Open Sci},
  volume = {1},
  number = {3},
  eprint = {1407.5296},
  eprinttype = {arxiv},
  pages = {140216},
  publisher = {The Royal Society},
  issn = {2054-5703},
  doi = {10.1098/rsos.140216},
  url = {http://dx.doi.org/10.1098/rsos.140216},
  abstract = {The following proposition is justified from several different points of view. If you use P = 0.05 to suggest that you have made a discovery, you will be wrong at least 30 percent of the time. If, as is often the case, experiments are under-powered, you will be wrong most of the time. It is concluded that if you wish to keep your false discovery rate below 5 percent, you need to use a 3-sigma rule, or to insist on P value below 0.001. And never use the word "significant".},
  archiveprefix = {arXiv},
  citeulike-article-id = {13434913},
  citeulike-attachment-1 = {col14inv.pdf; /pdf/user/harrelfe/article/13434913/1098732/col14inv.pdf; 497ff4f4fe19bb3f7c7bf2174c76280a3b97c65c},
  citeulike-linkout-0 = {http://arxiv.org/abs/1407.5296},
  citeulike-linkout-1 = {http://arxiv.org/pdf/1407.5296},
  citeulike-linkout-2 = {http://dx.doi.org/10.1098/rsos.140216},
  citeulike-linkout-3 = {http://rsos.royalsocietypublishing.org/content/1/3/140216.abstract},
  citeulike-linkout-4 = {http://rsos.royalsocietypublishing.org/content/1/3/140216.full.pdf},
  day = {01},
  posted-at = {2017-01-21 11:59:15},
  priority = {4},
  keywords = {fdr,misinterpretation-of-p-values,p-values,teaching-mds,teaching-statisticians}
}

@article{col15ide,
  title = {Identification of {{Emergency Department Patients With Acute Heart Failure}} at {{Low~Risk}} for 30-{{Day Adverse Events}}},
  author = {Collins, Sean P. and Jenkins, Cathy A. and Harrell, Frank E. and Liu, Dandan and Miller, Karen F. and Lindsell, Christopher J. and Naftilan, Allen J. and McPherson, John A. and Maron, David J. and Sawyer, Douglas B. and Weintraub, Neal L. and Fermann, Gregory J. and Roll, Susan K. and Sperling, Matthew and Storrow, Alan B.},
  date = {2015-10},
  journaltitle = {JACC: Heart Failure},
  volume = {3},
  number = {10},
  pages = {737--747},
  issn = {22131779},
  doi = {10.1016/j.jchf.2015.05.007},
  url = {http://dx.doi.org/10.1016/j.jchf.2015.05.007},
  abstract = {No prospectively derived or validated decision tools identify emergency department (ED) patients with acute heart failure (AHF) at low risk for 30-day adverse events who are thus potential candidates for safe ED discharge. This study sought to accomplish that goal. The nearly 1 million annual ED visits for AHF are associated with high proportions of admissions and consume significant resources. We prospectively enrolled 1,033 patients diagnosed with AHF in the ED from 4 hospitals between July 20, 2007, and February 4, 2011. We used an ordinal outcome hierarchy, defined as the incidence of the most severe adverse event within 30 days of ED evaluation (acute coronary syndrome, coronary revascularization, emergent dialysis, intubation, mechanical cardiac support, cardiopulmonary resuscitation, and death). Of 1,033 patients enrolled, 126 (12\%) experienced at least one 30-day adverse event. The decision tool had a C statistic of 0.68 (95\% confidence interval: 0.63 to 0.74). Elevated troponin (p~{$<$} 0.001) and renal function (p~= 0.01) were significant predictors of adverse events in our multivariable model, whereas B-type natriuretic peptide (p~= 0.09), tachypnea (p~= 0.09), and patients undergoing dialysis (p~= 0.07) trended toward significance. At risk thresholds of 1\%, 3\%, and 5\%, we found 0\%, 1.4\%, and 13.0\% patients were at low risk, with negative predictive values of 100\%, 96\%, and 93\%, respectively. The STRATIFY decision tool identifies ED patients with AHF who are at low risk for 30-day adverse events and may be candidates for safe ED discharge. After external testing, and perhaps when used as part of a shared decision-making strategy, it may significantly affect disposition strategies. (Improving Heart Failure Risk Stratification in the ED [STRATIFY]; NCT00508638)},
  citeulike-article-id = {13798028},
  citeulike-attachment-1 = {col15ide.pdf; /pdf/user/harrelfe/article/13798028/1037968/col15ide.pdf; 3102d00fe39b2549c1d4d78a93931062608f5bab},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jchf.2015.05.007},
  posted-at = {2015-10-09 00:02:54},
  priority = {2},
  keywords = {clinical-prediction,ctsafac,emergency-medicine-research,risk-prediction}
}

@article{col16qua,
  title = {Quantifying the Impact of Different Approaches for Handling Continuous Predictors on the Performance of a Prognostic Model},
  author = {Collins, Gary S. and Ogundimu, Emmanuel O. and Cook, Jonathan A. and Manach, Yannick L. and Altman, Douglas G.},
  date = {2016-10},
  journaltitle = {Stat Med},
  volume = {35},
  number = {23},
  pages = {4124--4135},
  issn = {02776715},
  doi = {10.1002/sim.6986},
  url = {http://dx.doi.org/10.1002/sim.6986},
  citeulike-article-id = {14257702},
  citeulike-attachment-1 = {col16qua.pdf; /pdf/user/harrelfe/article/14257702/1098563/col16qua.pdf; 777d21c7dafcffd5012b9f8f9928c2aeac69dcbd},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6986},
  day = {15},
  posted-at = {2017-01-19 01:17:02},
  priority = {4},
  keywords = {categorization,categorizing-continuous-variables,cutpoints,dichotomization,teaching-mds},
  note = {used rms package hazard regression method (hare) for survival model calibration}
}

@article{col16sam,
  title = {Sample Size Considerations for the External Validation of a Multivariable Prognostic Model: A Resampling Study},
  author = {Collins, Gary S. and Ogundimu, Emmanuel O. and Altman, Douglas G.},
  date = {2016-01},
  journaltitle = {Stat Med},
  volume = {35},
  number = {2},
  pages = {214--226},
  issn = {02776715},
  doi = {10.1002/sim.6787},
  url = {http://dx.doi.org/10.1002/sim.6787},
  citeulike-article-id = {14218261},
  citeulike-attachment-1 = {col16sam.pdf; /pdf/user/harrelfe/article/14218261/1093470/col16sam.pdf; 188484a5c9fa6a264d74e9b4d49bb3f4bac54ffa},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6787},
  day = {30},
  posted-at = {2016-12-01 14:36:04},
  priority = {0},
  keywords = {external-validation,sample-size,validation}
}

@article{col18sta,
  title = {Statistical Methods to Compare Functional Outcomes in Randomized Controlled Trials with High Mortality},
  author = {Colantuoni, Elizabeth and Scharfstein, Daniel O. and Wang, Chenguang and Hashem, Mohamed D. and Leroux, Andrew and Needham, Dale M. and Girard, Timothy D.},
  date = {2018-01-03},
  journaltitle = {BMJ},
  volume = {360},
  eprint = {29298779},
  eprinttype = {pmid},
  pages = {j5748},
  issn = {0959-8138, 1756-1833},
  doi = {10.1136/bmj.j5748},
  url = {https://www.bmj.com/content/360/bmj.j5748},
  urldate = {2019-09-07},
  abstract = {{$<$}p{$>$}Mortality is a common primary endpoint in randomized controlled trials of patients with a high severity of illness, such as critically ill patients. However, researchers are increasingly evaluating functional outcomes, such as quality of life. Importantly, in such trials some patients may die before the assessment of a functional outcome, resulting in the functional outcome being “truncated due to death.” As described in this paper, defining and testing treatment effects on functional outcomes in this setting requires careful consideration. Data from a completed trial of critically ill patients are used to highlight key differences among three statistical approaches used when analyzing such trials.{$<$}/p{$>$}},
  langid = {english},
  keywords = {multiple-endpoints,ordinal,rct,win-ratio}
}

@article{col19rel,
  title = {Relating Weight Growth Trajectory to Height and Age},
  author = {Cole, T. J.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {15},
  pages = {2901--2902},
  issn = {1097-0258},
  doi = {10.1002/sim.8109},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8109},
  urldate = {2019-06-10},
  langid = {english},
  keywords = {allometric-extension,bmi,measurement}
}

@article{col88,
  title = {Estimating the Power of the Two-Sample {{Wilcoxon}} Test for Location Shift},
  author = {Collings BJ, Hamilton M. A.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {847--860},
  citeulike-article-id = {13263905},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {distribution-free-methods,sample-size-estimation}
}

@article{col91sco,
  title = {A Scoring System to Quantify Illness in Babies under 6 Months of Age},
  author = {Cole, T. J. and Morley, C. J. and Thornton, A. J. and Fowler, M. A. and Hewson, P. H.},
  date = {1991},
  journaltitle = {J Roy Stat Soc A},
  volume = {154},
  pages = {287--304},
  citeulike-article-id = {13263907},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {clinical-prediction,model-simplification,ordinal-logistic-model,rounding-coefficients,severity-of-illness}
}

@article{col93cox,
  title = {Cox Regression Models for Quality Adjusted Survival Analysis},
  author = {Cole, Bernard F. and Gelber, Richard D. and Goldhirsch, Aron},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {975--987},
  citeulike-article-id = {13263908},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {multiple-endpoints,qaly,qol,utilities}
}

@book{col94,
  title = {Modelling {{Survival Data}} in {{Medical Research}}},
  author = {Collett, D.},
  date = {1994},
  publisher = {{Chapman and Hall}},
  location = {{London}},
  citeulike-article-id = {13263909},
  posted-at = {2014-07-14 14:09:25},
  priority = {0}
}

@article{col94par,
  title = {Parametric Approaches to Quality-Adjusted Survival Analysis},
  author = {Cole, Bernard F. and Gelber, Richard D. and Anderson, Keaven M.},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  pages = {621--631},
  citeulike-article-id = {13263910},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {competing-risk,compound-endpoints,multiple-endpoints,quality-of-life}
}

@book{colBookbin,
  title = {Modelling {{Binary Data}}},
  author = {Collett, D.},
  date = {2002},
  edition = {Second},
  publisher = {{Chapman and Hall}},
  location = {{London}},
  citeulike-article-id = {13263906},
  isbn = {1-58488-324-3},
  posted-at = {2014-07-14 14:09:25},
  priority = {0}
}

@article{com94int,
  title = {The Intraclass Correlation Coefficient: Distribution-Free Definition and Test},
  author = {Commenges, Daniel and Jacqmin, Helene},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  pages = {517--526},
  citeulike-article-id = {13263911},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {binary-data,cluster-sampling,intraclass-correlation,sample-design}
}

@article{con05sem,
  title = {Semi-Parametric Modelling for Costs of Health Care Technologies},
  author = {Conigliani, C. and Tancredi, A.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {3171--3184},
  citeulike-article-id = {13265451},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {analysis-of-cost,cost-data,extreme-value-theory,flexible-bayesian-model,generalized-pareto-distribution,health-economics,mcmc}
}

@article{con09sta,
  title = {Statistical Graphics in {{AJG}}: {{Save}} the Ink for the Information},
  author = {Connor, Jason T.},
  date = {2009},
  journaltitle = {Am J Gastroent},
  volume = {104},
  pages = {1624--1630},
  citeulike-article-id = {13265835},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {statistical-graphics}
}

@article{con88,
  title = {Condition Logistic Regression Models for Correlated Binary Data},
  author = {Connolly MA, Liang K. Y.},
  date = {1988},
  journaltitle = {Biometrika},
  volume = {75},
  pages = {501--506},
  citeulike-article-id = {13263912},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{con93ris,
  title = {The Risk of Determining Risk with Multivariable Models},
  author = {Concato, J. and Feinstein, A. R. and Holford, T. R.},
  date = {1993},
  journaltitle = {Ann Int Med},
  volume = {118},
  pages = {201--210},
  citeulike-article-id = {13263913},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {multivariable-modeling,reporting,statistical-results,teaching-mds}
}

@article{con96eff,
  title = {The Effectiveness of Right Heart Catheterization in the Initial Care of Critically Ill Patients},
  author = {Connors, Alfred F. and Speroff, Theodore and Dawson, Neal V. and Thomas, Charles and Harrell, Frank E. and Wagner, Douglas and Desbiens, Norman and Goldman, Lee and Wu, Albert W. and Califf, Robert M. and Fulkerson, William J. and Vidaillet, Humberto and Broste, Steven and Bellamy, Paul and Lynn, Joanne and Knaus, William A. and Investigators, The SUPPORT},
  date = {1996},
  journaltitle = {JAMA},
  volume = {276},
  eprint = {8782638},
  eprinttype = {pubmed},
  pages = {889--897},
  citeulike-article-id = {13263914},
  citeulike-linkout-0 = {http://www.ncbi.nlm.nih.gov/pubmed/8782638},
  citeulike-linkout-1 = {http://dx.doi.org/},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {propensity-score}
}

@article{con97out,
  title = {Outcomes Following Acute Exacerbation of Severe Chronic Obstructive Lung Disease. {{The SUPPORT Investigators}}},
  author = {Connors, A. F. and Dawson, N. V. and Thomas, C. and Harrell, F. E. and Desbiens, N. and Fulkerson, W. J. and Kussin, P. and Bellamy, P. and Goldman, L. and Knaus, W. A.},
  date = {1996},
  journaltitle = {Am J Resp Crit Care Med},
  volume = {154},
  pages = {959--967},
  citeulike-article-id = {13263915},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  annotation = {See erratum 155:386, 1997}
}

@book{con99obj,
  title = {Object {{Oriented Perl}}},
  author = {Conway, Damian},
  date = {1999},
  publisher = {{Manning}},
  citeulike-article-id = {13265241},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {data-management,object-oriented-programming,perl}
}

@article{coo03met,
  title = {Methods for Mid-Course Corrections in Clinical Trials with Survival Outcomes},
  author = {Cook, Thomas D.},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {3431--3447},
  citeulike-article-id = {13265358},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {clinical-trials-with-complex-design-features,conditional-power,lakatos-method-for-power-computation,mid-course-correction,survival-analysis,time-dependent-treatment-effect},
  note = {software available from http://www.biostat.wisc.edu/̃cook/software.html}
}

@article{coo04mar,
  title = {Marginal Analysis of Incomplete Longitudinal Binary Data: {{A}} Cautionary Note on {{LOCF}} Imputation},
  author = {Cook, Richard J. and Zeng, Leilei and Yi, Grace Y.},
  date = {2004},
  journaltitle = {Biometrics},
  volume = {60},
  pages = {820--828},
  citeulike-article-id = {13265392},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {dropout,gee,imputation,longitudinal-data-analysis,missing-data,misspecified-data,serial-data},
  note = {LOCF leads to large biases in treatment effects, inflation of type I error, poor coverage probability; Analyses based on all available data can result in relatively small bias;"probability weighted analyses yield consistent estimators subject to correct specification of the missing data process"}
}

@article{coo07fis,
  title = {Fisher {{Lecture}}:{{Dimension}} Reduction in Regression},
  author = {Cook, R. Dennis},
  date = {2007},
  journaltitle = {Stat Sci},
  volume = {22},
  pages = {1--26},
  citeulike-article-id = {13265614},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {central-subspace,grassmann-manifolds,inverse-regression,minimum-average-variance-estimation,principal-components,principal-fitted-components,sliced-inverse-regression,sufficient-dimension-reduction}
}

@article{coo07use,
  title = {Use and Misues of the Receiver Operating Characteristic Curve in Risk Prediction},
  author = {Cook, Nancy R.},
  date = {2007},
  journaltitle = {Circ},
  volume = {115},
  pages = {928--935},
  citeulike-article-id = {13265591},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {c-index,reclassification-table,roc-area},
  note = {example of large change in predicted risk in cardiovascular disease with tiny change in ROC area;possible limits to c index when calibration is perfect;importance of calibration accuracy and changes in predicted risk when new variables are added}
}

@article{coo08pri,
  title = {Principal Fitted Components for Dimension Reduction in Regression},
  author = {Cook, R. Dennis and Forzani, Liliana},
  date = {2008},
  journaltitle = {Stat Sci},
  volume = {23},
  number = {4},
  pages = {485--501},
  citeulike-article-id = {13265808},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {central-subspace,data-reduction,dimension-reduction,incomplete-principal-components-regression,principal-components,sliced-inverse-regression}
}

@article{coo10ass,
  title = {Assessing the Predictive Performance: {{Beyond}} the {{Framingham}} Risk Score},
  author = {Cook, Nancy and Moons, Karel G. M. and Harrell, Frank E.},
  date = {2010},
  journaltitle = {JAMA},
  volume = {303},
  number = {14},
  pages = {1368--1369},
  citeulike-article-id = {13265804},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  annotation = {letter to the editor}
}

@article{coo18qua,
  title = {Quantifying the Added Value of New Biomarkers: How and How Not},
  shorttitle = {Quantifying the Added Value of New Biomarkers},
  author = {Cook, Nancy R.},
  date = {2018-07-11},
  journaltitle = {Diagnostic and Prognostic Research},
  volume = {2},
  number = {1},
  pages = {14},
  issn = {2397-7523},
  doi = {10.1186/s41512-018-0037-2},
  url = {https://doi.org/10.1186/s41512-018-0037-2},
  urldate = {2018-08-29},
  abstract = {Over the past few decades, interest in biomarkers to enhance predictive modeling has soared. Methodology for evaluating these has also been an active area of research. There are now several performance measures available for quantifying the added value of biomarkers. This commentary provides an overview of methods currently used to evaluate new biomarkers, describes their strengths and limitations, and offers some suggestions on their use.},
  keywords = {accuracy,biomarker,roc,validation}
}

@article{coo88asy,
  title = {Asymmetric Stratification: {{An}} Outline for an Efficient Method for Controlling Confounding in Cohort Studies},
  author = {Cook, E. Francis and Goldman, Lee},
  date = {1988},
  journaltitle = {Am J Epi},
  volume = {127},
  pages = {626--639},
  citeulike-article-id = {13263916},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {cart,confounding,non-randomized-data,propensity-score,recursive-partitioning}
}

@article{coo90con,
  title = {Confidence Curves in Nonlinear Regression},
  author = {Cook RD, Weisberg S.},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {544--551},
  citeulike-article-id = {13263917},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {general,maximum-likelihood,regression}
}

@article{coo90dia,
  title = {Diagnostics for Assessing the Accurace of Normal Approximations in Exponential Family Nonlinear Models},
  author = {Cook RD, Tsai C. L.},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {770--777},
  citeulike-article-id = {13263918},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {maximum-likelihood}
}

@article{coo94int,
  title = {On the Interpretation of Regression Plots},
  author = {Cook, R. Dennis},
  date = {1994},
  journaltitle = {J Am Stat Assoc},
  volume = {89},
  pages = {177--189},
  citeulike-article-id = {13263919},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {graphical-methods,lack-of-fit,linear-regression,residuals}
}

@article{coo95des,
  title = {The Design and Analysis of Randomized Trials with Recurrent Events},
  author = {Cook, Richard J.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2081--2098},
  citeulike-article-id = {13263920},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {multiple-events,recurrent-events,repeated-events,study-design}
}

@article{coo96mul,
  title = {Multiplicity Considerations in the Design and Analysis of Clinical Trials},
  author = {Cook, Richard J. and Farewell, Vern T.},
  date = {1996},
  journaltitle = {J Roy Stat Soc A},
  volume = {159},
  pages = {93--110},
  citeulike-article-id = {13263921},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {multiple-endpoints,multiple-treatments,multiplicity,p-value-adjustment,type-i-error},
  note = {argues that if results are intended to be interpreted marginally, there may be no need for controlling experimentwise error rate.~ FH phrasing: Cook and Farewell point out that when a strong priority order is pre-specified for separate clinical questions, and that same order is also the reporting order (no cherry picking), there is no need for multiplicity adjustment.~ This is in contrast with a study whose aim is to find an endpoint or find a patient subgroup that is benefited by treatment, a situation requiring conservative multiplicity adjustment.}
}

@article{coo96rob,
  title = {Robust Tests for Treatment Comparisons Based on Recurrent Event Responses},
  author = {Cook, Richard J. and Lawless, Jerald F. and Nadeau, Claude},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {557--571},
  citeulike-article-id = {13263922},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {nonparametric,recurrent-events,repeated-events}
}

@article{coo97mar,
  title = {Marginal Analysis of Recurrent Events and a Terminating Event},
  author = {Cook, Richard J. and Lawless, Jerald F.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {911--924},
  citeulike-article-id = {13263923},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {multiple-events,recurrent-events,terminating-event},
  note = {promise for analyzing censored cost data}
}

@article{cop21opt,
  title = {Optimal Design of Cluster Randomized Trials Allowing Unequal Allocation of Clusters and Unequal Cluster Size between Arms},
  author = {Copas, Andrew J. and Hooper, Richard},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9135},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9135},
  urldate = {2021-07-28},
  abstract = {There are sometimes cost, scientific, or logistical reasons to allocate individuals unequally in an individually randomized trial. In cluster randomized trials we can allocate clusters unequally and/or allow different cluster size between trial arms. We consider parallel group designs with a continuous outcome, and optimal designs that require the smallest number of individuals to be measured given the number of clusters. Previous authors have derived the optimal allocation ratio for clusters under different variance and/or intracluster correlations (ICCs) between arms, allowing different but prespecified cluster sizes by arm. We derive closed-form expressions to identify the optimal proportions of clusters and of individuals measured for each arm, thereby defining optimal cluster sizes, when cluster size can be chosen freely. When ICCs differ between arms but the variance is equal, the optimal design allocates more than half the clusters to the arm with the higher ICC, but (typically only slightly) less than half the individuals and hence a smaller cluster size. We also describe optimal design under constraints on the number of clusters or cluster size in one or both arms. This methodology allows trialists to consider a range for the number of clusters in the trial and for each to identify the optimal design. Except if there is clear prior evidence for the ICC and variance by arm, a range of values will need to be considered. Researchers should choose a design with adequate power across the range, while also keeping enough clusters in each arm to permit the intended analysis method.},
  langid = {english},
  keywords = {cluster-randomization,cluster-randomized-trial,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9135}
}

@article{cop83pl,
  title = {Plotting p against x},
  author = {Copas, J. B.},
  date = {1983},
  journaltitle = {Appl Stat},
  volume = {32},
  pages = {25--31},
  citeulike-article-id = {13263924},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {binary-data,binary-regression,calibration-curve,nonparametric-smoother}
}

@article{cop83reg,
  title = {Regression, Prediction and Shrinkage (with Discussion)},
  author = {Copas, J. B.},
  date = {1983},
  journaltitle = {J Roy Stat Soc B},
  volume = {45},
  pages = {311--354},
  citeulike-article-id = {13263925},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {logistic-model,shrinkage,validation}
}

@article{cop87cro,
  title = {Cross-Validation Shrinkage of Regression Predictors},
  author = {Copas, J. B.},
  date = {1987},
  journaltitle = {J Roy Stat Soc B},
  volume = {49},
  pages = {175--183},
  citeulike-article-id = {13263926},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {calibration,shrinkage,validation}
}

@article{cop89unw,
  title = {Unweighted Sum of Squares Tests for Proportions},
  author = {Copas, J. B.},
  date = {1989},
  journaltitle = {Appl Stat},
  volume = {38},
  pages = {71--80},
  citeulike-article-id = {13263927},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {binary-data,global-goodness-of-fit-test}
}

@article{cop91est,
  title = {Estimating the Residual Variance in Orthogonal Regression with Variable Selection},
  author = {Copas, J. B. and Long, T.},
  date = {1991},
  journaltitle = {The Statistician},
  volume = {40},
  pages = {51--59},
  citeulike-article-id = {13263928},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  note = {"The choice of the variables to be included depends on estimated regression coefficients rather than their true values, and so X\_j is more likely to be included if its regression coefficient is overestimated than if its regression coefficient is underestimated".}
}

@article{cop98dea,
  title = {Dealing with Non-Ignorable Non-Response by Using an `enthusiasm-to-Respond' Variable},
  author = {Copas, Andrew J. and Farewell, Vern T.},
  date = {1998},
  journaltitle = {J Roy Stat Soc A},
  volume = {161},
  pages = {385--396},
  citeulike-article-id = {13263929},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {bootstrap,embarrassment-assessment,modeling-non-response,non-ignorable-non-response,propensity-score,sample-survey,unit-and-item-non-response}
}

@article{cop99eff,
  title = {The Effectiveness of Risk Scores: {{The}} Logit Rank Plot},
  author = {Copas, John},
  date = {1999},
  journaltitle = {Appl Stat},
  volume = {48},
  pages = {165--183},
  citeulike-article-id = {13263930},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {cross-validation,deficiencies-of-roc-area,logistic-regression,recidivism,risk-scores,shrinkage}
}

@article{cos17cas,
  title = {The {{Case}} for a {{Bayesian Approach}} to {{Benefit-Risk Assessment}}:},
  author = {Costa, Maria J. and He, Weili and Jemiai, Yannis and Zhao, Yueqin and Di Casoli, Carl},
  date = {2017-04},
  journaltitle = {Therapeutic Innovation \& Regulatory Science},
  volume = {51},
  number = {5},
  pages = {568--574},
  issn = {2168-4790},
  doi = {10.1177/2168479017698190},
  url = {http://dx.doi.org/10.1177/2168479017698190},
  citeulike-article-id = {14476450},
  citeulike-attachment-1 = {cos17cas.pdf; /pdf/user/harrelfe/article/14476450/1122771/cos17cas.pdf; 0ee7b8048869b3a12607d86e707e3e107426ffa5},
  citeulike-linkout-0 = {http://dx.doi.org/10.1177/2168479017698190},
  day = {04},
  posted-at = {2017-11-15 12:11:34},
  priority = {0},
  keywords = {bayes,bayesian-inference,bayesian-methods,drug-development,pharmaceutical-safety,risk-benefit-ratio}
}

@article{cos18bay,
  title = {Bayesian Joint Modelling of Benefit and Risk in Drug Development},
  author = {Costa, Maria J. and Drury, Thomas},
  date = {2018-02},
  journaltitle = {Pharm Stat},
  issn = {15391604},
  doi = {10.1002/pst.1852},
  url = {http://dx.doi.org/10.1002/pst.1852},
  citeulike-article-id = {14548318},
  citeulike-attachment-1 = {cos18bay.pdf; /pdf/user/harrelfe/article/14548318/1131793/cos18bay.pdf; 30b53d12eaf2eda1a1fb76fcd4770fdd3f1d2662},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1852},
  day = {22},
  posted-at = {2018-03-13 19:54:23},
  priority = {0},
  keywords = {bayes,bayesian-inference,drug-development,multiple-endpoints,risk-benefit-ratio}
}

@article{cos95met,
  title = {Methodological and Statistical Problems in the Construction of Composite Measurement Scales: {{A}} Survey of Six Medical and Epidemiological Journals},
  author = {Coste, J. and Fermanian, J. and Venot, A.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {331--345},
  citeulike-article-id = {13263931},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {measurement,psychometrics,scaling}
}

@article{cou21est,
  title = {Estimating the Marginal Effect of a Continuous Exposure on an Ordinal Outcome Using Data Subject to Covariate-Driven Treatment and Visit Processes},
  author = {Coulombe, Janie and Moodie, Erica E. M. and Platt, Robert W.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9151},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9151},
  urldate = {2021-08-03},
  abstract = {In the statistical literature, a number of methods have been proposed to ensure valid inference about marginal effects of variables on a longitudinal outcome in settings with irregular monitoring times. However, the potential biases due to covariate-driven monitoring times and confounding have rarely been considered simultaneously, and never in a setting with an ordinal outcome and a continuous exposure. In this work, we propose and demonstrate a methodology for causal inference in such a setting, relying on a proportional odds model to study the effect of the exposure on the outcome. Irregular observation times are considered via a proportional rate model, and a generalization of inverse probability of treatment weights is used to account for the continuous exposure. We motivate our methodology by the estimation of the marginal (causal) effect of the time spent on video or computer games on suicide attempts in the Add Health study, a longitudinal study in the United States. Although in the Add Health data, observation times are prespecified, our proposed approach is applicable even in more general settings such as when analyzing data from electronic health records where observations are highly irregular. In simulation studies, we let observation times vary across individuals and demonstrate that not accounting for biasing imbalances due to the monitoring and the exposure schemes can bias the estimate for the marginal odds ratio of exposure.},
  langid = {english},
  keywords = {causal-inference,ehr,marginal-approach,ordinal,ordinal-endpoints,po,time-dependent-effects,time-dependent-exposure},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9151}
}

@article{cou94mir,
  title = {The Miracle of {{DICE}} Therapy for Acute Stroke: Fact or Fictional Product of Subgroup Analysis?},
  author = {Counsell, Carl E. and Clarke, Mike J. and Slattery, Jim and Sandercock, Peter A. G.},
  date = {1994},
  journaltitle = {BMJ},
  volume = {309},
  pages = {1677--1681},
  citeulike-article-id = {13263932},
  posted-at = {2014-07-14 14:09:25},
  priority = {0},
  keywords = {clinical-trials,meta-analysis,publication-bias,rct,reporting,subgroup-analysis,systematic-review,teaching-mds}
}

@article{cox07par,
  title = {Parametric Survival Analysis and Taxonomy of Hazard Functions for the Generalized Gamma Distribution},
  author = {Cox, Christoper and Chu, Haitao and Schneider, Michael F. and Muñoz, Alvaro},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4352--4374},
  citeulike-article-id = {13265630},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {aids,generalized-gamma-distribution,haart,left-truncation,non-ph,non-proportional-hazards,parametric-survival-models,relative-times,survival-analysis},
  note = {nice tutoria;GG includes bathtub-shape hazard function; failed to reference Herndon}
}

@article{cox08gen,
  title = {The Generalized {{F}} Distribution: {{An}} Umbrella for Parametric Survival Analysis},
  author = {Cox, Christoper},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {4301--4313},
  citeulike-article-id = {13265699},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {flexible-parametric-distribution,generalized-f-distribution,generalized-gamma-distribution,hazard-function,parametric-survival-models}
}

@article{cox20eff,
  title = {Efficacy and Safety of Dapagliflozin in Acute Heart Failure: {{Rationale}} and Design of the {{DICTATE-AHF}} Trial},
  shorttitle = {Efficacy and Safety of Dapagliflozin in Acute Heart Failure},
  author = {Cox, Zachary L. and Collins, Sean P. and Aaron, Mark and Hernandez, Gabriel A. and Iii, A. Thomas McRae and Davidson, Beth T. and Fowler, Mike and Lindsell, Christopher J. and Jr, Frank E. Harrell and Jenkins, Cathy A. and Kampe, Christina and Miller, Karen F. and Stubblefield, William B. and Lindenfeld, JoAnn},
  date = {2020-11-02},
  journaltitle = {Am Heart J},
  volume = {232},
  eprint = {33144086},
  eprinttype = {pmid},
  pages = {116--124},
  issn = {1097-6744},
  doi = {10.1016/j.ahj.2020.10.071},
  abstract = {BACKGROUND: Dapagliflozin, a sodium-glucose cotransporter-2 inhibitor, reduces cardiovascular death and worsening heart failure in patients with chronic heart failure and reduced ejection fraction. Early initiation during an acute heart failure (AHF) hospitalization may facilitate decongestion, improve natriuresis, and facilitate safe transition to a beneficial outpatient therapy for both diabetes and heart failure. OBJECTIVE: The objective is to assess the efficacy and safety of initiating dapagliflozin within the first 24 hours of hospitalization in patients with AHF compared to usual care. METHODS: DICTATE-AHF is a prospective, multicenter, open-label, randomized trial enrolling a planned 240 patients in the United States. Patients with type 2 diabetes hospitalized with hypervolemic AHF and an estimated glomerular filtration rate of at least 30 mL/min/1.73m2 are eligible for participation. Patients are randomly assigned 1:1 to dapagliflozin 10 mg once daily or structured usual care until day 5 or hospital discharge. Both treatment arms receive protocolized diuretic and insulin therapies. The primary endpoint is diuretic response expressed as the cumulative change in weight per cumulative loop diuretic dose in 40 mg intravenous furosemide equivalents. Secondary and exploratory endpoints include inpatient worsening AHF, 30-day hospital readmission for AHF or diabetic reasons, change in NT-proBNP, and measures of natriuresis. Safety endpoints include the incidence of hyper/hypoglycemia, ketoacidosis, worsening kidney function, hypovolemic hypotension, and inpatient mortality. CONCLUSIONS: The DICTATE-AHF trial will establish the efficacy and safety of early initiation of dapagliflozin during AHF across both AHF and diabetic outcomes in patients with diabetes.},
  langid = {english},
  keywords = {collaboration}
}

@article{cox58reg,
  title = {The Regression Analysis of Binary Sequences (with Discussion)},
  author = {Cox, David R.},
  date = {1958},
  journaltitle = {J Roy Stat Soc B},
  volume = {20},
  pages = {215--242},
  citeulike-article-id = {13263933},
  citeulike-attachment-1 = {cox58reg.pdf; /pdf/user/harrelfe/article/13263933/1013217/cox58reg.pdf; ca03de34bc60bbed5aba5a9e0a0675a392266fb0},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {logistic-model,logistic-regression},
  note = {First known development of logistic model}
}

@article{cox58two,
  title = {Two Further Applications of a Model for Binary Regression},
  author = {Cox, D. R.},
  date = {1958},
  journaltitle = {Biometrika},
  volume = {45},
  number = {3/4},
  eprint = {2333203},
  eprinttype = {jstor},
  pages = {562--565},
  citeulike-article-id = {13263934},
  citeulike-linkout-0 = {http://www.jstor.org/stable/2333203},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@article{cox62fur,
  title = {Further Results on Tests of Separate Families of Hypotheses},
  author = {Cox, D. R.},
  date = {1962},
  journaltitle = {J Roy Stat Soc B},
  volume = {24},
  pages = {406--424},
  citeulike-article-id = {13263935},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {non-nested-models}
}

@article{cox68gen,
  title = {A General Definition of Residuals (with Discussion)},
  author = {Cox, D. R. and Snell, E. J.},
  date = {1968},
  journaltitle = {J Roy Stat Soc B},
  volume = {30},
  pages = {248--275},
  citeulike-article-id = {13263936},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {residuals-for-right-censored-survival-data}
}

@article{cox72,
  title = {Regression Models and Life-Tables (with Discussion)},
  author = {Cox, David R.},
  date = {1972},
  journaltitle = {J Roy Stat Soc B},
  volume = {34},
  pages = {187--220},
  citeulike-article-id = {13263937},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@article{cox75not,
  title = {A {{Note}} on {{Data-splitting}} for the {{Evaluation}} of {{Significance Levels}}},
  author = {Cox, D. R.},
  date = {1975},
  journaltitle = {Biometrika},
  volume = {62},
  pages = {441--444},
  citeulike-article-id = {13263938},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {jackknifing,multiple-comparisons,selection-effect}
}

@book{cox84,
  title = {Analysis of {{Survival Data}}},
  author = {Cox, D. R. and Oakes, D.},
  date = {1984},
  publisher = {{Chapman and Hall}},
  location = {{London}},
  citeulike-article-id = {13263939},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@book{cox89ana,
  title = {The {{Analysis}} of {{Binary Data}}},
  author = {Cox, D. R. and Snell, E. J.},
  date = {1989},
  edition = {Second},
  publisher = {{Chapman and Hall}},
  location = {{London}},
  citeulike-article-id = {13263940},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@article{cox90,
  title = {An Approximation to Maximum Likelihood Estimates in Reduced Models},
  author = {Cox DR, Wermuth N.},
  date = {1990},
  journaltitle = {Biometrika},
  volume = {77},
  pages = {747--761},
  citeulike-article-id = {13263941},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {maximum-likelihood,variable-selection}
}

@article{cox92,
  title = {A Comment on the Coefficient of Determination for Binary Responses},
  author = {Cox, D. R. and Wermuth, N.},
  date = {1992},
  journaltitle = {Am Statistician},
  volume = {46},
  pages = {1--4},
  citeulike-article-id = {13263942},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@article{cox92qua,
  title = {Quality-of-Life Assessment: Can We Keep It Simple? (With Discussion)},
  author = {Cox, D. R. and Fitzpatrick, R. and Fletcher, A. E. and Gore, S. M. and Spiegelhalter, D. J. and Jones, D. R.},
  date = {1992},
  journaltitle = {J Roy Stat Soc A},
  volume = {155},
  pages = {353--393},
  citeulike-article-id = {13263943},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {informative-censoring,multiple-endpoints,qol,quality-of-life}
}

@article{cox95loc,
  title = {Location-Scale Cumulative Odds Models for Ordinal Data: {{A}} Generalized Non-Linear Model Approach},
  author = {Cox, Christopher},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1191--1203},
  citeulike-article-id = {13263944},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {logistic-model-extensions,ordinal-response-data,partial-proportional-odds-model,proportional-odds-model}
}

@book{cox96mul,
  title = {Multivariate {{Dependencies}}: {{Models}}, {{Analysis}} and {{Interpretation}}},
  author = {Cox, D. R. and Wermuth, N.},
  date = {1996},
  publisher = {{Chapman and Hall}},
  location = {{London}},
  citeulike-article-id = {13263945},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {chain-models,path-analysis}
}

@book{cpm,
  title = {Clinical {{Prediction Models}}},
  author = {Steyerberg, Ewout W.},
  date = {2009},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265717},
  posted-at = {2014-07-14 14:10:02},
  priority = {0}
}

@article{cpm95bio,
  title = {Biostatistical Methodology in Clinical Trials in Applications for Marketing Authorizations for Medicinal Products},
  author = {Party, Cpmp W.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1659--1682},
  doi = {10.1002/sim.4780141507},
  url = {http://dx.doi.org/10.1002/sim.4780141507},
  citeulike-article-id = {13263946},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780141507},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {blinding,clinical-trials,covariable-adjustment,monitoring,pharmaceutical,rct,study-design}
}

@article{cpmp04poi,
  title = {Points to Consider on Adjustment for Baseline Covariates},
  author = {{Committee for Proprietary Medicinal Products}},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  pages = {701--709},
  citeulike-article-id = {13265369},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {analysis-of-covariance,baseline-covariates,covariate-adjustment,policy,randomized-trials,rct}
}

@article{cra08how,
  title = {How Conservative Is {{Fisher}}'s Exact Test? {{A}} Quantitative Evaluation of the Two-Sample Comparative Binomial Trial},
  author = {Crans, Gerald G. and Shuster, Jonathan J.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {3598--3611},
  doi = {10.1002/sim.3221},
  url = {http://dx.doi.org/10.1002/sim.3221},
  citeulike-article-id = {13265687},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3221},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {2x2-table,fishers-exact-test,size-of-test},
  note = {comparative binomial experiment;first paper to truly quantify the conservativeness of Fisher's test;"the test size of FET was less than 0.035 for nearly all sample sizes before 50 and did not approach 0.05 even for sample sizes over 100.";conservativeness of "exact" methods;see {$<$}i{$>$}Stat in Med{$<$}/i{$>$} {$<$}b{$>$}28{$<$}/b{$>$}:173-179, 2009 for a criticism which was unanswered}
}

@article{cra70dem,
  title = {The Demand for Automobiles},
  author = {Cragg, J. G. and Uhler, R.},
  date = {1970},
  journaltitle = {Canadian Journal of Economics},
  volume = {3},
  pages = {386--406},
  doi = {10.2307/133656},
  url = {http://dx.doi.org/10.2307/133656},
  citeulike-article-id = {13347074},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/133656},
  posted-at = {2014-09-04 23:24:53},
  priority = {2},
  keywords = {predictive-accuracy},
  note = {normalizing index of explained variation for binary reponse to have maximum value of 1;predated Nagelkerke pseudoR-squared;predictive accuracy index}
}

@article{cra87mea,
  title = {Mean and Variance of {{R}}² in Small and Moderate Samples},
  author = {Cramer, J. S.},
  date = {1987},
  journaltitle = {J Econometrics},
  volume = {35},
  number = {2–3},
  pages = {253--266},
  doi = {http://dx.doi.org/10.1016/0304-4076(87)90027-3},
  url = {http://www.sciencedirect.com/science/article/pii/0304407687900273},
  abstract = {We derive and use easily computable expressions for the mean and variance of R² in the standard linear regression model with fixed regressors. In respect to its probability limit R² is seriously biased upward in small samples; the `adjusted' R² does much better. But at sample sizes where these distinctions matter both measures are thoroughly unreliable because of their large dispersion. R² should not be quoted for samples of less than fifty observations.},
  citeulike-article-id = {13265980},
  citeulike-linkout-0 = {http://dx.doi.org/http://dx.doi.org/10.1016/0304-4076(87)90027-3},
  citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/pii/0304407687900273},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{cra95com,
  title = {A Comparison of Analytic Methods for Non-Random Missingness of Outcome Data},
  author = {Crawford, Sybil L. and Tennstedt, Sharon L. and McKinlay, John B.},
  date = {1995},
  journaltitle = {J Clin Epi},
  volume = {48},
  pages = {209--219},
  citeulike-article-id = {13263948},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {imputation,missing-data,missing-response-variable,multiple-imputation}
}

@article{cri89cor,
  title = {Correspondence Analysis as a Screening Method for Indicants for Clinical Diagnosis},
  author = {Crichton, N. J. and Hinde, J. P.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {1351--1362},
  citeulike-article-id = {13263949},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {data-reduction,multivariate-analysis,scaling}
}

@article{cri97mod,
  title = {Models for Diagnosing Chest Pain: {{Is CART}} Useful?},
  author = {Crichton, Nicola J. and Hinde, John P. and Marchini, Jonathan},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {717--727},
  citeulike-article-id = {13263950},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {cart,disappointing-classification-accuracy}
}

@article{cri98tra,
  title = {Training in Cognitive, Supportive-Expressive, and Drug Counseling Therapies for Cocaine Dependence},
  author = {Crits-Christoph, Paul and Siqueland, Lynne and em et {al}, Chittams},
  options = {useprefix=true},
  date = {1998},
  journaltitle = {J Cons Clin Psych},
  volume = {66},
  pages = {484--492},
  citeulike-article-id = {13265111},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {hierarchical-model,hlm},
  note = {assessment of psychotherapist performance and training;used in Hauenstein grant}
}

@article{cro08sta,
  title = {Statistical Methods to Correct for Verification Bias in Diagnostic Studies Are Inadequate When There Are Few False Negatives: A Simulation Study},
  author = {Cronin, Angel M. and Vickers, Andrew J.},
  date = {2008-11},
  journaltitle = {BMC Med Res Methodol},
  volume = {8},
  number = {1},
  eprint = {19014457},
  eprinttype = {pmid},
  pages = {75+},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-8-75},
  url = {http://dx.doi.org/10.1186/1471-2288-8-75},
  citeulike-article-id = {3507453},
  citeulike-attachment-1 = {cro08sta.pdf; /pdf/user/harrelfe/article/3507453/1086878/cro08sta.pdf; 89b5089e5b3f06a75e9291488e13805331b97cde},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2288-8-75},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19014457},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19014457},
  day = {11},
  posted-at = {2016-10-16 16:02:56},
  priority = {2},
  keywords = {diagnosis,diagnostic-accuracy,diagnostic-test,referral-bias,sensitivity}
}

@article{cro13sim,
  title = {Simulating Biologically Plausible Complex Survival Data},
  author = {Crowther, Michael J. and Lambert, Paul C.},
  date = {2013},
  journaltitle = {Stat Med},
  volume = {32},
  number = {23},
  pages = {4118--4134},
  doi = {10.1002/sim.5823},
  url = {http://dx.doi.org/10.1002/sim.5823},
  abstract = {Simulation studies are conducted to assess the performance of current and novel statistical models in pre-defined scenarios. It is often desirable that chosen simulation scenarios accurately reflect a biologically plausible underlying distribution. This is particularly important in the framework of survival analysis, where simulated distributions are chosen for both the event time and the censoring time. This paper develops methods for using complex distributions when generating survival times to assess methods in practice. We describe a general algorithm involving numerical integration and root-finding techniques to generate survival times from a variety of complex parametric distributions, incorporating any combination of time-dependent effects, time-varying covariates, delayed entry, random effects and covariates measured with error. User-friendly Stata software is provided.},
  citeulike-article-id = {13265985},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5823},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {delayed-entry,measurement-error,simulation,simulation-setup,survival,tdc,time-dependent-effects}
}

@article{cro93spe,
  title = {A Specification Test for Univariate and Multivariate Proportional Hazards Models},
  author = {Crouchley, Robert and Pickes, Andrew},
  date = {1993},
  journaltitle = {Biometrics},
  volume = {49},
  pages = {1067--1076},
  citeulike-article-id = {13263951},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {cluster-sampling,cox-model,huber,model-misspecification,sandwich-estimator}
}

@article{cro98app,
  title = {The Application of Sample Selection Models to Outcomes Research: {{The}} Case of Evaluating the Effects of Antidepressant Therapy on Resource Utilization},
  author = {Crown, William H. and Obenchain, Robert L. and Englehart, Luella and Lair, Tamra and Buesching, Don P. and Croghan, Thomas},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1943--1958},
  citeulike-article-id = {13263952},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {observational-study,propensity-score,sample-selection-model,treatment-selection-bias}
}

@article{cro99bay,
  title = {Bayesian Monitoring of Phase {{II}} Trials in Cancer Cemoprevention, with Discussion by {{H}}. {{C}}. van {{Houwelingen}}},
  author = {Cronin, Kathleen A. and Freedman, Laurence S. and Lieberman, Ronald and Weiss, Heidi L. and Beenken, Samuel W. and Keloff, Gary J.},
  date = {1999},
  journaltitle = {J Clin Epi},
  volume = {52},
  pages = {705--716},
  citeulike-article-id = {13263953},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  note = {using different priors for different purposes;van Houwelingen argues that this is not true Bayesian but the authors argue that one needs to convince different observers}
}

@article{cru09dea,
  title = {Dealing with Limited Overlap in Estimation of Average Treatment Effects},
  author = {Crump, Richard K. and Hotz, V. Joseph and Imbens, Guido W. and Mitnik, Oscar A.},
  date = {2009-01},
  journaltitle = {Biometrika},
  volume = {96},
  number = {1},
  pages = {asn055-199},
  publisher = {Oxford University Press},
  issn = {1464-3510},
  doi = {10.1093/biomet/asn055},
  url = {http://dx.doi.org/10.1093/biomet/asn055},
  abstract = {Estimation of average treatment effects under unconfounded or ignorable treatment assignment is often hampered by lack of overlap in the covariate distributions between treatment groups. This lack of overlap can lead to imprecise estimates, and can make commonly used estimators sensitive to the choice of specification. In such cases researchers have often used ad hoc methods for trimming the sample. We develop a systematic approach to addressing lack of overlap. We characterize optimal subsamples for which the average treatment effect can be estimated most precisely. Under some conditions, the optimal selection rules depend solely on the propensity score. For a wide range of distributions, a good approximation to the optimal rule is provided by the simple rule of thumb to discard all units with estimated propensity scores outside the range [0.1,0.9].},
  citeulike-article-id = {4172464},
  citeulike-attachment-1 = {cru09dea.pdf; /pdf/user/harrelfe/article/4172464/1001962/cru09dea.pdf; fa7879fde4385c8bca6f88002517ffcaac5e40d9},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/asn055},
  citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/96/1/187.abstract},
  citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/96/1/187.full.pdf},
  citeulike-linkout-3 = {http://www.ingentaconnect.com/content/oup/biomet/2009/00000096/00000001/art00014},
  day = {24},
  posted-at = {2015-01-22 13:53:54},
  priority = {2},
  keywords = {confounding,propensity-score}
}

@article{cui19eff,
  title = {On the Efficiency of Adaptive Sample Size Design},
  author = {Cui, Lu and Zhang, Lanju},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {6},
  pages = {933--944},
  issn = {1097-0258},
  doi = {10.1002/sim.8034},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8034},
  urldate = {2019-02-15},
  abstract = {Adaptive sample size designs, including group sequential designs, have been used as alternatives to fixed sample size designs to achieve more robust statistical power and better trial efficiency. This work investigates the efficiency of adaptive sample size designs as compared to group sequential designs. We show that given a group sequential design, a uniformly more efficient adaptive sample size design based on the same maximum sample size and rejection boundary can be constructed. While maintaining stable statistical power at the required level, the expected sample size of the obtained adaptive sample size design is uniformly smaller than that of the group sequential design with respect to a range of the true treatment difference. The finding provides further insights into the efficiency of adaptive sample size designs and challenges the popular belief of better efficiency associated with group sequential designs. Good adaptive performance plus easy implementation and other desirable operational features make adaptive sample size designs more attractive and applicable to modern clinical trials.},
  langid = {english},
  keywords = {adaptive,rct,sample-size,sequential}
}

@article{cup95age,
  title = {Age-Adjusted Survival Curves with Application in the {{Framingham Study}}},
  author = {Cupples, L. Adrienne and Gagnon, David R. and Ramaswamy, Ratna and D'Agostino, Ralph B.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1731--1744},
  citeulike-article-id = {13263954},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {adjusted-survival-curves,covariable-adjustment}
}

@article{cur01dev,
  title = {Development and Deployment of an {{Internet-based}} Data Management System for Use by the {{Asthma Clinical Research Network}}},
  author = {Curley, Robert M. and Evans, Richard L. and Kaylor, James and Pogash, Rosanne M. and Chinchilli, Vernon M.},
  date = {2001},
  journaltitle = {Controlled Clin Trials},
  volume = {22},
  pages = {135S-155S},
  citeulike-article-id = {13265247},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {budget-problems,internet-based-data-management,project-development-management,software-modules,used-x-terminals}
}

@book{cur83fac,
  title = {Factor {{Analysis}}, {{An Applied Approach}}},
  author = {Cureton, E. E. and D'Agostino, R. B.},
  date = {1983},
  publisher = {{Erlbaum}},
  location = {{Hillsdale, NJ}},
  citeulike-article-id = {13263955},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {battery-reduction,factor-analysis,multivariate-analysis,principal-components,variable-clustering}
}

@article{cut66rol,
  title = {The Role of Hypothesis Testing in Clinical Trials},
  author = {Cutler, S. J. and Greenhouse, S. W. and Cornfield, J. and Schneiderman, M. A.},
  date = {1966},
  journaltitle = {J Chron Dis},
  volume = {19},
  pages = {857--882},
  citeulike-article-id = {13263956},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  note = {Cornfield As quoted in ber87int:"Of course a re-examination in the light of results of the assumptions on which the pre-observational partition of the sample space was based would be regarded in some circles as bad statistics. It would, however, be widely regarded as good science. I do not believe that anything that is good science can be bad statistics, and conclude my remarks with the hope that there are no statisticians so inflexible as to decline to analyze an honest body of scientific data simply because it fails to conform to some favored theoretical scheme. If there are such, however, clinical trials, in my opinion, are not for them." (P. 866)}
}

@article{cuz89,
  title = {Rank Regression},
  author = {Cuzick, J.},
  date = {1989},
  journaltitle = {Ann Stat},
  volume = {16},
  pages = {1369--1389},
  citeulike-article-id = {13263957},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {distribution-free-methods,survival-analysis-proportional-hazards-model}
}

@article{cuz97adj,
  title = {Adjusting for Non-Compliance and Contamination in Randomized Clinical Trials},
  author = {Cuzick, Jack and Edwards, Robert and Segnan, Nereo},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1017--1029},
  citeulike-article-id = {13263958},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {dropin,dropout,equivalence-testing,intent-to-treat,non-compliance},
  annotation = {Correction 26:3821;2007},
  note = {adjusting for non-compliance increases width of confidence intervals;bias caused by intent-to-treat analyses in equivalence testing}
}

@article{da20ord,
  title = {Ordinal {{Outcomes Are Superior}} to {{Binary Outcomes}} for {{Designing}} and {{Evaluating Clinical Trials}} in {{Compensated Cirrhosis}}},
  author = {D’Amico, Gennaro and Abraldes, Juan G. and Rebora, Paola and Valsecchi, Maria Grazia and Garcia‐Tsao, Guadalupe},
  date = {2020},
  journaltitle = {Hepatology},
  volume = {n/a},
  number = {n/a},
  issn = {1527-3350},
  doi = {10.1002/hep.31070},
  url = {https://aasldpubs.onlinelibrary.wiley.com/doi/abs/10.1002/hep.31070},
  urldate = {2019-12-19},
  abstract = {Prevention of decompensation is a primary therapeutic target in patients with compensated cirrhosis. However, a major problem is the large sample size and long follow-up required to demonstrate a significant treatment effect because of the relatively low baseline risk. For this reason, it has been recently suggested that ordinal outcomes may be used in this area to gain power and to reduce sample size. The aim of this study was to assess the applicability of ordinal outcomes in cirrhosis. An inception cohort of 202 patients with compensated cirrhosis (no ascites, gastrointestinal bleeding, encephalopathy, or jaundice) without esophageal varices was included, and 5-year outcome is reported. Etiology was mostly viral and alcoholic, and there were no dropouts. The ordinal outcome was set according to six grades with a previously established prognostic ordinality: grade 1=no disease progression; grade 2=development of varices; grade 3 = bleeding alone; grade 4=nonbleeding single decompensation; grade 5=more than one decompensating event; and grade 6=death. At the 60-month time point, patients were distributed in grades 1 through 6 as follows: 129, 43, 2, 7, 5, and 16, respectively. Emulation of a clinical trial performed by dividing patients based on baseline platelet count into two groups (cutoff 150×109/L) demonstrated a statistically significant outcome difference between groups when using ordinal outcomes not detectable by binary logistic or chi-square or time-to-event analyses. Additionally, using ordinal outcomes in a hypothetical study to prevent decompensation resulted in sample size estimates 3-to 4-fold lower than using a binary composite endpoint. Conclusion: Compared to traditional binary outcomes, the use of ordinal outcomes in trials of cirrhosis decompensation may provide more power and thus may require a smaller sample size.},
  langid = {english},
  keywords = {ordinal,ordinal-endpoints,rct}
}

@article{dab87,
  title = {Estimates and Confidence Intervals for Median and Mean Life in the Proportional Hazard Model},
  author = {Dabrowska, D. M. and Doksum, K. A.},
  date = {1987},
  journaltitle = {Biometrika},
  volume = {74},
  pages = {799--807},
  citeulike-article-id = {13263959},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model}
}

@article{dab88,
  title = {Estimation and Testing in a Two-Sample Generalized Odds-Rate Model},
  author = {Dabrowska DM, Doksum K. A.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {744--749},
  citeulike-article-id = {13263960},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {general,logistic-ordinal-model,survival-analysis-regression}
}

@article{dab92met,
  title = {Methods for Comparing Cumulative Hazard Functions in a Semi-Proportional Hazard Model},
  author = {Dabrowska, Dorota M. and Doksum, Kjell A. and Feduska, Nicholas J. and Husing, Robert and Neville, Padraic},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1465--1476},
  citeulike-article-id = {13263961},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {assessing-proportional-hazards,non-proportional-hazards,treatment-comparisons}
}

@article{dag00est,
  title = {Estimating and Using Propensity Scores with Partially Missing Data},
  author = {{D'Agostino, Jr} and Rubin, Donald B.},
  date = {2000},
  journaltitle = {J Am Stat Assoc},
  volume = {95},
  pages = {749--759},
  citeulike-article-id = {13265142},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {imputation,missing-data,propensity-score},
  note = {missing data in propensity score;adding extra categories for missing;using indicators of missingness in propensity score to balance on missing data patterns;general location model for likelihood-based analysis of partial data}
}

@article{dag00pri,
  title = {Primary and Subsequent Coronary Risk Appraisal: {{New}} Results from {{The Framingham Study}}},
  author = {D'Agostino, Ralph B. and Russell, Mason W. and Huse, Daniel M. and Ellison, Curtis and Silbershatz, Halit and Wilson, Peter W. F. and Hartz, Stuart},
  date = {2000},
  journaltitle = {Am Heart J},
  volume = {139},
  pages = {272--281},
  citeulike-article-id = {13265106},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {2-year-survival-probabilities,health-risk-appraisal-function,logsbp,nice-point-score-tables,scoring-tables,weibull-model}
}

@article{dag05pri,
  title = {Principal {{Components Analysis}}},
  booktitle = {Encyclopedia of Biostatistics},
  author = {D'agostino, Ralph B.},
  date = {2005},
  publisher = {John Wiley & Sons, Ltd},
  doi = {10.1002/0470011815.b2a13069},
  url = {http://dx.doi.org/10.1002/0470011815.b2a13069},
  abstract = {Principal components analysis is a method for transforming a set of n correlated variables into m(},
  citeulike-article-id = {13452151},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/0470011815.b2a13069},
  posted-at = {2014-12-04 12:49:52},
  priority = {2},
  keywords = {data-reduction,pca}
}

@article{dag88,
  title = {The Appropriateness of Some Common Procedures for Testing the Equality of Two Independent Binomial Populations},
  author = {D'Agostino, R. B. and Chase, W. and Belanger, A.},
  date = {1988},
  journaltitle = {Am Statistician},
  volume = {42},
  pages = {198--202},
  citeulike-article-id = {13263962},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,statistical-computation-algorithms}
}

@article{dag90rel,
  title = {Relation of Pooled Logistic Regression to Time Dependent {{Cox}} Regression Analysis: {{The Framingham Heart Study}}},
  author = {D'Agostino, Ralph B. and Lee, M. L. and Belanger, A. J. and Cupples, L. A.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {1501--1515},
  doi = {10.1002/sim.4780091214},
  url = {http://dx.doi.org/10.1002/sim.4780091214},
  citeulike-article-id = {13263963},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780091214},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {person-years-logistic-model,repeated-measures-logistic-model,tdc}
}

@article{dag95dev,
  title = {Development of Health Risk Appraisal Functions in the Presence of Multiple Indicators: {{The Framingham Study}} Nursing Home Institutionalization Model},
  author = {D'Agostino, Ralph B. and Belanger, Albert J. and Markson, Elizabeth W. and Kelly-Hayes, Maggie and Wolf, Philip A.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1757--1770},
  citeulike-article-id = {13263964},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {data-reduction,factor-analysis,multivariate-analysis,principal-components,variable-clustering}
}

@article{dag95mea,
  title = {Measuring Effectiveness: {{What}} to Expect without a Randomized Control Group},
  author = {D'Agostino, Ralph B. and Kwan, Heidy},
  date = {1995},
  journaltitle = {Med Care},
  volume = {33},
  pages = {AS95-AS105},
  citeulike-article-id = {13263965},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {adjustment,bias,observational-study,propensity-score,retrospective-study,teaching-mds}
}

@article{dag98pro,
  title = {Tutorial in {{Biostatistics}}: {{Propensity}} Score Methods for Bias Reduction in the Comparison of a Treatment to a Non-Randomized Control Group},
  author = {{D'Agostino, Jr}},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {2265--2281},
  citeulike-article-id = {13263966},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {confounding,distance-matching,observational-study,propensity-score}
}

@article{dah18gen,
  title = {Generalizing Causal Inferences from Individuals in Randomized Trials to All Trial-Eligible Individuals},
  author = {Dahabreh, Issa J. and Robertson, Sarah E. and Tchetgen, Eric J. Tchetgen and Stuart, Elizabeth A. and Hernán, Miguel A.},
  date = {2018},
  journaltitle = {Biometrics},
  volume = {0},
  issn = {1541-0420},
  doi = {10.1111/biom.13009},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13009},
  urldate = {2018-12-01},
  abstract = {We consider methods for causal inference in randomized trials nested within cohorts of trial-eligible individuals, including those who are not randomized. We show how baseline covariate data from the entire cohort, and treatment and outcome data only from randomized individuals, can be used to identify potential (counterfactual) outcome means and average treatment effects in the target population of all eligible individuals. We review identifiability conditions, propose estimators, and assess the estimators' finite-sample performance in simulation studies. As an illustration, we apply the estimators in a trial nested within a cohort of trial-eligible individuals to compare coronary artery bypass grafting surgery plus medical therapy versus medical therapy alone for chronic coronary artery disease. This article is protected by copyright. All rights reserved},
  issue = {ja},
  langid = {english},
  keywords = {generalizability,rct,rct-interpretation}
}

@inproceedings{dai89com,
  title = {Comparison of Different Packages' Survival Test Results},
  booktitle = {Proceedings of the {{Statistical Computing Section ASA}}},
  author = {Dain, B. J. and Freeman, D. H. and Vredenburgh, J. J.},
  date = {1989},
  pages = {315--318},
  citeulike-article-id = {13263967},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {software-review}
}

@article{dal01pro,
  title = {Proposals for 2001 Samples of Anonymized Records: An Assessment of Disclosure Risk},
  author = {Dale, Angela and Elliot, Mark},
  date = {2001},
  journaltitle = {J Roy Stat Soc A},
  volume = {164},
  pages = {427--447},
  citeulike-article-id = {13265234},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {confidentiality,statistical-disclosure}
}

@article{dal18bet,
  title = {Better Decision Making in Drug Development through Adoption of Formal Prior Elicitation},
  author = {Dallow, Nigel and Best, Nicky and Montague, Timothy H.},
  date = {2018},
  journaltitle = {Pharm Stat},
  volume = {0},
  number = {0},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.1854},
  doi = {10.1002/pst.1854},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1854},
  abstract = {With the continued increase in the use of Bayesian methods in drug development, there is a need for statisticians to have tools to develop robust and defensible informative prior distributions. Whilst relevant empirical data should, where possible, provide the basis for such priors, it is often the case that limitations in data and/or our understanding may preclude direct construction of a data‐based prior. Formal expert elicitation methods are a key technique that can be used to determine priors in these situations. Within GlaxoSmithKline, we have adopted a structured approach to prior elicitation on the basis of the SHELF elicitation framework and routinely use this in conjunction with calculation of probability of success (assurance) of the next study(s) to inform internal decision making at key project milestones. The aim of this paper is to share our experiences of embedding the use of prior elicitation within a large pharmaceutical company, highlighting both the benefits and challenges of prior elicitation through a series of case studies. We have found that putting team beliefs into the shape of a quantitative probability distribution provides a firm anchor for all internal decision making, enabling teams to provide investment boards with formally appropriate estimates of the probability of trial success as well as robust plans for interim decision rules where appropriate. As an added benefit, the elicitation process provides transparency about the beliefs and risks of the potential medicine, ultimately enabling better portfolio and company‐wide decision making.},
  citeulike-article-id = {14560064},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1854},
  citeulike-linkout-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1854},
  posted-at = {2018-04-03 03:40:59},
  priority = {2},
  keywords = {bayes,choice-of-prior,clinical-decision-making,drug-development,elicitation,prior}
}

@article{dan21mak,
  title = {Making Apples from Oranges: {{Comparing}} Noncollapsible Effect Estimators and Their Standard Errors after Adjustment for Different Covariate Sets},
  shorttitle = {Making Apples from Oranges},
  author = {Daniel, Rhian and Zhang, Jingjing and Farewell, Daniel},
  date = {2021-03-01},
  journaltitle = {Biometrical Journal},
  volume = {63},
  number = {3},
  pages = {528--557},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {0323-3847},
  doi = {10.1002/bimj.201900297},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/bimj.201900297},
  urldate = {2021-05-05},
  abstract = {Abstract We revisit the well-known but often misunderstood issue of (non)collapsibility of effect measures in regression models for binary and time-to-event outcomes. We describe an existing simple but largely ignored procedure for marginalizing estimates of conditional odds ratios and propose a similar procedure for marginalizing estimates of conditional hazard ratios (allowing for right censoring), demonstrating its performance in simulation studies and in a reanalysis of data from a small randomized trial in primary biliary cirrhosis patients. In addition, we aim to provide an educational summary of issues surrounding (non)collapsibility from a causal inference perspective and to promote the idea that the words conditional and adjusted (likewise marginal and unadjusted) should not be used interchangeably.},
  keywords = {effect-measure,marginal-approach,non-collapsibility}
}

@article{dan97met,
  title = {Meta-Analysis for the Evaluatin of Potential Surrogate Markers},
  author = {Daniels, Michael J. and Hughes, Michael D.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1965--1982},
  citeulike-article-id = {13263968},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {meta-analysis,surrogate-endpoint-validation-using-multiple-studies}
}

@article{dan98how,
  title = {How to Decide on the Applicability of Clinical Trial Results to Your Patient},
  author = {Dans, Antonio L. and Dans, Leonila F. and Guyatt, Gordon H. and Richardson, Scott and {The Evidence-Based Medicine Working Group}},
  date = {1998},
  journaltitle = {JAMA},
  volume = {279},
  pages = {545--549},
  doi = {10.1001/jama.279.7.545},
  url = {http://dx.doi.org/10.1001/jama.279.7.545},
  citeulike-article-id = {13263969},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.279.7.545},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {clinical-trials,generalizability,rct,reporting,teaching-mds}
}

@book{data,
  title = {Data},
  author = {Andrews, D. F. and Herzberg, A. M.},
  date = {1985},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13263970},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@incollection{dav86,
  title = {An Example of Dependencies among Variables in a Conditional Logistic Regression},
  booktitle = {Modern {{Statistical Methods}} in {{Chronic Disease Epidemiology}}},
  author = {Davis, C. E. and Hyde, J. E. and Bangdiwala, S. I. and Nelson, J. J.},
  editor = {Moolgavkar, S. H. and Prentice, R. L.},
  date = {1986},
  pages = {140--147},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13263971},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@article{dav86eff,
  title = {Efficient Bootstrap Simulation},
  author = {Davison, A. C. and Hinkley, D. V. and Schechtman, E.},
  date = {1986},
  journaltitle = {Biometrika},
  volume = {73},
  pages = {555--566},
  citeulike-article-id = {13263972},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {balanced-bootstrap}
}

@article{dav87hyp,
  title = {Hypothesis Testing When a Nuisance Parameter Is Present Only under the Alternative},
  author = {Rb, Davies},
  date = {1987},
  journaltitle = {Biometrika},
  volume = {74},
  pages = {33--43},
  citeulike-article-id = {13263973},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {maximum-likelihood}
}

@article{dav87ran,
  title = {Ranking from Unbalanced Paired-Comparison Data},
  author = {Ha, David},
  date = {1987},
  journaltitle = {Biometrika},
  volume = {74},
  pages = {432--436},
  citeulike-article-id = {13263974},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {distribution-free-methods}
}

@article{dav88,
  title = {Detection of Influential Observations in Logistic Regression Using the {{SAS}} System},
  author = {Davis, C. S.},
  date = {1988},
  journaltitle = {Proc SAS Users Group Intnl Conference},
  volume = {13},
  pages = {964--969},
  citeulike-article-id = {13263975},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,statistical-computation-algorithms}
}

@article{dav89exp,
  title = {Exponential Survival Trees},
  author = {Davis, Roger B. and Anderson, James R.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {947--961},
  citeulike-article-id = {13263976},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {cart,parametric-survival-model,survival-analysis}
}

@article{dav94dat,
  title = {Data Monitoring in Clinical Trials: {{The}} Case for Stochastic Curtailment},
  author = {Davis, Barry R. and Hardy, Robert J.},
  date = {1994},
  journaltitle = {J Clin Epi},
  volume = {47},
  pages = {1033--1042},
  citeulike-article-id = {13263977},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {conditional-power,early-stopping,early-termination,interim-analysis,stochastic-curtailment,study-design}
}

@book{dav97boo,
  title = {Bootstrap {{Methods}} and {{Their Application}}},
  author = {Davison, A. C. and Hinkley, D. V.},
  date = {1997},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  citeulike-article-id = {13263978},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@book{davis-repmeas,
  title = {Statistical {{Methods}} for the {{Analysis}} of {{Repeated Measurements}}},
  author = {Davis, Charles S.},
  date = {2002},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265321},
  posted-at = {2014-07-14 14:09:54},
  priority = {0}
}

@article{daw00com,
  title = {Comment on “the Philosophy of Statistics” by {{D}}. {{V}}. {{Lindley}}},
  author = {Dawid, A. P.},
  date = {2000},
  journaltitle = {The Statistician},
  volume = {49},
  pages = {325--326},
  citeulike-article-id = {14438464},
  posted-at = {2017-09-26 18:54:59},
  priority = {2},
  keywords = {bayes}
}

@article{daw76pro,
  title = {Properties of Diagnostic Data Distributions},
  author = {Dawid, A. P.},
  date = {1976-09},
  journaltitle = {Biometrics},
  volume = {32},
  number = {3},
  eprint = {963177},
  eprinttype = {pmid},
  pages = {647--658},
  issn = {0006-341X},
  abstract = {In applications of statistical methods to medical diagnosis, information on patients' diseases and symptoms is collected and the resulting data-base is used to diagnose new patients. The data-structure is complicated by a number of factors, two of which are examined here: selection bias and unstable population. Under reasonable conditions, no correction for selection bias is required when assessing probabilities for diseases based on symptom information, and it is suggested that these "diagnostic distributions" should form the principal object of study. Transformation of these distributions under changing population structure is considered and shown to take on a simple form in many situations. It is argued that the prevailing paradigm of diagnostic statistics, which concentrates on incidence of symptoms for given disease, is largely inappropriate and should be replaced by an emphasis on diagnostic distributions. The generalized logistic model is seen to fit naturally into the new framework.},
  langid = {english},
  keywords = {diagnosis,sensitivity,specificity}
}

@article{daw89,
  title = {Clinical versus Actuarial Judgment},
  author = {Dawes, R. M. and Faust, D. and Meehl, P. E.},
  date = {1989},
  journaltitle = {Science},
  volume = {243},
  pages = {1668--1674},
  citeulike-article-id = {13263979},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {diagnosis,predictive-accuracy,testing}
}

@article{daw95unu,
  title = {The `{{Unusual Episode}}' Data Revisited},
  author = {Dawson, R. J. M.},
  date = {1995},
  journaltitle = {J Stat Edu},
  volume = {3},
  number = {3},
  citeulike-article-id = {13265154},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {categorical-analysis-of-titanic},
  annotation = {Online journal at www.amstat.­org/­publications/­jse/­v3n3/­datasets.­dawson.­html}
}

@article{daw98sam,
  title = {Sample Size Calculations Based on Slopes and Other Summary Statistics},
  author = {Dawson, Jeffrey D.},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {323--330},
  citeulike-article-id = {13263980},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {accounting-for-dropout,repeated-measures,sample-size,serial-data,study-design,summary-statistics}
}

@article{day00ope,
  title = {Operational Difficulties with Internal Pilot Studies to Update Sample Size},
  author = {Day, S.},
  date = {2000},
  journaltitle = {Drug Info J},
  volume = {34},
  pages = {461--468},
  citeulike-article-id = {13265512},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{day79,
  title = {Testing Hypotheses in Case-Control Studies - Equivalence of {{Mantel-Haenszel}} Statistics and Logit Score Tests},
  author = {Day, N. E. and Byar, D. P.},
  date = {1979},
  journaltitle = {Biometrics},
  volume = {35},
  pages = {623--630},
  citeulike-article-id = {13263981},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@article{day96tri,
  title = {Trial Design Based on Surrogate End Points---{{Application}} to Comparison of Different Breast Screening Frequencies},
  author = {Day, N. E. and Duffy, S. W.},
  date = {1996},
  journaltitle = {J Roy Stat Soc A},
  volume = {159},
  pages = {49--60},
  citeulike-article-id = {13263982},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {rct,study-design,surrogate-endpoint},
  note = {efficiency of using predicted mortality compared with actual mortality}
}

@article{day98dou,
  title = {Double Data Entry: {{What}} Value, What Price?},
  author = {Day, S. and Fayers, P. and Harvey, D.},
  date = {1998},
  journaltitle = {Controlled Clin Trials},
  volume = {19},
  pages = {15--24},
  doi = {10.1016/S0197-2456(97)00096-2},
  url = {http://dx.doi.org/10.1016/S0197-2456(97)00096-2},
  citeulike-article-id = {13265264},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0197-2456(97)00096-2},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-trials,data-management,double-data-entry,rct}
}

@article{de17sof,
  title = {{{SOFA}} and Mortality Endpoints in Randomized Controlled Trials: A Systematic Review and Meta-Regression Analysis},
  shorttitle = {{{SOFA}} and Mortality Endpoints in Randomized Controlled Trials},
  author = {de Grooth, Harm-Jan and Geenen, Irma L. and Girbes, Armand R. and Vincent, Jean-Louis and Parienti, Jean-Jacques and Oudemans-van Straaten, Heleen M.},
  options = {useprefix=true},
  date = {2017-02-24},
  journaltitle = {Crit Care},
  volume = {21},
  eprint = {28231816},
  eprinttype = {pmid},
  issn = {1364-8535},
  doi = {10.1186/s13054-017-1609-1},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5324238/},
  urldate = {2019-12-10},
  abstract = {Background The~sequential organ failure assessment score (SOFA) is increasingly used as an endpoint in intensive care randomized controlled trials (RCTs). Although serially measured SOFA is independently associated with mortality in observational cohorts, the association between treatment effects on SOFA vs. effects on mortality has not yet been quantified in RCTs. The aim of this study was to quantify the relationship between SOFA and mortality in RCTs and to identify which SOFA derivative best reflects between-group mortality differences. Methods The review protocol was prospectively registered (Prospero CRD42016034014). We performed a literature search (up to May 1, 2016) for RCTs reporting both SOFA and mortality, and analyzed between-group differences in these outcomes. Treatment effects on SOFA and mortality were calculated as the between-group SOFA standardized difference and log odds ratio (OR), respectively. We used random-effects meta-regression to (1) quantify the linear relationship between RCT treatment effects on mortality (logOR) and SOFA (i.e. responsiveness) and (2) quantify residual heterogeneity (i.e. consistency, expressed as I 2). Results Of 110 eligible RCTs, 87 qualified for analysis. Using all RCTs, SOFA was significantly associated with mortality (slope\,=\,0.49 (95\% CI 0.17; 0.82), p\,=\,0.006, I 2\,=\,5\%); the overall mortality effect explained by SOFA score (R 2) was 9\%. Fifty-eight RCTs used Fixed-day SOFA as an endpoint (i.e. the score on a fixed day after randomization), 25 studies used Delta SOFA as an endpoint (i.e. the trajectory from baseline score) and 15 studies used other SOFA derivatives as an endpoint. Fixed-day SOFA was not significantly associated with mortality (slope\,=\,0.35 (95\% CI −0.04; 0.75), p\,=\,0.08, I 2\,=\,12\%) and explained 3\% of the overall mortality effect (R 2). Delta SOFA was significantly associated with mortality (slope\,=\,0.70 (95\% CI 0.26; 1.14), p\,=\,0.004, I 2\,=\,0\%) and explained 32\% of the overall mortality effect (R 2). Conclusions Treatment effects on Delta SOFA appear to be reliably and consistently associated with mortality in RCTs. Fixed-day SOFA was the most frequently reported outcome among the reviewed RCTs, but was not significantly associated with mortality. Based on this study, we recommend using Delta SOFA rather than Fixed-day SOFA as an endpoint in future RCTs. Electronic supplementary material The online version of this article (doi:10.1186/s13054-017-1609-1) contains supplementary material, which is available to authorized users.},
  pmcid = {PMC5324238},
  keywords = {critical-illness,multiple-endpoints,rct,surrogate}
}

@article{de21joi,
  title = {Joint Control of Consensus and Evidence in {{Bayesian}} Design of Clinical Trials},
  author = {De Santis, Fulvio and Gubbiotti, Stefania},
  date = {2021},
  journaltitle = {Biometrical Journal},
  volume = {n/a},
  number = {n/a},
  issn = {1521-4036},
  doi = {10.1002/bimj.202100035},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202100035},
  urldate = {2021-12-11},
  abstract = {In Bayesian inference, prior distributions formalize preexperimental information and uncertainty on model parameters. Sometimes different sources of knowledge are available, possibly leading to divergent posterior distributions and inferences. Research has been recently devoted to the development of sample size criteria that guarantee agreement of posterior information in terms of credible intervals when multiple priors are available. In these articles, the goals of reaching consensus and evidence are typically kept separated. Adopting a Bayesian performance-based approach, the present article proposes new sample size criteria for superiority trials that jointly control the achievement of both minimal evidence and consensus, measured by appropriate functions of the posterior distributions. We develop both an average criterion and a more stringent criterion that accounts for the entire predictive distributions of the selected measures of minimal evidence and consensus. Methods are developed and illustrated via simulation for trials involving binary outcomes. A real clinical trial example on Covid-19 vaccine data is presented.},
  langid = {english},
  keywords = {bayes,prior,prior-elicitation,sample-size,teaching},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202100035}
}

@article{de21why,
  title = {Why Optional Stopping Can Be a Problem for {{Bayesians}}},
  author = {de Heide, Rianne and Grünwald, Peter D.},
  options = {useprefix=true},
  date = {2021-06-01},
  journaltitle = {Psychon Bull Rev},
  volume = {28},
  number = {3},
  pages = {795--812},
  issn = {1531-5320},
  doi = {10.3758/s13423-020-01803-x},
  url = {https://doi.org/10.3758/s13423-020-01803-x},
  urldate = {2022-03-24},
  abstract = {Recently, optional stopping has been a subject of debate in the Bayesian psychology community. Rouder (Psychonomic Bulletin \& Review 21(2), 301–308, 2014) argues that optional stopping is no problem for Bayesians, and even recommends the use of optional stopping in practice, as do (Wagenmakers, Wetzels, Borsboom, van der Maas \& Kievit, Perspectives on Psychological Science 7, 627–633, 2012). This article addresses the question of whether optional stopping is problematic for Bayesian methods, and specifies under which circumstances and in which sense it is and is not. By slightly varying and extending Rouder’s (Psychonomic Bulletin \& Review 21(2), 301–308, 2014) experiments, we illustrate that, as soon as the parameters of interest are equipped with default or pragmatic priors—which means, in most practical applications of Bayes factor hypothesis testing—resilience to optional stopping can break down. We distinguish between three types of default priors, each having their own specific issues with optional stopping, ranging from no-problem-at-all (type 0 priors) to quite severe (type II priors).},
  langid = {english},
  keywords = {bayes,bayes-factor,prior,sequential,sequential-monitoring,stopping},
  note = {Interesting taxonomy of priors}
}

@book{debBook,
  title = {A {{Practical Guide}} to {{Splines}}},
  author = {de Boor, Carl},
  options = {useprefix=true},
  date = {2001},
  edition = {Revised},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13263983},
  isbn = {0-387-95366-3},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@book{dee08mul,
  title = {Multivariate {{Data Visualization}} with {{R}}},
  author = {Deepayan, Sarkar},
  date = {2008},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265693},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {graphics,statistical-computing},
  annotation = {ISBN 978-0-387-75968-5}
}

@article{dee98qua,
  title = {Quantitative Refinements for Comparisons of Institutional Performance},
  author = {Deely, John J. and Smith, Adrian F. M.},
  date = {1998-01},
  journaltitle = {JRSSA},
  volume = {161},
  number = {1},
  pages = {5--12},
  publisher = {Blackwell Publishers Ltd.},
  doi = {10.1111/1467-985x.00087},
  url = {http://dx.doi.org/10.1111/1467-985x.00087},
  abstract = {In the context of the data and issues discussed by Goldstein and Spiegelhalter, we suggest refinements which can be used by decision makers when confronted with ranking problems associated with 'league tables'. Two ranking criteria are defined and their performance illustrated for one of the studies reported by Goldstein and Spiegelhalter.},
  citeulike-article-id = {13349284},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/1467-985x.00087},
  day = {1},
  posted-at = {2014-09-06 14:30:06},
  priority = {2},
  keywords = {poisson-regression,provider-profiling},
  note = {probability that a provider is worse than any other provider by a factor of c or greater}
}

@article{deg08mul,
  title = {Multiple Imputation to Correct for Partial Verification Bias Revisited},
  author = {de Groot, J. A. H. and Janssen, K. J. M. and Zwinderman, A. H. and Moons, K. G. M. and Reitsma, J. B.},
  options = {useprefix=true},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {5880--5889},
  citeulike-article-id = {13265544},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  note = {found a catastrophic error in har06mul;provided SAS and aregImpute code for doing multiple imputation in the presence of verification bias;see Stat in Med 28:899;2009}
}

@book{deg86pro,
  title = {Probability and {{Statistics}}},
  author = {DeGroot, M. H.},
  date = {1986},
  publisher = {{Addison Wesley}},
  location = {{Reading, MA}},
  citeulike-article-id = {13263985},
  posted-at = {2014-07-14 14:09:26},
  priority = {0}
}

@article{deg89,
  title = {Analysis of Doubly-Censored Survival Data, with Application to {{AIDS}}},
  author = {Gruttola, De},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {1--11},
  citeulike-article-id = {13263986},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {general,survival-analysis-regression}
}

@article{del01usi,
  title = {Using Observational Data to Estimate Prognosis: An Example Using a Coronary Artery Disease Registry},
  author = {DeLong, Elizabeth R. and Nelson, Charlotte L. and Wong, John B. and Pryor, David B. and Peterson, Eric D. and Lee, Kerry L. and Mark, Daniel B. and Califf, Robert M. and Pauker, Stephen G.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2505--2532},
  citeulike-article-id = {13265222},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {crossover,observational-data,prognostic-model,tutorial,waiting-time-bias},
  note = {tutorial in developing prognostic models for studies of medicine vs. surgery with crossovers}
}

@article{del09gif,
  title = {Gifi {{Methods}} for {{Optimal Scaling}} in {{R}}: {{The Package}} Homals},
  author = {de Leeuw, Jan and Mair, Patrick},
  options = {useprefix=true},
  date = {2009-08},
  journaltitle = {J Stat Software},
  volume = {31},
  number = {4},
  pages = {1--21},
  url = {http://www.jstatsoft.org/v31/i04},
  citeulike-article-id = {13265816},
  citeulike-linkout-0 = {http://www.jstatsoft.org/v31/i04},
  day = {4},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {multivariate-analysis,nonlinear-canonical-correlation,nonlinear-principal-components-analysis},
  note = {combines maximization of correlations with optimal scaling}
}

@article{del21ope,
  title = {Operational Characteristics of Generalized Pairwise Comparisons for Hierarchically Ordered Endpoints},
  author = {Deltuvaite-Thomas, Vaiva and Burzykowski, Tomasz},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2156},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2156},
  urldate = {2021-08-04},
  abstract = {The method of generalized pairwise comparisons (GPC) is a multivariate extension of the well-known non-parametric Wilcoxon–Mann–Whitney test. It allows comparing two groups of observations based on multiple hierarchically ordered endpoints, regardless of the number or type of the latter. The summary measure, “net benefit,” quantifies the difference between the probabilities that a random observation from one group is doing better than an observation from the opposite group. The method takes into account the correlations between the endpoints. We have performed a simulation study for the case of two hierarchical endpoints to evaluate the impact of their correlation on the type-I error probability and power of the test based on GPC. The simulations show that the power of the GPC test for the primary endpoint is modified if the secondary endpoint is included in the hierarchical GPC analysis. The change in power depends on the correlation between the endpoints. Interestingly, a decrease in power can occur, regardless of whether there is any marginal treatment effect on the secondary endpoint. It appears that the overall power of the hierarchical GPC procedure depends, in a complex manner, on the entire variance–covariance structure of the set of outcomes. Any additional factors (such as thresholds of clinical relevance, drop out, or censoring scheme) will also affect the power and will have to be taken into account when designing a trial based on the hierarchical GPC procedure.},
  langid = {english},
  keywords = {multiple-endpoints,multivariate,rct,wilcoxon-test},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2156}
}

@article{del88,
  title = {Comparing the Areas under Two or More Correlated Receiver Operating Characteristic Curves: {{A}} Nonparametric Approach},
  author = {DeLong ER, Clarke-Pearson D. L.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {837--845},
  citeulike-article-id = {13263987},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {diagnosis,predictive-accuracy,testing}
}

@article{del97com,
  title = {Comparing Risk-Adjustment Methods for Provider Profiling},
  author = {DeLong, Elizabeth R. and Peterson, Eric D. and DeLong, David M. and Muhlbaier, Lawrence H. and Hackett, Suzanne and Mark, Daniel B.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2645--2664},
  doi = {10.1002/(SICI)1097-0258(19971215)16:23\%3C2645::AID-SIM696\%3E3.0.CO;2-D},
  url = {http://dx.doi.org/10.1002/(SICI)1097-0258(19971215)16:23%3C2645::AID-SIM696%3E3.0.CO;2-D},
  citeulike-article-id = {13263988},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/(SICI)1097-0258(19971215)16:23%3C2645::AID-SIM696%3E3.0.CO;2-D},
  posted-at = {2014-07-14 14:09:26},
  priority = {0},
  keywords = {multiple-comparisons,provider-profiling,random-effects,risk-adjustment,scorecard},
  note = {random effects vs. fixed efects for providers}
}

@article{dem06tra,
  title = {Training of the next Generation of Biostatisticians: {{A}} Call to Action in the {{U}}.{{S}}.},
  author = {DeMets, David L. and Stormo, Gary and Boehnke, Michael and Louis, Thomas A. and Taylor, Jeremy and Dixon, Dennis},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {3415--3429},
  citeulike-article-id = {13265542},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {biostatistics,collaboration,graduate-program,job-market,supply-and-demand,training-grants,training-project},
  note = {"Most graduate students do not get adequate training in non-technical issues such as consulting, oral and written communication, leadership and management."; training programs should be interdisciplinary with a co-mentor beyond the department, e.g., a biomedical researcher co-advisor;trainees could rotate through biomedical research labs}
}

@article{dem07agr,
  title = {Agreement and Kappa-Type Indices},
  author = {de Mast, Jeroen},
  options = {useprefix=true},
  date = {2007},
  journaltitle = {Am Statistician},
  volume = {61},
  pages = {148--153},
  citeulike-article-id = {13265571},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {categorical-data,gauge-capability-analysis,measurement-system-analysis,nominal-data,observer-agreement,observer-variability,reliability,reproducibility},
  note = {kappa is a measure of predictive association rather than one purely of reproducibility}
}

@article{dem07sam,
  title = {Sample Size Determination for Logistic Regression Revisited},
  author = {Demidenko, Eugene},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3385--3397},
  doi = {10.1002/sim.2771},
  url = {http://dx.doi.org/10.1002/sim.2771},
  citeulike-article-id = {13265609},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2771},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {case-control-study,clinical-trials,fisher-information,logistic-model,logistic-regression,optimal-design,power-function,rct,sample-size,wald-test,z-score}
}

@article{dem12cur,
  title = {Current Development in Clinical Trials: Issues Old and New},
  author = {DeMets, David L.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {25},
  pages = {2944--2954},
  doi = {10.1002/sim.5405},
  url = {http://dx.doi.org/10.1002/sim.5405},
  abstract = {Clinical trials, especially the randomized clinical trial, have been and will remain the gold standard for the evaluation of new interventions, including pharmaceuticals, biologics, medical devices, procedures, or behavioral modifications. Despite more than five decades of experience, there are still challenges in their design, conduct, monitoring, and analyses. Some of these challenges remain and some are emerging, in part due to the progress in genomics and proteomics. These issues may be statistical, logistical, or a combination. Included are follow-up of subjects who withdraw from intervention, the proposed use of recent adaptive designs, implementing noninferiority designs, reliance on surrogate markers, and gene transfer studies. Comparative effectiveness studies are of increasing interest but present major design and analysis issues. Forces external to the trial are also becoming more common.},
  citeulike-article-id = {13265977},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5405},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {adaptive-design,noninferiority-design,randomized-trials,rct,surrogate-markers}
}

@article{dem12sim,
  title = {Simulation of Massive Public Health Data by Power Polynomials},
  author = {Demirtas, Hakan and Hedeker, Donald and Mermelstein, Robin J.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {27},
  pages = {3337--3346},
  doi = {10.1002/sim.5362},
  url = {http://dx.doi.org/10.1002/sim.5362},
  abstract = {Situations in which multiple outcomes and predictors of different distributional types are collected are becoming increasingly common in public health practice, and joint modeling of mixed types has been gaining popularity in recent years. Evaluation of various statistical techniques that have been developed for mixed data in simulated environments necessarily requires joint generation of multiple variables. Most massive public health data sets include different types of variables. For instance, in clustered or longitudinal designs, often multiple variables are measured or observed for each individual or at each occasion. This work is motivated by a need to jointly generate binary and possibly non-normal continuous variables. We illustrate the use of power polynomials to simulate multivariate mixed data on the basis of a real adolescent smoking study. We believe that our proposed technique for simulating such intensive data has the potential to be a handy methodological addition to public health researchers' toolkit.},
  citeulike-article-id = {13265953},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5362},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {biserial-correlation,fleishman-polynomials,phi-coefficient,random-number-generation,simulation,simulation-setup,tetrachoric-correlation}
}

@article{dem18cha,
  title = {Challenges of {{Non}}–{{Intention-to-Treat Analyses}}},
  author = {DeMets, David L. and Cook, Thomas},
  date = {2018-12-17},
  journaltitle = {JAMA},
  doi = {10.1001/jama.2018.19192},
  url = {https://jamanetwork.com/journals/jama/fullarticle/2719368},
  urldate = {2018-12-17},
  abstract = {reviews the rationale for intention-to-treat (ITT) analyses of randomized trials, explains how commonly used alternatives reintroduce confounding that randomization is intended to eliminate, and emphasizes that even an ITT analysis is no substitute for informed scientific and clinical judgement when...},
  langid = {english},
  keywords = {intent-to-treat,rct,rct-interpretation,teaching-mds}
}

@article{dem75pro,
  title = {On {{Probability}} as a {{Basis}} for {{Action}}},
  author = {Deming, W. Edwards},
  date = {1975-11},
  journaltitle = {Am Statistician},
  volume = {29},
  number = {4},
  pages = {146--152},
  publisher = {Taylor & Francis},
  doi = {10.1080/00031305.1975.10477402},
  url = {http://dx.doi.org/10.1080/00031305.1975.10477402},
  abstract = {Abstract The aim of the author is improvement of statistical practice. The author distinguishes between enumerative studies and analytic studies. An enumerative study has for its aim an estimate of the number of units of a frame that belong to a specified class. An analytic study has for its aim a basis for action on the cause-system or the process, in order to improve product of the future. A fair price to pay for an inventory is an example of an enumerative study. Tests of varieties of wheat, insecticides, drugs, manufacturing processes, are examples of analytic studies: the choice of variety or treatment will affect the future out-turn of wheat, future patients, future product. Techniques and methods of inference that are applicable to enumerative studies lead to faulty design and faulty inference for analytic problems. It is possible, in an enumerative problem, to reduce errors of sampling to any specified level. In contrast, in an analytic problem, it is impossible to compute the risk of making a wrong decision. The author provides a number of examples, and pleads for greater care in the writing and teaching of statistical theory and inference.},
  citeulike-article-id = {14104204},
  citeulike-attachment-1 = {dem75pro.pdf; /pdf/user/harrelfe/article/14104204/1113970/dem75pro.pdf; 2c54bed313fc6522de83637b49ab6b6f94615172},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00031305.1975.10477402},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1975.10477402},
  day = {1},
  posted-at = {2017-07-15 23:07:00},
  priority = {2},
  keywords = {clinical-decision-making,general}
}

@article{den01sam,
  title = {Sample Size Recalculation Using Conditional Power},
  author = {Denne, J. S.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2645--2660},
  citeulike-article-id = {13265510},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{den87,
  title = {An Example of the Use of Graphics in Regression},
  author = {{Denby}},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {33--38},
  citeulike-article-id = {13263989},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {graphical-methods,teaching}
}

@article{den98bay,
  title = {A {{Bayesian CART}} Algorithm},
  author = {Denison, David G. T. and Mallick, Bani K. and Smith, Adrian F. M.},
  date = {1998},
  journaltitle = {Biometrika},
  volume = {85},
  pages = {363--377},
  citeulike-article-id = {13263990},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bayesian-modeling,cart,choosing-most-probable-tree,recursive-partitioning,reversible-jump-mcmc}
}

@article{dep17imp,
  title = {Improving Transparency and Replication in {{Bayesian}} Statistics: {{The WAMBS-Checklist}}},
  shorttitle = {Improving Transparency and Replication in {{Bayesian}} Statistics},
  author = {Depaoli, Sarah and van de Schoot, Rens},
  options = {useprefix=true},
  date = {2017-06},
  journaltitle = {Psychol Methods},
  volume = {22},
  number = {2},
  eprint = {26690773},
  eprinttype = {pmid},
  pages = {240--261},
  issn = {1939-1463},
  doi = {10.1037/met0000065},
  abstract = {Bayesian statistical methods are slowly creeping into all fields of science and are becoming ever more popular in applied research. Although it is very attractive to use Bayesian statistics, our personal experience has led us to believe that naively applying Bayesian methods can be dangerous for at least 3 main reasons: the potential influence of priors, misinterpretation of Bayesian features and results, and improper reporting of Bayesian results. To deal with these 3 points of potential danger, we have developed a succinct checklist: the WAMBS-checklist (When to worry and how to Avoid the Misuse of Bayesian Statistics). The purpose of the questionnaire is to describe 10 main points that should be thoroughly checked when applying Bayesian analysis. We provide an account of "when to worry" for each of these issues related to: (a) issues to check before estimating the model, (b) issues to check after estimating the model but before interpreting results, (c) understanding the influence of priors, and (d) actions to take after interpreting results. To accompany these key points of concern, we will present diagnostic tools that can be used in conjunction with the development and assessment of a Bayesian model. We also include examples of how to interpret results when "problems" in estimation arise, as well as syntax and instructions for implementation. Our aim is to stress the importance of openness and transparency of all aspects of Bayesian estimation, and it is our hope that the WAMBS questionnaire can aid in this process. (PsycINFO Database Record},
  langid = {english},
  keywords = {basic,bayes,diagnostics,reporting}
}

@article{der86met,
  title = {Meta-Analysis in Clinical Trials},
  author = {DerSimonian, R. and Laird, N.},
  date = {1986},
  journaltitle = {Controlled Clin Trials},
  volume = {7},
  pages = {177--188},
  citeulike-article-id = {13263991},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {empirical-bayes,meta-analysis,random-effects-model}
}

@article{der92bac,
  title = {Backward, Forward and Stepwise Automated Subset Selection Algorithms: {{Frequency}} of Obtaining Authentic and Noise Variables},
  author = {Derksen, S. and Keselman, H. J.},
  date = {1992},
  journaltitle = {British J Math Stat Psych},
  volume = {45},
  pages = {265--282},
  citeulike-article-id = {13263992},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {variable-selection}
}

@article{det88,
  title = {Reliability of {{Bayesian}} Probability Analysis for Predicting Coronary Artery Disease in a Veterans Hospital},
  author = {Detrano, R. and Guppy, K. H. and Abbassii, N. and {Em Et Al}},
  date = {1988},
  journaltitle = {J Clin Epi},
  volume = {41},
  pages = {599--605},
  citeulike-article-id = {13263995},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {diagnosis,predictive-accuracy,testing}
}

@article{deu02sem,
  title = {A Seminar Series in Applied Biostatistics for Clinical Research Fellows, Faculty and Staff},
  author = {Deutsch, Reena},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {801--810},
  citeulike-article-id = {13265270},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {short-course,teaching-mds}
}

@article{deu07rol,
  title = {The Role of Education in Biostatistical Consulting},
  author = {Deutsch, Reena and Hurwitz, Shelley and Janosky, Janine and Oster, Robert},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {709--720},
  citeulike-article-id = {13265557},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {clinics,consulting,statistical-consultant,statistical-education,teaching},
  note = {"both the need and the opportunity exist for specialized biostatistical instruction during one-on-one sessions between a consulting biostatistician and physicians, medical students, and research staff. Academic researchers are ideally positioned to absorb this kind of training when they initiate a request for assistance with their own research project."}
}

@inproceedings{dev86,
  title = {Spline Functions for Logistic Regression Modeling},
  booktitle = {Proceedings of the {{Eleventh Annual SAS Users Group International Conference}}},
  author = {Devlin, T. F. and Weeks, B. J.},
  date = {1986},
  pages = {646--651},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary, NC}},
  citeulike-article-id = {13263996},
  posted-at = {2014-07-14 14:09:27},
  priority = {0}
}

@article{dia04pri,
  title = {Prior Convictions: {{Bayesian}} Approaches to the Analysis and Interpretation of Clinical Megatrials},
  author = {Diamond, George A. and Kaul, S.},
  date = {2004},
  journaltitle = {J Am Coll Cardiol},
  volume = {43},
  pages = {1929--1939},
  citeulike-article-id = {13265467},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  note = {Bayesian analysis of clinical trials;used normal approximation to likelihood to get a variety of simple posterior calculations}
}

@article{dia16mea,
  title = {Measuring the Individual Benefit of a Medical or Behavioral Treatment Using Generalized Linear Mixed-Effects Models},
  author = {Diaz, Francisco J.},
  date = {2016-10},
  journaltitle = {Stat Med},
  volume = {35},
  number = {23},
  pages = {4077--4092},
  issn = {02776715},
  doi = {10.1002/sim.7005},
  url = {http://dx.doi.org/10.1002/sim.7005},
  citeulike-article-id = {14219630},
  citeulike-attachment-1 = {dia16mea.pdf; /pdf/user/harrelfe/article/14219630/1093605/dia16mea.pdf; 7aa940687a13f2c677c8b9676b4f32b694a0972c},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7005},
  day = {15},
  posted-at = {2016-12-04 16:17:05},
  priority = {0},
  keywords = {individual-response,mixed-effects-model,mixed-models,personalized-medicine},
  note = {Formal analysis of individual response to treatment, generalizing some of Senn's work}
}

@article{dia19eff,
  title = {Efficient Methods for Signal Detection from Correlated Adverse Events in Clinical Trials},
  author = {Diao, Guoqing and Liu, Guanghan F. and Zeng, Donglin and Wang, William and Tan, Xianming and Heyse, Joseph F. and Ibrahim, Joseph G.},
  date = {2019},
  journaltitle = {Biometrics},
  volume = {0},
  number = {0},
  issn = {1541-0420},
  doi = {10.1111/biom.13031},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13031},
  urldate = {2019-04-01},
  abstract = {It is an important and yet challenging task to identify true signals from many adverse events that may be reported during the course of a clinical trial. One unique feature of drug safety data from clinical trials, unlike data from post-marketing spontaneous reporting, is that many types of adverse events are reported by only very few patients leading to rare events. Due to the limited study size, the p-values of testing whether the rate is higher in the treatment group across all types of adverse events are in general not uniformly distributed under the null hypothesis that there is no difference between the treatment group and the placebo group. A consequence is that typically fewer than percent of the hypotheses are rejected under the null at the nominal significance level of . The other challenge is multiplicity control. Adverse events from the same body system may be correlated. There may also be correlations between adverse events from different body systems. To tackle these challenging issues, we develop Monte-Carlo-based methods for the signal identification from patient-reported adverse events in clinical trials. The proposed methodologies account for the rare events and arbitrary correlation structures among adverse events within and/or between body systems. Extensive simulation studies demonstrate that the proposed method can accurately control the family-wise error rate and is more powerful than existing methods under many practical situations. Application to two real examples is provided.},
  langid = {english},
  keywords = {pharmaceutical-safety,safety,safety-monitoring,signal-detection}
}

@article{dia83cli,
  title = {Clinical Trials and Statistical Verdicts: {{Probable}} Grounds for Appeal ( {{Note}}: This Article Contains Some Serious Statistical Errors)},
  author = {Diamond, George A. and Forrester, James S.},
  date = {1983},
  journaltitle = {Ann Int Med},
  volume = {98},
  pages = {385--394},
  citeulike-article-id = {13263997},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {posterior-odds,posterior-probabilities-vs-p-values}
}

@article{dia86,
  title = {Proportional Hazards Models for Current Status Data: {{Application}} to the Study of Differentials in Age at Weaning in {{Paki}}},
  author = {Diamond ID, Shah I. H.},
  date = {1986},
  journaltitle = {Demography},
  volume = {23},
  pages = {607--620},
  citeulike-article-id = {13263998},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {survival-analysis-discrete-failure-time,survival-analysis-proportional-hazards-model}
}

@article{dia89,
  title = {Methods for Studying Coincidences},
  author = {{Diaconis}},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {853--861},
  citeulike-article-id = {13263999},
  posted-at = {2014-07-14 14:09:27},
  priority = {0}
}

@article{dic89pro,
  title = {Prognosis in Primary Biliary Cirrhosis: {{Model}} for Decision Making},
  author = {Dickson, E. R. and Grambsch, P. M. and Fleming, T. R. and Fisher, L. D. and Langworthy, A.},
  date = {1989},
  journaltitle = {Hepatology},
  volume = {10},
  pages = {1--7},
  citeulike-article-id = {13264000},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {survival-analysis-example}
}

@article{dic92mor,
  title = {More Accurate Confidence Intervals in Exponential Families},
  author = {DiCiccio, Thomas and Efron, Bradley},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {231--245},
  citeulike-article-id = {13264001},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {confidence-interval,maximum-likelihood}
}

@article{die97eff,
  title = {Effect Size and Power for Clinical Trials That Measure Years of Healthy Life},
  author = {Diehr, Paula and Psaty, Bruce M. and Patrick, Donald L.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1211--1223},
  citeulike-article-id = {13264002},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {change-score,qaly,serial-measurements,study-design,years-of-healthy-life}
}

@article{dig08joi,
  title = {Joint Modelling of Repeated Measurements and Time-to-Even Outcomes: {{The}} Fourth {{Armitage}} Lecture},
  author = {Diggle, Peter J. and Sousa, Ines and Chetwynd, Amanda G.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {2981--2998},
  citeulike-article-id = {13265688},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {failure-time,joint-modeling,longitudinal-analysis}
}

@article{dig21tut,
  title = {Tutorial on {{Directed Acyclic Graphs}}},
  author = {Digitale, Jean C. and Martin, Jeffrey N. and Glymour, M. Maria},
  date = {2021-08-06},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.08.001},
  url = {https://www.jclinepi.com/article/S0895-4356(21)00240-7/abstract},
  urldate = {2021-08-06},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}p{$>$}Directed acyclic graphs (DAGs) are an intuitive yet rigorous tool to communicate about causal questions in clinical and epidemiologic research and inform study design and statistical analysis. DAGs are constructed to depict prior knowledge about biological and behavioral systems related to specific causal research questions. DAG components portray who receives treatment or experience exposures; mechanisms by which treatments and exposures operate; and other factors that influence the outcome of interest or which persons are included in an analysis. Once assembled, DAGs — via a few simple rules — guide the researcher in identifying whether the causal effect of interest can be identified without bias and, if so, what must be done either in study design or data analysis to achieve this. Specifically, DAGs can identify variables that, if controlled for in the design or analysis phase, are sufficient to eliminate confounding and some forms of selection bias. DAGs also help recognize variables that, if controlled for, bias the analysis (e.g., mediators or factors influenced by both exposure and outcome). Finally, DAGs help researchers recognize insidious sources of bias introduced by selection of individuals into studies or failure to completely observe all individuals until study outcomes are reached. DAGs, however, are not infallible, largely owing to limitations in prior knowledge about the system in question. In such instances, several alternative DAGs are plausible, and researchers should assess whether results differ meaningfully across analyses guided by different DAGs and be forthright about uncertainty. DAGs are powerful tools to guide the conduct of clinical research.{$<$}/p{$>$}},
  langid = {english},
  keywords = {causal-inference,causal-model,dag,teaching}
}

@article{dig94inf,
  title = {Informative Drop-out in Longitudinal Data Analysis (with Discussion)},
  author = {Diggle, P. and Kenward, M. G.},
  date = {1994},
  journaltitle = {Appl Stat},
  volume = {43},
  pages = {49--93},
  citeulike-article-id = {13264003},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {informative-censoring,longitudinal-data,multiple-events,repeated-measures}
}

@book{diggle-longit,
  title = {Analysis of {{Longitudinal Data}}},
  author = {Diggle, Peter J. and Heagerty, Patrick and Liang, Kung-Yee and Zeger, Scott L.},
  date = {2002},
  edition = {second},
  publisher = {{Oxford University Press}},
  location = {{Oxford UK}},
  citeulike-article-id = {13265322},
  posted-at = {2014-07-14 14:09:54},
  priority = {0}
}

@article{din18dec,
  title = {Decomposing {{Treatment Effect Variation}}},
  author = {Ding, Peng and Feller, Avi and Miratrix, Luke},
  date = {2018-01-15},
  journaltitle = {Journal of the American Statistical Association},
  pages = {1--14},
  issn = {0162-1459},
  doi = {10.1080/01621459.2017.1407322},
  url = {https://amstat.tandfonline.com/doi/full/10.1080/01621459.2017.1407322},
  urldate = {2019-01-18},
  abstract = {Understanding and characterizing treatment effect variation in randomized experiments has become essential for going beyond the “black box” of the average treatment effect. Nonetheless, traditional statistical approaches often ignore or assume away such variation. In the context of randomized experiments, this article proposes a framework for decomposing overall treatment effect variation into a systematic component explained by observed covariates and a remaining idiosyncratic component. Our framework is fully randomization-based, with estimates of treatment effect variation that are entirely justified by the randomization itself. Our framework can also account for noncompliance, which is an important practical complication. We make several contributions. First, we show that randomization-based estimates of systematic variation are very similar in form to estimates from fully interacted linear regression and two-stage least squares. Second, we use these estimators to develop an omnibus test for systematic treatment effect variation, both with and without noncompliance. Third, we propose an R2-like measure of treatment effect variation explained by covariates and, when applicable, noncompliance. Finally, we assess these methods via simulation studies and apply them to the Head Start Impact Study, a large-scale randomized experiment. Supplementary materials for this article are available online.},
  keywords = {differential-treatment-effect,hte,RCT}
}

@article{div10exe,
  title = {Exemplary Data Set Sample Size Calculation for {{Wilcoxon--Mann--Whitney}} Tests},
  author = {Divine, George and Kapke, Alissa and Havstad, Suzanne and Joseph, Christine L. M.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  number = {1},
  pages = {108--115},
  citeulike-article-id = {13265825},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {exemplary-data-set-method-of-ralph-obrien,non-centrality-parameter,sample-size,wilcoxon-mann-whitney}
}

@article{dix91bay,
  title = {Bayesian Subset Analysis},
  author = {Dixon, D. O. and Simon, R.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {871--881},
  citeulike-article-id = {13264004},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bayesian-inference,shrinkage,subgroup-analysis}
}

@article{dix92bay,
  title = {Bayesian Subset Analysis in a Colorecta Cancer Clinical Trial},
  author = {Dixon, D. O. and Simon, R.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {13--22},
  citeulike-article-id = {13264005},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bayes,bayesian-inference,rct,shrinkage,subgroup-analysis}
}

@article{dmi02ana,
  title = {Analysis of the {{QT}} Interval in Clinical Trials},
  author = {Dmitrienko, Alex and Smith, Brian P.},
  date = {2002},
  journaltitle = {Drug Info J},
  volume = {36},
  pages = {269--279},
  citeulike-article-id = {13265283},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {cardiac-repolarization,clinical-safety,corrected-qt,pharmaceutical-safety,qt-interval,rct},
  note = {problems caused by longitudinal changes in heart rate}
}

@article{dog93com,
  title = {Comparisons of Approximate Confidence Intervals for Distributions Used in Life-Data Analysis},
  author = {Doganaksoy, Necip and Schmee, Josef},
  date = {1993},
  journaltitle = {Technometrics},
  volume = {35},
  pages = {175--184},
  citeulike-article-id = {13264006},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {confidence-limits,maximum-likelihood}
}

@article{doh81eff,
  title = {The Effects of {{Disobutamide}} on Electrophysiologic Properties of Canine Cardiac {{Purkinje}} Fibers and Papillary Muscle},
  author = {Dohrmann, M. L. and Harrell, F. E. and Strauss, H. C.},
  date = {1981},
  journaltitle = {J Pharm Exp Ther},
  volume = {217},
  pages = {549--554},
  citeulike-article-id = {13264007},
  posted-at = {2014-07-14 14:09:27},
  priority = {0}
}

@article{doi20que,
  title = {Questionable Utility of the Relative Risk in Clinical Research: {{A}} Call for Change to Practice},
  shorttitle = {Questionable Utility of the Relative Risk in Clinical Research},
  author = {Doi, Suhail A. and Furuya-Kanamori, Luis and Xu, Chang and Lin, Lifeng and Chivese, Tawanda and Thalib, Lukman},
  date = {2020-11-07},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  eprint = {33171273},
  eprinttype = {pmid},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2020.08.019},
  url = {https://www.jclinepi.com/article/S0895-4356(20)31171-9/abstract},
  urldate = {2020-11-22},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}In clinical trials, the relative risk or risk ratio (RR) is a mainstay of reporting of the effect magnitude for an intervention. The RR is the ratio of the probability of an outcome in an intervention group to its probability in a control group. Thus the RR provides a measure of change in the likelihood of an event linked to a given intervention. This measure has been widely used because it is today considered a measure with ‘portability' across varying outcome prevalence, especially when the outcome is rare. It turns out however that there is a much more important problem with this ratio, and this paper aims to demonstrate this problem.{$<$}/p{$><$}h3{$>$}Methods{$<$}/h3{$><$}p{$>$}We used mathematical derivation to determine if the RR is a measure of effect magnitude alone (i.e. a larger absolute value always indicating a stronger effect) or not. We also used the same derivation to determine its relationship to prevalence of an outcome. We confirm the derivation results with a follow-up analysis of 140,620 trials scraped from the Cochrane.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}We demonstrate that the RR varies for reasons other than magnitude of the effect because it is a ratio of two posterior probabilities, both of which are dependent on baseline prevalence of an outcome. Additionally we demonstrate that the RR shifts towards its null value with increasing outcome prevalence. The shift towards the null happens regardless of the strength of the association between intervention and outcome. The odds ratio (OR), the other commonly used ratio, measures solely the effect magnitude and has no relationship to prevalence of an outcome in a study nor does it overestimate the RR as is commonly thought.{$<$}/p{$><$}h3{$>$}Conclusions{$<$}/h3{$><$}p{$>$}The results demonstrate the need to a) end the primary use of the RR in clinical trials and meta-analyses as its direct interpretation is not meaningful; b) replace the RR by the OR; and c) only use the post-intervention risk recalculated from the OR for any expected level of baseline risk in absolute terms for purposes of interpretation such as the number needed to treat. These results will have far reaching implications such as reducing misleading results from clinical trials and meta-analyses and ushering in a new era in the reporting of such trials or meta-analyses in practice.{$<$}/p{$>$}},
  langid = {english},
  keywords = {association-measures,association-parameter,odds-ratio,or,risk-ratio}
}

@article{dom89,
  title = {An Evaluation of Simulation-Based Quantile Estimators},
  author = {Doman LE, Jernigan R. W.},
  date = {1989},
  journaltitle = {Proc Stat Comp Sect ASA},
  volume = {0},
  pages = {110--115},
  citeulike-article-id = {13264008},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {order-statistics,quantiles}
}

@article{don06rev,
  title = {Review: {{A}} Gentle Introduction to Imputation of Missing Values},
  author = {{Donders} and van der Heijden, Geert J. M. G. and Stijnen, Theo and Moons, Karel G. M.},
  options = {useprefix=true},
  date = {2006},
  journaltitle = {J Clin Epi},
  volume = {59},
  pages = {1087--1091},
  citeulike-article-id = {13265491},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {imputation,missing-data,teaching-mds},
  note = {simple demonstration of failure of the add new category method (indicator variable)}
}

@article{don16gen,
  title = {A Generalized Analytic Solution to the Win Ratio to Analyze a Composite Endpoint Considering the Clinical Importance Order among Components},
  author = {Dong, Gaohong and Li, Di and Ballerstedt, Steffen and Vandemeulebroecke, Marc},
  date = {2016},
  journaltitle = {Pharm Stat},
  issn = {15391604},
  doi = {10.1002/pst.1763},
  url = {http://dx.doi.org/10.1002/pst.1763},
  citeulike-article-id = {14112183},
  citeulike-attachment-1 = {don16gen.pdf; /pdf/user/harrelfe/article/14112183/1080330/don16gen.pdf; 6569d6cd68301833bd0ac954ea138d7477c4164e},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1763},
  posted-at = {2016-08-12 12:48:49},
  priority = {3},
  keywords = {multiple-endpoints,ordinal-response,time-and-severity-of-event,time-to-event-data}
}

@article{don1750,
  title = {50 {{Years}} of {{Data Science}}},
  author = {Donoho, David},
  date = {2017-10-02},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {26},
  number = {4},
  pages = {745--766},
  issn = {1061-8600},
  doi = {10.1080/10618600.2017.1384734},
  url = {https://doi.org/10.1080/10618600.2017.1384734},
  urldate = {2019-09-27},
  abstract = {More than 50 years ago, John Tukey called for a reformation of academic statistics. In “The Future of Data Analysis,” he pointed to the existence of an as-yet unrecognized science, whose subject of interest was learning from data, or “data analysis.” Ten to 20 years ago, John Chambers, Jeff Wu, Bill Cleveland, and Leo Breiman independently once again urged academic statistics to expand its boundaries beyond the classical domain of theoretical statistics; Chambers called for more emphasis on data preparation and presentation rather than statistical modeling; and Breiman called for emphasis on prediction rather than inference. Cleveland and Wu even suggested the catchy name “data science” for this envisioned field. A recent and growing phenomenon has been the emergence of “data science” programs at major universities, including UC Berkeley, NYU, MIT, and most prominently, the University of Michigan, which in September 2015 announced a \$100M “Data Science Initiative” that aims to hire 35 new faculty. Teaching in these new programs has significant overlap in curricular subject matter with traditional statistics courses; yet many academic statisticians perceive the new programs as “cultural appropriation.” This article reviews some ingredients of the current “data science moment,” including recent commentary about data science in the popular media, and about how/whether data science is really different from statistics. The now-contemplated field of data science amounts to a superset of the fields of statistics and machine learning, which adds some technology for “scaling up” to “big data.” This chosen superset is motivated by commercial rather than intellectual developments. Choosing in this way is likely to miss out on the really important intellectual event of the next 50 years. Because all of science itself will soon become data that can be mined, the imminent revolution in data science is not about mere “scaling up,” but instead the emergence of scientific studies of data analysis science-wide. In the future, we will be able to predict how a proposal to change data analysis workflows would impact the validity of data analysis across all of science, even predicting the impacts field-by-field. Drawing on work by Tukey, Cleveland, Chambers, and Breiman, I present a vision of data science based on the activities of people who are “learning from data,” and I describe an academic field dedicated to improving that activity in an evidence-based manner. This new field is a better academic enlargement of statistics and machine learning than today’s data science initiatives, while being able to accommodate the same short-term goals. Based on a presentation at the Tukey Centennial Workshop, Princeton, NJ, September 18, 2015.},
  keywords = {data-science,exploratory-data-analysis,history-of-statistics}
}

@article{don19win,
  title = {The Win Ratio: {{Impact}} of Censoring and Follow-up Time and Use with Nonproportional Hazards},
  shorttitle = {The Win Ratio},
  author = {Dong, Gaohong and Huang, Bo and Chang, Yu-Wei and Seifu, Yodit and Song, James and Hoaglin, David C.},
  date = {2019},
  journaltitle = {Pharmaceutical Statistics},
  volume = {0},
  number = {0},
  issn = {1539-1612},
  doi = {10.1002/pst.1977},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1977},
  urldate = {2019-11-03},
  abstract = {The win ratio has been studied methodologically and applied in data analysis and in designing clinical trials. Researchers have pointed out that the results depend on follow-up time and censoring time, which are sometimes used interchangeably. In this article, we distinguish between follow-up time and censoring time, show theoretically the impact of censoring on the win ratio, and illustrate the impact of follow-up time. We then point out that, if the treatment has long-term benefit from a more important but less frequent endpoint (eg, death), the win ratio can show that benefit by following patients longer, avoiding masking by more frequent but less important outcomes, which occurs in conventional time-to-first-event analyses. For the situation of nonproportional hazards, we demonstrate that the win ratio can be a good alternative to methods such as landmark survival rate, restricted mean survival time, and weighted log-rank tests.},
  langid = {english},
  keywords = {multiple-endpoints,non-ph,win-ratio}
}

@article{don81ran,
  title = {Randomization by Cluster: {{Sample}} Size Requirements and Analysis},
  author = {Donner, A. and Birkett, N. and Buck, C.},
  date = {1981},
  journaltitle = {Am J Epi},
  volume = {114},
  pages = {906--914},
  citeulike-article-id = {13264009},
  posted-at = {2014-07-14 14:09:27},
  priority = {0}
}

@article{don82rel,
  title = {The Relative Effectiveness of Procedures Commonly Used in Multiple Regression Analysis for Dealing with Missing Values},
  author = {Donner, Allan},
  date = {1982},
  journaltitle = {Am Statistician},
  volume = {36},
  pages = {378--381},
  citeulike-article-id = {13264010},
  posted-at = {2014-07-14 14:09:27},
  priority = {0}
}

@article{don87ana,
  title = {Analysis of Data Arising from a Stratified Design with the Cluster as Unit of Randomization},
  author = {Donner, Allan and Donald, Alan},
  date = {1987},
  journaltitle = {Stat Med},
  volume = {6},
  pages = {43--52},
  citeulike-article-id = {13265123},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {cluster-randomization,clustered-data,community-trials,intraclass-correlation}
}

@article{don89,
  title = {Statistical Methods in Ophthalmology: {{An}} Adjusted Chi-Square Approach},
  author = {Donner, A.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {605--611},
  citeulike-article-id = {13264011},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{don90,
  title = {The Relationship between Chi-Square Statistics from Matched and Unmatched Analyses},
  author = {{Donner}},
  date = {1990},
  journaltitle = {J Clin Epi},
  volume = {43},
  pages = {827--831},
  citeulike-article-id = {13264012},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {case-control-studies,categorical-data,matching}
}

@article{don93con,
  title = {Confidence Interval Construction for Effect Measures Arising from Cluster Randomization Trials},
  author = {Donner, Allan and Klar, Neil},
  date = {1993},
  journaltitle = {J Clin Epi},
  volume = {46},
  pages = {123--131},
  citeulike-article-id = {13265122},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {cluster-randomization,clustered-data,community-trials,intraclass-correlation,odds-ratio}
}

@article{don96sta,
  title = {Statistical Considerations in the Design and Analysis of Community Intervention Trials},
  author = {Donner, Allan and Klar, Neil},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {435--439},
  citeulike-article-id = {13264013},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {cluster-sampling,multivariate,study-design}
}

@article{don98som,
  title = {Some Aspects of the Design and Analysis of Cluster Randomization Trials},
  author = {Donner, Allan},
  date = {1998},
  journaltitle = {Appl Stat},
  volume = {47},
  pages = {95--113},
  citeulike-article-id = {13264014},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {correlated-binary-data,group-randomization,rct,sample-size,study-design}
}

@article{don99not,
  title = {A Note on Information Seldon Reported via the {{P}} Value},
  author = {Donahue, Rafe M. J.},
  date = {1999},
  journaltitle = {Am Statistician},
  volume = {53},
  pages = {303--306},
  citeulike-article-id = {13264015},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {distribution-of-p-value-under-alternative-hypothesis}
}

@article{double98,
  title = {Double Data Entry},
  author = {{Various}},
  date = {1998},
  journaltitle = {Controlled Clin Trials},
  volume = {19},
  citeulike-article-id = {13264016},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {1-letter,double-data-entry-2-articles}
}

@article{dra93eff,
  title = {Effects of Misspecification of the Propensity Score on Estimators of Treatment Effect},
  author = {Drake, Christiana},
  date = {1993},
  journaltitle = {Biometrics},
  volume = {49},
  pages = {1231--1236},
  citeulike-article-id = {13264017},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bias,confounding,observation-study,propensity-score}
}

@article{dra95ass,
  title = {Assessment and Propagation of Model Uncertainty (with Discussion)},
  author = {Draper, David},
  date = {1995},
  journaltitle = {J Roy Stat Soc B},
  volume = {57},
  pages = {45--97},
  citeulike-article-id = {13264018},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {model-uncertainty},
  note = {cha95mod P. 439 states that Draper concludes you should find a good model and expand around it}
}

@article{dro95dyn,
  title = {Dynamic Treatment Allocation Adjusting for Prognostic Factors for More than Two Treatments},
  author = {Dror, Shuki and Faraggi, David and Reiser, Benjamin},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {1338--1343},
  citeulike-article-id = {13264019},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {baseline-adjustment,covariable-adjustment,dynamic-treatment-allocation,optimality-theory,permuted-block,prognostic-factors,study-design}
}

@article{dru93com,
  title = {Comment on {{Regression}} Models for Discrete Longitudinal Responses by {{G}}. {{M}}. {{Fitzmaurice}}, {{N}}. {{M}}. {{Laird}}, and {{A}}. {{G}}. {{Rotnitzky}}},
  author = {Drum, Melinda and McCullagh, Peter},
  date = {1993},
  journaltitle = {Stat Sci},
  volume = {8},
  pages = {300--301},
  citeulike-article-id = {13264020},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {huber-sandwich-estimator,maximum-likelihood,robust-variance-estimation}
}

@article{dru96gui,
  title = {Guidelines for Authors and Peer Reviewers of Economic Submissions to the {{BMJ}}},
  author = {Drummond, M. F. and Jefferson, T. O. and Economic Evalation Working Party, The B. M. J.},
  date = {1996},
  journaltitle = {BMJ},
  volume = {313},
  pages = {275--283},
  citeulike-article-id = {13264021},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {cost-effectiveness-analysis,economic-evaluation,teaching-mds}
}

@article{du15lik,
  title = {Likelihood Approach for Evaluating Bioequivalence of Highly Variable Drugs},
  author = {Du, Liping and Choi, Leena},
  date = {2015-03},
  journaltitle = {Pharm Stat},
  volume = {14},
  number = {2},
  pages = {82--94},
  issn = {15391604},
  doi = {10.1002/pst.1661},
  url = {http://dx.doi.org/10.1002/pst.1661},
  citeulike-article-id = {14033210},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1661},
  posted-at = {2016-05-11 12:48:25},
  priority = {2},
  keywords = {ctsafac}
}

@article{du21las,
  title = {Lasso Estimation of Hierarchical Interactions for Analyzing Heterogeneity of Treatment Effect},
  author = {Du, Yu and Chen, Huan and Varadhan, Ravi},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9132},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9132},
  urldate = {2021-07-17},
  abstract = {Individuals differ in how they respond to a given treatment. In an effort to predict the treatment response and analyze the heterogeneity of treatment effect, we propose a general modeling framework by identifying treatment-covariate interactions honoring a hierarchical condition. We construct a single-step l1 norm penalty procedure that maintains the hierarchical structure of interactions in the sense that a treatment-covariate interaction term is included in the model only when either the covariate or both the covariate and treatment have nonzero main effects. We developed a constrained Lasso approach with two parameterization schemes that enforce the hierarchical interaction restriction differently. We solved the resulting constrained optimization problem using a spectral projected gradient method. We compared our methods to the unstructured Lasso using simulation studies including a scenario that violates the hierarchical condition (misspecified model). The simulations showed that our methods yielded more parsimonious models and outperformed the unstructured Lasso for correctly identifying nonzero treatment-covariate interactions. The superior performance of our methods are also corroborated by an application to a large randomized clinical trial data investigating a drug for treating congestive heart failure (N = 2569). Our methods provide a well-suited approach for doing secondary analysis in clinical trials to analyze heterogeneous treatment effects and to identify predictive biomarkers.},
  langid = {english},
  keywords = {differential-effects,hte,interaction,lasso},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9132}
}

@article{dua21ref,
  title = {Reflection on Modern Methods: Understanding Bias and Data Analytical Strategies through {{DAG-based}} Data Simulations},
  shorttitle = {Reflection on Modern Methods},
  author = {Duan, Chongyang and Dragomir, Anca D and Luta, George and Breitling, Lutz P},
  date = {2021-05-10},
  journaltitle = {International Journal of Epidemiology},
  issn = {0300-5771},
  doi = {10.1093/ije/dyab096},
  url = {https://doi.org/10.1093/ije/dyab096},
  urldate = {2021-05-16},
  abstract = {Directed acyclic graphs (DAGs) are increasingly used in epidemiology to identify and address different types of bias. The present work aims to demonstrate how DAG-based data simulation can be used to understand bias and compare data analytical strategies in an educational context. Examples based on classical confounding situations and an M-DAG are examined and used to introduce basic concepts and demonstrate some important features of regression analysis, as well as the harmful effect of adjusting for a collider variable. Other potential uses of DAG-based data simulation include systematic comparisons of data analytical strategies or the evaluation of the role of uncertainties in a hypothesized DAG structure, including other types of bias such as information bias. DAG-based data simulations, like those presented here, should facilitate the exploration of several key epidemiological concepts, DAG theory and data analysis. Some suggestions are also made on how to further expand the ideas from this study.},
  issue = {dyab096},
  keywords = {causal-inference,causal-model,causality,dag,simulation}
}

@article{dua83com,
  title = {A Comparison of Alternative Models for the Demand for Medical Care},
  author = {Duan, Naihua and Manning, Willard G. and Morris, Carl N. and Newhouse, Joseph P.},
  date = {1983},
  journaltitle = {Journal of Business \& Economic Statistics},
  volume = {1},
  pages = {115--126},
  citeulike-article-id = {13264024},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {analysis-of-cost,clumping-at-zero,resource-utilization,smearing},
  note = {good description of 2 and 4-part model;see dua83sme}
}

@article{dua83sme,
  title = {Smearing Estimate: {{A}} Nonparametric Retransformation Method},
  author = {Duan, Naihua},
  date = {1983},
  journaltitle = {J Am Stat Assoc},
  volume = {78},
  pages = {605--610},
  citeulike-article-id = {13264022},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {analysis-of-cost,empirical-cdf,log-normal-distribution,nonparametric,retransformation,see-dua83com,smearing-estimate}
}

@article{dub01eve,
  title = {Event History Graphs for Censored Data},
  author = {Dubin, Joel A. and Müller, Hans-George and Wang, Jane-Ling},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2951--2964},
  citeulike-article-id = {13265227},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {event-chart,event-history-chart,s-function}
}

@article{duc02bey,
  title = {Beyond Traditional Statistical Methods},
  author = {Duckworth, William M. and Stephenson, W. Robert},
  date = {2002},
  journaltitle = {Am Statistician},
  volume = {56},
  pages = {230--233},
  citeulike-article-id = {13265288},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {computer-intensive,instructional-modules,statistics-education,teaching-statistics},
  note = {"the scientists and engineers using the more sophisticated modern methods view our current statistical methods courses as out of date, relative to methods that are available in or that can be developed rapidly using progressive, extendible statistical or mathematical packages"}
}

@article{duc17smo,
  title = {Smooth Semi-Nonparametric ({{SNP}}) Estimation of the Cumulative Incidence Function},
  author = {Duc, Anh N. and Wolbers, Marcel},
  journaltitle = {Stat Med},
  pages = {n/a},
  doi = {10.1002/sim.7331},
  url = {http://dx.doi.org/10.1002/sim.7331},
  abstract = {This paper presents a novel approach to estimation of the cumulative incidence function in the presence of competing risks. The underlying statistical model is specified via a mixture factorization of the joint distribution of the event type and the time to the event. The time to event distributions conditional on the event type are modeled using smooth semi-nonparametric densities. One strength of this approach is that it can handle arbitrary censoring and truncation while relying on mild parametric assumptions. A stepwise forward algorithm for model estimation and adaptive selection of smooth semi-nonparametric polynomial degrees is presented, implemented in the statistical software R, evaluated in a sequence of simulation studies, and applied to data from a clinical trial in cryptococcal meningitis. The simulations demonstrate that the proposed method frequently outperforms both parametric and nonparametric alternatives. They also support the use of 'ad hoc' asymptotic inference to derive confidence intervals. An extension to regression modeling is also presented, and its potential and challenges are discussed.},
  citeulike-article-id = {14362349},
  citeulike-attachment-1 = {duc17smo.pdf; /pdf/user/harrelfe/article/14362349/1110319/duc17smo.pdf; 1d6d4a3b832e30a733149405d7beaba961e7e289},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7331},
  posted-at = {2017-05-24 14:28:02},
  priority = {3},
  keywords = {adaptive,competing-risks,survival-analysis}
}

@article{dud93com,
  title = {Comparison of Analytic Models for Estimating the Effect of Clinical Factors on the Cost of Coronary Artery Bypass Graft Surgery},
  author = {Dudley, R and Harrell, Frank E. and Smith, L and Mark, Daniel B. and Califf, Robert M. and Pryor, David B. and Glower, Donald and Lipscomb, Joseph and Hlatky, Mark},
  date = {1993},
  journaltitle = {J Clin Epi},
  volume = {46},
  pages = {261--271},
  citeulike-article-id = {13264023},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {charges,cost,cox-model,log-normal-distribution,median,weibull-distribution}
}

@article{dum99bay,
  title = {Bayesian {{Data Mining}} in {{Large Frequency Tables}}, with an {{Application}} to the {{FDA Spontaneous Reporting System}} ({{Disc}}: p. 190-202)},
  author = {DuMouchel, William},
  date = {1999},
  journaltitle = {Appl Stat},
  volume = {53},
  pages = {177--190},
  citeulike-article-id = {13265460},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {adverse-drug-reactions,association,gamma-poisson-distribution,mixture-model,shrinkage-estimator,statistical-practice}
}

@article{dun07gen,
  title = {Gene Expression Profiling: {{Does}} It Add Predictive Accuracy to Clinical Characteristics in Cancer Prognosis?},
  author = {Dunkler, Daniela and Michiels, Stefan and Schemper, Michael},
  date = {2007},
  journaltitle = {Eur J Ca},
  volume = {43},
  number = {4},
  pages = {745--751},
  doi = {10.1016/j.ejca.2006.11.018},
  url = {http://www.sciencedirect.com/science/article/pii/S0959804906010616},
  abstract = {It is widely accepted that gene expression classifiers need to be externally validated by showing that they predict the outcome well enough on other patients than those from whose data the classifier was derived. Unfortunately, the gain in predictive accuracy by the classifier as compared to established clinical prognostic factors often is not quantified. Our objective is to illustrate the application of appropriate statistical measures for this purpose. In order to compare the predictive accuracies of a model based on the clinical factors only and of a model based on the clinical factors plus the gene classifier, we compute the decrease in predictive inaccuracy and the proportion of explained variation. These measures have been obtained for three studies of published gene classifiers: for survival of lymphoma patients, for survival of breast cancer patients and for the diagnosis of lymph node metastases in head and neck cancer. For the three studies our results indicate varying and possibly small added explained variation and predictive accuracy due to gene classifiers. Therefore, the gain of future gene classifiers should routinely be demonstrated by appropriate statistical measures, such as the ones we recommend.},
  citeulike-article-id = {14574336},
  citeulike-linkout-0 = {http://dx.doi.org/https://doi.org/10.1016/j.ejca.2006.11.018},
  citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/pii/S0959804906010616},
  posted-at = {2018-04-23 19:56:29},
  priority = {2},
  keywords = {gene-expression,genomics,predictive-accuracy}
}

@article{dun10pre,
  title = {Predictors of Activity Level 2 Years after Anterior Cruciate Ligament Reconstruction ({{ACLR}}): A {{Multicenter Orthopaedic Outcomes Network}} ({{MOON}}) {{ACLR}} Cohort Study.},
  author = {Dunn, W. R. and Spindler, K. P. and Amendola, A. and Wolf, B. R. and Andrish, J. T. and Bergfeld, J. A. and Jones, M. H. and Parker, R. D. and Flanigan, D. C. and Kaeding, C. C. and Marx, R. G. and Matava, M. J. and Wright, R. W. and McCarty, E. C. and Wolcott, M. and Vidal, A. and Harrell, F. E. and Dittus, R. S.},
  date = {2010},
  journaltitle = {Am J Sports Med},
  volume = {38},
  number = {10},
  pages = {2040--2050},
  citeulike-article-id = {13265882},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {moon,sports-medicine}
}

@article{dun10whi,
  title = {Which Preoperative Factors, Including Bone Bruise, Are Associated with Knee Pain/Symptoms at Index Anterior Cruciate Ligament Reconstruction ({{ACLR}})? {{A Multicenter Orthopaedic Outcomes Network}} ({{MOON}}) {{ACLR}} Cohort Study},
  author = {Dunn, W. R. and Spindler, K. P. and Amendola, A. and Andrish, J. T. and Kaeding, C. C. and Marx, R. G. and McCarty, E. C. and Parker, R. D. and Harrell, F. E. and An, A. Q. and Wright, R. W. and Brophy, R. H. and {Matava} and Flanigan, D. C. and Huston, L. J. and Jones, M. H. and Wolcott, M. L. and Vidal, A. F. and Wolf, B. R. and Investigation, Moon A. C. L.},
  date = {2010},
  journaltitle = {Am J Sports Med},
  volume = {38},
  number = {9},
  pages = {1778--1787},
  citeulike-article-id = {13265880},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {moon,sports-medicine}
}

@article{dun15bas,
  title = {Baseline Predictors of Health-Related Quality of Life after Anterior Cruciate Ligament Reconstruction: A Longitudinal Analysis of a Multicenter Cohort at Two and Six Years.},
  author = {Dunn, Warren R. and Wolf, Brian R. and Harrell, Frank E. and Reinke, Emily K. and Huston, Laura J. and {MOON Knee Group} and Spindler, Kurt P.},
  date = {2015-04},
  journaltitle = {J Bone Joint Surg},
  volume = {97},
  number = {7},
  eprint = {25834079},
  eprinttype = {pmid},
  pages = {551--557},
  issn = {1535-1386},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25834079},
  abstract = {Limited information exists regarding predictors of general quality of life following anterior cruciate ligament (ACL) reconstruction with up to six-year follow-up. We hypothesized that certain variables evaluated at the time of ACL reconstruction will predict the general quality of life as measured by the Short Form-36 (SF-36). All unilateral ACL reconstructions from 2002 to 2004 in patients currently enrolled in a prospective multicenter cohort were evaluated. Patients preoperatively completed the SF-36 validated outcome instrument. Surgeons documented intra-articular pathological conditions and treatment, as well as the ACL reconstruction surgical technique. At baseline and at a minimum of two and six years postoperatively, patients completed the SF-36. Longitudinal analysis was performed for the two-year and six-year end points. Of the initial 1512 subjects, at least one follow-up questionnaire was obtained from 1411 subjects (93\%). The cohort was 44\% female, and the median patient age at enrollment was twenty-three years. The mean scores were 41.9 points for the Physical Component Summary (PCS) and 51.7 points for the Mental Component Summary (MCS) at baseline, 53.6 points for the PCS and 52.0 points for the MCS at two years, and 54.0 points for the PCS and 52.4 points for the MCS at six years. Significant predictors of a higher PCS score were a higher baseline PCS score, younger age, lower baseline body mass index, having {$>$}50\% of the lateral meniscus excised, or having no treatment done on a lateral meniscal tear. In contrast, significant predictors of a lower PCS score were a shorter follow-up time since surgery, revision ACL reconstruction, smoking at baseline, fewer years of education, and chondromalacia of the lateral tibial plateau. The mean utility gained at six years after ACL reconstruction was 5.3 quality-adjusted life years (QALYs). Large improvements in the PCS (with an effect size of 1.2) were noted at two years and were maintained at six years after ACL reconstruction. Lower education and smoking were significant predictors of lower PCS and MCS scores. ACL reconstruction resulted in a relatively high gain of QALYs. Copyright  2015 by The Journal of Bone and Joint Surgery, Incorporated.},
  citeulike-article-id = {14102490},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25834079},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25834079},
  day = {1},
  posted-at = {2016-07-26 21:17:16},
  priority = {2},
  keywords = {collaboration,orthopedics,sports-medicine}
}

@article{dun16201,
  title = {2013 {{Neer Award}}: Predictors of Failure of Nonoperative Treatment of Chronic, Symptomatic, Full-Thickness Rotator Cuff Tears},
  shorttitle = {2013 {{Neer Award}}},
  author = {Dunn, Warren R. and Kuhn, John E. and Sanders, Rosemary and An, Qi and Baumgarten, Keith M. and Bishop, Julie Y. and Brophy, Robert H. and Carey, James L. and Harrell, Frank and Holloway, Brian G. and Jones, Grant L. and Ma, C. Benjamin and Marx, Robert G. and McCarty, Eric C. and Poddar, Sourav K. and Smith, Matthew V. and Spencer, Edwin E. and Vidal, Armando F. and Wolf, Brian R. and Wright, Rick W. and {MOON Shoulder Group}},
  date = {2016-08},
  journaltitle = {J Shoulder Elbow Surg},
  volume = {25},
  number = {8},
  eprint = {27422460},
  eprinttype = {pmid},
  pages = {1303--1311},
  issn = {1532-6500},
  doi = {10.1016/j.jse.2016.04.030},
  abstract = {BACKGROUND: The purpose of this study is to help define the indications for rotator cuff repair by identifying predictors of failure of nonoperative treatment. METHODS: A prospective, multicenter, cohort study design was used. All patients with full-thickness rotator cuff tears on magnetic resonance imaging were offered participation. Baseline data from this cohort were used to examine risk factors for failing a standard rehabilitation protocol. Patients who underwent surgery were defined as failing nonoperative treatment. A Cox proportional hazards model was fit to determinethe baseline factors that predicted failure. The dependent variable was time to surgery. The independent variables were tear severity and baseline patient factors: age, activity level, body mass index, sex, Single Assessment Numeric Evaluation score, visual analog scale score for pain, education, handedness, comorbidities, duration of symptoms, strength, employment, smoking status, and patient expectations. RESULTS: Of the 433 subjects in this study, 87 underwent surgery with 93\% follow-up at 1 year and 88\% follow-up at 2 years. The median age was 62 years, and 49\% were female patients. Multivariate modeling, adjusted for the covariates listed previously, identified patient expectations regarding physical therapy (P\,{$<$}\,.0001) as the strongest predictor of surgery. Higher activity level (P\,=\,.011) and not smoking (P\,=\,.023) were also significant predictors of surgery. CONCLUSION: A patient's decision to undergo surgery is influenced more by low expectations regarding the effectiveness of physical therapy than by patient symptoms or anatomic features of the rotator cuff tear. As such, patient symptoms and anatomic features of the chronic rotator cuff tear may not be the best features to use when deciding on surgical intervention.},
  langid = {english},
  keywords = {award,collaboration,orthopedics}
}

@article{dun16pre,
  title = {2013 {{Neer Award}}: Predictors of Failure of Nonoperative Treatment of Chronic, Symptomatic, Full-Thickness Rotator Cuff Tears.},
  author = {Dunn, Warren R. and Kuhn, John E. and Sanders, Rosemary and An, Qi and Baumgarten, Keith M. and Bishop, Julie Y. and Brophy, Robert H. and Carey, James L. and Harrell, Frank and Holloway, Brian G. and Jones, Grant L. and Ma, Benjamin B. and Marx, Robert G. and McCarty, Eric C. and Poddar, Sourav K. and Smith, Matthew V. and Spencer, Edwin E. and Vidal, Armando F. and Wolf, Brian R. and Wright, Rick W. and {MOON Shoulder Group}},
  date = {2016-08},
  journaltitle = {J Shoulder Elbow Surg},
  volume = {25},
  number = {8},
  eprint = {27422460},
  eprinttype = {pmid},
  pages = {1303--1311},
  issn = {1532-6500},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/27422460},
  abstract = {The purpose of this study is to help define the indications for rotator cuff repair by identifying predictors of failure of nonoperative treatment. A prospective, multicenter, cohort study design was used. All patients with full-thickness rotator cuff tears on magnetic resonance imaging were offered participation. Baseline data from this cohort were used to examine risk factors for failing a standard rehabilitation protocol. Patients who underwent surgery were defined as failing nonoperative treatment. A Cox proportional hazards model was fit to determinethe baseline factors that predicted failure. The dependent variable was time to surgery. The independent variables were tear severity and baseline patient factors: age, activity level, body mass index, sex, Single Assessment Numeric Evaluation score, visual analog scale score for pain, education, handedness, comorbidities, duration of symptoms, strength, employment, smoking status, and patient expectations. Of the 433 subjects in this study, 87 underwent surgery with 93\% follow-up at 1 year and 88\% follow-up at 2 years. The median age was 62 years, and 49\% were female patients. Multivariate modeling, adjusted for the covariates listed previously, identified patient expectations regarding physical therapy (P\,{$<$}\,.0001) as the strongest predictor of surgery. Higher activity level (P\,=\,.011) and not smoking (P\,=\,.023) were also significant predictors of surgery. A patient's decision to undergo surgery is influenced more by low expectations regarding the effectiveness of physical therapy than by patient symptoms or anatomic features of the rotator cuff tear. As such, patient symptoms and anatomic features of the chronic rotator cuff tear may not be the best features to use when deciding on surgical intervention. Copyright  2016 Journal of Shoulder and Elbow Surgery Board of Trustees. Published by Elsevier Inc. All rights reserved.},
  citeulike-article-id = {14105710},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/27422460},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=27422460},
  posted-at = {2016-08-01 15:44:48},
  priority = {2},
  keywords = {collaboration,sports-medicine}
}

@article{dun94reg,
  title = {Regression for Longitudinal Data: {{A}} Bridge from Least Squares Regression},
  author = {Dunlop, Dorothy D.},
  date = {1994},
  journaltitle = {Am Statistician},
  volume = {48},
  pages = {299--303},
  citeulike-article-id = {13264025},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {dependent-responses,estimating-equations,gee,teaching}
}

@article{dup89,
  title = {Converting Relative Risks to Absolute Risks: {{A}} Graphical Approach},
  author = {DuPont, W. D.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {641--651},
  citeulike-article-id = {13264026},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {survival-analysis-non-regression}
}

@book{dupmod,
  title = {Statistical {{Modeling}} for {{Biomedical Researchers}}},
  author = {Dupont, William D.},
  date = {2008},
  edition = {second},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge, UK}},
  citeulike-article-id = {13265720},
  posted-at = {2014-07-14 14:10:02},
  priority = {0}
}

@article{dur05sim,
  title = {Simple Fitting of Subject-Specific Curves for Longitudinal Data},
  author = {Durbán, M. and Harezlak, J. and Wand, M. P. and Carroll, R. J.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {1153--1167},
  citeulike-article-id = {13265405},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {graphics,linear-mixed-models,penalized-splines,penalized-splines-with-random-coefficients,r,restricted-likelihood-ratio-tests},
  note = {nice graphics with confidence bands;S-Plus and R code;computational problems with SAS as needs to hold a large matrix not needed by S}
}

@article{dur89,
  title = {Flexible Regression Models with Cubic Splines},
  author = {Durrleman, S. and Simon, R.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {551--561},
  citeulike-article-id = {13264027},
  posted-at = {2014-07-14 14:09:27},
  priority = {0}
}

@article{dur90,
  title = {Planning and Monitoring of Equivalence Studies},
  author = {Durrleman, S. and Simon, R.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {329--336},
  citeulike-article-id = {13264028},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {pharmaceutical,study-design-and-stopping-rules}
}

@article{dur94new,
  title = {New Criteria for Diagnosis of Infective Endocarditis - Utilization of Specific Echocardiographic Findings},
  author = {Durack, D. T. and Lukes, A. S. and Bright, D. K. and Alberts, M. J. and Bashore, T. M. and Corey, G. R. and Douglas, J. M. and Gray, L. and Harrell, F. E. and Harrison, J. K. and Heinle, S. A. and Morris, A. and Kisslo, J. A. and Nicely, L. M. and Oldham, N. and Penning, L. M. and Sexton, D. J. and Towns, M. and Waugh, R. A.},
  date = {1994},
  journaltitle = {AJM},
  volume = {96},
  pages = {200--209},
  citeulike-article-id = {13265563},
  posted-at = {2014-07-14 14:09:59},
  priority = {0}
}

@article{dzi14tim,
  title = {Time-Varying Effect Models for Ordinal Responses with Applications in Substance Abuse Research},
  author = {Dziak, John J. and Li, Runze and Zimmerman, Marc A. and Buu, Anne},
  date = {2014-12},
  journaltitle = {Stat Med},
  volume = {33},
  number = {29},
  pages = {5126--5137},
  doi = {10.1002/sim.6303},
  url = {http://dx.doi.org/10.1002/sim.6303},
  abstract = {Ordinal responses are very common in longitudinal data collected from substance abuse research or other behavioral research. This study develops a new statistical model with free SAS macros that can be applied to characterize time-varying effects on ordinal responses. Our simulation study shows that the ordinal-scale time-varying effects model has very low estimation bias and sometimes offers considerably better performance when fitting data with ordinal responses than a model that treats the response as continuous. Contrary to a common assumption that an ordinal scale with several levels can be treated as continuous, our results indicate that it is not so much the number of levels on the ordinal scale but rather the skewness of the distribution that makes a difference on relative performance of linear versus ordinal models. We use longitudinal data from a well-known study on youth at high risk for substance abuse as a motivating example to demonstrate that the proposed model can characterize the time-varying effect of negative peer influences on alcohol use in a way that is more consistent with the developmental theory and existing literature, in comparison with the linear time-varying effect model.},
  citeulike-article-id = {13444238},
  citeulike-attachment-1 = {dzi14tim.pdf; /pdf/user/harrelfe/article/13444238/995482/dzi14tim.pdf; 02de672109de22707a31d0271d1e427671d959bf},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6303},
  day = {20},
  posted-at = {2014-11-24 18:19:44},
  priority = {0},
  keywords = {extensions-of-logistic-ordinal-model,ordinal-regression,ordinal-response,proportional-odds-model,tdc}
}

@article{eas96opt,
  title = {Optimal Sample Allocation in Clinical Trials Designed to Investigate Relative Risks},
  author = {Eastwood, Brian J.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2523--2538},
  citeulike-article-id = {13264029},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {study-design,treatment-allocation}
}

@book{eat95tit,
  title = {Titanic: {{Triumph}} and {{Tragedy}}},
  author = {Eaton, John P. and Haas, Charles A.},
  date = {1995},
  edition = {Second},
  publisher = {{W. W. Norton}},
  location = {{New York}},
  citeulike-article-id = {13265159},
  posted-at = {2014-07-14 14:09:50},
  priority = {0}
}

@article{ebb12eff,
  title = {Effects of {{Dietary Composition}} on {{Energy Expenditure During Weight-Loss Maintenance}}},
  author = {Ebbeling, Cara B. and Swain, Janis F. and Feldman, Henry A. and Wong, William W. and Hachey, David L. and Garcia-Lago, Erica and Ludwig, David S.},
  date = {2012-06-27},
  journaltitle = {JAMA},
  volume = {307},
  number = {24},
  pages = {2627--2634},
  issn = {0098-7484},
  doi = {10.1001/jama.2012.6607},
  url = {https://jamanetwork.com/journals/jama/fullarticle/1199154},
  urldate = {2019-10-02},
  abstract = {{$<$}h3{$>$}Context{$<$}/h3{$>$}Reduced energy expenditure following weight loss is thought to contribute to weight gain. However, the effect of dietary composition on energy expenditure during weight-loss maintenance has not been studied.{$<$}h3{$>$}Objective{$<$}/h3{$>$}To examine the effects of 3 diets differing widely in macronutrient composition and glycemic load on energy expenditure following weight loss.{$<$}h3{$>$}Design, Setting, and Participants{$<$}/h3{$>$}A controlled 3-way crossover design involving 21 overweight and obese young adults conducted at Children's Hospital Boston and Brigham and Women's Hospital, Boston, Massachusetts, between June 16, 2006, and June 21, 2010, with recruitment by newspaper advertisements and postings.{$<$}h3{$>$}Intervention{$<$}/h3{$>$}After achieving 10\% to 15\% weight loss while consuming a run-in diet, participants consumed an isocaloric low-fat diet (60\% of energy from carbohydrate, 20\% from fat, 20\% from protein; high glycemic load), low–glycemic index diet (40\% from carbohydrate, 40\% from fat, and 20\% from protein; moderate glycemic load), and very low-carbohydrate diet (10\% from carbohydrate, 60\% from fat, and 30\% from protein; low glycemic load) in random order, each for 4 weeks.{$<$}h3{$>$}Main Outcome Measures{$<$}/h3{$>$}Primary outcome was resting energy expenditure (REE), with secondary outcomes of total energy expenditure (TEE), hormone levels, and metabolic syndrome components.{$<$}h3{$>$}Results{$<$}/h3{$>$}Compared with the pre–weight-loss baseline, the decrease in REE was greatest with the low-fat diet (mean [95\% CI], –205 [–265 to –144] kcal/d), intermediate with the low–glycemic index diet (–166 [–227 to –106] kcal/d), and least with the very low-carbohydrate diet (−138 [–198 to –77] kcal/d; overall P = .03; P for trend by glycemic load = .009). The decrease in TEE showed a similar pattern (mean [95\% CI], −423 [–606 to –239] kcal/d; −297 [–479 to –115] kcal/d; and −97 [–281 to 86] kcal/d, respectively; overall P = .003; P for trend by glycemic load \&lt; .001). Hormone levels and metabolic syndrome components also varied during weight maintenance by diet (leptin, P \&lt; .001; 24-hour urinary cortisol, P = .005; indexes of peripheral [P = .02] and hepatic [P = .03] insulin sensitivity; high-density lipoprotein [HDL] cholesterol, P \&lt; .001; non-HDL cholesterol, P \&lt; .001; triglycerides, P \&lt; .001; plasminogen activator inhibitor 1, P for trend = .04; and C-reactive protein, P for trend = .05), but no consistent favorable pattern emerged.{$<$}h3{$>$}Conclusion{$<$}/h3{$>$}Among overweight and obese young adults compared with pre–weight-loss energy expenditure, isocaloric feeding following 10\% to 15\% weight loss resulted in decreases in REE and TEE that were greatest with the low-fat diet, intermediate with the low–glycemic index diet, and least with the very low-carbohydrate diet.{$<$}h3{$>$}Trial Registration{$<$}/h3{$>$}clinicaltrials.gov Identifier: NCT00315354},
  langid = {english},
  keywords = {crossover,diet,experimental-design,teaching,teaching-mds}
}

@book{ebe05wik,
  title = {Wiki {{Web Collaboration}}},
  author = {Ebersbach, Anja and Glaser, Markus and Heigl, Richard},
  date = {2005},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265624},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  annotation = {ISBN-10: 3540259953 ISBN-13: 978-3540259954}
}

@article{edl21ris,
  title = {Risk Prediction Models for Discrete Ordinal Outcomes: {{Calibration}} and the Impact of the Proportional Odds Assumption},
  shorttitle = {Risk Prediction Models for Discrete Ordinal Outcomes},
  author = {Edlinger, Michael and van Smeden, Maarten and Alber, Hannes F and Wanitschek, Maria and Van Calster, Ben},
  options = {useprefix=true},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9281},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9281},
  urldate = {2021-12-14},
  abstract = {Calibration is a vital aspect of the performance of risk prediction models, but research in the context of ordinal outcomes is scarce. This study compared calibration measures for risk models predicting a discrete ordinal outcome, and investigated the impact of the proportional odds assumption on calibration and overfitting. We studied the multinomial, cumulative, adjacent category, continuation ratio, and stereotype logit/logistic models. To assess calibration, we investigated calibration intercepts and slopes, calibration plots, and the estimated calibration index. Using large sample simulations, we studied the performance of models for risk estimation under various conditions, assuming that the true model has either a multinomial logistic form or a cumulative logit proportional odds form. Small sample simulations were used to compare the tendency for overfitting between models. As a case study, we developed models to diagnose the degree of coronary artery disease (five categories) in symptomatic patients. When the true model was multinomial logistic, proportional odds models often yielded poor risk estimates, with calibration slopes deviating considerably from unity even on large model development datasets. The stereotype logistic model improved the calibration slope, but still provided biased risk estimates for individual patients. When the true model had a cumulative logit proportional odds form, multinomial logistic regression provided biased risk estimates, although these biases were modest. Nonproportional odds models require more parameters to be estimated from the data, and hence suffered more from overfitting. Despite larger sample size requirements, we generally recommend multinomial logistic regression for risk prediction modeling of discrete ordinal outcomes.},
  langid = {english},
  keywords = {calibration,ordinal,po,po-assumption},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9281}
}

@article{edw63bay,
  title = {Bayesian Statistical Inference for Psychological Research},
  author = {Edwards, Ward and Lindman, Harold and Savage, Leonard J.},
  date = {1963-05},
  journaltitle = {Psych Rev},
  volume = {70},
  number = {3},
  pages = {193--242},
  url = {http://psycnet.apa.org/doi/10.1037/h0044139},
  abstract = {Bayesian statistics, a currently controversial viewpoint concerning statistical inference, is based on a definition of probability as a particular measure of the opinions of ideally consistent people. Statistical inference is modification of these opinions in the light of evidence, and Bayes' theorem specifies how such modifications should be made. The tools of Bayesian statistics include the theory of specific distributions and the principle of stable estimation, which specifies when actual prior opinions may be satisfactorily approximated by a uniform distribution. A common feature of many classical significance tests is that a sharp null hypothesis is compared with a diffuse alternative hypothesis. Often evidence which, for a Bayesian statistician, strikingly supports the null hypothesis leads to rejection of that hypothesis by standard classical procedures. The likelihood principle emphasized in Bayesian statistics implies, among other things, that the rules governing when data collection stops are irrelevant to data interpretation. It is entirely appropriate to collect data until a point has been proven or disproven, or until the data collector runs out of time, money, or patience.},
  citeulike-article-id = {14287855},
  citeulike-linkout-0 = {http://psycnet.apa.org/doi/10.1037/h0044139},
  posted-at = {2017-02-26 17:54:58},
  priority = {2},
  keywords = {bayes,bayesian-inference}
}

@article{edw99mod,
  title = {On Model Pre-Specification in Confirmatory Randomized Studies},
  author = {Edwards, David},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {771--785},
  institution = {Statistics Department, Novo Nordisk},
  location = {DK-2880 Bagsvaerd, Denmark. DEd@novo.dk},
  citeulike-article-id = {13264030},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {analysis-plan,covariable-adjustment-in-rct,pharmaceutical,statistics-sop}
}

@article{efr01emp,
  title = {Empirical {{Bayes}} Analysis of a Microarray Experiment},
  author = {Efron, Bradley and Tibshirani, Robert and Storey, John D. and Tusher, Virginia},
  date = {2001},
  journaltitle = {J Am Stat Assoc},
  pages = {1151--1160},
  citeulike-article-id = {13265246},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {false-discovery-rate,functional-genomics,microarray,normalization},
  note = {concise summary of what microarrays are; normalization worked best if used logged but subtracted 1/2 of background}
}

@article{efr13bay,
  title = {Bayesian Inference and the Parametric Bootstrap},
  author = {Efron, Bradley},
  date = {2012},
  journaltitle = {Ann Appl Stat},
  volume = {6},
  number = {4},
  pages = {1971--1997},
  doi = {10.1214/12-AOAS571},
  url = {http://dx.doi.org/10.1214/12-AOAS571},
  abstract = {Summary: The parametric bootstrap can be used for the efficient computation of Bayes posterior distributions. Importance sampling formulas take on an easy form relating to the deviance in exponential families and are particularly simple starting from Jeffreys invariant prior. Because of the i.i.d. nature of bootstrap sampling, familiar formulas describe the computational accuracy of the Bayes estimates. Besides computational methods, the theory provides a connection between Bayesian and frequentist analysis. Efficient algorithms for the frequentist accuracy of Bayesian inferences are developed and demonstrated in a model selection example.},
  citeulike-article-id = {13265974},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/12-AOAS571},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {deviance,exponential-families,generalized-linear-models,jeffreys-prior}
}

@article{efr20aut,
  title = {The {{Automatic Construction}} of {{Bootstrap Confidence Intervals}}},
  author = {Efron, Bradley and Narasimhan, Balasubramanian},
  date = {2020-01-14},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {0},
  number = {0},
  pages = {1--12},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1080/10618600.2020.1714633},
  url = {https://doi.org/10.1080/10618600.2020.1714633},
  urldate = {2020-03-13},
  abstract = {The standard intervals, for example, θ̂±1.96σ̂ for nominal 95\% two-sided coverage, are familiar and easy to use, but can be of dubious accuracy in regular practice. Bootstrap confidence intervals offer an order of magnitude improvement—from first order to second order accuracy. This article introduces a new set of algorithms that automate the construction of bootstrap intervals, substituting computer power for the need to individually program particular applications. The algorithms are described in terms of the underlying theory that motivates them, along with examples of their application. They are implemented in the R package bcaboot. Supplementary materials for this article are available online.},
  keywords = {bootstrap,confidence-interval,double-bootstrap},
  annotation = {\_eprint: https://doi.org/10.1080/10618600.2020.1714633}
}

@incollection{efr67two,
  title = {The Two Sample Problem with Censored Data},
  booktitle = {Proceedings of the {{Fifth Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}},
  author = {Efron, Bradley},
  date = {1967},
  volume = {4},
  pages = {831--853},
  citeulike-article-id = {13265696},
  posted-at = {2014-07-14 14:10:02},
  priority = {0}
}

@article{efr75dat,
  title = {Data Analysis Using {{Stein}}'s Estimator and Its Generalizations},
  author = {Efron, Bradley and Morris, Carl},
  date = {1975},
  journaltitle = {J Am Stat Assoc},
  volume = {70},
  pages = {311--319},
  citeulike-article-id = {13264031},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {empirical-bayes,james-stein,shrinkage}
}

@article{efr77eff,
  title = {The Efficiency of {{Cox}}'s Likelihood Function for Censored Data},
  author = {Efron, Bradley},
  date = {1977},
  journaltitle = {J Am Stat Assoc},
  volume = {72},
  pages = {557--565},
  citeulike-article-id = {13264032},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {cox-model,maximum-likelihood}
}

@article{efr77sti,
  title = {Stein's Paradox in Statistics},
  author = {Efron, Bradley and Morris, Carl},
  date = {1977},
  journaltitle = {Sci Am},
  volume = {236},
  number = {5},
  pages = {119--127},
  citeulike-article-id = {13264033},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {baseball-batting-average-example,shrinkage}
}

@article{efr78,
  title = {Regression and {{ANOVA}} with Zero-One Data: Measures of Residual Variation},
  author = {Efron, B.},
  date = {1978},
  journaltitle = {J Am Stat Assoc},
  volume = {73},
  pages = {113--121},
  citeulike-article-id = {13264034},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,predictive-accuracy}
}

@article{efr79boo,
  title = {Bootstrap Methods: {{Another}} Look at the Jackknife},
  author = {Efron, Bradley},
  date = {1979},
  journaltitle = {Ann Stat},
  volume = {7},
  number = {1},
  pages = {1--26},
  citeulike-article-id = {13265817},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {bootstrap}
}

@article{efr83est,
  title = {Estimating the Error Rate of a Prediction Rule: {{Improvement}} on Cross-Validation},
  author = {Efron, B.},
  date = {1983},
  journaltitle = {J Am Stat Assoc},
  volume = {78},
  pages = {316--331},
  citeulike-article-id = {13264035},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  note = {suggested need at least 200 models to get an average that is adequate, i.e., 20 repeats of 10-fold cv}
}

@article{efr83lei,
  title = {A Leisurely Look at the Bootstrap, the Jackknife, and Cross-Validation},
  author = {Efron, B. and Gong, G.},
  date = {1983},
  journaltitle = {Am Statistician},
  volume = {37},
  pages = {36--48},
  citeulike-article-id = {13264036},
  posted-at = {2014-07-14 14:09:27},
  priority = {0}
}

@article{efr86,
  title = {How Biased Is the Apparent Error Rate of a Prediction Rule?},
  author = {Efron, B.},
  date = {1986},
  journaltitle = {J Am Stat Assoc},
  volume = {81},
  pages = {461--470},
  citeulike-article-id = {13264037},
  posted-at = {2014-07-14 14:09:27},
  priority = {0}
}

@article{efr86boo,
  title = {Bootstrap Methods for Standard Errors, Confidence Intervals, and Other Measures of Statistical Accuracy},
  author = {Efron, Bradley and Tibshirani, Robert},
  date = {1986},
  journaltitle = {Stat Sci},
  volume = {1},
  pages = {54--77},
  citeulike-article-id = {13264038},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bootstrap,informative-censoring,predictive-accuracy}
}

@article{efr88,
  title = {Logistic Regression, Survival Analysis, and the {{Kaplan-Meier}} Curve},
  author = {Efron, B.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {414--425},
  doi = {10.1080/01621459.1988.10478612},
  url = {http://dx.doi.org/10.1080/01621459.1988.10478612},
  citeulike-article-id = {13264039},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1988.10478612},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {general,logistic-model-extensions,survival-analysis-regression}
}

@article{efr90,
  title = {More Efficient Bootstrap Computations},
  author = {{Efron}},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {79--89},
  citeulike-article-id = {13264040},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bootstrapping,jackknifing}
}

@article{efr93bay,
  title = {Bayes and Likelihood Calculations from Confidence Intervals},
  author = {Efron, Bradley},
  date = {1993},
  journaltitle = {Biometrika},
  volume = {80},
  pages = {3--26},
  citeulike-article-id = {13264041},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bayesian-inference,bayesian-intervals-and-confidence-intervals}
}

@article{efr94mis,
  title = {Missing Data, Imputation, and the Bootstrap (with Discussion)},
  author = {Efron, Bradley},
  date = {1994},
  journaltitle = {J Am Stat Assoc},
  volume = {89},
  pages = {463--479},
  citeulike-article-id = {13264042},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bootstrap,imputation,missing-data,multiple-imputation}
}

@article{efr96boo,
  title = {Bootstrap Confidence Levels for Phylogenetic Trees},
  author = {Efron, Bradley and Halloran, Elizabeth and Holmes, Susan},
  date = {1996},
  journaltitle = {PNAS},
  volume = {93},
  pages = {13429--13434},
  citeulike-article-id = {13265168},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {bootstrap,felsenstein-method,phylogenetic-tree,teaching,tree}
}

@article{efr97imp,
  title = {Improvements on Cross-Validation: {{The}} .632+ Bootstrap Method},
  author = {Efron, Bradley and Tibshirani, Robert},
  date = {1997},
  journaltitle = {J Am Stat Assoc},
  volume = {92},
  pages = {548--560},
  citeulike-article-id = {13264043},
  posted-at = {2014-07-14 14:09:27},
  priority = {0},
  keywords = {bootstrap,internal-and-external-validation,internal-and-external-variability,model-validation,simulation-setup}
}

@article{eft17mar,
  title = {Α {{Markov}} Model for Longitudinal Studies with Incomplete Dichotomous Outcomes},
  author = {Efthimiou, Orestis and Welton, Nicky and Samara, Myrto and Leucht, Stefan and Salanti, Georgia},
  date = {2017},
  journaltitle = {Pharmaceutical Statistics},
  volume = {16},
  number = {2},
  pages = {122--132},
  issn = {1539-1612},
  doi = {10.1002/pst.1794},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1794},
  urldate = {2021-05-02},
  abstract = {Missing outcome data constitute a serious threat to the validity and precision of inferences from randomized controlled trials. In this paper, we propose the use of a multistate Markov model for the analysis of incomplete individual patient data for a dichotomous outcome reported over a period of time. The model accounts for patients dropping out of the study and also for patients relapsing. The time of each observation is accounted for, and the model allows the estimation of time-dependent relative treatment effects. We apply our methods to data from a study comparing the effectiveness of 2 pharmacological treatments for schizophrenia. The model jointly estimates the relative efficacy and the dropout rate and also allows for a wide range of clinically interesting inferences to be made. Assumptions about the missingness mechanism and the unobserved outcomes of patients dropping out can be incorporated into the analysis. The presented method constitutes a viable candidate for analyzing longitudinal, incomplete binary data.},
  langid = {english},
  keywords = {binary-data,binary-outcomes,markov,missing,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.1794}
}

@article{eid96sem,
  title = {The Semi-Proportional Hazards Model Revisited: {{Practical}} Reparameterizations},
  author = {Eide, Geir E. and Omenaas, Ernst and Gulsvik, Amund},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1771--1777},
  citeulike-article-id = {13264044},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {strata-by-covariable-interactions}
}

@article{eij18com,
  title = {Comparing Methods to Combine Functional Loss and Mortality in Clinical Trials for Amyotrophic Lateral Sclerosis},
  author = {van Eijk, Ruben PA and Eijkemans, Marinus JC and Rizopoulos, Dimitris and van den Berg, Leonard H. and Nikolakopoulos, Stavros},
  date = {2018-03-19},
  journaltitle = {CLEP},
  volume = {10},
  pages = {333--341},
  publisher = {{Dove Press}},
  doi = {10.2147/CLEP.S153196},
  url = {https://www.dovepress.com/comparing-methods-to-combine-functional-loss-and-mortality-in-clinical-peer-reviewed-fulltext-article-CLEP},
  urldate = {2021-08-25},
  abstract = {Comparing methods to combine functional loss and mortality in clinical trials for amyotrophic lateral sclerosis Ruben PA van Eijk,1 Marinus JC Eijkemans,2 Dimitris Rizopoulos,3 Leonard H van den Berg,4,* Stavros Nikolakopoulos5,* 1Department of Neurology, University Medical Center Utrecht, Utrecht, the Netherlands; 2Department of Biostatistics, University Medical Center Utrecht, Utrecht, the Netherlands; 3Department of Biostatistics, Erasmus University Medical Center, Rotterdam, the Netherlands; 4Department of Neurology, University Medical Center Utrecht, Utrecht, the Netherlands; 5Department of Biostatistics, University Medical Center Utrecht, Utrecht, the Netherlands *These authors contributed equally to this work Objective: Amyotrophic lateral sclerosis (ALS) clinical trials based on single end points only partially capture the full treatment effect when both function and mortality are affected, and may falsely dismiss efficacious drugs as futile. We aimed to investigate the statistical properties of several strategies for the simultaneous analysis of function and mortality in ALS clinical trials. Methods: Based on the Pooled Resource Open-Access ALS Clinical Trials (PRO-ACT) database, we simulated longitudinal patterns of functional decline, defined by the revised amyotrophic lateral sclerosis functional rating scale (ALSFRS-R) and conditional survival time. Different treatment scenarios with varying effect sizes were simulated with follow-up ranging from 12 to 18\&nbsp;months. We considered the following analytical strategies: 1) Cox model; 2) linear mixed effects (LME) model; 3) omnibus test based on Cox and LME models; 4) composite time-to-6-point decrease or death; 5) combined assessment of function and survival (CAFS); and 6) test based on joint modeling framework. For each analytical strategy, we calculated the empirical power and sample size. Results: Both Cox and LME models have increased false-negative rates when treatment exclusively affects either function or survival. The joint model has superior power compared to other strategies. The composite end point increases false-negative rates among all treatment scenarios. To detect a 15\% reduction in ALSFRS-R decline and 34\% decline in hazard with 80\% power after 18\&nbsp;months, the Cox model requires 524 patients, the LME model 794 patients, the omnibus test 526 patients, the composite end point 1,274 patients, the CAFS 576 patients and the joint model 464 patients. Conclusion: Joint models have superior statistical power to analyze simultaneous effects on survival and function and may circumvent pitfalls encountered by other end points. Optimizing trial end points is essential, as selecting suboptimal outcomes may disguise important treatment clues. Keywords: joint models, CAFS, clinical trials, amyotrophic lateral sclerosis},
  langid = {english},
  keywords = {composite-endpoint,longitudinal,mixed-effects,mixed-effects-model,multiple-endpoints,serial}
}

@article{elg95peo,
  title = {Are People {{Bayesian}}? {{Uncovering}} Behavioral Strategies},
  author = {El-Gamal, Mahmoud A. and Grether, David M.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {1137--1145},
  citeulike-article-id = {13264045},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {bayes-rule,predictive-accuracy,probability-assessment}
}

@article{ell01ind,
  title = {Independent Data Monitoring Committees: Rationale, Operations and Controversies},
  author = {Ellenberg, Susan S.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2573--2583},
  citeulike-article-id = {13265225},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {confidentiality,disclosure,dsmb,rct},
  note = {public release of interim data;indepedence of DMC (DSMB);confidentiality;DMC responsibilities}
}

@book{ell02dat,
  title = {Data {{Monitoring Committees}} in {{Clinical Trials}}: {{A Practical Perspective}}},
  author = {Ellenberg, Susan S. and Fleming, Thomas R. and DeMets, David L.},
  date = {2002},
  publisher = {{Wiley}},
  location = {{Chichester, England}},
  citeulike-article-id = {13265299},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-safety,data-monitoring-committees,dmc,dsmb,sequential-monitoring},
  note = {review in Biometrics 59:457-458, June 2003 by Freidlin saying that sometimes an independent reporting statistician is not worth the added cost}
}

@book{elt10atl,
  title = {Atlas of the {{Transatlantic Slave Trade}}},
  author = {Eltis, David and Richardson, David},
  date = {2010},
  publisher = {{Yale University Press}},
  location = {{New Haven, CT}},
  citeulike-article-id = {13265868},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {excellent-graphics}
}

@article{ely04del,
  title = {Delirium as a Predictor of Mortality in Mechanically Ventilated Patients in the Intensive Care Unit},
  author = {Ely, E. Wesley and Shintani, Ayumi and Truman, Brenda and Speroff, Theodore and Gordon, Sharon M. and Harrell, Frank E. and Inouye, Sharon K. and Bernard, Gordon R. and Dittus, Robert S.},
  date = {2004},
  journaltitle = {JAMA},
  volume = {291},
  pages = {1753--1762},
  citeulike-article-id = {13265367},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {cox-model,tdc}
}

@article{elz17com,
  title = {Comparison of {{Propensity Score Methods}} and {{Covariate Adjustment}}: {{Evaluation}} in 4 {{Cardiovascular Studies}}},
  shorttitle = {Comparison of {{Propensity Score Methods}} and {{Covariate Adjustment}}},
  author = {Elze, Markus C. and Gregson, John and Baber, Usman and Williamson, Elizabeth and Sartori, Samantha and Mehran, Roxana and Nichols, Melissa and Stone, Gregg W. and Pocock, Stuart J.},
  date = {2017-01-24},
  journaltitle = {Journal of the American College of Cardiology},
  volume = {69},
  number = {3},
  pages = {345--357},
  issn = {0735-1097},
  doi = {10.1016/j.jacc.2016.10.060},
  url = {https://www.sciencedirect.com/science/article/pii/S073510971637036X},
  urldate = {2021-03-01},
  abstract = {Propensity scores (PS) are an increasingly popular method to adjust for confounding in observational studies. Propensity score methods have theoretical advantages over conventional covariate adjustment, but their relative performance in real-word scenarios is poorly characterized. We used datasets from 4 large-scale cardiovascular observational studies (PROMETHEUS, ADAPT-DES [the Assessment of Dual AntiPlatelet Therapy with Drug-Eluting Stents], THIN [The Health Improvement Network], and CHARM [Candesartan in Heart Failure-Assessment of Reduction in Mortality and Morbidity]) to compare the performance of conventional covariate adjustment with 4 common PS methods: matching, stratification, inverse probability weighting, and use of PS as a covariate. We found that stratification performed poorly with few outcome events, and inverse probability weighting gave imprecise estimates of treatment effect and undue influence to a small number of observations when substantial confounding was present. Covariate adjustment and matching performed well in all of our examples, although matching tended to give less precise estimates in some cases. PS methods are not necessarily superior to conventional covariate adjustment, and care should be taken to~select the most suitable method.},
  langid = {english},
  keywords = {covariate-adjustment,matching,propensity,stratification}
}

@article{eme06iss,
  title = {Issues in the Use of Adaptive Clinical Trial Designs},
  author = {Emerson, Scott S.},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {3270--3296},
  citeulike-article-id = {13265488},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {group-sequential,rct,sequential-sampling,stopping-rules},
  note = {good description of issues a clinical statistician has to deal with}
}

@article{eme07fre,
  title = {Frequentist Evaluation of Group Sequential Clinical Trial Designs},
  author = {Emerson, Scott S. and Kittelson, John M. and Gillen, Daniel L.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {5047--5080},
  doi = {10.1002/sim.2901},
  url = {http://dx.doi.org/10.1002/sim.2901},
  citeulike-article-id = {13265647},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2901},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {bayes,group-sequential-test,interim-analyses,monitoring,operating-characteristics,rct,sample-size,sequential-monitoring,stopping-rules,tutorial}
}

@article{eme95sto,
  title = {Stopping a Clinical Trial Very Early Based on Unplanned Interim Analysis: {{A}} Group Sequential Approach},
  author = {Emerson, Scott S.},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {1152--1162},
  citeulike-article-id = {13264046},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {group-sequential-monitoring,monitoring,rct,study-design,unplanned-analysis,why-bayesian}
}

@article{eme96sta,
  title = {Statistical Packages for Group Sequential Methods},
  author = {Emerson, Scott S.},
  date = {1996},
  journaltitle = {Am Statistician},
  volume = {50},
  pages = {183--192},
  citeulike-article-id = {13264047},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {group-sequential-methods,nice-overview-of-dsmb-and-sequential-monitoring-in-clinical-trials,software}
}

@book{enc2,
  title = {Encyclopedia of {{Statistical Sciences}}},
  editor = {Kotz, Samuel and Johnson, Norman L.},
  date = {1982},
  volume = {2},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264049},
  posted-at = {2014-07-14 14:09:28},
  priority = {0}
}

@book{enc9,
  title = {Encyclopedia of {{Statistical Sciences}}},
  editor = {Kotz, Samuel and Johnson, Norman L.},
  date = {1988},
  volume = {9},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264048},
  posted-at = {2014-07-14 14:09:28},
  priority = {0}
}

@article{eng03imp,
  title = {Imputation of Missing Longitudinal Data: A Comparison of Methods},
  author = {Engels, Jean M. and Diehr, Paula},
  date = {2003},
  journaltitle = {J Clin Epi},
  volume = {56},
  pages = {968--976},
  citeulike-article-id = {13265356},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {longitudinal-data,repeated-measures},
  note = {within-subject imputation vs. using baseline data vs. population group;natural experiment that solved problems of simulated data because used real data with real missingness pattern with known true value;true value was a value observed after a missing response at a certain time, which was made to be artificially missing;most subjects had such measurements really missing;gold standard was ability to reproduce the known value, not performance in the final response model (or group comparison);LOCF;longitudinal imputation;next observation carried backward}
}

@article{eng90,
  title = {Alternatives to {{Fisher}}'s},
  author = {{Engeman}},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {267--268},
  citeulike-article-id = {13264050},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {categorical-data}
}

@article{enn98com,
  title = {A Comparison of Statistical Learning Methods on the {{GUSTO}} Database},
  author = {Ennis, Marguerite and Hinton, Geoffrey and Naylor, David and Revow, Mike and Tibshirani, Robert},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {2501--2508},
  citeulike-article-id = {13264051},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {gam,gusto,mars,neural-network,prediction}
}

@article{eps96biv,
  title = {A Bivariate Parametric Model for Survival and Intermediate Event Times},
  author = {Epstein, Leonardo D. and Munoz, Alvaro},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1171--1185},
  citeulike-article-id = {13264052},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {intermediate-event,intervening-event,multiple-endpoints}
}

@article{eri97does,
  title = {Does Admission to a Medical Department Improve Patient Life Expectancy},
  author = {Eriksen, Bjorn O. and Kristiansen, Erik N. and Pape, Jan F. and Almdahl, Sven M. and Hensrud, Anne and Jaeger, Steinar and Murer, Fred A. and Robertsen, Reidar and Thorsen, Glen},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {987--995},
  citeulike-article-id = {13264053},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {life-expectancy-gain},
  note = {most patients have little absolute gain but some have a lot, so average gain is substantial;uses expert judgment to estimate gain}
}

@article{erl16dea,
  title = {Dealing with Missing Covariates in Epidemiologic Studies: A Comparison between Multiple Imputation and a Full {{Bayesian}} Approach},
  author = {Erler, Nicole S. and Rizopoulos, Dimitris and Rosmalen, Joost and Jaddoe, Vincent W. V. and Franco, Oscar H. and Lesaffre, Emmanuel M. E. H.},
  date = {2016-07},
  journaltitle = {Stat Med},
  volume = {35},
  number = {17},
  pages = {2955--2974},
  issn = {02776715},
  doi = {10.1002/sim.6944},
  url = {http://dx.doi.org/10.1002/sim.6944},
  citeulike-article-id = {14240448},
  citeulike-attachment-1 = {erl16dea.pdf; /pdf/user/harrelfe/article/14240448/1096087/erl16dea.pdf; fd801a70c09a641a0f364c5d5ec25a273f4dc27e},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6944},
  day = {30},
  posted-at = {2016-12-29 15:43:06},
  priority = {0},
  keywords = {bayesian-inference,bayesian-methods,missing-data}
}

@article{esp19ass,
  title = {Assessing the Relationship between Markers of Glycemic Control through Flexible Copula Regression Models},
  author = {Espasandín‐Domínguez, J. and Cadarso‐Suárez, C. and Kneib, T. and Marra, G. and Klein, N. and Radice, R. and Lado‐Baleato, O. and González‐Quintela, A. and Gude, F.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8358},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8358},
  urldate = {2019-10-10},
  abstract = {Glycated haemoglobin (HbA1c) is a sensitive marker of blood glucose in patients with diabetes. However, levels can vary considerably, even amongst individuals with similar mean blood glucose concentrations. Other glycated proteins, such as fructosamine, can also act as blood sugar markers, but estimating HbA1c and fructosamine via independent models may lead to errors of interpretation regarding disease severity. From a clinical standpoint, it would be of great interest to know the factors that affect the mean concentration of both HbA1c and fructosamine, which influence the variability in the concentrations of these glycated markers and cause HbA1c/fructosamine discordance. Flexible models are required to illustrate the behaviour of these variables as well as the association between them. This work reviews existing models that might serve in this regard. Flexible copula regression models using splines were used to provide a better understanding of the behaviour of both glycated proteins and the relationship between them under the possible influence of different covariates. This work shows the usefulness of this type of models in practise and provides a basis for their clinical interpretation by means of an understandable case study. Ultimately, to better understand the effects of each continuous covariate, they are represented at the true scale of the response variables.},
  langid = {english},
  keywords = {copula,diabetes,multiple-endpoints}
}

@article{est16tim,
  title = {Time-Varying Effect Modeling with Longitudinal Data Truncated by Death: Conditional Models, Interpretations, and Inference},
  author = {Estes, Jason P. and Nguyen, Danh V. and Dalrymple, Lorien S. and Mu, Yi and ¸Sentürk, Damla},
  date = {2016-05},
  journaltitle = {Stat Med},
  volume = {35},
  number = {11},
  pages = {1834--1847},
  issn = {02776715},
  doi = {10.1002/sim.6836},
  url = {http://dx.doi.org/10.1002/sim.6836},
  citeulike-article-id = {14240457},
  citeulike-attachment-1 = {est16tim.pdf; /pdf/user/harrelfe/article/14240457/1096089/est16tim.pdf; 0c16eab438d2001e67f4b81afe6702bcb13dd229},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6836},
  day = {20},
  posted-at = {2016-12-29 15:52:57},
  priority = {2},
  keywords = {handling-deaths-when-studying-nonfatal-endpoints,multiple-endpoints,survival-analysis,truncation-by-death}
}

@article{ete87,
  title = {Extended Hazard Regression for Censored Survival Data with Covariates: {{A}} Spline Approximation for the Baseline Hazard Function},
  author = {Etezadi-Amoli, J. and Ciampi, A.},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {181--191},
  citeulike-article-id = {13264054},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {general,survival-analysis-regression,testing-proportional-hazards}
}

@article{etm21adj,
  title = {To {{Adjust}} or {{Not}} to {{Adjust}}: {{The Role}} of {{Different Covariates}} in {{Cardiovascular Observational Studies}}},
  shorttitle = {To {{Adjust}} or {{Not}} to {{Adjust}}},
  author = {Etminan, Mahyar and Brophy, James M. and Collins, Gary and Nazemipour, Maryam and Mansournia, Mohammad Ali},
  date = {2021-07-01},
  journaltitle = {American Heart Journal},
  volume = {237},
  pages = {62--67},
  issn = {0002-8703},
  doi = {10.1016/j.ahj.2021.03.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0002870321000739},
  urldate = {2021-07-21},
  abstract = {Covariate adjustment is integral to the validity of observational studies assessing causal effects. It is common practice to adjust for as many variables as possible in observational studies in the hopes of reducing confounding by other variables. However, indiscriminate adjustment for variables using standard regression models may actually lead to biased estimates. In this paper, we differentiate between confounders, mediators, colliders, and effect modifiers. We will discuss that while confounders should be adjusted for in the analysis, one should be wary of adjusting for colliders. Mediators should not be adjusted for when examining the total effect of an exposure on an outcome. Automated statistical programs should not be used to decide which variables to include in causal models. Using a case scenario in cardiology, we will demonstrate how to identify confounders, colliders, mediators and effect modifiers and the implications of adjustment or non-adjustment for each of them.},
  langid = {english},
  keywords = {collider,confounding,covariate-adjustment,observational-study,observational-study-design,observational-treatment-comparisons,rms}
}

@article{etz95bay,
  title = {Bayesian Statistical Methods in Public Health and Medicine},
  author = {Etzioni, R. D. and Kadane, J. B.},
  date = {1995},
  journaltitle = {Ann Rev Pub Hlth},
  volume = {16},
  pages = {23--41},
  citeulike-article-id = {13264055},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {bayesian-inference,teaching}
}

@article{etz96est,
  title = {Estimating the Costs Attributable to a Disease with Application to Ovarian Cancer},
  author = {Etzioni, Ruth and Urban, Nicole and Baker, Mary},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {95--103},
  citeulike-article-id = {13264056},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {analysis-of-costs,attributable-costs,censored-cost-data,discounting,economics}
}

@article{etz99use,
  title = {On the Use of Survival Analysis Techniques to Estimate Medical Care Costs},
  author = {Etzioni, Ruth D. and Feuer, Eric J. and Sullivan, Sean D. and Lin, Danyu and Hu, Chengcheng and Ramsey, Scott D.},
  date = {1999},
  journaltitle = {J Hlth Econ},
  volume = {18},
  pages = {365--380},
  citeulike-article-id = {13265115},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {analysis-of-cost,informative-censoring},
  note = {Zhao \& Tsiatis estimator;see zha97con;problems with Cox regression;good description of problem caused by cost accrual not being 1-1 function of time;very good review paper}
}

@article{eva15des,
  title = {Desirability of {{Outcome Ranking}} ({{DOOR}}) and {{Response Adjusted}} for {{Duration}} of {{Antibiotic Risk}} ({{RADAR}})},
  author = {Evans, Scott R. and Rubin, Daniel and Follmann, Dean and Pennello, Gene and Huskins, W. Charles and Powers, John H. and Schoenfeld, David and Chuang-Stein, Christy and Cosgrove, Sara E. and Fowler, Vance G. and Lautenbach, Ebbing and Chambers, Henry F.},
  date = {2015-09-01},
  journaltitle = {Clin. Infect. Dis.},
  volume = {61},
  number = {5},
  eprint = {26113652},
  eprinttype = {pmid},
  pages = {800--806},
  issn = {1537-6591},
  doi = {10.1093/cid/civ495},
  abstract = {Clinical trials that compare strategies to optimize antibiotic use are of critical importance but are limited by competing risks that distort outcome interpretation, complexities of noninferiority trials, large sample sizes, and inadequate evaluation of benefits and harms at the patient level. The Antibacterial Resistance Leadership Group strives to overcome these challenges through innovative trial design. Response adjusted for duration of antibiotic risk (RADAR) is a novel methodology utilizing a superiority design and a 2-step process: (1) categorizing patients into an overall clinical outcome (based on benefits and harms), and (2) ranking patients with respect to a desirability of outcome ranking (DOOR). DOORs are constructed by assigning higher ranks to patients with (1) better overall clinical outcomes and (2) shorter durations of antibiotic use for similar overall clinical outcomes. DOOR distributions are compared between antibiotic use strategies. The probability that a randomly selected patient will have a better DOOR if assigned to the new strategy is estimated. DOOR/RADAR represents a new paradigm in assessing the risks and benefits of new strategies to optimize antibiotic use.},
  langid = {english},
  pmcid = {PMC4542892},
  keywords = {multiple-endpoints,ordinal-endpoints,rct}
}

@article{eva16usi,
  title = {Using {{Outcomes}} to {{Analyze Patients Rather}} than {{Patients}} to {{Analyze Outcomes}}: {{A Step Toward Pragmatism}} in {{Benefit}}:{{Risk Evaluation}}},
  shorttitle = {Using {{Outcomes}} to {{Analyze Patients Rather}} than {{Patients}} to {{Analyze Outcomes}}},
  author = {Evans, Scott R. and Follmann, Dean},
  date = {2016-10-01},
  journaltitle = {Statistics in Biopharmaceutical Research},
  volume = {8},
  number = {4},
  pages = {386--393},
  issn = {null},
  doi = {10.1080/19466315.2016.1207561},
  url = {https://doi.org/10.1080/19466315.2016.1207561},
  urldate = {2019-08-06},
  abstract = {In the future, clinical trials will have an increased emphasis on pragmatism, providing a practical description of the effects of new treatments in realistic clinical settings. Accomplishing pragmatism requires better summaries of the totality of the evidence in ways that clinical trials consumers—patients, physicians, insurers—find transparent and allow for informed benefit:risk decision-making.The current approach to the analysis of clinical trials is to analyze efficacy and safety separately and then combine these analyses into a benefit:risk assessment. Many assume that this will effectively describe the impact on patients. But this approach is suboptimal for evaluating the totality of effects on patients.We discuss methods for benefit:risk assessment that have greater pragmatism than methods that separately analyze efficacy and safety. These include the concepts of within-patient analyses and composite benefit:risk endpoints with a goal of understanding how to analyze one patient before trying to figure out how to analyze many. We discuss the desirability of outcome ranking (DOOR) and introduce the partial credit strategy using an example in a clinical trial evaluating the effects of a new antibiotic. As part of the example, we introduce a strategy to engage patients as a resource to inform benefit:risk analyses consistent with the goal of measuring and weighing outcomes that are most important from the patient's perspective.We describe a broad vision for the future of clinical trials consistent with increased pragmatism. Greater focus on using endpoints to analyze patients rather than patients to analyze endpoints particularly in late-phase/stage clinical trials is an important part of this vision.},
  keywords = {multiple-endpoints,ordinal-endpoints,rct},
  note = {Proposed methods do not handle time until events fully.~ For example there is no discussion of how to trade off an early heart attack with a late death.~ Also does not allow for interim missing data.
\par
Wrongly implied that the Wilcoxon test does not assume the proportional odds assumption (p. 10 bottom).}
}

@book{eve95cam,
  title = {The {{Cambridge Dictionary}} of {{Statistics}} in the {{Medical Sciences}}},
  author = {Everitt, B. S.},
  date = {1995},
  publisher = {{Cambridge University Press}},
  location = {{New York}},
  citeulike-article-id = {13264057},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {dictionary,general,glossary,teaching-mds}
}

@online{ext,
  title = {Extracorporeal Membrane Oxygenation for Severe Acute Respiratory Distress Syndrome Associated with {{COVID-19}}: A Retrospective Cohort Study - {{The Lancet Respiratory Medicine}}},
  url = {https://www.thelancet.com/journals/lanres/article/PIIS2213-2600(20)30328-3/fulltext},
  urldate = {2021-11-11},
  keywords = {covid19,longitudinal,ordinal,transition-model,transition-probability}
}

@article{fac98man,
  title = {The Management of Interim Analyses in Drug Development},
  author = {Facey, Karen M. and Lewis, John A.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1801--1809},
  citeulike-article-id = {13264058},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {rct,sequential-monitoring,study-design}
}

@article{fae09eff,
  title = {The Effective Sample Size and an Alternative Small-Sample Degrees-of-Freedom Method},
  author = {Faes, Christel and Molenberghs, Geert and Aerts, Marc and Verbeke, Geert and Kenward, Michael G.},
  date = {2009},
  journaltitle = {Am Statistician},
  volume = {63},
  number = {4},
  pages = {389--399},
  citeulike-article-id = {13265789},
  citeulike-attachment-1 = {fae09eff.pdf; /pdf/user/harrelfe/article/13265789/1010626/fae09eff.pdf; 563b82aadc7a389d13cee03053c51c2ab29cbed7},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {amount-of-information,correlated-data,information-limit,longitudinal-data-analysis,mixed-models,repeated-measures,serial-data,small-sample-inference},
  note = {useful way to think about information content in correlated repeated measures;effective sample size}
}

@article{fag13goo,
  title = {A Goodness-of-Fit Test for the Proportional Odds Regression Model},
  author = {Fagerland, Morten W. and Hosmer, David W.},
  date = {2013},
  journaltitle = {Stat Med},
  volume = {32},
  number = {13},
  pages = {2235--2249},
  doi = {10.1002/sim.5645},
  url = {http://dx.doi.org/10.1002/sim.5645},
  abstract = {We examine goodness-of-fit tests for the proportional odds logistic regression model—the most commonly used regression model for an ordinal response variable. We derive a test statistic based on the Hosmer–Lemeshow test for binary logistic regression. Using a simulation study, we investigate the distribution and power properties of this test and compare these with those of three other goodness-of-fit tests. The new test has lower power than the existing tests; however, it was able to detect a greater number of the different types of lack of fit considered in this study. Moreover, the test allows for the results to be summarized in a contingency table of observed and estimated frequencies, which is a useful supplementary tool to assess model fit. We illustrate the ability of the tests to detect lack of fit using a study of aftercare decisions for psychiatrically hospitalized adolescents. The test proposed in this paper is similar to a recently developed goodness-of-fit test for multinomial logistic regression. A unified approach for testing goodness of fit is now available for binary, multinomial, and ordinal logistic regression models.},
  citeulike-article-id = {13265966},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5645},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {goodness-of-fit,hosmerlemeshow-test,ordinal-logistic-regression,ordinal-models,ordinal-response,proportional-odds}
}

@article{fai97sum,
  title = {Summary Measures and Statistics for Comparison of Quality of Life in a Clinical Trial of Cancer Therapy},
  author = {Fairclough, Diane L.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1197--1209},
  citeulike-article-id = {13264059},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {area-under-qol-curve,auc,missing-data,qaly,qol,quality-of-life,serial-measurements,study-design}
}

@article{fan07amn,
  title = {To Amnio or Not to Amnio: {{That}} Is the Decision for {{Bayes}}},
  author = {Fan, Juanjuan and Levine, Richard A.},
  date = {2007},
  journaltitle = {Chance},
  volume = {20},
  number = {3},
  pages = {26--32},
  citeulike-article-id = {13265622},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {bayes-decision-tutorial,decision-theory,diagnosis,utility-theory}
}

@article{fan90,
  title = {Parametric Inference in a Multiple Renewal Process with Time-Dependent Covariates},
  author = {Fang, J. Q. and Shi, Z. L. and Wang, Y. and Zhang, X. and Zeng, D. L. and Zhang, J. N.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {849--854},
  citeulike-article-id = {13264060},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {general,survival-analysis-regression}
}

@article{far01und,
  title = {Understanding Neural Networks Using Regression Trees: An Application to Multiple Myeloma Survival Data},
  author = {Faraggi, David and LeBlanc, Michael and Crowley, John},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2965--2976},
  citeulike-article-id = {13265228},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {approximating-a-neural-network-using-a-regression-tree,cart,model-approximation,pre-conditioning,survival-analysis}
}

@article{far02mul,
  title = {Multiple Imputation versus Data Enhancement for Dealing with Missing Data in Observational Health Care Outcome Analyses},
  author = {Faris, Peter D. and Ghali, William A. and Brant, Rollin and Norris, Colleen M. and Galbraith, P. Diane and Knudtson, Merril L.},
  date = {2002},
  journaltitle = {J Clin Epi},
  volume = {55},
  pages = {184--191},
  citeulike-article-id = {13265261},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {multiple-imputation,r,transcan},
  note = {evaluated transcan vs. MICE vs NORM on complete cases on an independent test sample using C index}
}

@article{far92cos,
  title = {The Cost of Data Analysis},
  author = {Faraway, J. J.},
  date = {1992},
  journaltitle = {J Comp Graph Stat},
  volume = {1},
  pages = {213--229},
  citeulike-article-id = {13264061},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {bootstrap,model-uncertainty,modeling-strategy,predictive-accuracy,regression-diagnostics,validation}
}

@article{far96int,
  title = {Interval Censored Survival Data: {{A}} Generalized Linear Modelling Approach},
  author = {Farrington, C. P.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {283--292},
  citeulike-article-id = {13264062},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {logistic-model-extensions,logistic-model-in-survival-analysis,nonparametric-estimation-with-interval-censoring}
}

@article{far96sim,
  title = {A Simulation Study of Cross-Validation for Selecting an Optimal Cutpoint in Univariate Survival Analysis},
  author = {Faraggi, David and Simon, Richard},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2203--2213},
  citeulike-article-id = {13264063},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {cutpoints,information-loss,teaching-mds},
  note = {bias in point estimate of effect from selecting cutpoints based on P-value; loss of information from dichotomizing continuous predictors}
}

@article{far97lar,
  title = {Large Sample {{Bayesian}} Inference on the Parameters of the Proportional Hazard Model},
  author = {Faraggi, David and Simon, Richard},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2573--2585},
  citeulike-article-id = {13264064},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {approximate-bayesian-inference,variable-selection}
}

@article{fav05dis,
  title = {A Discussion on the Role of Clinimetrics and the Misleading Effects of Psychometric Theory},
  author = {Fava, Giovanni A. and Belaise, Carlotta},
  date = {2005},
  journaltitle = {J Clin Epi},
  volume = {58},
  pages = {753--756},
  citeulike-article-id = {13265436},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {anxiety,change,clinical-assessment,clinimetrics,depression,rating-scales},
  note = {optimizing psychometric properties of a scale may make it insensitive for measuring changes in clinical state;simple global scales may work best}
}

@article{fay11fle,
  title = {A Flexible Genome-Wide Bootstrap Method That Accounts for Ranking and Threshold-Selection Bias in {{GWAS}} Interpretation and Replication Study Design},
  author = {Faye, Laura L. and Sun, Lei and Dimitromanolakis, Apostolos and Bull, Shelley B.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  number = {15},
  pages = {1898--1912},
  doi = {10.1002/sim.4228},
  url = {http://dx.doi.org/10.1002/sim.4228},
  abstract = {The phenomenon known as the winner's curse is a form of selection bias that affects estimates of genetic association. In genome-wide association studies (GWAS) the bias is exacerbated by the use of stringent selection thresholds and ranking over hundreds of thousands of single nucleotide polymorphisms (SNPs). We develop an improved multi-locus bootstrap point estimate and confidence interval, which accounts for both ranking- and threshold-selection bias in the presence of genome-wide SNP linkage disequilibrium structure. The bootstrap method easily adapts to various study designs and alternative test statistics as well as complex SNP selection criteria. The latter is demonstrated by our application to the Wellcome Trust Case Control Consortium findings, in which the selection criterion was the minimum of the p-values for the additive and genotypic genetic effect models. In contrast, existing likelihood-based bias-reduced estimators account for the selection criterion applied to an SNP as if it were the only one tested, and so are more simple computationally, but do not address ranking across SNPs. Our simulation studies show that the bootstrap bias-reduced estimates are usually closer to the true genetic effect than the likelihood estimates and are less variable with a narrower confidence interval. Replication study sample size requirements computed from the bootstrap bias-reduced estimates are adequate 75–90 per cent of the time compared to 53-60 per cent of the time for the likelihood method. The bootstrap methods are implemented in a user-friendly package able to provide point and interval estimation for both binary and quantitative phenotypes in large-scale GWAS.},
  citeulike-article-id = {13265907},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4228},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {bias-reduction,case-control-studies,genetic-effect-estimates,quantitative-traits,statistical-genetics,winners-curse}
}

@article{fay18cau,
  title = {Causal Estimands and Confidence Intervals Associated with {{Wilcoxon-Mann-Whitney}} Tests in Randomized Experiments},
  author = {Fay, Michael P. and Brittain, Erica H. and Shih, Joanna H. and Follmann, Dean A. and Gabriel, Erin E.},
  date = {2018},
  journaltitle = {Statistics in Medicine},
  volume = {37},
  number = {20},
  pages = {2923--2937},
  issn = {1097-0258},
  doi = {10.1002/sim.7799},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7799},
  urldate = {2021-04-01},
  abstract = {Although the P value from a Wilcoxon-Mann-Whitney test is used often with randomized experiments, it is rarely accompanied with a causal effect estimate and its confidence interval. The natural parameter for the Wilcoxon-Mann-Whitney test is the Mann-Whitney parameter, ϕ, which measures the probability that a randomly selected individual in the treatment arm will have a larger response than a randomly selected individual in the control arm (plus an adjustment for ties). We show that the Mann-Whitney parameter may be framed as a causal parameter and show that it is not equal to a closely related and nonidentifiable causal effect, ψ, the probability that a randomly selected individual will have a larger response under treatment than under control (plus an adjustment for ties). We review the paradox, first expressed by Hand, that the ψ parameter may imply that the treatment is worse (or better) than control, while the Mann-Whitney parameter shows the opposite. Unlike the Mann-Whitney parameter, ψ is nonidentifiable from a randomized experiment. We review some nonparametric assumptions that rule out Hand's paradox through bounds on ψ and use bootstrap methods to make inferences on those bounds. We explore the relationship of the proportional odds parameter to Hand's paradox, showing that the paradox may occur for proportional odds parameters between 1/9 and 9. Thus, large effects are needed to ensure that if treatment appears better by the Mann-Whitney parameter, then treatment improves responses in most individuals. We demonstrate these issues using a vaccine trial.},
  langid = {english},
  keywords = {causal-effects,estimand,ordinal,proportional-odds,wilcoxon-mann-whitney,wilcoxon-test},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7799},
  note = {Contrasts between-patient and within-patient treatment effects.~~~ In the case of no ties in Y, Eq. (9) provides the exact relationship between the OR and the concordance probability.~~ Need to see if this relationship works only for the true parameters are also for parameter estimates.~ In Eq. (9) one can show that log phi is almost exactly linear in the log odds ratio, and the slope of predicting log(OR) from logit phi is 0.6974 with a reciprocal of 1.43 which is about the right constant for relating a probit model effect to the concordance probability (perhaps by coincidence).~ But this differs from the slope of 1.52 that has been empirically found to work in general.}
}

@article{fay18con,
  title = {Confidence Intervals of the {{Mann-Whitney}} Parameter That Are Compatible with the {{Wilcoxon-Mann-Whitney}} Test},
  author = {Fay, Michael P. and Malinovsky, Yaakov},
  date = {2018},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.7890},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7890},
  urldate = {2018-07-09},
  abstract = {For the two-sample problem, the Wilcoxon-Mann-Whitney (WMW) test is used frequently: it is simple to explain (a permutation test on the difference in mean ranks), it handles continuous or ordinal responses, it can be implemented for large or small samples, it is robust to outliers, it requires few assumptions, and it is efficient in many cases. Unfortunately, the WMW test is rarely presented with an effect estimate and confidence interval. A natural effect parameter associated with this test is the Mann-Whitney parameter, φ = Pr[ X},
  langid = {english},
  keywords = {c-index,concordance-probability,confidence-interval,u-statistic,wilcoxon-mann-whitney,wilcoxon-test}
}

@article{fay21cur,
  title = {The Current State of {{Bayesian}} Methods in Nonclinical Pharmaceutical Statistics: {{Survey}} Results and Recommendations from the {{DIA}}/{{ASA-BIOP Nonclinical Bayesian Working Group}}},
  shorttitle = {The Current State of {{Bayesian}} Methods in Nonclinical Pharmaceutical Statistics},
  author = {Faya, Paul and Sondag, Perceval and Novick, Steven and Banton, Dwaine and Jr, John W. Seaman and Stamey, James D. and Boulanger, Bruno},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {20},
  number = {2},
  pages = {245--255},
  issn = {1539-1612},
  doi = {10.1002/pst.2072},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2072},
  urldate = {2021-03-07},
  abstract = {The use of Bayesian methods to support pharmaceutical product development has grown in recent years. In clinical statistics, the drive to provide faster access for patients to medical treatments has led to a heightened focus by industry and regulatory authorities on innovative clinical trial designs, including those that apply Bayesian methods. In nonclinical statistics, Bayesian applications have also made advances. However, they have been embraced far more slowly in the nonclinical area than in the clinical counterpart. In this article, we explore some of the reasons for this slower rate of adoption. We also present the results of a survey conducted for the purpose of understanding the current state of Bayesian application in nonclinical areas and for identifying areas of priority for the DIA/ASA-BIOP Nonclinical Bayesian Working Group. The survey explored current usage, hurdles, perceptions, and training needs for Bayesian methods among nonclinical statisticians. Based on the survey results, a set of recommendations is provided to help guide the future advancement of Bayesian applications in nonclinical pharmaceutical statistics.},
  langid = {english},
  keywords = {adoption,bayes,drug-development},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2072}
}

@article{fay97bay,
  title = {Tutorial in {{Biostatistics}}: {{Bayesian}} Data Monitoring in Clinical Trials},
  author = {Fayers, Peter M. and Ashby, Deborah and Parmar, Mahesh K.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1413--1430},
  citeulike-article-id = {13264065},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {bayesian-inference,choice-of-prior-distribution,convincing-clinicians-to-alter-medical-practice,rct,sequential-monitoring,skeptical-prior,study-design,teaching-paper}
}

@article{fay98con,
  title = {Conditional Logistic Regression with Sandwich Estimators: {{Application}} to a Meta-Analysis},
  author = {Fay, Michael P. and Graubard, Barry I. and Freedman, Laurence S. and Midthune, Douglas N.},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {195--208},
  citeulike-article-id = {13264066},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {gee,improving-sandwich-estimator-when-number-of-clusters-is-small,random-effects,robust-variance,sandwich-estimator}
}

@article{fec17para,
  title = {Parenting Stress and Salivary Cortisol in Parents of Children with Autism Spectrum Disorder: {{Longitudinal}} Variations in the Context of a Service Dog's Presence in the Family},
  shorttitle = {Parenting Stress and Salivary Cortisol in Parents of Children with Autism Spectrum Disorder},
  author = {Fecteau, Stéphanie-M. and Boivin, Louise and Trudel, Marcel and Corbett, Blythe A. and Harrell, Frank E. and Viau, Robert and Champagne, Noël and Picard, Frédéric},
  date = {2017-02},
  journaltitle = {Biol Psychol},
  volume = {123},
  eprint = {27986514},
  eprinttype = {pmid},
  pages = {187--195},
  issn = {1873-6246},
  doi = {10.1016/j.biopsycho.2016.12.008},
  abstract = {A significant portion of parents of children with autism spectrum disorder report high levels of stress related to parenting responsibilities, which have been linked to abnormal cortisol patterns. This study seeks to better understand the parents' adaptation to caregiving demands and use of a service dog, by taking into account longitudinal variations in salivary cortisol and perception of parental stress. Salivary cortisol was collected one day per week for 15 weeks by 98 primary caregivers of children with ASD. Overall, parents perceived high levels of stress at baseline. Mean morning cortisol increase was below expected levels for healthy adults, and perception of stress predicted morning cortisol activity. Hypocorticolism related to chronic stress may be present in parents of children with ASD. Longitudinal analysis revealed that the presence of a service dog in the family had an effect on parenting stress, wakening and morning cortisol levels.},
  langid = {english},
  keywords = {collaboration}
}

@article{fed09con,
  title = {Consequences of Dichotomization},
  author = {Fedorov, Valerii and Mannino, Frank and Zhang, Rongmei},
  date = {2009},
  journaltitle = {Pharm Stat},
  volume = {8},
  pages = {50--61},
  doi = {10.1002/pst.331},
  url = {http://dx.doi.org/10.1002/pst.331},
  citeulike-article-id = {13265728},
  citeulike-attachment-1 = {fed09con.pdf; /pdf/user/harrelfe/article/13265728/1027987/fed09con.pdf; 7e1edf1558bbca47ebed9e0ccb36ec439f5e402d},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.331},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {categorization-of-outcome-variable,continuous-variables,cutpoints,dichotomization,graphics,loss-of-information,loss-of-power,response,teaching-mds,theoretical-calculations},
  note = {optimal cutpoint depends on unknown parameters;should only entertain dichotomization when "estimating a value of the cumulative distribution and when the assumed model is very different from the true model";nice graphics}
}

@article{fei11ext,
  title = {Extracting {{Sunbeams From Cucumbers}}},
  author = {Feinberg, Richard A. and Wainer, Howard},
  date = {2011},
  journaltitle = {J Comp Graph Stat},
  volume = {20},
  number = {4},
  eprint = {http://pubs.amstat.org/doi/pdf/10.1198/jcgs.2011.204a},
  pages = {793--810},
  doi = {10.1198/jcgs.2011.204a},
  url = {http://pubs.amstat.org/doi/abs/10.1198/jcgs.2011.204a},
  abstract = {In this article we survey the display formats used in the J Comp Graph Stat during the period 2005–2010 and discover that the most dominant format was the table. We then examine the actual tables used and find that most could have been made more comprehensible had they utilized one or more of three simple rules for table construction. We illustrate these rules on tables drawn from the Journal and elsewhere.},
  citeulike-article-id = {13265915},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/jcgs.2011.204a},
  citeulike-linkout-1 = {http://pubs.amstat.org/doi/abs/10.1198/jcgs.2011.204a},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {statistical-graphics,table-making,tables}
}

@book{fei77cli,
  title = {Clinical {{Biostatistics}}},
  author = {Feinstein, Alvan R.},
  date = {1977},
  publisher = {{C. V. Mosby}},
  location = {{St. Louis}},
  citeulike-article-id = {13264067},
  posted-at = {2014-07-14 14:09:28},
  priority = {0}
}

@incollection{fei77cliKelvin,
  title = {Clinical {{Biostatistics}}},
  author = {Feinstein, Alvan R.},
  date = {1977},
  pages = {229--242},
  publisher = {{C. V. Mosby Co.}},
  location = {{St. Louis, MO}},
  chapter = {16},
  citeulike-article-id = {13265753},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  note = {coined the phrase "the curse of Kelvin", to refer to the unthinking and inappropriate worship of quantifiable information in medicine.}
}

@article{fei90,
  title = {A Comparison of Multivariable Mathematical Methods for Predicting Survival (Parts {{I}},{{II}},{{III}})},
  author = {Feinstein, A. R. and Wells, C. K. and Walter, S. D.},
  date = {1990},
  journaltitle = {J Clin Epi},
  volume = {43},
  pages = {339--372},
  citeulike-article-id = {13264068},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {predictive-accuracy,variable-selection}
}

@book{fei96mul,
  title = {Multivariable {{Analysis}}},
  author = {Feinstein, Alvan R.},
  date = {1996},
  publisher = {{Yale University Press}},
  location = {{New Haven, Connecticut}},
  citeulike-article-id = {13264069},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {interpretation-of-parameters,multivariable-modeling,teaching-mds}
}

@article{fel06pre,
  title = {A Preference-Based Measure for Test Performance with an Application to Prenatal Diagnostics},
  author = {Felder, Stefan and Robra, Bernt-Peter},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {3696--3706},
  citeulike-article-id = {13265528},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {diagnosis,diagnostic-accuracy,expected-utility,prenatal-diagnostics,roc}
}

@article{fel21pro,
  title = {Probabilistic {{Readjudication}} of {{Heart Failure Hospitalization Events}} in the {{PARAGON-HF Study}}},
  author = {Felker, G. Michael and Butler, Javed and Januzzi, James L. and Desai, Akshay S. and McMurray, John J.V. and Solomon, Scott D.},
  date = {2021-06-08},
  journaltitle = {Circulation},
  volume = {143},
  number = {23},
  pages = {2316--2318},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCULATIONAHA.121.054496},
  url = {https://www.ahajournals.org/doi/10.1161/CIRCULATIONAHA.121.054496},
  urldate = {2021-06-12},
  keywords = {adjudication,endpoints,imputation,multiple-endpoints,rct,uncertainty}
}

@article{fen95ana,
  title = {The Analysis of Censored Treatment Cost Data in Economic Evaluation},
  author = {Fenn, Paul and McGuire, Alistair and Phillips, Victoria and Backhouse, Martin and Jones, David},
  date = {1995},
  journaltitle = {Med Care},
  volume = {8},
  pages = {851--863},
  citeulike-article-id = {13264070},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {analysis-of-cost-data,censored-cost-data,economics}
}

@article{fen96com,
  title = {A Comparison of Statistical Methods for Clustered Data Analysis with {{Gaussian}} Error},
  author = {Feng, Ziding and McLerran, Dale and Grizzle, James},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1793--1806},
  citeulike-article-id = {13264071},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {cluster-bootstrap,clustered-data,gee,longitudinal-data,moving-blocks-bootstrap,repeated-measurement-data,simulation-setup},
  note = {bootstrap performed extremely well with small numbers of large clusters}
}

@article{fen96mod,
  title = {Modelling Programme Costs in Economic Evaluation},
  author = {Fenn, Paul and McGuire, Alistair and Backhouse, Martin and Jones, David},
  date = {1996},
  journaltitle = {J Hlth Econ},
  volume = {15},
  pages = {115--125},
  citeulike-article-id = {13264072},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {analysis-of-cost-data,cox-model},
  note = {nice section on hazard and survival functions incorporating the transformation from the time scale to the accumulated cost scale;lack of understanding of informative censoring when fitting Cox and other models;poor literature review}
}

@article{fer07met,
  title = {Methodologic Discussions for Using and Interpreting Composite Endpoints Are Limited, but Still Identify Major Concerns (with Discussion)},
  author = {Ferreira-González, Ignacio and Permanyer-Miralda, Gaietá and Busse, Jason W. and Bryant, Dianne M. and Montori, Victor M. and Alonso-Coello, Pablo and Walter, Stephen D. and Guyatt, Gordon H.},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {651--662},
  citeulike-article-id = {13265601},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {clinical-trials,combined-outcomes,composite-endpoints,overview,rct}
}

@article{fer13int,
  title = {Integrating Mortality and Morbidity Outcomes: Using Quality-Adjusted Life Years in Critical Care Trials},
  shorttitle = {Integrating Mortality and Morbidity Outcomes},
  author = {Ferguson, Niall D. and Scales, Damon C. and Pinto, Ruxandra and Wilcox, M. Elizabeth and Cook, Deborah J. and Guyatt, Gordon H. and Schünemann, Holger J. and Marshall, John C. and Herridge, Margaret S. and Meade, Maureen O. and {Canadian Critical Care Trials Group}},
  date = {2013-02-01},
  journaltitle = {Am J Respir Crit Care Med},
  volume = {187},
  number = {3},
  eprint = {23204250},
  eprinttype = {pmid},
  pages = {256--261},
  issn = {1535-4970},
  doi = {10.1164/rccm.201206-1057OC},
  abstract = {RATIONALE: Outcome measures that integrate mortality and morbidity, like quality-adjusted life years (QALYs), have been proposed for critical care clinical trials. OBJECTIVES: We sought to describe the distribution of QALYs in critically ill patients and estimate sample size requirements for a hypothetical trial using QALYs as the primary outcome. METHODS: We used data from a prospective cohort study of survivors of acute respiratory distress syndrome to generate utility values and calculate QALYs at 6 and 12 months. Using multiple simulations, we estimated the required sample sizes for multiple outcome scenarios in a hypothetical trial, including a base-case wherein the intervention improved both mortality and QALYs among survivors. MEASUREMENTS AND MAIN RESULTS: From 195 enrolled patients, follow-up was sufficient to generate QALY outcomes for 168 (86.2\%) at 6 months and 159 (81.5\%) at 1 year. For a hypothetical intervention that reduced mortality from 48 to 44\% and improved QALYs by 0.025 in survivors at 6 months, the required per-group sample size was 571 (80\% power; two-sided α = 0.05), compared with 2,436 patients needed for a comparison focusing on mortality alone. When only mortality or QALY in survivors (but not both) showed improvement by these amounts, 3,426 and 1,827 patients per group were needed, respectively. When mortality and morbidity effects moved in opposite directions, simulation results became impossible to interpret. CONCLUSIONS: QALYs may be a feasible outcome in critical care trials yielding a patient-centered result and major gains in statistical power under certain conditions, but this approach is susceptible to several threats, including loss to follow-up.},
  langid = {english},
  keywords = {critical-illness,multiple-endpoints,qaly,qol,rct,utility}
}

@article{fer98det,
  title = {Determining the Dimension in Sliced Inverse Regression and Related Methods},
  author = {Ferré, Louis},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {132--149},
  citeulike-article-id = {13264073},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {data-reduction,sliced-inverse-regression}
}

@article{feu92gra,
  title = {Graphical Representation of Survival Curves Associated with a Binary Non-Reversible Time Dependent Covariate},
  author = {Feuer, E. J. and Hankey, B. F. and Gaynor, J. J. and Wesley, M. N. and Baker, S. G. and Meyer, J. S.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {455--474},
  citeulike-article-id = {13264074},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {tdc}
}

@article{fie01sta,
  title = {Statistical Perspectives on Confidentiality and Data Access in Public Health},
  author = {Feinberg, Stephen E.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1347--1356},
  citeulike-article-id = {13265194},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {confidentiality,disclosure},
  note = {good overview of statistical disclosure methods}
}

@book{fieBookana,
  title = {The {{Analysis}} of {{Cross-Classified Categorical Data}}},
  author = {Fienberg, Steven E.},
  date = {2007},
  edition = {Second},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13264075},
  isbn = {0-387-72824-4},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {continuation-ratio-model}
}

@article{fil07cat,
  title = {Categorizing {{BMI}} May Lead to Biased Results in Studies Investigating In-Hospital Mortality after Isolated {{CABG}}},
  author = {Filardo, Giovanni and Hamilton, Cody and Hamman, Baron and Ng, Hon K. T. and Grayburn, Paul},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {1132--1139},
  doi = {10.1016/j.jclinepi.2007.01.008},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2007.01.008},
  citeulike-article-id = {13265639},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2007.01.008},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {bmi,cabg,categorization,categorizing-continuous-variables,cutpoints,dichtomization,epidemiology,hospital-mortality,smoothing,surgical-adverse-events},
  note = {investigators should waive categorization entirely and use smoothed functions for continuous variables;examples of non-monotonic relationships}
}

@article{fin06cal,
  title = {Calibration Guidelines Challenge Outlier Practices},
  author = {Finney, David J.},
  date = {2006},
  journaltitle = {Am Statistician},
  volume = {60},
  pages = {309--313},
  citeulike-article-id = {13265530},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {anticoagulant-therapy,bias,causal-inference,causation,ethics,objectivity,outliers},
  note = {guidelines for treatment of outliers;overview of types of outliers;letter to the editor and reply 61:187 May 2007}
}

@article{fin21ass,
  title = {Assessing Vaccine Durability in Randomized Trials Following Placebo Crossover},
  author = {Fintzi, Jonathan and Follmann, Dean},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9001},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9001},
  urldate = {2021-04-30},
  abstract = {Randomized vaccine trials are used to assess vaccine efficacy (VE) and to characterize the durability of vaccine-induced protection. If efficacy is demonstrated, the treatment of placebo volunteers becomes an issue. For COVID-19 vaccine trials, there is broad consensus that placebo volunteers should be offered a vaccine once efficacy has been established. This will likely lead to most placebo volunteers crossing over to the vaccine arm, thus complicating the assessment of long term durability. We show how to analyze durability following placebo crossover and demonstrate that the VE profile that would be observed in a placebo controlled trial is recoverable in a trial with placebo crossover. This result holds no matter when the crossover occurs and with no assumptions about the form of the efficacy profile. We only require that the VE profile applies to the newly vaccinated irrespective of the timing of vaccination. We develop different methods to estimate efficacy within the context of a proportional hazards regression model and explore via simulation the implications of placebo crossover for estimation of VE under different efficacy dynamics and study designs. We apply our methods to simulated COVID-19 vaccine trials with durable and waning VE and a total follow-up of 2 years.},
  langid = {english},
  keywords = {covid19,cross-over-trials,drug-development,vaccine},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9001}
}

@article{fin99com,
  title = {Combining Mortality and Longitudinal Measures in Clinical Trials},
  author = {Finkelstein, Dianne M. and Schoenfeld, David A.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1341--1354},
  citeulike-article-id = {13264076},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {continuous-response-and-survival-time,fatal-and-nonfatal-endpoint,multiple-endpoints}
}

@article{fin99pro,
  title = {A Proportional Hazards Model for the Subdistribution of a Competing Risk},
  author = {Fine, J. P. and Gray, R. J.},
  date = {1999},
  journaltitle = {J Am Stat Assoc},
  volume = {94},
  pages = {496--509},
  citeulike-article-id = {13265469},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {competing-risks,subdistribution-functions}
}

@article{fio08red,
  title = {Reduced-Rank Proportional Hazards Regression and Simulation-Based Predictino for Multi-State Models},
  author = {Fiocco, Marta and Putter, Hein and van Houwelingen, Hans C.},
  options = {useprefix=true},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {4340--4358},
  citeulike-article-id = {13265700},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {multi-state-models,prediction,reduced-rank,resampling,simulations}
}

@article{fis01act,
  title = {Active-Control Trials: {{How}} Would a New Agent Compare with Placebo? {{A}} Method Illustrated with Clopidogrel, Aspirin, and Placebo},
  author = {Fisher, Lloyd D. and Gent, Michael and Buller, Harry R.},
  date = {2001},
  journaltitle = {Am Heart J},
  volume = {141},
  pages = {26--32},
  doi = {10.1067/mhj.2001.111262},
  url = {http://dx.doi.org/10.1067/mhj.2001.111262},
  citeulike-article-id = {13265176},
  citeulike-linkout-0 = {http://dx.doi.org/10.1067/mhj.2001.111262},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {active-control,rct},
  note = {how to estimate the treatment effect against placebo in active-control trials using results of previous trial comparator vs. placebo;based on odds ratios}
}

@article{fis96com,
  title = {Comments on {{Bayesian}} and Frequentist Analysis and Interpretation of Clinical Trials},
  author = {Fisher, Lloyd D.},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {423--434},
  citeulike-article-id = {13264077},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {bayesian-inference,problems-selecting-priors,randomized-trials,stylized-priors}
}

@article{fit01alt,
  title = {An Alternative Parameterization of the General Linear Mixture Model for Longitudinal Data with Non-Ignorable Drop-Outs},
  author = {Fitzmaurice, Garrett M. and Laird, Nan M. and Shneyer, Lucy},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1009--1021},
  citeulike-article-id = {13265190},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {informative-censoring,informative-dropout,non-ignorable-non-response,nonrandom-dropout,repeated-measures,serial-data},
  note = {tries to solve problems caused by methods which condition on dropout times when trying to marginalize over the distribution of dropout times (this caused unconditional means to not be linear in the original parameters)}
}

@article{fit93lik,
  title = {A Likelihood-Based Method for Analysing Longitudinal Binary Responses},
  author = {FITZMAURICE, GARRETT M. and LAIRD, NAN M.},
  date = {1993-03-01},
  journaltitle = {Biometrika},
  volume = {80},
  number = {1},
  pages = {141--151},
  issn = {0006-3444},
  doi = {10.1093/biomet/80.1.141},
  url = {https://doi.org/10.1093/biomet/80.1.141},
  urldate = {2020-12-27},
  abstract = {In this paper, we discuss a likelihood-based method for analysing correlated binary responses based on a multivariate model. It is related to the pseudo-maximum likelihood approach suggested recently by Zhao \&amp; Prentice (1990). Their parameterization results in a simple pairwise model, in which the association between responses is modelled in terms of correlations, while the present paper uses conditional log odds-ratios. With this approach, higher-order associations can be incorporated in a natural way. One important advantage of this parameterization is that the maximum likelihood estimates of the marginal mean parameters are robust to misspecification of the time dependence. We describe an iterative two-stage procedure for obtaining the maximum likelihood estimates. Two examples are presented to illustrate this methodology.},
  keywords = {binary-data,markov-model,serial},
  note = {odds ratios as dependence parameters; dependence structures more general than Markov including compound symmetry-type models.~ General model uses a matrix of all pairwise co-occurrences.~ The paper starts with a general multivariate distribution for all the binary responses for one subject.}
}

@article{fit93reg,
  title = {Regression Models for Discrete Longitudinal Responses (with Discussion)},
  author = {Fitzmaurice, Garrett M. and Laird, Nan M. and Rotnitzky, Andrea G.},
  date = {1993},
  journaltitle = {Stat Sci},
  volume = {8},
  pages = {284--309},
  citeulike-article-id = {13264078},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {categorical-data,gee,logistic-model-extensions,maximum-likelihood,repeated-measures,robust-variance-estimation,sandwich-estimator}
}

@article{fit94ana,
  title = {Analysing Incomplete Longitudinal Binary Responses: {{A}} Likelihood-Based Approach},
  author = {Fitzmaurice, Garrett M. and Laird, Nan M. and Lipsitz, Stuart R.},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  pages = {601--612},
  citeulike-article-id = {13264079},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {longitudinal-analysis,missing-data,repeated-measures}
}

@article{fit95cav,
  title = {A Caveat Concerning Independence Estimating Equations with Multivariate Binary Data},
  author = {Fitzmaurice, Garrett M.},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {309--317},
  citeulike-article-id = {13264080},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {clustered-data,logistic-model-extensions,working-independence-model}
}

@article{fit96log,
  title = {Logistic Regression Models for Binary Panel Data with Attrition},
  author = {Fitzmaurice, Garrett M. and Heath, Anthony F. and Clifford, Peter},
  date = {1996},
  journaltitle = {J Roy Stat Soc A},
  volume = {159},
  pages = {249--263},
  citeulike-article-id = {13264081},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {informative-dropouts,longitudinal-data,missing-data,panel-data}
}

@article{fla87,
  title = {Frequency of Selecting Noise Variables in Subset Regression Analysis: {{A}} Simulation Study},
  author = {Flack, V. F. and Chang, P. C.},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {84--86},
  citeulike-article-id = {13264082},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {general,regression,variable-selection}
}

@article{fla95two,
  title = {A Two-Stage Procedure for Survival Studies with Surrogate Endpoints},
  author = {Flandre, Philippe and O'Quigley, John},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {969--976},
  citeulike-article-id = {13264083},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {multiple-endpoints,study-design,surrogate-endpoints}
}

@article{fle08mai,
  title = {Maintaining Confidentiality of Interim Data to Enhance Trial Integrity and Credibility},
  author = {Fleming, Thomas R. and Sharples, Katrina and McCall, John and Moore, Andrew and Rodgers, Anthony and Stewart, Ralph},
  date = {2008},
  journaltitle = {Clin Trials},
  volume = {5},
  pages = {157--167},
  doi = {10.1177/1740774508089459},
  url = {http://dx.doi.org/10.1177/1740774508089459},
  citeulike-article-id = {13265662},
  citeulike-linkout-0 = {http://dx.doi.org/10.1177/1740774508089459},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {blinding,confidentiality,interim-monitoring-of-rct,rct}
}

@article{fle84non,
  title = {Nonparametric Estimation of the Survival Distribution in Censored Data},
  author = {Fleming, T. R. and Harrington, D. P.},
  date = {1984},
  journaltitle = {Comm Stat Th Meth},
  volume = {13},
  number = {20},
  pages = {2469--2486},
  citeulike-article-id = {13264084},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {kaplan-meier,nelson-altschuler}
}

@incollection{fle86sur,
  title = {The {{SURVDIFF}} Procedure},
  booktitle = {{{SUGI Supplemental Library User}}'s {{Guide}}, {{Version}} 5 {{Edition}}},
  author = {Fleming, Thomas R. and Augustine, G. A. and Elcombe, S. A. and Offord, K. P.},
  date = {1986},
  pages = {535--553},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary NC}},
  citeulike-article-id = {13264085},
  posted-at = {2014-07-14 14:09:28},
  priority = {0}
}

@book{fle91cou,
  title = {Counting {{Processes}} \& {{Survival Analysis}}},
  author = {Fleming, Thomas R. and Harrington, David P.},
  date = {1991},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264086},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {counting-process,survival-analysis}
}

@article{fol20ana,
  title = {Analysis of Ordered Composite Endpoints},
  author = {Follmann, Dean and Fay, Michael P. and Hamasaki, Toshimitsu and Evans, Scott},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8431},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8431},
  urldate = {2019-12-20},
  abstract = {Composite endpoints are frequently used in clinical trials, but simple approaches, such as the time to first event, do not reflect any ordering among the endpoints. However, some endpoints, such as mortality, are worse than others. A variety of procedures have been proposed to reflect the severity of the individual endpoints such as pairwise ranking approaches, the win ratio, and the desirability of outcome ranking. When patients have different lengths of follow-up, however, ranking can be difficult and proposed methods do not naturally lead to regression approaches and require specialized software. This paper defines an ordering score O to operationalize the patient ranking implied by hierarchical endpoints. We show how differential right censoring of follow-up corresponds to multiple interval censoring of the ordering score allowing standard software for survival models to be used to calculate the nonparametric maximum likelihood estimators (NPMLEs) of different measures. Additionally, if one assumes that the ordering score is transformable to an exponential random variable, a semiparametric regression is obtained, which is equivalent to the proportional hazards model subject to multiple interval censoring. Standard software can be used for estimation. We show that the NPMLE can be poorly behaved compared to the simple estimators in staggered entry trials. We also show that the semiparametric estimator can be more efficient than simple estimators and explore how standard Cox regression maneuvers can be used to assess model fit, allow for flexible generalizations, and assess interactions of covariates with treatment. We analyze a trial of short versus long-term antiplatelet therapy using our methods.},
  langid = {english},
  keywords = {multiple-endpoints,ordinal,rct}
}

@article{fol88dis,
  title = {Distinguishing Heterogeneity from Decreasing Hazard Rates},
  author = {Follman, D. A. and Goldberg, M. S.},
  date = {1988},
  journaltitle = {Technometrics},
  volume = {30},
  pages = {389--396},
  citeulike-article-id = {13264087},
  posted-at = {2014-07-14 14:09:28},
  priority = {0}
}

@article{fol92use,
  title = {The Use of Subjective Rankings in Clinical Trials with an Application to Cardiovascular Disease},
  author = {Follmann, D. and Wittes, J. and Cutler, J. A.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {427--437},
  citeulike-article-id = {13264088},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {multiple-endpoints,ordinal-endpoints}
}

@article{fol95mul,
  title = {Multivariate Tests for Multiple Endpoints in Clinical Trials},
  author = {Follmann, Dean},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1163--1175},
  citeulike-article-id = {13264089},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {compound-endpoints,multiple-endpoints,risk-score,study-design},
  note = {excellent literature review; scoring non-fatal endpoints by how they predict death}
}

@article{for02rol,
  title = {The Role of Covariates in Estimating Treatment Effects and Risk in Long-Term Clinical Trials},
  author = {Ford, Ian and Norrie, John},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {2899--2908},
  citeulike-article-id = {13265297},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {covariable-adjustment,rct},
  note = {adjusted and unadjusted models cannot both be right;illustrations with actual clinical trial data}
}

@article{for95mod,
  title = {Model Inconsistency, Illustrated by the {{Cox}} Proportional Hazards Model},
  author = {Ford, Ian and Norrie, John and Ahmadi, Susan},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {735--746},
  citeulike-article-id = {13264090},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {adjusted-estimates,baseline-imbalances,covariable-adjustment,model-identification,model-misspecification,rct}
}

@article{fos04var,
  title = {Variable {{Selection}} in {{Data Mining}}},
  author = {Foster, Dean P. and Stine, Robert A.},
  date = {2004-06},
  journaltitle = {JASA},
  volume = {99},
  number = {466},
  pages = {303--313},
  publisher = {Taylor & Francis},
  issn = {0162-1459},
  doi = {10.1198/016214504000000287},
  url = {http://dx.doi.org/10.1198/016214504000000287},
  abstract = {We predict the onset of personal bankruptcy using least squares regression. Although well publicized, only 2,244 bankruptcies occur in our dataset of 2.9 million months of credit-card activity. We use stepwise selection to find predictors of these from a mix of payment history, debt load, demographics, and their interactions. This combination of rare responses and over 67,000 possible predictors leads to a challenging modeling question: How does one separate coincidental from useful predictors? We show that three modifications turn stepwise regression into an effective methodology for predicting bankruptcy. Our version of stepwise regression (1) organizes calculations to accommodate interactions, (2) exploits modern decision theoretic criteria to choose predictors, and (3) conservatively estimates p-values to handle sparse data and a binary response. Omitting any one of these leads to poor performance. A final step in our procedure calibrates regression predictions. With these modifications, stepwise regression predicts bankruptcy as well as, if not better than, recently developed data-mining tools. When sorted, the largest 14,000 resulting predictions hold 1,000 of the 1,800 bankruptcies hidden in a validation sample of 2.3 million observations. If the cost of missing a bankruptcy is 200 times that of a false positive, our predictions incur less than 2/3 of the costs of classification errors produced by the tree-based classifier C4.5.},
  citeulike-article-id = {7963665},
  citeulike-attachment-1 = {fos04var.pdf; /pdf/user/harrelfe/article/7963665/1027679/fos04var.pdf; 520a58310049bd7c4dea67026f7f0a52d83d8b36},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/016214504000000287},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1198/016214504000000287},
  day = {1},
  posted-at = {2015-07-23 21:08:57},
  priority = {0},
  keywords = {shrinkage,variable-selection},
  note = {promising recalibration of naiive stepwise variable selection in high-dimensional context}
}

@article{fow02use,
  title = {The Use of a Personal Digital Assistant for Wireless Entry of Data into a Database via the {{Internet}}},
  author = {Fowler, D. L. and Hogle, N. J. and Martini, F. and Roh, M. S.},
  date = {2002},
  journaltitle = {Surg Endo},
  volume = {16},
  pages = {221--223},
  citeulike-article-id = {13265267},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {data-management,hipaa,pda,personal-digital-assistant}
}

@article{fow87som,
  title = {Some Diagnostics for Binary Logistic Regression via Smoothing},
  author = {Fowlkes, Edward B.},
  date = {1987},
  journaltitle = {Biometrika},
  volume = {74},
  pages = {503--515},
  citeulike-article-id = {13264091},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {binary-logistic-model,smoothed-partial-residual-plots}
}

@article{fow88,
  title = {Evaluating Logistic Models for Large Contingency Tables},
  author = {Fowlkes, E. B. and Freeny, A. E. and Landwehr, J. M.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {611--622},
  citeulike-article-id = {13264092},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,graphical-methods,logistic-model}
}

@article{fox02boo,
  title = {Bootstrapping {{Regression Models}}: {{An Appendix}} to {{An R}} and {{S-PLUS Companion}} to {{Applied Regression}}},
  author = {{Fox, John}},
  date = {2002},
  url = {http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-bootstrapping.pdf},
  citeulike-article-id = {13265592},
  citeulike-linkout-0 = {http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-bootstrapping.pdf},
  posted-at = {2014-07-14 14:10:00},
  priority = {0}
}

@book{fox02R,
  title = {An {{R}} and {{S-PLUS Companion}} to {{Applied Regression}}},
  author = {Fox, John},
  date = {2002},
  publisher = {{SAGE Publications}},
  location = {{Thousand Oaks, CA}},
  citeulike-article-id = {13265595},
  posted-at = {2014-07-14 14:10:00},
  priority = {0}
}

@book{fox08app,
  title = {Applied {{Regression Analysis}} and {{Generalized Linear Models}}},
  author = {Fox, John},
  date = {2008},
  edition = {second},
  publisher = {{SAGE Publications}},
  location = {{Thousand Oaks, CA}},
  citeulike-article-id = {13265594},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  note = {good review in Technometrics 51 No. 3 p. 342-343, 2009}
}

@book{fox97app,
  title = {Applied {{Regression Analysis}}, {{Linear Models}}, and {{Related Methods}}},
  author = {Fox, John},
  date = {1997},
  publisher = {{SAGE Publications}},
  location = {{Thousand Oaks, CA}},
  citeulike-article-id = {13265593},
  posted-at = {2014-07-14 14:10:00},
  priority = {0}
}

@article{fra04let,
  title = {Letter to Editor on “{{The}} Worst Injury Predicts Mortality Outcome the Best”},
  author = {Frankema, Sander P. G. and Steyerberg, Ewout W. and Harrell, Frank E.},
  date = {2004},
  journaltitle = {J Trauma},
  volume = {56},
  pages = {928},
  citeulike-article-id = {13265370},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{fra09pre,
  title = {Preengraftment Syndrome after Unrelated Cord Blood Transplant Is a Strong Predictor of Acute and Chronic Graft-versus-Host Disease},
  author = {Frangoul, H. and Wang, L. and Harrell, F. E. and Ho, R. and Domm, J.},
  date = {2009},
  journaltitle = {Bone Mar Transpl},
  volume = {15},
  number = {11},
  pages = {1485--8},
  citeulike-article-id = {13265801},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  note = {CTSA}
}

@article{fra10unr,
  title = {Unrelated Umbilical Cord Blood Transplantation in Children with Immune Deficiency: Results of a Multicenter Study},
  author = {Frangoul, H. and Wang, L. and Harrell, F. E. and Manes, B. and Calder, C. and Domm, J.},
  date = {2010},
  journaltitle = {Bone Mar Transpl},
  volume = {45},
  citeulike-article-id = {13265776},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  note = {CTSA}
}

@article{fra15reg,
  title = {Regularized {{Regression Versus}} the {{High-Dimensional Propensity Score}} for {{Confounding Adjustment}} in {{Secondary Database Analyses}}.},
  author = {Franklin, Jessica M. and Eddings, Wesley and Glynn, Robert J. and Schneeweiss, Sebastian},
  date = {2015-10},
  journaltitle = {Am J Epi},
  volume = {182},
  number = {7},
  eprint = {26233956},
  eprinttype = {pmid},
  pages = {651--659},
  publisher = {Oxford University Press},
  issn = {1476-6256},
  doi = {10.1093/aje/kwv108},
  url = {http://dx.doi.org/10.1093/aje/kwv108},
  abstract = {Selection and measurement of confounders is critical for successful adjustment in nonrandomized studies. Although the principles behind confounder selection are now well established, variable selection for confounder adjustment remains a difficult problem in practice, particularly in secondary analyses of databases. We present a simulation study that compares the high-dimensional propensity score algorithm for variable selection with approaches that utilize direct adjustment for all potential confounders via regularized regression, including ridge regression and lasso regression. Simulations were based on 2 previously published pharmacoepidemiologic cohorts and used the plasmode simulation framework to create realistic simulated data sets with thousands of potential confounders. Performance of methods was evaluated with respect to bias and mean squared error of the estimated effects of a binary treatment. Simulation scenarios varied the true underlying outcome model, treatment effect, prevalence of exposure and outcome, and presence of unmeasured confounding. Across scenarios, high-dimensional propensity score approaches generally performed better than regularized regression approaches. However, including the variables selected by lasso regression in a regular propensity score model also performed well and may provide a promising alternative variable selection method.  The Author 2015. Published by Oxford University Press on behalf of the Johns Hopkins Bloomberg School of Public Health. All rights reserved. For permissions, please e-mail: journals.permissions@oup.com.},
  citeulike-article-id = {13898359},
  citeulike-attachment-1 = {fra15reg.pdf; /pdf/user/harrelfe/article/13898359/1048898/fra15reg.pdf; 39307cda8e267a66c86bee376049380256c9fc8c},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwv108},
  citeulike-linkout-1 = {http://aje.oxfordjournals.org/content/early/2015/08/01/aje.kwv108.abstract},
  citeulike-linkout-2 = {http://aje.oxfordjournals.org/content/early/2015/08/01/aje.kwv108.full.pdf},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/26233956},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=26233956},
  day = {1},
  posted-at = {2016-01-05 23:01:42},
  priority = {0},
  keywords = {penalization,propensity-score,simulation-setup},
  note = {plasmode simulation; references Bross method of simultaneously scoring association with exposure, association with outcome, and prevalence}
}

@article{fra17com,
  title = {Comparing the Performance of Propensity Score Methods in Healthcare Database Studies with Rare Outcomes},
  author = {Franklin, Jessica M. and Eddings, Wesley and Austin, Peter C. and Stuart, Elizabeth A. and Schneeweiss, Sebastian},
  date = {2017-01},
  journaltitle = {Stat Med},
  pages = {n/a},
  doi = {10.1002/sim.7250},
  url = {http://dx.doi.org/10.1002/sim.7250},
  abstract = {Nonrandomized studies of treatments from electronic healthcare databases are critical for producing the evidence necessary to making informed treatment decisions, but often rely on comparing rates of events observed in a small number of patients. In addition, studies constructed from electronic healthcare databases, for example, administrative claims data, often adjust for many, possibly hundreds, of potential confounders. Despite the importance of maximizing efficiency when there are many confounders and few observed outcome events, there has been relatively little research on the relative performance of different propensity score methods in this context. In this paper, we compare a wide variety of propensity-based estimators of the marginal relative risk. In contrast to prior research that has focused on specific statistical methods in isolation of other analytic choices, we instead consider a method to be defined by the complete multistep process from propensity score modeling to final treatment effect estimation. Propensity score model estimation methods considered include ordinary logistic regression, Bayesian logistic regression, lasso, and boosted regression trees. Methods for utilizing the propensity score include pair matching, full matching, decile strata, fine strata, regression adjustment using one or two nonlinear splines, inverse propensity weighting, and matching weights. We evaluate methods via a 'plasmode' simulation study, which creates simulated datasets on the basis of a real cohort study of two treatments constructed from administrative claims data. Our results suggest that regression adjustment and matching weights, regardless of the propensity score model estimation method, provide lower bias and mean squared error in the context of rare binary outcomes. Copyright  2017 John Wiley \& Sons, Ltd.},
  citeulike-article-id = {14281729},
  citeulike-attachment-1 = {fra17com.pdf; /pdf/user/harrelfe/article/14281729/1102672/fra17com.pdf; 1f5fe6204e1398690f6b3f39020f8561d32247ad},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7250},
  day = {1},
  posted-at = {2017-02-17 13:30:43},
  priority = {2},
  keywords = {covariable-adjustment,epub-replace,propensity-score},
  note = {Included regression adjustment for spline of propensity in the comparison, which came out as co-winner with weighted matching.}
}

@article{fra21whe,
  title = {When {{Can Nonrandomized Studies Support Valid Inference Regarding Effectiveness}} or {{Safety}} of {{New Medical Treatments}}?},
  author = {Franklin, Jessica M. and Platt, Richard and Dreyer, Nancy A. and London, Alex John and Simon, Gregory E. and Watanabe, Jonathan H. and Horberg, Michael and Hernandez, Adrian and Califf, Robert M.},
  date = {2021},
  journaltitle = {Clinical Pharmacology \& Therapeutics},
  volume = {n/a},
  number = {n/a},
  issn = {1532-6535},
  doi = {10.1002/cpt.2255},
  url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt.2255},
  urldate = {2021-05-10},
  abstract = {The randomized controlled trial (RCT) is the gold standard for evaluating the causal effects of medications. Limitations of RCTs have led to increasing interest in using real-world evidence (RWE) to augment RCT evidence and inform decision making on medications. Although RWE can be either randomized or nonrandomized, nonrandomized RWE can capitalize on the recent proliferation of large healthcare databases and can often answer questions that cannot be answered in randomized studies due to resource constraints. However, the results of nonrandomized studies are much more likely to be impacted by confounding bias, and the existence of unmeasured confounders can never be completely ruled out. Furthermore, nonrandomized studies require more complex design considerations which can sometimes result in design-related biases. We discuss questions that can help investigators or evidence consumers evaluate the potential impact of confounding or other biases on their findings: Does the design emulate a hypothetical randomized trial design? Is the comparator or control condition appropriate? Does the primary analysis adjust for measured confounders? Do sensitivity analyses quantify the potential impact of residual confounding? Are methods open to inspection and (if possible) replication? Designing a high-quality nonrandomized study of medications remains challenging and requires broad expertise across a range of disciplines, including relevant clinical areas, epidemiology, and biostatistics. The questions posed in this paper provide a guiding framework for assessing the credibility of nonrandomized RWE and could be applied across many clinical questions.},
  langid = {english},
  keywords = {observation-study,observational-data,observational-research,observational-study-design,observational-treatment-comparisons},
  annotation = {\_eprint: https://ascpt.onlinelibrary.wiley.com/doi/pdf/10.1002/cpt.2255}
}

@article{fra80com,
  title = {Comparison of Biplane and Single Plane Left Ventricular Volumes in Atrial Septal Defect},
  author = {Fraker, T. D. and Wise, N. K. and Harrell, F. E. and Behar, V. S.},
  date = {1980},
  journaltitle = {Cath Cardiovasc Diag},
  volume = {6},
  pages = {39--48},
  citeulike-article-id = {13264093},
  posted-at = {2014-07-14 14:09:28},
  priority = {0}
}

@article{fra84log,
  title = {A Log Logistic Model for Survival Time with Covariates},
  author = {Franco, M. A. P.},
  date = {1984},
  journaltitle = {Biometrika},
  volume = {71},
  pages = {621--623},
  citeulike-article-id = {13265604},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {categorization,cutpoint,dichotomization},
  note = {inefficient of dichtomizing survival time; optimal cut point is the median survival time, but the resulting analysis is still very inefficient}
}

@article{fra91sta,
  title = {Statistical Inference: {{Likelihood}} to Significance},
  author = {Fraser, D. A. S.},
  date = {1991},
  journaltitle = {J Am Stat Assoc},
  volume = {86},
  pages = {258--265},
  citeulike-article-id = {13264094},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {maximum-likelihood}
}

@article{fra96vis,
  title = {Visualization of Event Histories},
  author = {Francis, Brian and Fuller, Mark},
  date = {1996},
  journaltitle = {J Roy Stat Soc A},
  volume = {159},
  pages = {301--308},
  citeulike-article-id = {13264095},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {graphical-methods,graphics-for-survival-data}
}

@article{fra98met,
  title = {A Method of Biased Coin Randomization, Its Implementation, and Its Validation},
  author = {Frane, James W.},
  date = {1998},
  journaltitle = {Drug Info J},
  volume = {32},
  pages = {423--432},
  citeulike-article-id = {13264096},
  posted-at = {2014-07-14 14:09:28},
  priority = {0},
  keywords = {biased-coin-randomization,imbalance,rct,s-plus,study-design}
}

@article{fre08ana,
  title = {An Analysis of the Controversy over Classical One-Sided Tests},
  author = {Freedman, Laurence S.},
  date = {2008},
  journaltitle = {Clin Trials},
  volume = {5},
  pages = {635--640},
  citeulike-article-id = {13265719},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  note = {"Using a Bayesian decision framework, it is shown that there is no reason to double the p-value when moving from a one-sided to a two-sided test. Within the classical framework, it is shown that the doubling of the p-value results from a discontinuity due to testing a point null hypothesis. A three-decision rule, credited to Neyman or Wald, is presented that does not require the doubling of the p-value, and is consistent with a Bayesian approach. For most comparative clinical trials the three-decision rule is appropriate, and its use would abolish the controversy over one-sided tests."}
}

@article{fre08sur,
  title = {Survival Analysis: {{A}} Primer},
  author = {Freedman, David A.},
  date = {2008},
  journaltitle = {Am Statistician},
  volume = {62},
  number = {2},
  pages = {110--119},
  doi = {10.1198/000313008X298439},
  url = {http://dx.doi.org/10.1198/000313008X298439},
  citeulike-article-id = {13265670},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/000313008X298439},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {covariate-adjustment,cox-model,ph,rct,survival-analysis},
  note = {Cox model;this article has errors, especially on p. 113: "Proportional-hazards models are often used in observational studies and in clinical trials. The latter fact is a real curiosity. There is no need to adjust for confounding if the trial is randomized." and in its description of the accidental nature of the partial likelihood}
}

@article{fre19how,
  title = {How to Communicate Evidence to Patients},
  author = {Freeman, Alexandra L. J.},
  date = {2019-08-01},
  journaltitle = {DTB},
  volume = {57},
  number = {8},
  eprint = {31345957},
  eprinttype = {pmid},
  pages = {119--124},
  issn = {0012-6543, 1755-5248},
  doi = {10.1136/dtb.2019.000008},
  url = {https://dtb.bmj.com/content/57/8/119},
  urldate = {2019-08-16},
  abstract = {All medical treatments have potential harms as well as benefits, and it is vital that everyone has a good understanding of what these might be, how dramatic they might be and how likely. In fact, in the UK, the Montgomery judgement in the supreme court in 2015 (see Box 1) has made it a legal necessity for patients to be given comprehensible, personally relevant information about all reasonable treatment options, including none.1 So, how should we ensure good, clear communication of relevant evidence? Box 1.  \#\#\# The Montgomery judgement In 1999, Nadine Montgomery was preparing for the birth of her son Sam. She was of small stature, with diabetes, and was concerned about being able to give birth naturally. Unfortunately, difficulties did arise during birth, and Sam suffered brain damage as a result. Her obstetrician had not discussed the risk of this particular complication occurring, deeming it best Nadine attempted a vaginal birth. On appeal at the supreme court, Nadine Montgomery won her case. This laid down a new legal basis for informed consent, in line with the General Medical Council guidelines;1  {$>$} “The doctor is therefore under a duty to take reasonable care to ensure that the patient is aware of any material risks involved in any recommended treatment, and of any reasonable alternative or variant treatments.” {$>$}  {$>$} “The test of materiality is whether, in the circumstances of the particular case, a reasonable person in the patient's position would be likely to attach significance to the risk, or the doctor is or should reasonably be aware that the particular patient would be likely to attach significance to it. ”  {$>$}  {$>$} “The assessment of whether a risk is material cannot be reduced to percentages. The significance of a given risk is likely to reflect a variety of factors besides its magnitude” {$>$}  {$>$} “The doctor’s advisory role involves dialogue, …},
  langid = {english},
  keywords = {risk-communication}
}

@article{fre21cri,
  title = {A {{Critical Review}} of {{LASSO}} and {{Its Derivatives}} for {{Variable Selection Under Dependence Among Covariates}}},
  author = {Freijeiro-González, Laura and Febrero-Bande, Manuel and González-Manteiga, Wenceslao},
  date = {2021},
  journaltitle = {International Statistical Review},
  volume = {n/a},
  number = {n/a},
  issn = {1751-5823},
  doi = {10.1111/insr.12469},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12469},
  urldate = {2021-10-26},
  abstract = {The limitations of the well-known LASSO regression as a variable selector are tested when there exists dependence structures among covariates. We analyse both the classic situation with n ≥ p and the high dimensional framework with p {$>$} n. Known restrictive properties of this methodology to guarantee optimality, as well as inconveniences in practice, are analysed and tested by means of an extensive simulation study. Examples of these drawbacks are showed making use of different dependence scenarios. In order to search for improvements, a broad comparison with LASSO derivatives and alternatives is carried out. Eventually, we give some guidance about what procedures work best in terms of the considered data nature.},
  langid = {english},
  keywords = {collinearity,lasso,pmle,variable-selection},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/insr.12469}
}

@incollection{fre88imp,
  title = {On the {{Impact}} of {{Variable Selection}} in {{Fitting Regression Equations}}},
  author = {Freedman, D. and Navidi, W. and Peters, S.},
  date = {1988},
  series = {Lecture {{Notes}} in {{Economics}} and {{Mathematical Systems}}},
  pages = {1--16},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13264097},
  posted-at = {2014-07-14 14:09:28},
  priority = {0}
}

@article{fre89ret,
  title = {Return to a {{Note}} on {{Screening Regression Equations}}},
  author = {Freedman, Laurence S. and Pee, David},
  date = {1989},
  journaltitle = {Am Statistician},
  volume = {43},
  pages = {279--282},
  citeulike-article-id = {13264098},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {univariable-screening}
}

@article{fre90,
  title = {Hypothesis versus Significance Testing for Controlled Clinical Trials: {{Comment}}},
  author = {{Freedman}},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {213--214},
  citeulike-article-id = {13264099},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {miscellaneous,study-design-and-stopping-rules}
}

@article{fre92pro,
  title = {The {{Problem}} of {{Underestimating}} the {{Residual Error Variance}} in {{Forward Stepwise Regression}}},
  author = {Freedman, L. S. and Pee, D. and Midthune, D. N.},
  date = {1992},
  journaltitle = {JRSSD},
  volume = {41},
  number = {4},
  eprint = {2349005},
  eprinttype = {jstor},
  pages = {405--412},
  publisher = {[Royal Statistical Society, Wiley]},
  abstract = {Under the global null hypothesis that all covariates are unrelated to the outcome variables, forward stepwise regression procedures should have the property that the probability of selecting a given variable and finding it significant at the α level is equal to α. Because of the problem of underestimating the residual error variance the actual probability can be very different from α. This problem becomes of practical concern when the ratio of the number of variables to the number of observations becomes greater than 0.25, and is more serious for logistic than for linear regression.},
  citeulike-article-id = {14089322},
  citeulike-attachment-1 = {fre92pro.pdf; /pdf/user/harrelfe/article/14089322/1076144/fre92pro.pdf; 3e6274c86dfda1c68355f8b54c8775c36679bf7a},
  citeulike-linkout-0 = {http://www.jstor.org/stable/2349005},
  posted-at = {2016-07-04 18:07:56},
  priority = {0},
  keywords = {bias,effective-degrees-of-freedom,stepwise,variable-selection}
}

@article{fre92sta,
  title = {Statistical Validation of Intermediate Endpoints for Chronic Disease},
  author = {Freedman, L. S. and Graubard, B. I. and Schatzkin, A.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {167--178},
  citeulike-article-id = {13264100},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {multiple-endpoints,surrogate-endpoints}
}

@article{fre94wha,
  title = {The What, Why and How of {{Bayesian}} Clinical Trials Monitoring},
  author = {Freedman, Laurence S. and Spiegelhalter, David J. and Parmar, Mahesh K. B.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1371--1383},
  citeulike-article-id = {13264101},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {bayesian-inference,early-termination,sequential-monitoring,study-design},
  note = {gives example adjustment for sequential testing yields 0.95 CI that includes 0.0 even for data indicating that study should be stopped at the first interim analysis}
}

@article{fre96app,
  title = {Aproaches to Monitoring the Results of Long-Term Disease Prevention Trials: {{Examples}} from the {{Women}}'s {{Health Initiative}}},
  author = {Freedman, Laurence and Anderson, Garnet and Kipnis, Victor and Prentice, Ross and Wang, C. Y. and Rossouw, Jacques and Wittes, Janet and DeMets, David},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {509--525},
  citeulike-article-id = {13264102},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {clinical-trials,data-and-safety-monitoring,dsmb,multiple-endpoints,rct,stopping-rules}
}

@article{fre96bay,
  title = {Bayesian Statistical Methods},
  author = {Freedman, Laurence},
  date = {1996},
  journaltitle = {BMJ},
  volume = {313},
  pages = {569--570},
  citeulike-article-id = {13264103},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {bayesian-inference,teaching-mds}
}

@article{free06so,
  title = {On the So-Called “{{Huber}} Sandwich Estimator” and “Robust Standard Errors”},
  author = {Freedman, David A.},
  date = {2006},
  journaltitle = {Am Statistician},
  volume = {60},
  pages = {299--302},
  citeulike-article-id = {13265531},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  note = {nice summary of derivation of sandwich estimators;questions why we should be interested in getting the right variance of the wrong parameters when the model doesn't fit}
}

@article{fri00kno,
  title = {Knowledge Discovery from Databases and Data Mining: {{New}} Paradigms for Statistics and Data Analysis?},
  author = {Friedman, Herman P. and Goldberg, Judith D.},
  date = {2000},
  journaltitle = {Biopharm Rep ASA},
  volume = {8},
  number = {2},
  pages = {1--12},
  citeulike-article-id = {13265156},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  note = {excellent review article about interface between statistics and data mining;applications of data mining;excellent literature review}
}

@article{fri00sho,
  title = {Should the Median Test Be Retired from General Use?},
  author = {Freidlin, Boris and Gastwirth, Joseph L.},
  date = {2000},
  journaltitle = {Am Statistician},
  volume = {54},
  number = {3},
  pages = {161--164},
  citeulike-article-id = {13265551},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {mood-median-test},
  note = {inefficiency of Mood median test}
}

@article{fri05gra,
  title = {Graphical Views of Suppression and Multicollinearity in Multiple Linear Regression},
  author = {Friedman, Lynn and Wall, Melanie},
  date = {2005},
  journaltitle = {Am Statistician},
  volume = {59},
  pages = {127--136},
  citeulike-article-id = {13265412},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {collinearity,enhancement,multiple-regression,suppression,variable-selection},
  note = {"Horst (1941) ... gave the name 'suppressor variable' to an independent variable that (1) has no correlation with the outcome variable, but (2) is correlated with the other independent variable, and (3) increases the variance explained ... Darlington (1968) defined a suppressor variable as one that produces a negative 'beta weight' --- a regression coefficient for a variable in the standardized model---in the regression equation despite the fact that all correlations between the predictor and outcome variables are nonnegative.";graphical explanation of suppression}
}

@article{fri08gol,
  title = {The Golden Age of Statistical Graphics},
  author = {Friendly, Michael},
  date = {2008},
  journaltitle = {Stat Sci},
  volume = {23},
  number = {4},
  pages = {502--535},
  citeulike-article-id = {13265766},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {charles-joseph-minard,data-visualization,florence-nightengale,frances-walker,francis-galton,history-of-statistics,smoothing,statistical-graphics,thematic-cartography}
}

@article{fri16eva,
  title = {Evaluation of the {{F2R IVS-14A}}/{{T PAR1}} Polymorphism with Subsequent Cardiovascular Events and Bleeding in Patients Who Have Undergone Percutaneous Coronary Intervention.},
  author = {Friedman, Eitan A. and Texeira, Luisa and Delaney, Jessica and Weeke, Peter E. and Lynch, Donald R. and Kasasbeh, Ehab and Song, Yanna and Harrell, Frank E. and Denny, Josh C. and Hamm, Heidi E. and Roden, Dan M. and Cleator, John H.},
  date = {2016-05},
  journaltitle = {J Thrombosis Thrombolysis},
  volume = {41},
  number = {4},
  eprint = {26446588},
  eprinttype = {pmid},
  pages = {656--662},
  issn = {1573-742X},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26446588},
  abstract = {Abnormal platelet reactivity is associated with recurrent ischemia and bleeding following percutaneous coronary intervention (PCI). Protease-activated receptor-1 (PAR1), encoded by F2R, is a high affinity thrombin receptor on platelets and the target of the antiplatelet drug vorapaxar. The intronic single nucleotide polymorphism F2R IVS-14 A/T affects PAR1 receptor density and function. We hypothesized that carriers of the T allele, who have been shown to have decreased platelet reactivity, would be at lower risk for thrombotic events, but higher risk for bleeding following PCI. Using BioVU, the Vanderbilt DNA repository linked to the electronic medical record, we studied 660 patients who underwent PCI for unstable or stable coronary artery disease. Primary outcome measures were major adverse cardiovascular events (MACE, composite of revascularization, MI, stroke, death) and bleeding (assessed by Bleeding Academic Research Consortium scale) over 24~months. The minor allele (T) frequency was 14.8~\%. There were no genotypic differences in the frequency of MACE (33.7, 28.8, and 31.6~\% for A/A, A/T, and T/T respectively, P~=~0.50) or bleeding (15.7, 14.7, and 18.8~\% for A/A, A/T, and T/T respectively, P~=~0.90). In a Cox regression model, fully adjusted for age, race, sex, BMI, and smoking status, carrying a T allele was not associated with MACE (HR 1.19, 95~\% CI 0.89-1.59, P~=~0.23) or bleeding (HR 0.73, 95~\% CI 0.37-1.4, P~=~0.34). In conclusion, in our population, F2R IVS-14 PAR1 variability does not affect risk of MACE or bleeding following PCI.},
  citeulike-article-id = {14102487},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26446588},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26446588},
  posted-at = {2016-07-26 21:08:42},
  priority = {2},
  keywords = {collaboration}
}

@report{fri84,
  type = {Technical Report},
  title = {A Variable Span Smoother},
  author = {Friedman, J. H.},
  date = {1984},
  number = {5},
  institution = {{Laboratory for Computational Statistics, Department of Statistics, Stanford University}},
  citeulike-article-id = {13264104},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{fri87exp,
  title = {Exploratory Projection Pursuit},
  author = {Friedman, J. H.},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {249--266},
  citeulike-article-id = {13264105},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{fri91mul,
  title = {Multivariate Adaptive Regression Splines (with Discussion)},
  author = {Friedman, J. H.},
  date = {1991},
  journaltitle = {Ann Stat},
  volume = {19},
  pages = {1--141},
  citeulike-article-id = {13264106},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {mars}
}

@article{fri92rep,
  title = {Repeated Measures in Clinical Trials: {{Analysis}} Using Mean Summary Statistics and Its Implications for Design},
  author = {Frison, Lars and Pocock, Stuart J.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1685--1704},
  citeulike-article-id = {13264107},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {analysis-of-change,pre-post,repeated-measures},
  annotation = {See letter to editor SM 19:3133-3135; 2000}
}

@article{fro21rel,
  title = {Relationship between the {{Clinical Frailty Scale}} and Short-Term Mortality in Patients\,≥\,80~Years Old Acutely Admitted to the {{ICU}}: A Prospective Cohort Study},
  shorttitle = {Relationship between the {{Clinical Frailty Scale}} and Short-Term Mortality in Patients\,≥\,80~Years Old Acutely Admitted to the {{ICU}}},
  author = {Fronczek, Jakub and Polok, Kamil and de Lange, Dylan W. and Jung, Christian and Beil, Michael and Rhodes, Andrew and Fjølner, Jesper and Górka, Jacek and Andersen, Finn H. and Artigas, Antonio and Cecconi, Maurizio and Christensen, Steffen and Joannidis, Michael and Leaver, Susannah and Marsh, Brian and Morandi, Alessandro and Moreno, Rui and Oeyen, Sandra and Agvald-Öhman, Christina and Bollen Pinto, Bernardo and Schefold, Joerg C. and Valentin, Andreas and Walther, Sten and Watson, Ximena and Zafeiridis, Tilemachos and Sviri, Sigal and van Heerden, Peter Vernon and Flaatten, Hans and Guidet, Bertrand and Szczeklik, Wojciech and Schmutz, R. and Wimmer, F. and Eller, P. and Joannidis, M. and De Buysscher, P. and De Neve, N. and Oeyen, S. and Swinnen, W. and Bollen Pinto, B. and Abraham, P. and Hergafi, L. and Schefold, J. C. and Biskup, E. and Piza, P. and Taliadoros, I. and Fjølner, J. and Dey, N. and Sølling, C. and Rasmussen, B. S. and Christensen, S. and Forceville, X. and Besch, G. and Mentec, H. and Michel, P. and Mateu, P. and Michel, P. and Vettoretti, L. and Bourenne, J. and Marin, N. and Guillot, M. and Aissaoui, N. and Goulenok, C. and Thieulot-Rolin, N. and Messika, J. and Lamhaut, L. and Guidet, B. and Charron, C. and Lauten, A. and Sacher, A. L. and Brenner, T. and Franz, M. and Bloos, F. and Ebelt, H. and Schaller, S. J. and Fuest, K. and Rabe, C. and Dieck, T. and Steiner, S. and Graf, T. and Nia, A. M. and Jung, C. and Janosi, R. A. and Meybohm, P. and Simon, P. and Utzolino, S. and Rahmel, T. and Barth, E. and Jung, C. and Schuster, M. and Aidoni, Z. and Aloizos, S. and Tasioudis, P. and Lampiri, K. and Zisopoulou, V. and Ravani, I. and Pagaki, E. and Antoniou, A. and Katsoulas, T. A. and Kounougeri, A. and Marinakis, G. and Tsimpoukas, F. and Spyropoulou, A. and Zygoulis, P. and Kyparissi, A. and Gupta, M. and Gurjar, M. and Maji, I. M. and Hayes, I. and Marsh, B. and Kelly, Y. and Westbrook, A. and Fitzpatrick, G. and Maheshwari, D. and Motherway, C. and Negri, G. and Spadaro, S. and Nattino, G. and Pedeferri, M. and Boscolo, A. and Rossi, S. and Calicchio, G. and Cubattoli, L. and Di Lascio, G. and Barbagallo, M. and Berruto, F. and Codazzi, D. and Bottazzi, A. and Fumagalli, P. and Negro, G. and Lupi, G. and Savelli, F. and Vulcano, G. A. and Fumagalli, R. and Marudi, A. and Lefons, U. and Lembo, R. and Babini, M. and Paggioro, A. and Parrini, V. and Zaccaria, M. and Clementi, S. and Gigliuto, C. and Facondini, F. and Pastorini, S. and Munaron, S. and Calamai, I. and Bocchi, A. and Adorni, A. and Bocci, M. G. and Cortegiani, A. and Casalicchio, T. and Mellea, S. and Graziani, E. and Barattini, M. and Brizio, E. and Rossi, M. and Hahn, M. and Flaatten, H. and Kemmerer, N. and Strietzel, H. F. and Dybwik, K. and Legernaes, T. and Klepstad, P. and Olaussen, E. B. and Olsen, K. I. and Brresen, O. M. and Bjorsvik, G. and Andersen, F. H. and Maini, S. and Fehrle, L. and Czuczwar, M. and Krawczyk, P. and Ziętkiewicz, M. and Nowak, Ł. R. and Kotfis, K. and Cwyl, K. and Gajdosz, R. and Biernawska, J. and Bohatyrewicz, R. and Gawda, R. and Grudzień, P. and Nasiłowski, P. and Popek, N. and Cyrankiewicz, W. and Wawrzyniak, K. and Wnuk, M. and Maciejewski, D. and Studzińska, D. and Żukowski, M. and Bernas, S. and Piechota, M. and Szczeklik, W. and Nowak-Kózka, I. and Fronczek, J. and Serwa, M. and Machała, W. and Stefaniak, J. and Wujtewicz, M. and Maciejewski, P. and Szymkowiak, M. and Adamik, B. and Polok, K. and Górka, J. and Catorze, N. and Branco, M. C. and Barros, N. and Barros, I. and Krystopchuk, A. and Honrado, T. and Sousa, C. and Munoz, F. and Rebelo, M. and Gomes, R. and Nunes, J. and Dias, C. and Fernandes, A. M. and Petrisor, C. and Constantin, B. and Belskiy, V. and Boskholov, B. and Rodriguez, E. and Aguilar, G. and Masdeu, G. and Jaimes, M. I. and Mira, A. P. and Bodi, M. A. and Mendoza, J. A. B. and López-Cuenca, S. and Guzman, M. H. and Rico-Feijoo, J. and Ibarz, M. and Alvarez, J. Trenado and Kawati, R. and Sivik, J. and Nauska, J. and Smole, D. and Parenmark, F. and Lyrén, J. and Rockstroh, K. and Rydén, S. and Spångfors, M. and Strinnholm, M. and Walther, S. and De Geer, L. and Nordlund, P. and Pålsson, S. and Zetterquist, H. and Nilsson, A. and Thiringer, K. and Jungner, M. and Bark, B. and Nordling, B. and Sköld, H. and Brorsson, C. and Persson, S. and Bergström, A. and Berkius, J. and Holmström, J. and van Dijk, I. and van Lelyveld-Haas, L. E. M. and Jansen, T. and Nooteboom, F. and van der Voort, P. H. J. and de Lange, D. and Dieperink, W. and de Waard, M. C. and de Smet, A. G. E. and Bormans, L. and Dormans, T. and Dempsey, G. and Mathew, S. J. and Raj, A. S. and Grecu, I. and Cupitt, J. and Lawton, T. and Clark, R. and Popescu, M. and Spittle, N. and Faulkner, M. and Cowton, A. and Williams, P. and Elloway, E. and Reay, M. and Chukkambotla, S. and Kumar, R. and Al-Subaie, N. and Kent, L. and Tamm, T. and Kajtor, I. and Burns, K. and Pugh, R. and Ostermann, M. and Kam, E. and Bowyer, H. and Smith, N. and Templeton, M. and Henning, J. and Goffin, K. and Kapoor, R. and {for the VIP1}},
  options = {useprefix=true},
  date = {2021-07-01},
  journaltitle = {Critical Care},
  volume = {25},
  number = {1},
  pages = {231},
  issn = {1364-8535},
  doi = {10.1186/s13054-021-03632-3},
  url = {https://doi.org/10.1186/s13054-021-03632-3},
  urldate = {2022-04-17},
  abstract = {The Clinical Frailty Scale (CFS) is frequently used to measure frailty in critically ill adults. There is wide variation in the approach to analysing the relationship between the CFS score and mortality after admission to the ICU. This study aimed to evaluate the influence of modelling approach on the association between the CFS score and short-term mortality and quantify the prognostic value of frailty in this context.},
  keywords = {added-value,adequacy-index,application,relative-information}
}

@article{fro89,
  title = {Methodology for Measuring Health-State Preferences - {{II}}: Scaling Methods},
  author = {Froberg DG, Kane R. L.},
  date = {1989},
  journaltitle = {J Clin Epi},
  volume = {42},
  pages = {459--471},
  citeulike-article-id = {13264108},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {general,measurement,medical,research-methods}
}

@article{fud16dri,
  title = {Driveline {{Infection Risk}} with {{Utilization}} of a {{Temporary External Anchoring Suture After Implantation}} of a {{Left Ventricular Assist Device}}.},
  author = {Fudim, Marat and Brown, Christopher L. and Davis, Mary E. and Djunaidi, Monica and Danter, Matthew R. and Harrell, Frank E. and Stulak, John M. and Haglund, Nicholas A. and Maltais, Simon},
  date = {2016},
  journaltitle = {ASAIO},
  volume = {62},
  number = {3},
  eprint = {26809083},
  eprinttype = {pmid},
  pages = {291--296},
  issn = {1538-943X},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26809083},
  abstract = {Driveline infections (DLI) are a cause of morbidity after continuous-flow left ventricular assist device (CF-LVAD) implantation. Because driveline trauma contributes to DLI, we assessed whether intraoperative placement of a temporary external anchoring suture (EAS) influenced DLI rate. We analyzed 161 consecutive patients with CF-LVAD (HMII 82; HW 79) implantation. Two groups were defined: placement of EAS (n = 85) or No EAS (n = 76). For NO EAS patients, the driveline was permanently anchored internally to the rectus fascia. Cox proportional analysis was performed to assess the effect of EAS on time to first confirmed DLI. Baseline characteristics were comparable between groups (all p = 0.3). Mean follow-up time was 0.93 years. A total of 18 (11.1\%) patients developed confirmed culture positive DLI, with "first infection" rate of 0.13 events/year. Mean time to confirmed DLI was 0.69 years. Driveline infection was less likely (hazard ratio [HR] = 0.28, 0.95 confidence interval [CI] = 0.06-1.25, p = 0.056) to occur in NO EAS (2/18) then in EAS (16/18). Confirmed DLI was comparable between device types (p = 0.3). Multivariable regression adjusted for age, BMI, blood product use, device type, and diabetes showed equivocal effect of EAS (HR = 0.33, 0.95 CI = 0.07-1.54, p = 0.12). Patients with a temporary EAS may have an increased risk of confirmed DLI after device implantation.},
  citeulike-article-id = {14102480},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26809083},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26809083},
  posted-at = {2016-07-26 21:00:25},
  priority = {2},
  keywords = {collaboration}
}

@article{fur21met,
  title = {Methodological Challenges in the Analysis of Recurrent Events for Randomised Controlled Trials with Application to Cardiovascular Events in {{LEADER}}},
  author = {Furberg, Julie Kjærulff and Rasmussen, Søren and Andersen, Per Kragh and Ravn, Henrik},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2167},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2167},
  urldate = {2021-09-08},
  abstract = {Analysis of recurrent events is becoming increasingly popular for understanding treatment effects in randomised controlled trials. The analysis of recurrent events can improve efficiency and capture disease burden compared to standard time-to-first event analyses. However, the added knowledge about the multi-state process comes at the cost of modelling complexity. High mortality rates can complicate matters even more. A case study using data from a randomised controlled trial, LEADER, is presented to highlight interpretation of common methods as well as potential pitfalls when analysing recurrent events in the presence of a competing risk. The presented methods either target features of the underlying intensity functions or marginal traits of a multi-state process which includes terminal events or not. In particular, approaches to handle death as a part of an event and as a competing risk are discussed. A new method targeting the marginal mean function for a composite endpoint, which includes both death as a component and as a competing risk, will be introduced. Finally, recommendations for how to capture meaningful treatment effects in randomised controlled trials when analysing recurrent and terminal events will be made.},
  langid = {english},
  keywords = {rct,recurrent-event-with-competing-risk,recurrent-events},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2167}
}

@article{fur95nif,
  title = {Nifedipine: {{Dose-related}} Increase in Mortality in Patients with Coronary Heart Disease},
  author = {Furberg, Curt D. and Psaty, Bruce M. and Meyer, Jeffrey V.},
  date = {1995},
  journaltitle = {Circ},
  volume = {92},
  pages = {1326--1331},
  citeulike-article-id = {13264109},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {ccb,dose-response,meta-analysis}
}

@article{gab08bur,
  title = {Burnout in Medical School Deans: An Uncommon Problem},
  author = {Gabbe, Steven G. and Webb, Lyne E. and Moore, Donald E. and Harrell, Frank E. and Spickard, W. Anderson and Powell, R.},
  date = {2008},
  journaltitle = {Acad Med},
  volume = {83},
  number = {5},
  pages = {476--82},
  citeulike-article-id = {13265676},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {burnout,leadership,splines,stress}
}

@article{gag11com,
  title = {A Combined Comorbidity Score Predicted Mortality in Elderly Patients Better than Existing Scores},
  author = {Gagne, Joshua J. and Glynn, Robert J. and Avorn, Jerry and Levin, Raisa and Schneeweiss, Sebastian},
  date = {2011},
  journaltitle = {J Clin Epi},
  volume = {64},
  pages = {749--759},
  citeulike-article-id = {13265883},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {comorbidity-score},
  note = {nice review of comorbidity scores;improvements over Charlson and possibly Elixhauser;code at http://www.drugepi.org/downloads}
}

@article{gai05cri,
  title = {On Criteria for Evaluating Models of Absolute Risk},
  author = {Gail, Mitchell H. and Pfeiffer, Ruth M.},
  date = {2005},
  journaltitle = {Biostatistics},
  volume = {6},
  number = {2},
  pages = {227--239},
  citeulike-article-id = {13265649},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {absolute-risk-model,accuracy,brier-score,loss-functions-for-clinical-decisions,negative-predictive-value,positive-predictive-value,roc-curve,utilities,utility}
}

@article{gai72,
  title = {Does Cardiac Transplantation Prolong Life? {{A}} Reassessment},
  author = {Gail, M. H.},
  date = {1972},
  journaltitle = {Ann Int Med},
  volume = {76},
  pages = {815--817},
  citeulike-article-id = {13264110},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{gai84bia,
  title = {Biased Estimates of Treatment Effect in Randomized Experiments with Nonlinear Regressions and Omitted Covariates},
  author = {Gail, M. H. and Wieand, S. and Piantadosi, S.},
  date = {1984},
  journaltitle = {Biometrika},
  volume = {71},
  pages = {431--444},
  citeulike-article-id = {13264111},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {covariable-adjustment},
  note = {bias if omitted covariables and model is nonlinear}
}

@incollection{gai86adj,
  title = {Adjusting for Covariates That Have the Same Distribution in Exposed and Unexposed Cohorts},
  booktitle = {Modern {{Statistical Methods}} in {{Chronic Disease Epidemiology}}},
  author = {Gail, Mitchell H.},
  editor = {Moolgavkar, S. H. and Prentice, R. L.},
  date = {1986},
  pages = {3--18},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264112},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {covariable-adjustment,multiple-models-studied,omitted-covariable,power-loss},
  note = {unadjusted test can have larger type I error than nominal}
}

@article{gai88tes,
  title = {Tests for No Treatment Effect in Randomized Clinical Trials},
  author = {Gail, M. H. and Tan, W. Y. and Piantadosi, S.},
  date = {1988},
  journaltitle = {Biometrika},
  volume = {75},
  pages = {57--64},
  citeulike-article-id = {13264113},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {covariable-adjustment,model-misspecification,omitted-covariables},
  note = {test based on randomization distribution of residuals;unadjusted test can have larger type I error than nominal}
}

@article{gai96des,
  title = {On Design Considerations and Randomization-Based Inference for Community Intervention Trials},
  author = {Gail, Mitchell H. and Mark, Steven D. and Carroll, Raymond J. and Green, Sylvan and Pee, David},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1069--1092},
  citeulike-article-id = {13264114},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {cluster-randomization}
}

@article{gal02gui,
  title = {Guidelines for the Design of Clinical Trials with Longitudinal Outcomes},
  author = {Galbraith, Sally and Marschner, Ian C.},
  date = {2002},
  journaltitle = {Controlled Clin Trials},
  volume = {23},
  pages = {257--273},
  citeulike-article-id = {13265282},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-trials-design,power,random-effects,rates-of-change,sample-size,serial-data},
  note = {accounting for dropout in sample size calculations}
}

@article{gal14ant,
  title = {Anti-Remodeling and Anti-Fibrotic Effects of the Neuregulin-1β Glial Growth Factor 2 in a Large Animal Model of Heart Failure.},
  author = {Galindo, Cristi L. and Kasasbeh, Ehab and Murphy, Abigail and Ryzhov, Sergey and Lenihan, Sean and Ahmad, Farhaan A. and Williams, Philip and Nunnally, Amy and Adcock, Jamie and Song, Yanna and Harrell, Frank E. and Tran, Truc-Linh L. and Parry, Tom J. and Iaci, Jen and Ganguly, Anindita and Feoktistov, Igor and Stephenson, Matthew K. and Caggiano, Anthony O. and Sawyer, Douglas B. and Cleator, John H.},
  date = {2014-10},
  journaltitle = {J Am Hrt Assoc},
  volume = {3},
  number = {5},
  eprint = {25341890},
  eprinttype = {pmid},
  issn = {2047-9980},
  doi = {10.1161/JAHA.113.000773},
  url = {http://dx.doi.org/10.1161/JAHA.113.000773},
  abstract = {Neuregulin-1β (NRG-1β) is a growth factor critical for cardiac development and repair with therapeutic potential for heart failure. We previously showed that the glial growth factor 2 (GGF2) isoform of NRG-1β improves cardiac function in rodents after myocardial infarction (MI), but its efficacy in a large animal model of cardiac injury has not been examined. We therefore sought to examine the effects of GGF2 on ventricular remodeling, cardiac function, and global transcription in post-MI swine, as well as potential mechanisms for anti-remodeling effects. MI was induced in anesthetized swine (n=23) by intracoronary balloon occlusion. At 1 week post-MI, survivors (n=13) received GGF2 treatment (intravenous, biweekly for 4 weeks; n=8) or were untreated (n=5). At 5 weeks post-MI, fractional shortening was higher (32.8\% versus 25.3\%, P=0.019), and left ventricular (LV) end-diastolic dimension lower (4.5 versus 5.3 cm, P=0.003) in GGF2-treated animals. Treatment altered expression of 528 genes, as measured by microarrays, including collagens, basal lamina components, and matricellular proteins. GGF2-treated pigs exhibited improvements in LV cardiomyocyte mitochondria and intercalated disk structures and showed less fibrosis, altered matrix structure, and fewer myofibroblasts (myoFbs), based on trichrome staining, electron microscopy, and immunostaining. In vitro experiments with isolated murine and rat cardiac fibroblasts demonstrate that NRG-1β reduces myoFbs, and suppresses TGFβ-induced phospho-SMAD3 as well as αSMA expression. These results suggest that GGF2/NRG-1β prevents adverse remodeling after injury in part via anti-fibrotic effects in the heart.  2014 The Authors. Published on behalf of the American Heart Association, Inc., by Wiley Blackwell.},
  citeulike-article-id = {13416177},
  citeulike-linkout-0 = {http://dx.doi.org/10.1161/JAHA.113.000773},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/25341890},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=25341890},
  posted-at = {2014-11-02 22:57:44},
  priority = {0},
  keywords = {collaboration,cv}
}

@article{gal97rel,
  title = {Relationship of Body Mass Index to Subsequent Mortality among Seriously Ill Hospitalized Patients.},
  author = {Galanos, A. N. and Pieper, C. F. and Kussin, P. S. and Winchell, M. T. and Fulkerson, W. J. and Harrell, F. E. and Teno, J. M. and Layde, P. and Connors, A. F. and Phillips, R. S. and Wenger, N. S.},
  date = {1997},
  journaltitle = {Crit Care Med},
  volume = {25},
  pages = {1962--1968},
  citeulike-article-id = {13264115},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{gal98pra,
  title = {Practical Issues in Linear Models Analyses in Multicenter Clinical Trials},
  author = {Gallo, Paul P.},
  date = {1998},
  journaltitle = {Biopharm Rep ASA},
  volume = {6},
  number = {2},
  pages = {1--9},
  citeulike-article-id = {13264116},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {efficiency,multicenter-clinical-trial,pooling-centers,power,type-iii-test-and-contrast,variance}
}

@article{gam17sta,
  title = {Statistical Modeling for {{Bayesian}} Extrapolation of Adult Clinical Trial Information in Pediatric Drug Evaluation},
  author = {Gamalo-Siebers, Margaret and Savic, Jasmina and Basu, Cynthia and Zhao, Xin and Gopalakrishnan, Mathangi and Gao, Aijun and Song, Guochen and Baygani, Simin and Thompson, Laura and Xia, H. Amy and Price, Karen and Tiwari, Ram and Carlin, Bradley P.},
  date = {2017},
  journaltitle = {Pharm Stat},
  issn = {15391604},
  doi = {10.1002/pst.1807},
  url = {http://dx.doi.org/10.1002/pst.1807},
  citeulike-article-id = {14346294},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1807},
  posted-at = {2017-04-28 14:51:20},
  priority = {2},
  keywords = {bayesian-inference,choice-of-prior,drug-development,pediatric}
}

@article{gan04som,
  title = {Some Unexplained Aspects of Analysis of Covariance in Pretest-Posttest Studies},
  author = {Ganju, Jitendra},
  date = {2004},
  journaltitle = {Biometrics},
  volume = {60},
  pages = {829--833},
  citeulike-article-id = {13265393},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {ancova,change,change-scores,conditional-analysis,fixed-random-baseline-measurement},
  note = {"adjusting for the pretest variable in observational studies may actually introduce bias where none previously existed"}
}

@article{gan95com,
  title = {A Comparison of Methods for Correlated Ordinal Meaures with Opthalmic Applications},
  author = {Gange, Stephen J. and Linton, Kathryn L. P. and Scott, Alastair J. and DeMets, David L. and Klein, Ronald},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1961--1974},
  citeulike-article-id = {13264117},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {correlated-responses,data-summary,multivariate,ordinal-response,response-summary}
}

@article{gan96use,
  title = {Use of the Beta-Binomial Distribution to Model the Effect of Policy Changes on Appropriateness of Hospital Stays},
  author = {Gange, Stephen J. and Munoz, Alvaro and Sáez, Marc and Alonso, Jordi},
  date = {1996},
  journaltitle = {Appl Stat},
  volume = {45},
  pages = {371--382},
  citeulike-article-id = {13264118},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {appropriateness,clustered-data,health-policy,length-of-stay}
}

@article{gao97emp,
  title = {An Empirical Comparison of Two Semi-Parametric Approaches for the Estimation of Covariate Effects from Multivariate Failure Time Data},
  author = {Gao, Suguan and Zhou, Xiao-Hua},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2049--2062},
  citeulike-article-id = {13264119},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {clustered-survival-times,multiple-events,multivariate-failure-time-data,simulation-setup}
}

@article{gar09com,
  title = {Does Comparative-Effectiveness Research Threaten Personalized Medicine?},
  author = {Garber, Alan M. and Tunis, Sean R.},
  date = {2009},
  journaltitle = {NEJM},
  volume = {360},
  pages = {1925--1927},
  citeulike-article-id = {13265751},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {cer,comparative-effectiveness-research,personalized-medicine},
  note = {"CER is not a panacea, but it is a key to individualized care and innovation, not a threat. An initiative to advance our knowledge about the effectiveness of clinical strategies can hasten the day when personalized medicine transforms health care.... large observational databases and pooled trial results can be used to learn more about the subgroups of patients who benefit from therapy. A recent study showed that mortality was similar overall for patients with coronary disease whether treated with percutaneous coronary intervention (PCI) or coronary-artery bypass surgery. However, the results varied strikingly with age: mortality was much lower with surgery among patients 65 years of age or older and lower with PCI among those 55 years of age or younger. Such information is important not only for patients with varying risk characteristics and coexisting conditions but for women, members of minority groups, and others who have historically been underrepresented in clinical trials. Current CER efforts aim to ensure that much more useful data will be collected and that better methods will be developed for understanding differences in effectiveness among different patient groups. ... The greatest obstacle to the adoption of personalized approaches such as genomic testing, however, is the lack of adequately designed studies assessing their clinical utility. Often there is little consensus about the best way to design and implement such studies. We may know very little about how a test might improve health in typical clinical settings. These are precisely the kinds of issues that CER is designed to address. ... Genomic medicine, however, has had little impact to date in most areas of care -- a fact that some critics blame on payers, claiming that they impose unrealistically high evidence barriers before agreeing to pay for genomic tests. But payers have often championed personalized approaches -- for example, by reimbursing for KRAS testing before the Food and Drug Administration (FDA) has fully embraced it. The real bottleneck is often the science itself: progress in identifying clinically important genetic variants has been slow, since seldom does the presence of a common variant greatly increase the relative risk of a serious disease or of severe harm from treatment. Moreover, only some genomic tests provide clinically important information. For example, although the FDA endorsed the use of genomic tests to identify persons with warfarin sensitivity, comparative trials showed that the tests added little value over careful monitoring of the international normalized ratio. Chromosomal mutation 9p21.3 is associated with increased risk of cardiovascular disease in women, but a recent study showed that knowledge of its presence adds no additional predictive power to the standard information on risk. ".}
}

@article{gar09fix,
  title = {Fixed Effects, Random Effects and {{GEE}}: {{What}} Are the Differences?},
  author = {Gardiner, Joseph C. and Luo, Zhehui and Roman, Lee A.},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {221--239},
  citeulike-article-id = {13265730},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {ces-d,conditional-maximum-likelihood,fixed-effects,generalized-linear-mixed-model,hausman-test,linear-mixed-model,random-effects,robust-variance},
  note = {nice comparison of models; econometrics; different use of the term "fixed effects model"}
}

@article{gar95res,
  title = {Respondent},
  author = {Garfield, Joan B.},
  date = {1995},
  journaltitle = {Am Statistician},
  volume = {49},
  pages = {18--20},
  citeulike-article-id = {13264120},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {general,teaching-methods}
}

@book{gar96und,
  title = {Understanding {{Medical Research}}: {{A Practitioner}}'s {{Guide}}},
  author = {Garb, Jane L.},
  date = {1996},
  publisher = {{Little, Brown}},
  location = {{Boston}},
  citeulike-article-id = {13264121},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {general,study-design,teaching-mds},
  note = {1997 review-in-jasa-92798}
}

@article{gas94how,
  title = {How a Court Accepted an Impossible Explanation},
  author = {Gastwirth, Joseph and Krieger, Abba and Rosenbaum, Paul},
  date = {1994},
  journaltitle = {Am Statistician},
  volume = {48},
  pages = {313--315},
  citeulike-article-id = {13264122},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {adjustment,propensity-score,study-design,unmeasured-covariables},
  note = {see follow up articles in am stat 51 no 2 may 1997}
}

@article{gat95sta,
  title = {The Standard Error of a Weighted Mean Concentration--{{I}}. {{Bootstrapping}} vs Other Methods},
  author = {Gatz, Donald F. and Smith, Luther},
  date = {1995},
  journaltitle = {Atmosph Env},
  volume = {29},
  number = {11},
  pages = {1185--1193},
  url = {http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6X/ 2/18b627259a75ff9b765410aaa231e352},
  abstract = {Concentrations of chemical constituents of precipitation are frequently expressed in terms of the precipitation-weighted mean, which has several desirable properties. Unfortunately, the weighted mean has no analytical analog of the standard error of the arithmetic mean for use in characterizing its statistical uncertainty. Several approximate expressions have been used previously in the literature, but there is no consensus as to which is best. This paper compares three methods from the literature with a standard based on bootstrapping. Comparative calculations were carried out for nine major ions measured at 222 sampling sites in the National Atmospheric Deposition/National Trends Network (NADP/NTN). The ratio variance approximation of Cochran (1977) gave results that were not statistically different from those of bootstrapping, and is suggested as the method of choice for routine computing of the standard error of the weighted mean. The bootstrap method has advantages of its own, including the fact that it is nonparametric, but requires additional effort and computation time.},
  citeulike-article-id = {13265580},
  citeulike-linkout-0 = {http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6X/ 2/18b627259a75ff9b765410aaa231e352},
  posted-at = {2014-07-14 14:09:59},
  priority = {0}
}

@article{gat95stab,
  title = {The Standard Error of a Weighted Mean Concentration--{{II}}. {{Estimating}} Confidence Intervals},
  author = {Gatz, Donald F. and Smith, Luther},
  date = {1995},
  journaltitle = {Atmosph Env},
  volume = {29},
  number = {11},
  pages = {1195--1200},
  url = {http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6Y/ 2/a187487377ef52b741e3dabdfca97517},
  abstract = {One motivation for estimating the standard error, SEMw, of a weighted mean concentration, Mw, of an ion in precipitation is to use it to compute a confidence interval for Mw. Typically this is done by multiplying the standard error by a factor that depends on the degree of confidence one wishes to express, on the assumption that the weighted mean has a normal distribution. This paper compares confidence intervals of Mw concentrations of ions in precipitation, as computed using the assumption of a normal distribution, with those estimated from distributions produced by bootstrapping. The hypothesis that Mw was normally distributed was rejected about half the time (at the 5\% significance level) in tests involving nine major ions measured at ten diverse sites in the National Atmospheric Deposition Program/National Trends Network (NADP/NTN). Most of these rejections occurred at sites with fewer than 100 samples, in agreement with previous results. Nevertheless, the hypothesis was often rejected at sites with more than 100 samples as well. The maximum error (relative to Mw) in the 95\% confidence limits made by assuming a normal distribution of the Mw at the ten sites examined was about 27\%. Most such errors were less than 10\%, and errors were smaller at sampling sites with {$>$} 100 samples than at those with {$<$} 100 samples.},
  citeulike-article-id = {13265581},
  citeulike-linkout-0 = {http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6Y/ 2/a187487377ef52b741e3dabdfca97517},
  posted-at = {2014-07-14 14:09:59},
  priority = {0}
}

@article{gay09goo,
  title = {Good Practices for Adaptive Clinical Trials in Pharmaceutical Product Development},
  author = {Gaydos, B. and Anderson, K. M. and Berry, D. and Burnham, N. and Chuang-Stein, Christy and Dudinak, Jennifer and Fardipour, Parvin and Gallo, P. and Givens, S. and Lewis, R. and Maca, J. and Pinheiro, J. and Pritchett, Y. and Krams, M.},
  date = {2009},
  journaltitle = {Drug Info J},
  volume = {43},
  pages = {539--556},
  citeulike-article-id = {13265784},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {adaptive-clinical-trials,dmcs,dsmbs,good-practices-for-trial-simulation,rct,trial-documentation}
}

@article{gay87,
  title = {The Use of Time Dependent Covariates in Modelling Data from an Occupational Cohort Study},
  author = {Gaynor, J. J.},
  date = {1987},
  journaltitle = {Appl Stat},
  volume = {36},
  pages = {340--351},
  citeulike-article-id = {13264123},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {general,survival-analysis-proportional-hazards-model,survival-analysis-regression}
}

@article{gay93use,
  title = {On the Use of Cause-Specific Failure and Conditional Failure Probabilities: {{Examples}} from Clinical Oncology Data},
  author = {Gaynor, Jeffrey J. and Feuer, Eric J. and Tan, Claire C. and Wu, Danny H. and Little, Claudia R. and Straus, David J. and Clarkson, Dayard D. and Brennan, Murray F.},
  date = {1993},
  journaltitle = {J Am Stat Assoc},
  volume = {88},
  pages = {400--409},
  citeulike-article-id = {13264124},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {competing-risks,dependent-events,kaplan-meier,multiple-endpoints,survival-analysis}
}

@article{gbur95key,
  title = {Key Words and Phrases---{{The}} Key to Scholarly Visibility and Efficiency in an Information Explosion},
  author = {Gbur, Edward E. and Trumbo, Bruce E.},
  date = {1995},
  journaltitle = {Am Statistician},
  volume = {49},
  pages = {29--33},
  citeulike-article-id = {13264125},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {information-retrieval,writing}
}

@article{geb20rec,
  title = {Recurrent Time-to-Event Models with Ordinal Outcomes},
  author = {Gebski, Val and Byth, Karen and Asher, Rebecca and Marschner, Ian},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2057},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2057},
  urldate = {2020-10-10},
  abstract = {A model to accommodate time-to-event ordinal outcomes was proposed by Berridge and Whitehead. Very few studies have adopted this approach, despite its appeal in incorporating several ordered categories of event outcome. More recently, there has been increased interest in utilizing recurrent events to analyze practical endpoints in the study of disease history and to help quantify the changing pattern of disease over time. For example, in studies of heart failure, the analysis of a single fatal event no longer provides sufficient clinical information to manage the disease. Similarly, the grade/frequency/severity of adverse events may be more important than simply prolonged survival in studies of toxic therapies in oncology. We propose an extension of the ordinal time-to-event model to allow for multiple/recurrent events in the case of marginal models (where all subjects are at risk for each recurrence, irrespective of whether they have experienced previous recurrences) and conditional models (subjects are at risk of a recurrence only if they have experienced a previous recurrence). These models rely on marginal and conditional estimates of the instantaneous baseline hazard and provide estimates of the probabilities of an event of each severity for each recurrence over time. We outline how confidence intervals for these probabilities can be constructed and illustrate how to fit these models and provide examples of the methods, together with an interpretation of the results.},
  langid = {english},
  keywords = {multiple-endpoints,ordinal,ordinal-endpoints,recurrent-events,survival},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2057}
}

@article{geb21rec,
  title = {Recurrent Time-to-Event Models with Ordinal Outcomes},
  author = {Gebski, Val and Byth, Karen and Asher, Rebecca and Marschner, Ian},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {20},
  number = {1},
  pages = {77--92},
  issn = {1539-1612},
  doi = {10.1002/pst.2057},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2057},
  urldate = {2021-01-30},
  abstract = {A model to accommodate time-to-event ordinal outcomes was proposed by Berridge and Whitehead. Very few studies have adopted this approach, despite its appeal in incorporating several ordered categories of event outcome. More recently, there has been increased interest in utilizing recurrent events to analyze practical endpoints in the study of disease history and to help quantify the changing pattern of disease over time. For example, in studies of heart failure, the analysis of a single fatal event no longer provides sufficient clinical information to manage the disease. Similarly, the grade/frequency/severity of adverse events may be more important than simply prolonged survival in studies of toxic therapies in oncology. We propose an extension of the ordinal time-to-event model to allow for multiple/recurrent events in the case of marginal models (where all subjects are at risk for each recurrence, irrespective of whether they have experienced previous recurrences) and conditional models (subjects are at risk of a recurrence only if they have experienced a previous recurrence). These models rely on marginal and conditional estimates of the instantaneous baseline hazard and provide estimates of the probabilities of an event of each severity for each recurrence over time. We outline how confidence intervals for these probabilities can be constructed and illustrate how to fit these models and provide examples of the methods, together with an interpretation of the results.},
  langid = {english},
  keywords = {multiple-endpoints,ordinal,recurrent-events},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2057},
  note = {Extension of Berridge and Whitehead}
}

@article{geb21usi,
  title = {Using Recurrent Time-to-Event Models with Multinomial Outcomes to Generate Toxicity Profiles},
  author = {Gebski, Val and Marschner, Ian and Asher, Rebecca and Byth, Karen},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2113},
  url = {http://pericles.pericles.prod.literatumonline.com/doi/abs/10.1002/pst.2113},
  urldate = {2021-03-18},
  abstract = {Most clinical studies, which investigate the impact of therapy simultaneously, record the frequency of adverse events in order to monitor safety of the intervention. Study reports typically summarise adverse event data by tabulating the frequencies of the worst grade experienced but provide no details of the temporal profiles of specific types of adverse events. Such 'toxicity profiles' are potentially important tools in disease management and in the assessment of newer therapies including targeted treatments and immunotherapy where different types of toxicity may be more common at various times during long-term drug exposure. Toxicity profiles of commonly experienced adverse events occurring due to exposure to long-term treatment could assist in evaluating the costs of the health care benefits of therapy. We show how to generate toxicity profiles using an adaptation of the ordinal time-to-event model comprising of a two-step process, involving estimation of the multinomial response probabilities using multinomial logistic regression and combining these with recurrent time to event hazard estimates to produce cumulative event probabilities for each of the multinomial adverse event response categories. Such a model permits the simultaneous assessment of the risk of events over time and provides cumulative risk probabilities for each type of adverse event response. The method can be applied more generally by using different models to estimate outcome/response probabilities. The method is illustrated by developing toxicity profiles for three distinct types of adverse events associated with two treatment regimens for patients with advanced breast cancer.},
  langid = {english},
  keywords = {aes,drug-development,multiple-events,pharmaceutical,recurrent-events,safety,safety-monitoring,safety-profile},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2113}
}

@article{gehjir,
  title = {How to Find the Cure for Cancer},
  author = {Gehan, Edmund A.},
  journaltitle = {J Irreproduc Results},
  volume = {35},
  number = {4},
  pages = {2--4},
  citeulike-article-id = {13264126},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {subgroups}
}

@incollection{gei82obs,
  title = {Observations on Graduate Programs in Statistics and Related Issues},
  booktitle = {Teaching of {{Statistics}} and {{Statistical Consulting}}},
  author = {Geisser, Seymour},
  editor = {Rustagi, Jagdish and Wolfe, Douglas A.},
  date = {1982},
  pages = {21--33},
  publisher = {{Academic Press}},
  location = {{New York}},
  citeulike-article-id = {13265337},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {teaching},
  note = {Contains amazingly perceptive discussion of amazingly predictive earlier article by Hotelling;why statisticians should teach all levels of statistics courses;curriculum;dangers of spending too much time teaching consulting;}
}

@article{gel02let,
  title = {Let's Practice What We Preach: {{Turning}} Tables into Graphs},
  author = {Gelman, Andrew and Pasarica, Cristian and Dodhia, Rahul},
  date = {2002},
  journaltitle = {Am Statistician},
  volume = {56},
  pages = {121--130},
  citeulike-article-id = {13265280},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {data-reduction,graphics,reporting,simulation,tables,teaching,teaching-mds,visual-display},
  note = {graphical reporting of simulations; turning tables into graphics}
}

@book{gel06dat,
  title = {Data {{Analysis Using Regression}} and {{Multilevel}}/{{Hierarchical Models}}},
  author = {Gelman, Andrew and Hill, Jennifer},
  date = {2006-12},
  edition = {1},
  publisher = {{Cambridge University Press}},
  url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/052168689X},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors\&\#8217; own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
  citeulike-article-id = {1334704},
  citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/052168689X},
  citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/052168689X},
  citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/052168689X},
  citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/052168689X},
  citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/052168689X/citeulike00-21},
  citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/052168689X},
  citeulike-linkout-6 = {http://www.worldcat.org/isbn/052168689X},
  citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN052168689X},
  citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=052168689X&index=books&linkCode=qs},
  citeulike-linkout-9 = {http://www.librarything.com/isbn/052168689X},
  day = {18},
  howpublished = {Paperback},
  isbn = {0-521-68689-X},
  posted-at = {2016-12-04 21:00:49},
  priority = {2},
  keywords = {causal-inference,hierarchical-model,propensity-score}
}

@article{gel08sca,
  title = {Scaling Regression Inputs by Dividing by Two Standard Deviations},
  author = {Gelman, Andrew},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {2865--2873},
  citeulike-article-id = {13265681},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {generalized-linear-models,linear-regression,logistic-regression,standardization,z-score}
}

@article{gel13pva,
  title = {P {{Values}} and {{Statistical Practice}}},
  author = {Gelman, Andrew},
  date = {2013-01},
  journaltitle = {Epi},
  volume = {24},
  number = {1},
  eprint = {23232612},
  eprinttype = {pmid},
  pages = {69--72},
  issn = {1044-3983},
  doi = {10.1097/ede.0b013e31827886f7},
  url = {http://dx.doi.org/10.1097/ede.0b013e31827886f7},
  citeulike-article-id = {12016982},
  citeulike-attachment-1 = {gel13pva.pdf; /pdf/user/harrelfe/article/12016982/1093670/gel13pva.pdf; 427d0fe50a4a72ea4942faafd733b289079aba1f},
  citeulike-linkout-0 = {http://dx.doi.org/10.1097/ede.0b013e31827886f7},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/23232612},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=23232612},
  posted-at = {2016-12-05 15:48:53},
  priority = {0},
  keywords = {bayesian-inference,choice-of-prior,misinterpretation-of-p-values,p-values}
}

@article{gel15bay,
  title = {Bayesian and {{Frequentist Regression Methods}}},
  author = {Gelman, Andrew},
  date = {2015-03},
  journaltitle = {Stat Med},
  volume = {34},
  number = {7},
  pages = {1259--1260},
  issn = {02776715},
  doi = {10.1002/sim.6427},
  url = {http://dx.doi.org/10.1002/sim.6427},
  citeulike-article-id = {14187479},
  citeulike-attachment-1 = {Gelman-2015-Statistics<sub>i</sub>n<sub>M</sub>edicine.pdf; /pdf/user/harrelfe/article/14187479/1092189/Gelman-2015-Statistics<sub>i</sub>n<sub>M</sub>edicine.pdf; f721f578779a78858951150d3d213e55da97c22d},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6427},
  day = {30},
  posted-at = {2016-11-20 13:39:31},
  priority = {0},
  keywords = {bayesian-inference}
}

@unpublished{gel17bey,
  title = {Beyond Subjective and Objective in Statistics},
  author = {Gelman, Andrew and Hennig, Christian},
  date = {2017-06},
  url = {http://www.stat.columbia.edu/̃gelman/research/published/objectivityr5.pdf},
  citeulike-article-id = {14389022},
  day = {21},
  posted-at = {2017-07-06 21:31:21},
  priority = {2},
  keywords = {bayesian-inference,objectivity}
}

@article{gel18fai,
  title = {The {{Failure}} of {{Null Hypothesis Significance Testing When Studying Incremental Changes}}, and {{What}} to {{Do About It}}},
  author = {Gelman, Andrew},
  date = {2018-01-01},
  journaltitle = {Pers Soc Psychol Bull},
  volume = {44},
  number = {1},
  pages = {16--23},
  issn = {0146-1672},
  doi = {10.1177/0146167217729162},
  url = {https://doi.org/10.1177/0146167217729162},
  urldate = {2019-12-04},
  abstract = {A standard mode of inference in social and behavioral science is to establish stylized facts using statistical significance in quantitative studies. However, in a world in which measurements are noisy and effects are small, this will not work: selection on statistical significance leads to effect sizes which are overestimated and often in the wrong direction. After a brief discussion of two examples, one in economics and one in social psychology, we consider the procedural solution of open postpublication review, the design solution of devoting more effort to accurate measurements and within-person comparisons, and the statistical analysis solution of multilevel modeling and reporting all results rather than selection on significance. We argue that the current replication crisis in science arises in part from the ill effects of null hypothesis significance testing being used to study small effects with noisy data. In such settings, apparent success comes easy but truly replicable results require a more serious connection between theory, measurement, and data.},
  langid = {english},
  keywords = {bad-science,p-value,reproducibility}
}

@article{gel18rsq,
  title = {R-Squared for {{Bayesian Regression Models}}},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  date = {2018-12-10},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--7},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1549100},
  url = {https://doi.org/10.1080/00031305.2018.1549100},
  urldate = {2019-05-17},
  abstract = {The usual definition of R2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian fits, as the numerator can be larger than the denominator. We propose an alternative definition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the expected variance of the errors.},
  keywords = {accuracy,bayes,predictive-accuracy,regression}
}

@unpublished{gel20bay,
  title = {Bayesian {{Workflow}}},
  author = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C. and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and Bürkner, Paul-Christian and Modrák, Martin},
  date = {2020-11-03},
  eprint = {2011.01808},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2011.01808},
  urldate = {2021-09-08},
  abstract = {The Bayesian approach to data analysis provides a powerful way to handle uncertainty in all observations, model parameters, and model structure using probability theory. Probabilistic programming languages make it easier to specify and fit Bayesian models, but this still leaves us with many options regarding constructing, evaluating, and using these models, along with many remaining challenges in computation. Using Bayesian inference to solve real-world problems requires not only statistical skills, subject matter knowledge, and programming, but also awareness of the decisions made in the process of data analysis. All of these aspects can be understood as part of a tangled workflow of applied Bayesian statistics. Beyond inference, the workflow also includes iterative model building, model checking, validation and troubleshooting of computational problems, model understanding, and model comparison. We review all these aspects of workflow in the context of several examples, keeping in mind that in practice we will be fitting many models for any given problem, even if only a subset of them will ultimately be relevant for our conclusions.},
  archiveprefix = {arXiv},
  keywords = {bayes,computational,strategy},
  note = {Comment: 77 pages, 35 figures}
}

@article{gel87,
  title = {Interim Analyses in Randomized Clinical Trials: Ramifications and Guidelines for Practitioners},
  author = {Geller NL, S. J.},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {213--223},
  citeulike-article-id = {13264127},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {study-design-and-stopping-rules}
}

@article{gel89,
  title = {A Quality-of-Life-Oriented Endpoint for Comparing Therapies},
  author = {Gelber RD, Goldhirsch A.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {781--795},
  citeulike-article-id = {13264128},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {measurement,research-methods,survival-analysis-non-regression}
}

@book{gel95bay,
  title = {Bayesian {{Data Analysis}}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Rubin, Donald B.},
  date = {1995},
  publisher = {{Chapman \& Hall}},
  location = {{London}},
  citeulike-article-id = {13264129},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{gen91loc,
  title = {Local Full Likelihood Estimation for the Proportional Hazards Model},
  author = {Gentleman, R. and Crowley, J.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {1283--1296},
  citeulike-article-id = {13264130},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {maximum-likelihood,ph-model,transformations}
}

@article{geo94sto,
  title = {Stopping a Trial Early: {{Frequentist}} and {{Bayesian}} Approaches Applied to a {{CALGB}} Trial of Non-Small Cell Lung Cancer},
  author = {George, S. L. and Li, C. and Berry, D. A. and Green, M. R.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1313--1328},
  doi = {10.1002/sim.4780131305},
  url = {http://dx.doi.org/10.1002/sim.4780131305},
  citeulike-article-id = {13264131},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780131305},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {bayes,bayesian-inference,posterior,updating},
  note = {nice graph showing updating of posterior}
}

@article{ger14cal,
  title = {Calibration Plots for Risk Prediction Models in the Presence of Competing Risks},
  author = {Gerds, Thomas A. and Andersen, Per K. and Kattan, Michael W.},
  date = {2014-08},
  journaltitle = {Stat Med},
  volume = {33},
  number = {18},
  pages = {3191--3203},
  doi = {10.1002/sim.6152},
  url = {http://dx.doi.org/10.1002/sim.6152},
  abstract = {A predicted risk of 17\% can be called reliable if it can be expected that the event will occur to about 17 of 100 patients who all received a predicted risk of 17\%. Statistical models can predict the absolute risk of an event such as cardiovascular death in the presence of competing risks such as death due to other causes. For personalized medicine and patient counseling, it is necessary to check that the model is calibrated in the sense that it provides reliable predictions for all subjects. There are three often encountered practical problems when the aim is to display or test if a risk prediction model is well calibrated. The first is lack of independent validation data, the second is right censoring, and the third is that when the risk scale is continuous, the estimation problem is as difficult as density estimation. To deal with these problems, we propose to estimate calibration curves for competing risks models based on jackknife pseudo-values that are combined with a nearest neighborhood smoother and a cross-validation approach to deal with all three problems.},
  citeulike-article-id = {13448115},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6152},
  day = {15},
  posted-at = {2014-11-29 16:14:49},
  priority = {2},
  keywords = {calibration,competing-risks,survival-analysis}
}

@article{ger21wis,
  title = {{{WiSER}}: {{Robust}} and Scalable Estimation and Inference of within-Subject Variances from Intensive Longitudinal Data},
  shorttitle = {{{WiSER}}},
  author = {German, Christopher A. and Sinsheimer, Janet S. and Zhou, Jin and Zhou, Hua},
  date = {2021},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13506},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13506},
  urldate = {2021-06-18},
  abstract = {The availability of vast amounts of longitudinal data from electronic health records (EHR) and personal wearable devices opens the door to numerous new research questions. In many studies, individual variability of a longitudinal outcome is as important as the mean. Blood pressure fluctuations, glycemic variations, and mood swings are prime examples where it is critical to identify factors that affect the within-individual variability. We propose a scalable method, within-subject variance estimator by robust regression (WiSER), for the estimation and inference of the effects of both time-varying and time-invariant predictors on within-subject variance. It is robust against the misspecification of the conditional distribution of responses or the distribution of random effects. It shows similar performance as the correctly specified likelihood methods but is times faster. The estimation algorithm scales linearly in the total number of observations, making it applicable to massive longitudinal data sets. The effectiveness of WiSER is evaluated in extensive simulation studies. Its broad applicability is illustrated using the accelerometry data from the Women's Health Study and a clinical trial for longitudinal diabetes care.},
  langid = {english},
  keywords = {gee,mobile-health,serial,time-series,variability},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13506}
}

@article{ger88res,
  title = {Resolving Conflicting Clinical Trials: {{Guidelines}} for Meta-Analysis},
  author = {Gerbarg, Zachary B. and Horwitz, Ralph I.},
  date = {1988},
  journaltitle = {J Clin Epi},
  volume = {41},
  pages = {503--509},
  citeulike-article-id = {13264132},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {clinical-trials,meta-analysis,publication-bias,quality-of-studies,rct,teaching-mds}
}

@article{ges11cau,
  title = {Cause-Specific Cumulative Incidence Estimation and the {{Fine}} and {{Gray}} Model under Both Left Truncation and Right Censoring},
  author = {Geskus, Ronald B.},
  date = {2011},
  journaltitle = {Biometrics},
  volume = {67},
  number = {1},
  pages = {39--49},
  doi = {10.1111/j.1541-0420.2010.01420.x},
  url = {http://dx.doi.org/10.1111/j.1541-0420.2010.01420.x},
  abstract = {Summary The standard estimator for the cause-specific cumulative incidence function in a competing risks setting with left truncated and/or right censored data can be written in two alternative forms. One is a weighted empirical cumulative distribution function and the other a product-limit estimator. This equivalence suggests an alternative view of the analysis of time-to-event data with left truncation and right censoring: individuals who are still at risk or experienced an earlier competing event receive weights from the censoring and truncation mechanisms. As a consequence, inference on the cumulative scale can be performed using weighted versions of standard procedures. This holds for estimation of the cause-specific cumulative incidence function as well as for estimation of the regression parameters in the Fine and Gray proportional subdistribution hazards model. We show that, with the appropriate filtration, a martingale property holds that allows deriving asymptotic results for the proportional subdistribution hazards model in the same way as for the standard Cox proportional hazards model. Estimation of the cause-specific cumulative incidence function and regression on the subdistribution hazard can be performed using standard software for survival analysis if the software allows for inclusion of time-dependent weights. We show the implementation in the R statistical package. The proportional subdistribution hazards model is used to investigate the effect of calendar period as a deterministic external time varying covariate, which can be seen as a special case of left truncation, on AIDS related and non-AIDS related cumulative mortality.},
  citeulike-article-id = {13265927},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1541-0420.2010.01420.x},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {competing-risks,inverse-probability-weight,subdistribution-hazard,survival-analysis}
}

@book{ggplot2,
  title = {Ggplot2: Elegant Graphics for Data Analysis},
  author = {Wickham, Hadley},
  date = {2009},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13470861},
  isbn = {978-0-387-98140-6},
  posted-at = {2014-12-29 01:23:13},
  priority = {0},
  keywords = {graphics,software}
}

@article{gia14opt,
  title = {Do Optimal Prognostic Thresholds in Continuous Physiological Variables Really Exist? {{Analysis}} of Origin of Apparent Thresholds, with Systematic Review for Peak Oxygen Consumption, Ejection Fraction and {{BNP}}},
  author = {Giannoni, A. and Baruah, R. and Leong, T. and Rehman, M. B. and Pastormerlo, L. E. and Harrell, F. E. and Coats, A. J. and Francis, D. P.},
  date = {2014},
  journaltitle = {PLoS ONE},
  volume = {9},
  number = {1},
  doi = {10.1371/journal.pone.0081699},
  url = {http://dx.doi.org/10.1371/journal.pone.0081699},
  abstract = {Clinicians are sometimes advised to make decisions using thresholds in measured variables, derived from prognostic studies. We studied why there are conflicting apparently-optimal prognostic thresholds, for example in exercise peak oxygen uptake (pVO2), ejection fraction (EF), and Brain Natriuretic Peptide (BNP) in heart failure (HF). Studies testing pVO2, EF or BNP prognostic thresholds in heart failure, published between 1990 and 2010, listed on Pubmed. First, we examined studies testing pVO2, EF or BNP prognostic thresholds. Second, we created repeated simulations of 1500 patients to identify whether an apparently-optimal prognostic threshold indicates step change in risk. 33 studies (8946 patients) tested a pVO2 threshold. 18 found it prognostically significant: the actual reported threshold ranged widely (10-18 ml/kg/min) but was overwhelmingly controlled by the individual study population's mean pVO2 (r = 0.86, p{$<$}0.00001). In contrast, the 15 negative publications were testing thresholds 199\% further from their means (p = 0.0001). Likewise, of 35 EF studies (10220 patients), the thresholds in the 22 positive reports were strongly determined by study means (r = 0.90, p{$<$}0.0001). Similarly, in the 19 positives of 20 BNP studies (9725 patients): r = 0.86 (p{$<$}0.0001). Second, survival simulations always discovered a "most significant" threshold, even when there was definitely no step change in mortality. With linear increase in risk, the apparently-optimal threshold was always near the sample mean (r = 0.99, p{$<$}0.001). This study cannot report the best threshold for any of these variables; instead it explains how common clinical research procedures routinely produce false thresholds. First, shifting (and/or disappearance) of an apparently-optimal prognostic threshold is strongly determined by studies' average pVO2, EF or BNP. Second, apparently-optimal thresholds always appear, even with no step in prognosis. Emphatic therapeutic guidance based on thresholds from observational studies may be ill-founded. We should not assume that optimal thresholds, or any thresholds, exist.},
  citeulike-article-id = {13265988},
  citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0081699},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {categorization,categorizing-continuous-variables,ctsafac}
}

@article{gib83use,
  title = {The Use of Radionuclide Angiography in the Diagnosis of Coronary Artery Disease---a Logistic Regression Analysis},
  author = {Gibbons, R. J. and Lee, K. L. and Pryor, D. and Harrell, F. E. and Coleman, R. E. and Cobb, F. R. and Rosati, R. A. and Jones, R. H.},
  date = {1983},
  journaltitle = {Circ},
  volume = {68},
  pages = {740--746},
  citeulike-article-id = {13264133},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{gib91con,
  title = {Conditional Logistic Regression with Missing Data},
  author = {Gibbons, L. B. and Hosmer, D. W.},
  date = {1991},
  journaltitle = {Comm Stat B},
  volume = {20},
  pages = {109--120},
  citeulike-article-id = {13264134},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {conditional-logistic-regression,missing-data},
  note = {compared mean fill-in with predicted covariables with and without error, casewise deletion}
}

@article{gib94dou,
  title = {Is Double Data Entry Necessary? {{The CHART}} Trials},
  author = {Gibson, Della and Harvey, Angela J. and Everett, Vincent and Parmar, Maehesh K. B.},
  date = {1994},
  journaltitle = {Controlled Clin Trials},
  volume = {15},
  pages = {482--488},
  doi = {10.1016/0197-2456(94)90005-1},
  url = {http://dx.doi.org/10.1016/0197-2456(94)90005-1},
  abstract = {There is some controversy over the need for double data entry in clinical trials. In particular, does the number and types of errors identified with this approach justify the extra effort involved? We report the results of a study carried out to address this question. Our main outcome measure was the frequency and types of errors involved in the entry of data for the CHART (continuous, hyperfractionated, accelerated radiotherapy) trials. Data were reentered for a sample of 44 patients by a data manager other than the one making the initial entry. The second entry was then compared with the first entry. The error rate for the two entries combined was 14 per 10,000 data items (fields) (95\% confidence interval 10, 19). The error rate for the initial entry alone was 15 per 10,000 fields (95\% confidence interval 9.5, 22), and the vital/important error rate (defined as any error on a principal outcome measure or a major error on any other endpoint or variable) was 2.5 per 10,000 fields (95\% confidence interval 0.68, 6.4). On this evidence double data entry is not performed for the CHART trials.},
  citeulike-article-id = {13265262},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0197-2456(94)90005-1},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-trials,data-management,double-data-entry,rct},
  note = {Study demonstrated performing double vs. single data entry in a centralized data entry environment decreased error rates from 0.15\% to 0.13\%. When errors were further classified based on their study impact, the single entry error rate was 0.04\%. The authors concluded the calculated difference was insignificant based on their work practices, and acknowledged the success or failure of single data entry required skilled staff and comprehensive computer data edit checking systems.}
}

@article{gib98hea,
  title = {Health Service Utilitization and Insurance Coverage: {{A}} Multivariate Probit Analysis},
  author = {Gibbons, Robert D. and Wilcox-Gök, Virginia},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {63--72},
  citeulike-article-id = {13264135},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {hsr,multivariate-binary-data}
}

@article{gil13sen,
  title = {Sensitivity {{Analysis}} of {{Per-Protocol Time-to-Event Treatment Efficacy}} in {{Randomized Clinical Trials}}},
  author = {Gilbert, Peter B. and Shepherd, Bryan E. and Hudgens, Michael G.},
  date = {2013-09},
  journaltitle = {JASA},
  volume = {108},
  number = {503},
  pages = {789--800},
  publisher = {Taylor & Francis},
  doi = {10.1080/01621459.2013.786649},
  url = {http://dx.doi.org/10.1080/01621459.2013.786649},
  abstract = {Assessing per-protocol (PP) treatment efficacy on a time-to-event endpoint is a common objective of randomized clinical trials. The typical analysis uses the same method employed for the intention-to-treat analysis (e.g., standard survival analysis) applied to the subgroup meeting protocol adherence criteria. However, due to potential post-randomization selection bias, this analysis may mislead about treatment efficacy. Moreover, while there is extensive literature on methods for assessing causal treatment effects in compliers, these methods do not apply to a common class of trials where (a) the primary objective compares survival curves, (b) it is inconceivable to assign participants to be adherent and event free before adherence is measured, and (c) the exclusion restriction assumption fails to hold. HIV vaccine efficacy trials including the recent RV144 trial exemplify this class, because many primary endpoints (e.g., HIV infections) occur before adherence is measured, and nonadherent subjects who receive some of the planned immunizations may be partially protected. Therefore, we develop methods for assessing PP treatment efficacy for this problem class, considering three causal estimands of interest. Because these estimands are not identifiable from the observable data, we develop nonparametric bounds and semiparametric sensitivity analysis methods that yield estimated ignorance and uncertainty intervals. The methods are applied to RV144. Supplementary materials for this article are available online.},
  citeulike-article-id = {12888994},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.2013.786649},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2013.786649},
  day = {1},
  posted-at = {2016-05-11 21:30:33},
  priority = {2},
  keywords = {ctsafac}
}

@article{gil16rat,
  title = {Rate {{Control}} versus {{Rhythm Control}} for {{Atrial Fibrillation}} after {{Cardiac Surgery}}},
  author = {Gillinov, A. Marc and Bagiella, Emilia and Moskowitz, Alan J. and Raiten, Jesse M. and Groh, Mark A. and Bowdish, Michael E. and Ailawadi, Gorav and Kirkwood, Katherine A. and Perrault, Louis P. and Parides, Michael K. and Smith, Robert L. and Kern, John A. and Dussault, Gladys and Hackmann, Amy E. and Jeffries, Neal O. and Miller, Marissa A. and Taddei-Peters, Wendy C. and Rose, Eric A. and Weisel, Richard D. and Williams, Deborah L. and Mangusan, Ralph F. and Argenziano, Michael and Moquete, Ellen G. and O'Sullivan, Karen L. and Pellerin, Michel and Shah, Kinjal J. and Gammie, James S. and Mayer, Mary L. and Voisine, Pierre and Gelijns, Annetine C. and O'Gara, Patrick T. and Mack, Michael J.},
  date = {2016-04},
  journaltitle = {NEJM},
  volume = {374},
  number = {20},
  pages = {1911--1921},
  publisher = {Massachusetts Medical Society},
  doi = {10.1056/nejmoa1602002},
  url = {http://dx.doi.org/10.1056/nejmoa1602002},
  abstract = {In recent years, much research has focused on the prevention of atrial fibrillation after cardiac surgery, but highly effective interventions are lacking. Thus, postoperative atrial fibrillation remains the most common complication after cardiac surgery, with an incidence of 20 to 50\%.1?4 This complication has major adverse consequences for patients and the health care system, including increased rates of death, complications, and hospitalizations and inflated costs.1?9 Therefore, efforts to determine the most effective preventive strategies and management practices are important. There are two general approaches to managing postoperative atrial fibrillation: heart-rate control (hereafter ?rate control?) and rhythm control with .~.~.},
  citeulike-article-id = {14559813},
  citeulike-linkout-0 = {http://dx.doi.org/10.1056/nejmoa1602002},
  citeulike-linkout-1 = {http://www.nejm.org/doi/abs/10.1056/NEJMoa1602002},
  day = {4},
  posted-at = {2018-04-02 03:37:29},
  priority = {0},
  keywords = {instrumental-variables,rct}
}

@article{gil87,
  title = {A Simple Test of the Proportional Hazards Assumption},
  author = {Gill, R. and Schumacher, M.},
  date = {1987},
  journaltitle = {Biometrika},
  volume = {74},
  pages = {289--300},
  citeulike-article-id = {13264136},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model}
}

@book{gil91how,
  title = {How {{We Know What Isn}}'t {{So}}: {{The Fallibility}} of {{Human Reason}} in {{Everyday Life}}},
  author = {Gilovich, Thomas},
  date = {1991},
  publisher = {{Free Press}},
  location = {{New York}},
  citeulike-article-id = {13265180},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  note = {"It ain't so much the things we don't know that get us into trouble. It's the things we know that just ain't so" - Artemus Ward. This well written book provides an account of the many ways humans come to believe certain pieces of information, including how rumors are spread and why so many people believe in UFOs and ESP. The book also deals quite a bit with why people believe in ineffective remedies for illness, and why people are impressed with coincidences. A theme that runs through the book is that people are good with numerators but not with denominators. The book has widespread applicability to how we interpret information and will make every reader a better decision maker.}
}

@article{gir08sam,
  title = {Sample Size Calculation for Cluster Randomized Cross-over Trials},
  author = {Giraudeau, B. and Ravaud, P. and Donner, A.},
  date = {2008-11},
  journaltitle = {Stat Med},
  volume = {27},
  number = {27},
  pages = {5578--5585},
  publisher = {John Wiley & Sons, Ltd.},
  issn = {02776715},
  doi = {10.1002/sim.3383},
  url = {http://dx.doi.org/10.1002/sim.3383},
  abstract = {The cluster randomized cross-over design has been proposed in particular because it prevents an imbalance that may bring into question the internal validity of parallel group cluster trials. We derived a sample size formula for continuous outcomes that takes into account both the intraclass correlation coefficient (representing the clustering effect) and the interperiod correlation (induced by the cross-over design). Copyright  2008 John Wiley \& Sons, Ltd.},
  citeulike-article-id = {10311507},
  citeulike-attachment-1 = {gir08sam.pdf; /pdf/user/harrelfe/article/10311507/1110042/gir08sam.pdf; 8107ea9cce0ad2245d921010c301e23924b80df7},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3383},
  day = {29},
  posted-at = {2017-05-21 19:43:42},
  priority = {0},
  keywords = {cluster-randomization,cluster-randomized-trial,crossover,crossover-study,rct}
}

@article{gir16sta,
  title = {Statistical Efficiency and Optimal Design for Stepped Cluster Studies under Linear Mixed Effects Models},
  author = {Girling, Alan J. and Hemming, Karla},
  date = {2016-06},
  journaltitle = {Stat Med},
  volume = {35},
  number = {13},
  pages = {2149--2166},
  issn = {02776715},
  doi = {10.1002/sim.6850},
  url = {http://dx.doi.org/10.1002/sim.6850},
  abstract = {In stepped cluster designs the intervention is introduced into some (or all) clusters at different times and persists until the end of the study. Instances include traditional parallel cluster designs and the more recent stepped-wedge designs. We consider the precision offered by such designs under mixed-effects models with fixed time and random subject and cluster effects (including interactions with time), and explore the optimal choice of uptake times. The results apply both to cross-sectional studies where new subjects are observed at each time-point, and longitudinal studies with repeat observations on the same subjects. The efficiency of the design is expressed in terms of a 'cluster-mean correlation' which carries information about the dependency-structure of the data, and two design coefficients which reflect the pattern of uptake-times. In cross-sectional studies the cluster-mean correlation combines information about the cluster-size and the intra-cluster correlation coefficient. A formula is given for the 'design effect' in both cross-sectional and longitudinal studies. An algorithm for optimising the choice of uptake times is described and specific results obtained for the best balanced stepped designs. In large studies we show that the best design is a hybrid mixture of parallel and stepped-wedge components, with the proportion of stepped wedge clusters equal to the cluster-mean correlation. The impact of prior uncertainty in the cluster-mean correlation is considered by simulation. Some specific hybrid designs are proposed for consideration when the cluster-mean correlation cannot be reliably estimated, using a minimax principle to ensure acceptable performance across the whole range of unknown values.  2016 The Authors. Stat Med published by John Wiley \& Sons Ltd.},
  citeulike-article-id = {13907976},
  citeulike-attachment-1 = {gir16sta.pdf; /pdf/user/harrelfe/article/13907976/1096091/gir16sta.pdf; a8b3b2d6c12bdb01bc691786513661e540963e27},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6850},
  day = {15},
  posted-at = {2016-12-29 16:01:19},
  priority = {2},
  keywords = {cluster-randomization,stepped-wedge}
}

@article{giu11spe,
  title = {Spending Degrees of Freedom in a Poor Economy: {{A}} Case Study of Building a Sightability Model for Moose in Northeastern Minnesota},
  author = {Giudice, John H. and Fieberg, John R. and Lenarz, Mark S.},
  date = {2011},
  journaltitle = {J Wildlife Manage},
  doi = {10.1002/jwmg.213},
  url = {http://dx.doi.org/10.1002/jwmg.213},
  abstract = {Sightability models are binary logistic-regression models used to estimate and adjust for visibility bias in wildlife-population surveys. Like many models in wildlife and ecology, sightability models are typically developed from small observational datasets with many candidate predictors. Aggressive model-selection methods are often employed to choose a best model for prediction and effect estimation, despite evidence that such methods can lead to overfitting (i.e., selected models may describe random error or noise rather than true predictor–response curves) and poor predictive ability. We used moose (Alces alces) sightability data from northeastern Minnesota (2005–2007) as a case study to illustrate an alternative approach, which we refer to as degrees-of-freedom (df) spending: sample-size guidelines are used to determine an acceptable level of model complexity and then a pre-specified model is fit to the data and used for inference. For comparison, we also constructed sightability models using Akaike's Information Criterion (AIC) step-down procedures and model averaging (based on a small set of models developed using df-spending guidelines). We used bootstrap procedures to mimic the process of model fitting and prediction, and to compute an index of overfitting, expected predictive accuracy, and model-selection uncertainty. The index of overfitting increased 13\% when the number of candidate predictors was increased from three to eight and a best model was selected using step-down procedures. Likewise, model-selection uncertainty increased when the number of candidate predictors increased. Model averaging (based on R\,=\,30 models with 1–3 predictors) effectively shrunk regression coefficients toward zero and produced similar estimates of precision to our 3-df pre-specified model. As such, model averaging may help to guard against overfitting when too many predictors are considered (relative to available sample size). The set of candidate models will influence the extent to which coefficients are shrunk toward zero, which has implications for how one might apply model averaging to problems traditionally approached using variable-selection methods. We often recommend the df-spending approach in our consulting work because it is easy to implement and it naturally forces investigators to think carefully about their models and predictors. Nonetheless, similar concepts should apply whether one is fitting 1 model or using multi-model inference. For example, model-building decisions should consider the effective sample size, and potential predictors should be screened (without looking at their relationship to the response) for missing data, narrow distributions, collinearity, potentially overly influential observations, and measurement errors (e.g., via logical error checks).},
  citeulike-article-id = {13265898},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/jwmg.213},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {aerial-survey,alces-alces,degrees-of-freedom-spending,logistic-regression,minnesota,model-averaging,model-selection,moose,rms,shrinkage,sightability,visibility-bias}
}

@article{giv97pub,
  title = {Publication Bias in Meta-Analysis: {{A Bayesian}} Data-Augmentation Approach to Account for Issues Exemplified in the Passive Smoking Debate (with Discussion)},
  author = {Givens, Geof H. and Smith, D. D. and Tweedie, R. L.},
  date = {1997},
  journaltitle = {Stat Sci},
  volume = {12},
  pages = {221--250},
  citeulike-article-id = {13264137},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {bayesian-inference,data-augmentation,meta-analysis,publication-bias}
}

@inproceedings{gje77pro,
  title = {Producing {{Kolmogorov-Smirnov}} Type Statistics and Plotting Empirical Distributions on a Line Plotter within {{SAS}}},
  booktitle = {Proceedings of the {{Second Annual Conference}} of the {{SAS User}}'s {{Group International}}},
  author = {Gjertsen, W. R. and Harrell, F. E.},
  date = {1977},
  pages = {37--43},
  location = {{Raleigh NC}},
  citeulike-article-id = {13264138},
  organization = {SAS Institute},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{gla10cri,
  title = {A {{Critique}} of the {{Hypothesis}}, and a {{Defense}} of the {{Question}}, as a {{Framework}} for {{Experimentation}}},
  author = {Glass, D. J.},
  date = {2010-05},
  journaltitle = {Clin Chem},
  volume = {56},
  number = {7},
  eprint = {20511448},
  eprinttype = {pmid},
  pages = {1080--1085},
  publisher = {American Association for Clinical Chemistry},
  issn = {0009-9147},
  doi = {10.1373/clinchem.2010.144477},
  url = {http://dx.doi.org/10.1373/clinchem.2010.144477},
  abstract = {Scientists are often steered by common convention, funding agencies, and journal guidelines into a hypothesis-driven experimental framework, despite Isaac Newton's dictum that hypotheses have no place in experimental science. Some may think that Newton's cautionary note, which was in keeping with an experimental approach espoused by Francis Bacon, is inapplicable to current experimental method since, in accord with the philosopher Karl Popper, modern-day hypotheses are framed to serve as instruments of falsification, as opposed to verification. But Popper's "critical rationalist" framework too is problematic. It has been accused of being: inconsistent on philosophical grounds; unworkable for modern "large science," such as systems biology; inconsistent with the actual goals of experimental science, which is verification and not falsification; and harmful to the process of discovery as a practical matter. A criticism of the hypothesis as a framework for experimentation is offered. Presented is an alternative framework-the query/model approach-which many scientists may discover is the framework they are actually using, despite being required to give lip service to the hypothesis.},
  citeulike-article-id = {11923481},
  citeulike-attachment-1 = {gla10cri.pdf; /pdf/user/harrelfe/article/11923481/1098423/gla10cri.pdf; bf702e04e5864aa981e681f97f9828037373be91},
  citeulike-linkout-0 = {http://dx.doi.org/10.1373/clinchem.2010.144477},
  citeulike-linkout-1 = {http://www.clinchem.org/content/56/7/1080.abstract},
  citeulike-linkout-2 = {http://www.clinchem.org/content/56/7/1080.full.pdf},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/20511448},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=20511448},
  day = {28},
  posted-at = {2017-01-19 01:20:33},
  priority = {4},
  keywords = {experimental-design,hypothesis-testing,study-design}
}

@book{gla14exp,
  title = {Experimental {{Design}} for {{Biologists}}},
  author = {Glass, David J.},
  date = {2014-08-06},
  edition = {2 edition},
  publisher = {{Cold Spring Harbor Laboratory Press}},
  location = {{Cold Spring Harbor, New York}},
  abstract = {The effective design and analysis of experiments in biology are critical to success, yet graduate students in biological and medical sciences typically receive very little formal training in these steps. With feedback from readers of the first edition, colleagues, and students taking the very popular experimental design courses taught by the author, this second edition of Experimental Design for Biologists retains the engaging writing style while organizing the book around the four elements of experimental design: the framework, the system, the experiment, and the model. The approach has been tested in the classroom, where the author has taught numerous graduate students, MD/PhD students, and postdoctoral fellows. The goal of every scientist is to discover something new and with the aid of Experimental Design for Biologists, this task is made a little easier.This handbook explains how to establish the framework for an experimental project, how to set up all of the components of an experimental system, design experiments within that system, determine and use the correct set of controls, and formulate models to test the veracity and resiliency of the data. This thoroughly updated edition of Experimental Design for Biologists is an essential source of theory and practical guidance for designing a research plan.},
  isbn = {978-1-62182-041-3},
  langid = {english},
  pagetotal = {294},
  keywords = {experimental-design}
}

@article{gla67,
  title = {Exponential Survival with Covariance},
  author = {Glasser, M.},
  date = {1967},
  journaltitle = {J Am Stat Assoc},
  volume = {62},
  pages = {561--568},
  citeulike-article-id = {13264139},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@book{gla90,
  title = {Primer of {{Applied Regression}} and {{Analysis}} of {{Variance}}},
  author = {Glantz, S. A. and Slinker, B. K.},
  date = {1990},
  publisher = {{McGraw-Hill}},
  location = {{New York}},
  citeulike-article-id = {13264140},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{gla90qua,
  title = {Quality Adjusted Survival Analysis},
  author = {Glasziou, P. P. and Simes, R. J. and Gelber, R. D.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {1259--1276},
  citeulike-article-id = {13264141},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {multiple-endpoints,qaly,qol,utilities}
}

@article{gla97des,
  title = {Design of a Cost-Effectiveness Study within a Randomized Trial: {{The LIPID Trial}} for {{Secondary Prevention}} of {{IHD}}},
  author = {Glasziou, Paul P. and Simes, R. John and Hall, Jane and Donaldson, Cam and {The Lipid Study Group}},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {464--476},
  citeulike-article-id = {13264142},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {analysis-of-cost,cost-effectiveness,economic-evaluation,qaly,qol,study-design}
}

@article{gla98qua,
  title = {Quality Adjusted Survival Analysis with Repeated Quality of Life Measures},
  author = {Glasziou, Paul P. and Cole, Bernard F. and Gelber, Richard D. and Hilden, Jorgen and Simes, R. John},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1215--1229},
  citeulike-article-id = {13264143},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {informative-censoring,q-twist,qaly,qol,quality-adjusted-survival-curve,repeated-measurements,serial-data}
}

@article{gle96mod,
  title = {Models for Estimating the Number of Unpublished Studies},
  author = {Gleser, Leon J. and Olkin, Ingram},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2493--2507},
  citeulike-article-id = {13264144},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {meta-analysis,publication-bias}
}

@article{glo12who,
  title = {Who {{Advises}} the {{Data Monitoring Committee}} ({{DMC}})? {{A Review}} of {{Regulatory Guidance}} for {{Sponsors}} on {{DMCs After}} 5 {{Years}} and {{Advice}} for {{DMC Members}}},
  author = {Glover, Josephine M. and Kay, Richard},
  date = {2012},
  journaltitle = {Drug Info J},
  volume = {46},
  number = {5},
  eprint = {http://dij.sagepub.com/content/46/5/525.full.pdf+html},
  pages = {525--531},
  doi = {10.1177/0092861512452123},
  url = {http://dij.sagepub.com/content/46/5/525.abstract},
  abstract = {Regulatory authorities in the US and EU recommend that pharmaceutical companies employ data monitoring committees (DMCs) to protect the safety of patients taking part in large randomized trials involving diseases with high morbidity or mortality and have provided guidance as to how such committees should be used. This article, whose authors have considerable experience in DMC membership, reviews the applicability of guidance to sponsors after 5 years and suggests that regulatory support for DMC members would be valuable. Advice is offered to members, often very experienced clinicians but inexperienced in pharmaceutical data review, as to how standard DMC data packages should be reviewed, which aspects of trial validity should be addressed, and how communication with the trial sponsor should be handled. It is suggested that DMCs could be supported by regulatory authorities in managing ethical and legal dilemmas to make DMC membership less exposed and more inviting.},
  citeulike-article-id = {13265940},
  citeulike-linkout-0 = {http://dx.doi.org/10.1177/0092861512452123},
  citeulike-linkout-1 = {http://dij.sagepub.com/content/46/5/525.abstract},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {dmc,dsmb,overview,report-components}
}

@article{gly94com,
  title = {Comparison of Alternative Regression Models for Paired Binary Data},
  author = {Glynn, Robert J. and Rosner, Bernard},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1023--1036},
  citeulike-article-id = {13264145},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {cluster-sampling,correlated-binary-responses,logistic-model-extensions}
}

@article{gne07str,
  title = {Strictly Proper Scoring Rules, Prediction, and Estimation},
  author = {Gneiting, Tilmann and Raftery, Adrian E.},
  date = {2007},
  journaltitle = {J Am Stat Assoc},
  volume = {102},
  pages = {359--378},
  citeulike-article-id = {13265560},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {accuracy,bayes-factor,brier-score,coherent,continuous-ranked-probability-score,cross-validation,entropy,kernel-score,loss-function,minimum-contrast-estimation,negative-definite-function,prediction,prediction-interval,predictive-distribution,proper-scoring-rule,quantile-forecast,skill-score,strictly-proper,utility-function},
  note = {wonderful review article except missing references from Scandanavian and German medical decision making literature}
}

@article{goe96ana,
  title = {Analysing Non-Compliance in Clinical Trials: {{Ethical}} Imperative or Mission Impossible?},
  author = {Goetghebeur, Els J. T. and Shapiro, Stanley H.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2813--2826},
  citeulike-article-id = {13264146},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {compliance,intention-to-treat,rct,study-design}
}

@article{gol09com,
  title = {Common Genetic Variation and Human Traits},
  author = {Goldstein, David B.},
  date = {2009},
  journaltitle = {NEJM},
  volume = {360},
  pages = {1696--1698},
  citeulike-article-id = {13265749},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  note = {posits an equation that can be used to estimate the number of SNPs that are required to explain a large amount of variation in phenotypes; in the case of explaining 0.8 of the variation in height the estimate is 93000 SNPs; the predicted effect size of the nᵗʰ SNP is k + a (-bn);see yan96com}
}

@article{gol17com,
  title = {A Comparison of Risk Prediction Methods Using Repeated Observations: An Application to Electronic Health Records for Hemodialysis},
  author = {Goldstein, Benjamin A. and Pomann, Gina M. and Winkelmayer, Wolfgang C. and Pencina, Michael J.},
  date = {2017},
  journaltitle = {Stat Med},
  issn = {02776715},
  doi = {10.1002/sim.7308},
  url = {http://dx.doi.org/10.1002/sim.7308},
  citeulike-article-id = {14349813},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7308},
  posted-at = {2017-05-03 14:25:38},
  priority = {2},
  keywords = {competing-risks,ehr,longitudinal-data,prediction,predictive-methods,serial-data}
}

@article{gol22est,
  title = {Estimating Design Operating Characteristics in {{Bayesian}} Adaptive Clinical Trials},
  author = {Golchi, Shirin},
  date = {2022},
  journaltitle = {Canadian Journal of Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1708-945X},
  doi = {10.1002/cjs.11699},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.11699},
  urldate = {2022-04-17},
  abstract = {Bayesian adaptive designs have gained popularity in all phases of clinical trials with numerous new developments in the past few decades. During the COVID-19 pandemic, the need to establish evidence for the effectiveness of vaccines, therapeutic treatments, and policies that could resolve or control the crisis emphasized the advantages offered by efficient and flexible clinical trial designs. In many COVID-19 clinical trials, because of the high level of uncertainty, Bayesian adaptive designs were considered advantageous. Designing Bayesian adaptive trials, however, requires extensive simulation studies that are generally considered challenging, particularly in time-sensitive settings such as a pandemic. In this article, we propose a set of methods for efficient estimation and uncertainty quantification for design operating characteristics of Bayesian adaptive trials. Specifically, we model the sampling distribution of Bayesian probability statements that are commonly used as the basis of decision making. To showcase the implementation and performance of the proposed approach, we use a clinical trial design with an ordinal disease-progression scale endpoint that was popular among COVID-19 trials. However, the proposed methodology may be applied generally in the clinical trial context where design operating characteristics cannot be obtained analytically.},
  langid = {english},
  keywords = {adaptive,bayes,experimental-design,optimal-design,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cjs.11699}
}

@article{gol82inc,
  title = {Incremental Value of the Exercise Test for Diagnosing the Presence or Absence of Coronary Artery Disease},
  author = {Goldman, L. and Cook, E. F. and Mitchell, N. and Flatley, M. and Sherman, H. and Rosati, R. A. and Harrell, F. and Lee, K. and Cohn, P. F.},
  date = {1982},
  journaltitle = {Circ},
  volume = {66},
  pages = {945--953},
  citeulike-article-id = {13264147},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {comparing-pre-test-and-post-test-probabilities}
}

@article{gol86mul,
  title = {Multilevel Mixed Linear Model Analyis Using Iterative Generalized Least Squares},
  author = {Goldstein, Harvey},
  date = {1986},
  journaltitle = {Biometrika},
  volume = {73},
  number = {1},
  pages = {43--56},
  citeulike-article-id = {13265958},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{gol89res,
  title = {Restricted Unbiased Iterative Generalized Least-Squares Estimation},
  author = {Goldstein, Harvey},
  date = {1989},
  journaltitle = {Biometrika},
  volume = {76},
  number = {3},
  pages = {622--623},
  citeulike-article-id = {13265959},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {reml},
  note = {derivation of REML}
}

@article{gol89sur,
  title = {Survival Analysis Software on {{MS}}/{{PC-DOS}} Computers},
  author = {Goldstein, R. and Anderson, J. and Ash, A. and Craig, B. and Harrington, D. and Pagano, M.},
  date = {1989},
  journaltitle = {J Appl Economet},
  volume = {4},
  pages = {393--414},
  citeulike-article-id = {13264148},
  posted-at = {2014-07-14 14:09:29},
  priority = {0}
}

@article{gol90res,
  title = {Research Training in Clinical Effectiveness: \{\vphantom\}{{Replacing}}\vphantom\{\} "in My Experience …'' with Rigorous Clinical Investigation},
  author = {Goldman, Lee and Cook, E. Francis and Orav, John and Epstein, Arnold M. and Komaroff, Anthony L. and Delbanco, Thomas L. and Mulley, Albert G. and Hiatt, Howard H.},
  date = {1990},
  journaltitle = {Clin Res},
  volume = {38},
  pages = {686--693},
  citeulike-article-id = {13264149},
  posted-at = {2014-07-14 14:09:29},
  priority = {0},
  keywords = {clinical-investigation,teaching-mds}
}

@article{gol91sta,
  title = {Statistical {{Computing}} Editor's Notes},
  author = {Goldstein, R.},
  date = {1991},
  journaltitle = {Am Statistician},
  volume = {45},
  pages = {304--305},
  citeulike-article-id = {13264150},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gol92,
  title = {{{EVENTCHARTS}}: {{Visualizing}} Survival and Other Timed-Events Data},
  author = {Goldman, A. I.},
  date = {1992},
  journaltitle = {Am Statistician},
  volume = {46},
  pages = {13--18},
  citeulike-article-id = {13264151},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gol92res,
  title = {Restricted Cubic Spline Functions},
  author = {Goldstein, Richard},
  date = {1992-11},
  journaltitle = {Stata Tech Bull},
  volume = {STB-10},
  pages = {29--32},
  citeulike-article-id = {13264152},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gol94com,
  title = {The Comparison of Models in Discrimination Cases},
  author = {Goldstein, Richard},
  date = {1994},
  journaltitle = {Jurimetrics J},
  volume = {34},
  pages = {215--234},
  citeulike-article-id = {13264153},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {comparing-non-nested-models}
}

@article{gol96lea,
  title = {League Tables and Their Limitations: {{Statistical}} Issues in Comparisons of Institutional Performance},
  author = {Goldstein, Harvey and Spiegelhalter, David J.},
  date = {1996},
  journaltitle = {J Roy Stat Soc A},
  volume = {159},
  pages = {385--443},
  citeulike-article-id = {13264154},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {bayesian-methods,hierarchical-models,multilevel-models,physician-profiling,ranking-outcomes-and-institutions,shrinkage}
}

@incollection{gol98sur,
  title = {Survival Analysis, Software},
  booktitle = {Encyclopedia of {{Biostatistics}}},
  author = {Goldstein, R. and Harrell, F. E.},
  date = {1998},
  volume = {6},
  pages = {4461--4466},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264155},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gom11mon,
  title = {Monitoring Binary Outcomes Using Risk-Adjusted Charts: A Comparative Study},
  author = {Gombay, Edit and Hussein, Abdulkadir A. and Steiner, Stefan H.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  number = {23},
  pages = {2815--2826},
  doi = {10.1002/sim.4305},
  url = {http://dx.doi.org/10.1002/sim.4305},
  abstract = {Monitoring binary outcomes when evaluating health care performance has recently become common. Classical statistical methodologies such as cumulative sum (CUSUM) charts have been refined and used for this purpose. For instance, the risk-adjusted CUSUM chart (RA-CUSUM) for monitoring binary outcomes was proposed for monitoring 30-day mortality following cardiac surgery. The RA-CUSUM inherits optimality properties of the original CUSUM charts in the sense of signaling early when there is change. However, although the RA-CUSUM is a powerful monitoring tool, it will always eventually signal a change with probability 1 even when there is no real change. In other words, the probability of a type I error for the RA-CUSUM is 1. It also turns out that, because of the skewed distribution of the run lengths of the RA-CUSUM, the median is often well below the mean, and as a consequence more than half of all its false alarms occur before the designed average run length. In addition, when the change to be detected occurs at a later time in the series of observations being monitored, the rate of false alarms increases, and the RA-CUSUM may not be appropriate. Therefore, if the price of false alarms is high, it is preferable to use methods that control the rate of false alarms. In this paper, we propose alternative sequential curtailed and risk-adjusted charts that control the type I error rate in the context of monitoring 30-day mortality following cardiac surgery. We explore the merits of each of these methodologies in terms of average run lengths as well as in terms of type I error probabilities, and we compare them to the RA-CUSUM chart. We illustrate the methodologies by using data on monitoring performance of seven surgeons from a medical center.},
  citeulike-article-id = {13265896},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4305},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {change-point,curtailed-sequential-tests,cusum,provider-profiling,quality-outcomes,risk-adjusted}
}

@article{gom19cop,
  title = {Copula Selection Models for Non-{{Gaussian}} Outcomes That Are Missing Not at Random},
  author = {Gomes, Manuel and Radice, Rosalba and Brenes, Jose Camarena and Marra, Giampiero},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {3},
  pages = {480--496},
  issn = {1097-0258},
  doi = {10.1002/sim.7988},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7988},
  urldate = {2019-01-05},
  abstract = {Missing not at random (MNAR) data pose key challenges for statistical inference because the substantive model of interest is typically not identifiable without imposing further (eg, distributional) assumptions. Selection models have been routinely used for handling MNAR by jointly modeling the outcome and selection variables and typically assuming that these follow a bivariate normal distribution. Recent studies have advocated parametric selection approaches, for example, estimated by multiple imputation and maximum likelihood, that are more robust to departures from the normality assumption compared with those assuming that nonresponse and outcome are jointly normally distributed. However, the proposed methods have been mostly restricted to a specific joint distribution (eg, bivariate t-distribution). This paper discusses a flexible copula-based selection approach (which accommodates a wide range of non-Gaussian outcome distributions and offers great flexibility in the choice of functional form specifications for both the outcome and selection equations) and proposes a flexible imputation procedure that generates plausible imputed values from the copula selection model. A simulation study characterizes the relative performance of the copula model compared with the most commonly used selection models for estimating average treatment effects with MNAR data. We illustrate the methods in the REFLUX study, which evaluates the effect of laparoscopic surgery on long-term quality of life in patients with reflux disease. We provide software code for implementing the proposed copula framework using the R package GJRM.},
  langid = {english},
  keywords = {copula,missing,multiple-endpoints}
}

@article{gon05con,
  title = {Concordance Probability and Discriminatory Power in Proportional Hazards Regression},
  author = {Gönen, Mithat and Heller, Glenn},
  date = {2005-12},
  journaltitle = {Biometrika},
  volume = {92},
  number = {4},
  pages = {965--970},
  publisher = {Oxford University Press},
  issn = {1464-3510},
  doi = {10.1093/biomet/92.4.965},
  url = {http://dx.doi.org/10.1093/biomet/92.4.965},
  abstract = {The concordance probability is used to evaluate the discriminatory power and the predictive accuracy of nonlinear statistical models. We derive an analytical expression for the concordance probability in the Cox proportional hazards model. The proposed estimator is a function of the regression parameters and the covariate distribution only and does not use the observed event and censoring times. For this reason it is asymptotically unbiased, unlike Harrell's c-index based on informative pairs. The asymptotic distribution of the concordance probability estimate is derived using U-statistic theory and the methodology is applied to a predictive model in lung cancer.},
  citeulike-article-id = {397157},
  citeulike-attachment-1 = {gon05con.pdf; /pdf/user/harrelfe/article/397157/1010498/gon05con.pdf; a1b7a8c1bf0ec257281d491edeb2f4d7ccb37c15},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/92.4.965},
  citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/92/4/965.abstract},
  citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/92/4/965.full.pdf},
  citeulike-linkout-3 = {http://biomet.oxfordjournals.org/cgi/content/abstract/92/4/965},
  citeulike-linkout-4 = {http://www.ingentaconnect.com/content/oup/biomet/2005/00000092/00000004/art00965},
  day = {01},
  posted-at = {2015-03-22 22:09:37},
  priority = {2},
  keywords = {accuracy,c-index,discrimination-measures,predictive-accuracy}
}

@article{gon12rp,
  title = {The {{R Package}} Bild for the {{Analysis}} of {{Binary Longitudinal Data}}},
  author = {Gonçalves, M. Helena and Cabral, M. Salomé and Azzalini, Adelchi},
  date = {2012-02},
  journaltitle = {J Stat Software},
  volume = {46},
  number = {9},
  pages = {1--17},
  url = {http://www.jstatsoft.org/v46/i09},
  citeulike-article-id = {13265935},
  citeulike-linkout-0 = {http://www.jstatsoft.org/v46/i09},
  day = {6},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {longitudinal-binary-data,multivariate,serial}
}

@article{gon86,
  title = {Cross-Validation, the Jackknife, and the Bootstrap: {{Excess}} Error Estimation in Forward Logistic Regression},
  author = {Gong, Gail},
  date = {1986},
  journaltitle = {J Am Stat Assoc},
  volume = {81},
  pages = {108--113},
  citeulike-article-id = {13264156},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gon90,
  title = {Censored Survival Data with Misclassified Covariates: {{A}} Case Study of Breast-Cancer Mortality},
  author = {{Gong} and Whittemore, A. S. and Grosser, S.},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {20--28},
  citeulike-article-id = {13264157},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model,testing-proportional-hazards}
}

@book{goo79,
  title = {Measures of {{Association}} for {{Cross-Classifications}}},
  author = {Goodman, L. A. and Kruskal, W. H.},
  date = {1979},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13264158},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{goo92com,
  title = {A Comment on Replication, {{P-values}} and Evidence},
  author = {Goodman, Steven N.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {875--879},
  citeulike-article-id = {13264159},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {bayesian-inference,problems-in-interpreting-p-value-as-an-observed-error-rate,replication-probability}
}

@article{goo93p,
  title = {P-Values, Hypothesis Tests, and Likelihood: {{Implications}} for Epidemiology of a Neglected Historical Debate},
  author = {Goodman, S. N.},
  date = {1993},
  journaltitle = {Am J Epi},
  volume = {137},
  pages = {485--496},
  citeulike-article-id = {13265742},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@article{goo94err,
  title = {Errors of Calculating Errors after Research Is Completed},
  author = {Goodman, S. and Berlin, J.},
  date = {1994},
  journaltitle = {Ann Int Med},
  volume = {121},
  pages = {200--206},
  citeulike-article-id = {13264160},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {post-hoc-power,power,study-design}
}

@article{goo94use,
  title = {The Use of Predicted Confidence Intervals When Planning Experiments and the Misuse of Power When Interpreting Results},
  author = {Goodman, S. N. and Berlin, J. A.},
  date = {1994},
  journaltitle = {Ann Int Med},
  volume = {121},
  pages = {200--206},
  citeulike-article-id = {13264161},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {confidence-intervals,misuse-of-power,teaching-mds}
}

@book{goo97lat,
  title = {The {{LᴬT}}{{{\textsubscript{E}}}}{{X Graphics Companion}}},
  author = {Goosens, Michel and Rahtz, Sabastian and Mittelbach, Frank},
  date = {1997},
  publisher = {{Addison Wesley}},
  location = {{Reading, MA}},
  citeulike-article-id = {13265260},
  posted-at = {2014-07-14 14:09:53},
  priority = {0}
}

@article{goo99est,
  title = {Estimation of Failure Probabilities in the Presence of Competing Risks: {{New}} Representations of Old Estimators},
  author = {Gooley, Ted A. and Leisenring, Wendy and Crowley, John and Storer, Barry E.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {695--706},
  citeulike-article-id = {13264162},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {competing-risks},
  note = {examples where there are problems with Kaplan-Meier estimator but where the cumulative incidence estimate is appropriate}
}

@article{goo99tow,
  title = {Toward {{Evidence-Based Medical Statistics}}. 1: {{The P Value Fallacy}}},
  author = {Goodman, Steven N.},
  date = {1999-06},
  journaltitle = {Ann Int Med},
  volume = {130},
  number = {12},
  pages = {995+},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-130-12-199906150-00008},
  url = {http://dx.doi.org/10.7326/0003-4819-130-12-199906150-00008},
  citeulike-article-id = {14434285},
  citeulike-linkout-0 = {http://dx.doi.org/10.7326/0003-4819-130-12-199906150-00008},
  day = {15},
  posted-at = {2017-09-19 15:46:02},
  priority = {0},
  keywords = {bayes,bayesian-inference,misinterpretation-of-p-values,p-values},
  note = {Nice language for what happens when scientists use NHST to justify strong statements in their conclusions and interpretation; p-value fallacy}
}

@article{gor01lar,
  title = {Large Upward Bias in Estimation of Locus-Specific Effects from Genomewide Scans},
  author = {Göring, Harald H. H. and Terwilliger, Joseph D. and Blangero, John},
  date = {2001},
  journaltitle = {Am J Hum Gen},
  volume = {69},
  pages = {1357--1369},
  citeulike-article-id = {13265259},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {genomics,multiple-comparisons,multiplicity,overfitting,pre-test},
  note = {"esimates of locus-specific effect size at genomewide LOD score peaks tend to be grossly inflated and can even be virtually independent of the true effect size, even for studies on large samples when the true effect size is small ... When the LOD score is maximized over the many pointwise tests being conducted throughout the genome, the locus-specific effect-size estimate is therefore maximized as well."}
}

@article{gor03cli,
  title = {Clinical Prediction Rule for 30-Day Mortality in {{Björk-Shiley}} Convexo-Concave Valve Replacement},
  author = {van Gorp, M. J. and Steyerberg, E. W. and Kallewaard, M. and var der Graaf, Y.},
  options = {useprefix=true},
  date = {2003},
  journaltitle = {J Clin Epi},
  volume = {56},
  pages = {1006--1012},
  citeulike-article-id = {13265355},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  note = {nice example of score chart;external validation using val.prob}
}

@article{gor15cer,
  title = {Cervical Disc Arthroplasty with {{PRESTIGE LP}} Disc versus Anterior Cervical Discectomy and Fusion: A Prospective, Multicenter Investigational Device Exemption Study},
  author = {Gornet, Matthew F. and Burkus, J. Kenneth and Shaffrey, Mark E. and Argires, Perry J. and Nian, Hui and Harrell, Frank E.},
  date = {2015-11},
  journaltitle = {J Neurosurg: Spine},
  volume = {23},
  number = {5},
  pages = {558--573},
  issn = {1547-5654},
  doi = {10.3171/2015.1.spine14589},
  url = {http://dx.doi.org/10.3171/2015.1.spine14589},
  citeulike-article-id = {14229683},
  citeulike-linkout-0 = {http://dx.doi.org/10.3171/2015.1.spine14589},
  posted-at = {2016-12-18 16:59:51},
  priority = {2},
  keywords = {device,epub-replace,medtronic}
}

@article{gor16cera,
  title = {Cervical {{Disc Arthroplasty}} with {{Prestige LP Disc Versus Anterior Cervical Discectomy}} and {{Fusion}}: {{Seven-Year Outcomes}}},
  shorttitle = {Cervical {{Disc Arthroplasty}} with {{Prestige LP Disc Versus Anterior Cervical Discectomy}} and {{Fusion}}},
  author = {Gornet, Matthew F. and Burkus, J. Kenneth and Shaffrey, Mark E. and Nian, Hui and Harrell, Frank E.},
  date = {2016},
  journaltitle = {Int J Spine Surg},
  volume = {10},
  eprint = {27441182},
  eprinttype = {pmid},
  pages = {24},
  issn = {2211-4599},
  doi = {10.14444/3024},
  abstract = {BACKGROUND: Cervical disc arthroplasty (CDA) has emerged as an alternative to anterior cervical discectomy and fusion (ACDF) for the treatment of cervical pathologies. Studies are on-going to assess the long term outcomes of CDA. This study assessed the safety and efficacy of the Prestige(®) LP Disc at 84-months follow up. METHODS: Prospective data from 280 CDA patients with single-level cervical disc disease with radiculopathy or myelopathy were compared with 265 historical control ACDF patients. Clinical and radiographic follow up was completed pre-operatively, intraoperatively, and at intervals up to 84 months. RESULTS: Follow-up rate was 75.9\% for CDA and 70.0\% for ACDF patients. Statistical improvements (p {$<$} 0.001) in Neck Disability Index (NDI), neck/arm pain, and SF-36 were achieved by 1.5 months in both groups and maintained through 84 months. At 84 months, 86.1\% of CDA versus 80.1\% of ACDF patients achieved NDI success, (≥15-point improvement over baseline). Mean NDI score improvements exceeded 30 points in both groups. SF-36 PCS/MCS mean improvements were 13.1±11.9/8.2±12.3 points for CDA and 10.7±11.8/8.3±13.6 points for ACDF. Neurological success was 92.8\% for CDA and 79.7\% for ACDF patients. The rate of Overall Success was 74.9\% for CDA and 63.2\% for ACDF. At 84 months, 17.5\% of CDA and 16.6\% of ACDF patients had a possibly implant- or implant-surgical procedure-related adverse event. Eighteen (6.4\%) CDA and 29 (10.9\%) ACDF patients had a second surgery at the index level. In CDA patients, mean angular motion at the target level was maintained at 24 (7.5°) and 84 (6.9°) months. Bridging bone was reported in 5.9\%/9.5\%/10.2\%/13.0\% of CDA patients at 24/36/60/84 months. Change in mean preoperative angulation of the adjacent segment above/below the index level was1.06±4.39/1.25±4.06 for CDA and (-0.23)±5.37/1.25±5.07 for ACDF patients. At 84 months, 90.9\% of CDA and 85.6\% of ACDF patients were satisfied with the results of their treatment. CONCLUSIONS: Prestige LP maintained significantly improved clinical outcomes and segmental motion; statistical superiority of CDA was concluded for overall success. This investigational device exemption study was sponsored by Medtronic Spinal and Biologics, Memphis, TN. Study approved by the Hughston Sports Medicine Center Institutional Review Board on January 7, 2005. Clinical trial registered at clinicaltrials.gov: NCT00667459. All participants signed an informed consent.},
  langid = {english},
  pmcid = {PMC4943164},
  keywords = {collaboration}
}

@article{gor17cer,
  title = {Cervical Disc Arthroplasty with the {{Prestige LP}} Disc versus Anterior Cervical Discectomy and Fusion, at 2 Levels: Results of a Prospective, Multicenter Randomized Controlled Clinical Trial at 24 Months},
  shorttitle = {Cervical Disc Arthroplasty with the {{Prestige LP}} Disc versus Anterior Cervical Discectomy and Fusion, at 2 Levels},
  author = {Gornet, Matthew F. and Lanman, Todd H. and Burkus, J. Kenneth and Hodges, Scott D. and McConnell, Jeffrey R. and Dryer, Randall F. and Copay, Anne G. and Nian, Hui and Harrell, Frank E.},
  date = {2017-06},
  journaltitle = {J Neurosurg Spine},
  volume = {26},
  number = {6},
  eprint = {28304237},
  eprinttype = {pmid},
  pages = {653--667},
  issn = {1547-5646},
  doi = {10.3171/2016.10.SPINE16264},
  abstract = {OBJECTIVE The authors compared the efficacy and safety of arthroplasty using the Prestige LP cervical disc with those of anterior cervical discectomy and fusion (ACDF) for the treatment of degenerative disc disease (DDD) at 2 adjacent levels. METHODS Patients from 30 investigational sites were randomized to 1 of 2 groups: investigational patients (209) underwent arthroplasty using a Prestige LP artificial disc, and control patients (188) underwent ACDF with a cortical ring allograft and anterior cervical plate. Patients were evaluated preoperatively, intraoperatively, and at 1.5, 3, 6, 12, and 24 months postoperatively. Efficacy and safety outcomes were measured according to the Neck Disability Index (NDI), Numeric Rating Scales for neck and arm pain, 36-Item Short-Form Health Survey (SF-36), gait abnormality, disc height, range of motion (investigational) or fusion (control), adverse events (AEs), additional surgeries, and neurological status. Treatment was considered an overall success when all 4 of the following criteria were met: 1) NDI score improvement of ≥ 15 points over the preoperative score, 2) maintenance or improvement in neurological status compared with preoperatively, 3) no serious AE caused by the implant or by the implant and surgical procedure, and 4) no additional surgery (supplemental fixation, revision, or nonelective implant removal). Independent statisticians performed Bayesian statistical analyses. RESULTS The 24-month rates of overall success were 81.4\% for the investigational group and 69.4\% for the control group. The posterior mean for overall success in the investigational group exceeded that in the control group by 0.112 (95\% highest posterior density interval = 0.023 to 0.201) with a posterior probability of 1 for noninferiority and 0.993 for superiority, demonstrating the superiority of the investigational group for overall success. Noninferiority of the investigational group was demonstrated for all individual components of overall success and individual effectiveness end points, except for the SF-36 Mental Component Summary. The investigational group was superior to the control group for NDI success. The proportion of patients experiencing any AE was 93.3\% (195/209) in the investigational group and 92.0\% (173/188) in the control group, which were not statistically different. The rate of patients who reported any serious AE (Grade 3 or 4) was significantly higher in the control group (90 [47.9\%] of 188) than in the investigational group (72 [34.4\%] of 209) with a posterior probability of superiority of 0.996. Radiographic success was achieved in 51.0\% (100/196) of the investigational patients (maintenance of motion without evidence of bridging bone) and 82.1\% (119/145) of the control patients (fusion). At 24 months, heterotopic ossification was identified in 27.8\% (55/198) of the superior levels and 36.4\% (72/198) of the inferior levels of investigational patients. CONCLUSIONS Arthroplasty with the Prestige LP cervical disc is as effective and safe as ACDF for the treatment of cervical DDD at 2 contiguous levels and is an alternative treatment for intractable radiculopathy or myelopathy at 2 adjacent levels. Clinical trial registration no.: NCT00637156 ( clinicaltrials.gov ).},
  langid = {english},
  keywords = {consulting}
}

@article{gor20cla,
  title = {A Class of Generalized Linear Mixed Models Adjusted for Marginal Interpretability},
  author = {Gory, Jeffrey J. and Craigmile, Peter F. and MacEachern, Steven N.},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8782},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8782},
  urldate = {2020-10-23},
  abstract = {Two popular approaches for relating correlated measurements of a non-Gaussian response variable to a set of predictors are to fit a marginal model using generalized estimating equations and to fit a generalized linear mixed model (GLMM) by introducing latent random variables. The first approach is effective for parameter estimation, but leaves one without a formal model for the data with which to assess quality of fit or make individual-level predictions for future observations. The second approach overcomes these deficiencies, but leads to parameter estimates that must be interpreted conditional on the latent variables. To obtain marginal summaries, one needs to evaluate an analytically intractable integral or use attenuation factors as an approximation. Further, we note an unpalatable implication of the standard GLMM. To resolve these issues, we turn to a class of marginally interpretable GLMMs that lead to parameter estimates with a marginal interpretation while maintaining the desirable statistical properties of a conditionally specified model and avoiding problematic implications. We establish the form of these models under the most commonly used link functions and address computational issues. For logistic mixed effects models, we introduce an accurate and efficient method for evaluating the logistic-normal integral.},
  langid = {english},
  keywords = {glm,longitudinal,marginal-model,mixed-effects,random-effects,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8782}
}

@article{gor84reg,
  title = {Regression Models and Non-Proportional Hazards in the Analysis of Breast Cancer Survival},
  author = {Gore, Sheila M. and Pocock, Stuart J. and Kerr, Gillian R.},
  date = {1984},
  journaltitle = {Appl Stat},
  volume = {33},
  pages = {176--195},
  citeulike-article-id = {13264163},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {assessing-proportional-hazards,graphical-methods,parametric-survival-models}
}

@article{gor96myt,
  title = {The Myth of Continuity-Corrected Sample Size Formulae},
  author = {Gordon, Ian and Watson, Ray},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {71--76},
  citeulike-article-id = {13264164},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {power,sample-size}
}

@article{got06spe,
  title = {Speech before 2006 {{Conference}} on {{Adaptive Design}}},
  author = {Gottlieb, Scott},
  date = {2006-07},
  url = {http://www.fda.gov/oc/speeches/2006/trialdesign0710.html},
  citeulike-article-id = {13265476},
  citeulike-linkout-0 = {http://www.fda.gov/oc/speeches/2006/trialdesign0710.html},
  posted-at = {2014-07-14 14:09:57},
  priority = {0}
}

@article{got96bli,
  title = {Blinding during Data Analysis and Writing of Manuscripts},
  author = {Gmboxøtzsche, Peter C.},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {285--293},
  citeulike-article-id = {13264165},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {blinding,ethics,statistical-collaboration,study-design,writing},
  note = {approval of manuscript before breaking blind;writing two manuscripts in advance}
}

@article{gou14bay,
  title = {Bayesian Adaptive Determination of the Sample Size Required to Assure Acceptably Low Adverse Event Risk},
  author = {Lawrence Gould, A. and Zhang, Xiaohua D.},
  date = {2014-03},
  journaltitle = {Stat Med},
  volume = {33},
  number = {6},
  pages = {940--957},
  doi = {10.1002/sim.5993},
  url = {http://dx.doi.org/10.1002/sim.5993},
  abstract = {An emerging concern with new therapeutic agents, especially treatments for type 2 diabetes, a prevalent condition that increases an individual's risk of heart attack or stroke, is the likelihood of adverse events, especially cardiovascular events, that the new agents may cause. These concerns have led to regulatory requirements for demonstrating that a new agent increases the risk of an adverse event relative to a control by no more than, say, 30\% or 80\% with high (e.g., 97.5\%) confidence. We describe a Bayesian adaptive procedure for determining if the sample size for a development program needs to be increased and, if necessary, by how much, to provide the required assurance of limited risk. The decision is based on the predictive likelihood of a sufficiently high posterior probability that the relative risk is no more than a specified bound. Allowance can be made for between-center as well as within-center variability to accommodate large-scale developmental programs, and design alternatives (e.g., many small centers, few large centers) for obtaining additional data if needed can be explored. Binomial or Poisson likelihoods can be used, and center-level covariates can be accommodated. The predictive likelihoods are explored under various conditions to assess the statistical properties of the method.},
  citeulike-article-id = {13448164},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5993},
  day = {15},
  posted-at = {2014-11-29 16:36:41},
  priority = {2},
  keywords = {adaptive-design,adverse-events,bayesian-inference,clinical-safety,pharmaceutical-safety,sample-size}
}

@article{gou93con,
  title = {Confidence Intervals in Logit and Probit Models},
  author = {Gould, William},
  date = {1993-07},
  journaltitle = {Stata Tech Bull},
  volume = {STB-14},
  pages = {26--28},
  url = {http://www.stata.com/products/stb/journals/stb14.pdf},
  citeulike-article-id = {13264166},
  citeulike-linkout-0 = {http://www.stata.com/products/stb/journals/stb14.pdf},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {logistic-model,maximum-likelihood,wald-test},
  annotation = {http://www.stata.com/products/stb/journals/stb14.pdf},
  note = {invalidity of using the t distribution for logistic model tests}
}

@article{gou98mod,
  title = {Modifying the Design of Ongoing Trials without Unblinding},
  author = {Gould, A. Lawrence and Shih, W. Joseph},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {89--100},
  citeulike-article-id = {13264167},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {changing-sample-size,modifying-study,study-design}
}

@article{gou98mul,
  title = {Multi-Centre Trial Analysis Revisited},
  author = {Gould, A. Lawrence},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1779--1797},
  doi = {10.1002/(SICI)1097-0258(19980815/30)17:15/16\%3C1779::AID-SIM979\%3E3.3.CO;2-Z},
  url = {http://dx.doi.org/10.1002/(SICI)1097-0258(19980815/30)17:15/16%3C1779::AID-SIM979%3E3.3.CO;2-Z},
  citeulike-article-id = {13264168},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/(SICI)1097-0258(19980815/30)17:15/16%3C1779::AID-SIM979%3E3.3.CO;2-Z},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {bivariate-density-graph,bugs,hierarchical-model,mcmc-diagnostics,meta-analysis,multi-center,multi-center-rct,random-effects,rct}
}

@article{gov07com,
  title = {Comparing Smoothing Techniques in {{Cox}} Models for Exposure-Response Relationships},
  author = {Govindarajulu, Usha S. and Spiegelman, Donna and Thurston, Sally W. and Ganguli, Bhaswati and Eisen, Ellen A.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3735--3752},
  citeulike-article-id = {13265616},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {bootstrapping,dose-response,environmental-epidemiology,fractional-polynomial,natural-spline,penalized-spline,restricted-cubic-spline,sas,smoothing},
  note = {authors wrote a SAS macro for restricted cubic splines even though such a macro as existed since 1984; would have gotten more useful results had simulation been used so would know the true regression shape;measure of agreement of two estimated curves by computing the area between them, standardized by average of areas under the two;penalized spline and rcs were closer to each other than to fractional polynomials}
}

@article{gov11fai,
  title = {Frailty Models: {{Applications}} to Biomedical and Genetic Studies},
  author = {Govindarajulu, Usha S. and Lin, Haiqun and Lunetta, Kathryn L. and D'Agostino, R. B.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  number = {22},
  pages = {2754--2764},
  doi = {10.1002/sim.4277},
  url = {http://dx.doi.org/10.1002/sim.4277},
  abstract = {In survival analysis, frailty models are potential choices for modeling unexplained heterogeneity in a population. This tutorial presents an overview and general framework of frailty modeling and estimation for multiplicative hazards models in the context of biomedical and genetic studies. Other topics in frailty models, such as diagnostic methods for model adequacy and inference in frailty models, are also discussed. Examples of analyses using multivariate frailty models in a non-parametric hazards setting on biomedical datasets are provided, and the implications of choosing to use frailty and relevance to genetic applications are discussed.},
  citeulike-article-id = {13265902},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4277},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {correlated,cox-model,frailty,genetic,tutorial}
}

@article{gov18int,
  title = {Integrated Prediction and Decision Models Are Valuable in Informing Personalized Decision Making},
  author = {Govers, Tim M. and Rovers, Maroeska M. and Brands, Marieke T. and Dronkers, Emilie A. C. and de Jong, Robert J. Baatenburg and Merkx, Matthias A. W. and Takes, Robert P. and Grutters, Janneke P. C.},
  date = {2018-08-28},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  eprint = {30170106, 30170106},
  eprinttype = {pmid},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2018.08.016},
  url = {https://www.jclinepi.com/article/S0895-4356(18)30447-5/abstract},
  urldate = {2018-09-01},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To show how prediction models can be incorporated in decision models, to allow for personalized decisions; and to assess the value of this approach using the management of the neck in early stage oral cavity squamous cell carcinoma (OCSCC) as an example.{$<$}/p{$><$}h3{$>$}Study design and setting{$<$}/h3{$><$}p{$>$}In a decision model, three approaches were compared: a 'population-based' approach in which patients undergo the strategy that is optimal for the population; a ‘perfectly predicted' approach, in which each patient receives the optimal strategy for that specific patient; and a 'prediction model' approach in which each patient receives the strategy that is optimal based on prediction models. The average differences in costs and Quality Adjusted Life Years (QALYs) for the population between these approaches were studied.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}The population-based approach resulted on average in 4.9158 QALYs with €8,675 in costs, per patient. The perfectly predicted approach yielded 0.21 more QALYs and saved €1,024 per patient. The prediction model approach yielded 0.0014 more QALYs and saved €152 per patient compared with the population-based approach.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}The perfectly predicted approach shows that personalized care is worthwhile. However, current prediction models in the field of OCSCC have limited value. Incorporating prediction models in decision models appears to be a valuable method to assess the value of personalized decision making.{$<$}/p{$>$}},
  langid = {english},
  keywords = {decision-support-techniques,decision-theory}
}

@article{goy05gam,
  title = {Gamma Knife Surgery for the Treatment of Intracranial Metastases from Breast Cancer},
  author = {Goyal, S. and Prasad, D. and Harrell, F. E. and Matsumoto, J. and Rich, T. and Steiner, L.},
  date = {2005},
  journaltitle = {J Neurosurg},
  volume = {103},
  number = {2},
  pages = {218--23},
  url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks&dbfrom=pubmed&retmode=ref&id=16175849},
  citeulike-article-id = {13265466},
  citeulike-linkout-0 = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks&#38;dbfrom=pubmed&#38;retmode=ref&#38;id=16175849},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {collaboration}
}

@article{gra03com,
  title = {Communicating Risk --- Coronary Risk Scores},
  author = {Graham, Ian M. and Clavel, Elizabeth},
  date = {2003},
  journaltitle = {J Roy Stat Soc A},
  volume = {166},
  pages = {217--223},
  citeulike-article-id = {13265342},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {cardiovascular-risk-predictions,graphics,health-risk-appraisal,presentation-modes,risk-factors}
}

@article{gra07how,
  title = {How Many Imputations Are Really Needed? {{Some}} Practical Clarifications of Multiple Imputation Theory},
  author = {Graham, J. W. and Olchowski, A. E. and Gilreath, T. D.},
  date = {2007},
  journaltitle = {Prev Sci},
  volume = {8},
  pages = {206--213},
  abstract = {Multiple imputation (MI) and full information maximum likelihood (FIML) are the two most common approaches to missing data analysis. In theory, MI and FIML are equivalent when identical models are tested using the same variables, and when m, the number of imputations performed with MI, approaches infinity. However, it is important to know how many imputations are necessary before MI and FIML are sufficiently equivalent in ways that are important to prevention scientists. MI theory suggests that small values of m, even on the order of three to five imputations, yield excellent results. Previous guidelines for sufficient m are based on relative efficiency, which involves the fraction of missing information (gamma) for the parameter being estimated, and m. In the present study, we used a Monte Carlo simulation to test MI models across several scenarios in which gamma and m were varied. Standard errors and p-values for the regression coefficient of interest varied as a function of m, but not at the same rate as relative efficiency. Most importantly, statistical power for small effect sizes diminished as m became smaller, and the rate of this power falloff was much greater than predicted by changes in relative efficiency. Based our findings, we recommend that researchers using MI should perform many more imputations than previously considered sufficient. These recommendations are based on gamma, and take into consideration one's tolerance for a preventable power falloff (compared to FIML) due to using too few imputations.},
  citeulike-article-id = {13265633},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {missing-data,multiple-imputation}
}

@article{gra19acc,
  title = {Accounting for a Decaying Correlation Structure in Cluster Randomized Trials with Continuous Recruitment},
  author = {Grantham, Kelsey L. and Kasza, Jessica and Heritier, Stephane and Hemming, Karla and Forbes, Andrew B.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {11},
  pages = {1918--1934},
  issn = {1097-0258},
  doi = {10.1002/sim.8089},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8089},
  urldate = {2019-04-06},
  abstract = {A requirement for calculating sample sizes for cluster randomized trials (CRTs) conducted over multiple periods of time is the specification of a form for the correlation between outcomes of subjects within the same cluster, encoded via the within-cluster correlation structure. Previously proposed within-cluster correlation structures have made strong assumptions; for example, the usual assumption is that correlations between the outcomes of all pairs of subjects are identical (“uniform correlation”). More recently, structures that allow for a decay in correlation between pairs of outcomes measured in different periods have been suggested. However, these structures are overly simple in settings with continuous recruitment and measurement. We propose a more realistic “continuous-time correlation decay” structure whereby correlations between subjects' outcomes decay as the time between these subjects' measurement times increases. We investigate the use of this structure on trial planning in the context of a primary care diabetes trial, where there is evidence of decaying correlation between pairs of patients' outcomes over time. In particular, for a range of different trial designs, we derive the variance of the treatment effect estimator under continuous-time correlation decay and compare this to the variance obtained under uniform correlation. For stepped wedge and cluster randomized crossover designs, incorrectly assuming uniform correlation will underestimate the required sample size under most trial configurations likely to occur in practice. Planning of CRTs requires consideration of the most appropriate within-cluster correlation structure to obtain a suitable sample size.},
  langid = {english},
  keywords = {cluster-randomization,cluster-randomized-trial,study-design}
}

@article{gra19avo,
  title = {Avoiding Pitfalls When Combining Multiple Imputation and Propensity Scores},
  author = {Granger, Emily and Sergeant, Jamie C. and Lunt, Mark},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {26},
  pages = {5120--5132},
  issn = {1097-0258},
  doi = {10.1002/sim.8355},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8355},
  urldate = {2019-10-21},
  abstract = {Overcoming bias due to confounding and missing data is challenging when analyzing observational data. Propensity scores are commonly used to account for the first problem and multiple imputation for the latter. Unfortunately, it is not known how best to proceed when both techniques are required. We investigate whether two different approaches to combining propensity scores and multiple imputation (Across and Within) lead to differences in the accuracy or precision of exposure effect estimates. Both approaches start by imputing missing values multiple times. Propensity scores are then estimated for each resulting dataset. Using the Across approach, the mean propensity score across imputations for each subject is used in a single subsequent analysis. Alternatively, the Within approach uses propensity scores individually to obtain exposure effect estimates in each imputation, which are combined to produce an overall estimate. These approaches were compared in a series of Monte Carlo simulations and applied to data from the British Society for Rheumatology Biologics Register. Results indicated that the Within approach produced unbiased estimates with appropriate confidence intervals, whereas the Across approach produced biased results and unrealistic confidence intervals. Researchers are encouraged to implement the Within approach when conducting propensity score analyses with incomplete data.},
  langid = {english},
  keywords = {imputatation,missing,propensity}
}

@article{gra19how,
  title = {How Many Times Should a Cluster Randomized Crossover Trial Cross Over?},
  author = {Grantham, Kelsey L. and Kasza, Jessica and Heritier, Stephane and Hemming, Karla and Litton, Edward and Forbes, Andrew B.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8349},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8349},
  urldate = {2019-09-06},
  abstract = {Trial planning requires making efficient yet practical design choices. In a cluster randomized crossover trial, clusters of subjects cross back and forth between implementing the control and intervention conditions over the course of the trial, with each crossover marking the start of a new period. If it is possible to set up such a trial with more crossovers, a pertinent question is whether there are efficiency gains from clusters crossing over more frequently, and if these gains are substantial enough to justify the added complexity and cost of implementing more crossovers. We seek to determine the optimal number of crossovers for a fixed trial duration, and then identify other highly efficient designs by allowing the total number of clusters to vary and imposing thresholds on maximum cost and minimum statistical power. Our results pertain to trials with continuous recruitment and a continuous primary outcome, with the treatment effect estimated using a linear mixed model. To account for the similarity between subjects' outcomes within a cluster, we assume a correlation structure in which the correlation decays gradually in a continuous manner as the time between subjects' measurements increases. The optimal design is characterized by crossovers between the control and intervention conditions with each successive subject. However, this design is neither practical nor cost-efficient to implement, nor is it necessary: the gains in efficiency increase sharply in moving from a two-period to a four-period trial design, but approach an asymptote for the scenarios considered as the number of crossovers continues to increase.},
  langid = {english},
  keywords = {cluster-randomization,crossover,pragmatic-trial}
}

@article{gra21dex,
  title = {Dexamethasone 12~Mg versus 6~Mg for Patients with {{COVID-19}} and Severe Hypoxaemia: A Pre-Planned, Secondary {{Bayesian}} Analysis of the {{COVID STEROID}} 2 Trial},
  shorttitle = {Dexamethasone 12~Mg versus 6~Mg for Patients with {{COVID-19}} and Severe Hypoxaemia},
  author = {Granholm, Anders and Munch, Marie Warrer and Myatra, Sheila Nainan and Vijayaraghavan, Bharath Kumar Tirupakuzhi and Cronhjort, Maria and Wahlin, Rebecka Rubenson and Jakob, Stephan M. and Cioccari, Luca and Kjær, Maj-Brit Nørregaard and Vesterlund, Gitte Kingo and Meyhoff, Tine Sylvest and Helleberg, Marie and Møller, Morten Hylander and Benfield, Thomas and Venkatesh, Balasubramanian and Hammond, Naomi E. and Micallef, Sharon and Bassi, Abhinav and John, Oommen and Jha, Vivekanand and Kristiansen, Klaus Tjelle and Ulrik, Charlotte Suppli and Jørgensen, Vibeke Lind and Smitt, Margit and Bestle, Morten H. and Andreasen, Anne Sofie and Poulsen, Lone Musaeus and Rasmussen, Bodil Steen and Brøchner, Anne Craveiro and Strøm, Thomas and Møller, Anders and Khan, Mohd Saif and Padmanaban, Ajay and Divatia, Jigeeshu Vasishtha and Saseedharan, Sanjith and Borawake, Kapil and Kapadia, Farhad and Dixit, Subhal and Chawla, Rajesh and Shukla, Urvi and Amin, Pravin and Chew, Michelle S. and Wamberg, Christian Aage and Gluud, Christian and Lange, Theis and Perner, Anders},
  date = {2021-11-10},
  journaltitle = {Intensive Care Med},
  issn = {1432-1238},
  doi = {10.1007/s00134-021-06573-1},
  url = {https://doi.org/10.1007/s00134-021-06573-1},
  urldate = {2021-11-12},
  abstract = {We compared dexamethasone 12 versus 6~mg daily for up to 10~days in patients with coronavirus disease 2019 (COVID-19) and severe hypoxaemia in the international, randomised, blinded COVID STEROID 2 trial. In the primary, conventional analyses, the predefined statistical significance thresholds were not reached. We conducted a pre-planned Bayesian analysis to facilitate probabilistic interpretation.},
  langid = {english},
  keywords = {bayes,rct,teaching-mds}
}

@article{gra21mis,
  title = {Missing Data in Prediction Research: {{A}} Five Step Approach for Multiple Imputation, Illustrated in the {{CENTER-TBI}} Study},
  shorttitle = {Missing Data in Prediction Research},
  author = {Gravesteijn, Benjamin and Sewalt, Charlie and Venema, Esmee and Nieboer, Daan and Steyerberg, Ewout W},
  date = {2021-01-20},
  journaltitle = {Journal of Neurotrauma},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {0897-7151},
  doi = {10.1089/neu.2020.7218},
  url = {https://www.liebertpub.com/doi/abs/10.1089/neu.2020.7218},
  urldate = {2021-01-27},
  abstract = {In medical research, missing data is common. In acute diseases such as traumatic brain injury (TBI), even well conducted prospective studies may suffer from missing data in baseline characteristics and outcomes. Statistical models may simply drop patients with any missing values, potentially leaving a selected subset of the original cohort. Imputation is widely accepted by methodologists as an appropriate way to deal with missing data. We aim to provide practical guidance on handling missing data for prediction modelling. We hereto propose a five-step approach, centred around single and multiple imputation: 1) explore the missing data patterns; 2) choose a method of imputation; 3) perform imputation; 4) assess diagnostics of the imputation; and 5) analyse the imputed datasets. We illustrate these 5 steps with the estimation and validation of the IMPACT prognostic model in 1375 patients from the CENTER-TBI database, included in 53 centers across 17 countries, with moderate or severe TBI in the prospective European CENTER-TBI study. Future prediction modelling studies in acute diseases may benefit from following the suggested 5 steps for optimal statistical analysis and interpretation, after maximal effort have been made to minimize missing data.},
  keywords = {imputation,missing,prediction,teaching-mds}
}

@article{gra87,
  title = {Choice of Column Scores for Testing Independence in Ordered {{2xK}} Contingency Tables},
  author = {Graubard, B. I. and Korn, E. L.},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {471--476},
  citeulike-article-id = {13264169},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {distribution-free-methods}
}

@article{gra90,
  title = {Some Diagnostic Methods for {{Cox}} Regression Models through Hazard Smoothing},
  author = {Gray, R. J.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {93--102},
  citeulike-article-id = {13264170},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gra91,
  title = {The Effects of Transformations and Preliminary Tests for Non-Linearity in Regression},
  author = {Grambsch, P. M. and O'Brien, P. C.},
  date = {1991},
  journaltitle = {Stat Med},
  volume = {10},
  pages = {697--709},
  citeulike-article-id = {13264171},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gra92fle,
  title = {Flexible Methods for Analyzing Survival Data Using Splines, with Applications to Breast Cancer Prognosis},
  author = {Gray, Robert J.},
  date = {1992},
  journaltitle = {J Am Stat Assoc},
  volume = {87},
  pages = {942--951},
  citeulike-article-id = {13264172},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {penalized-maximum-likelihood,proportional-hazards,splines}
}

@article{gra94pro,
  title = {Proportional Hazards Tests and Diagnostics Based on Weighted Residuals},
  author = {Grambsch, P. and Therneau, T.},
  date = {1994},
  journaltitle = {Biometrika},
  volume = {81},
  pages = {515--526},
  citeulike-article-id = {13264173},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {assessment-of-ph,graphical-methods,smoothed-residual-plots,varying-coefficients-model},
  annotation = {Amendment and corrections in 82: 668 (1995)}
}

@article{gra94reg,
  title = {Regression Analysis with Clustered Data},
  author = {Graubard, Barry I. and Korn, Edward L.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {509--522},
  citeulike-article-id = {13264174},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {clustered-data,complex-sample-survey,robust-covariance-estimator,sandwich-estimator}
}

@article{gra94spl,
  title = {Spline-Based Tests in Survival Analysis},
  author = {Gray, Robert J.},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  pages = {640--652},
  citeulike-article-id = {13264175},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {assessment-of-ph,penalized-mle,sensitivity-to-number-of-knots,spline-test-for-ph,splines}
}

@article{gra95tes,
  title = {Tests for Variation over Groups in Survival Data},
  author = {Gray, Robert J.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {198--203},
  citeulike-article-id = {13264176},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {site-variation,study-design}
}

@article{gre00whe,
  title = {When Should Epidemiologic Regressions Use Random Coefficients?},
  author = {Greenland, Sander},
  date = {2000},
  journaltitle = {Biometrics},
  volume = {56},
  pages = {915--921},
  doi = {10.1111/j.0006-341X.2000.00915.x},
  url = {http://dx.doi.org/10.1111/j.0006-341X.2000.00915.x},
  citeulike-article-id = {13265446},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.0006-341X.2000.00915.x},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {bayesian-methods,causal-inference,empirical-bayes-estimators,epidemiologic-method,hierarchical-regression,mixed-models,multilevel-modeling,random-coefficient-regression,shrinkage,variance-components},
  note = {use of statistics in epidemiology is largely primitive;stepwise variable selection on confounders leaves important confounders uncontrolled;composition matrix;example with far too many significant predictors with many regression coefficients absurdly inflated when overfit;lack of evidence for dietary effects mediated through constituents;shrinkage instead of variable selection;larger effect on confidence interval width than on point estimates with variable selection;uncertainty about variance of random effects is just uncertainty about prior opinion;estimation of variance is pointless;instead the analysis should be repeated using different values;"if one feels compelled to estimate \$\textbackslash tau\^\{2\}\$, I would recommend giving it a proper prior concentrated amount contextually reasonable values";claim about ordinary MLE being unbiased is misleading because it assumes the model is correct and is the only model entertained;shrinkage towards compositional model;"models need to be complex to capture uncertainty about the relations...an honest uncertainty assessment requires parameters for all effects that we know may be present. This advice is implicit in an antiparsimony principle often attributed to L. J. Savage 'All models should be as big as an elephant (see Draper, 1995)'". See also gus06per.}
}

@article{gre16sta,
  title = {Statistical Tests, {{P}} Values, Confidence Intervals, and Power: A Guide to Misinterpretations},
  author = {Greenland, Sander and Senn, Stephen J. and Rothman, Kenneth J. and Carlin, John B. and Poole, Charles and Goodman, Steven N. and Altman, Douglas G.},
  date = {2016},
  journaltitle = {Eur J Epi},
  volume = {31},
  number = {4},
  pages = {337--350},
  doi = {10.1007/s10654-016-0149-3},
  url = {http://dx.doi.org/10.1007/s10654-016-0149-3},
  keywords = {general,misinterpretation-of-p-values,p-values},
  note = {Best article on misinterpretation of p-values. Pithy summaries.}
}

@article{gre19val,
  title = {Valid {{P-Values Behave Exactly}} as {{They Should}}: {{Some Misleading Criticisms}} of {{P-Values}} and {{Their Resolution With S-Values}}},
  shorttitle = {Valid {{P-Values Behave Exactly}} as {{They Should}}},
  author = {Greenland, Sander},
  date = {2019-03-29},
  journaltitle = {The American Statistician},
  volume = {73},
  pages = {106--114},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1529625},
  url = {https://doi.org/10.1080/00031305.2018.1529625},
  urldate = {2021-09-15},
  abstract = {The present note explores sources of misplaced criticisms of P-values, such as conflicting definitions of “significance levels” and “P-values” in authoritative sources, and the consequent misinterpretation of P-values as error probabilities. It then discusses several properties of P-values that have been presented as fatal flaws: That P-values exhibit extreme variation across samples (and thus are “unreliable”), confound effect size with sample size, are sensitive to sample size, and depend on investigator sampling intentions. These properties are often criticized from a likelihood or Bayesian framework, yet they are exactly the properties P-values should exhibit when they are constructed and interpreted correctly within their originating framework. Other common criticisms are that P-values force users to focus on irrelevant hypotheses and overstate evidence against those hypotheses. These problems are not however properties of P-values but are faults of researchers who focus on null hypotheses and overstate evidence based on misperceptions that p = 0.05 represents enough evidence to reject hypotheses. Those problems are easily seen without use of Bayesian concepts by translating the observed P-value p into the Shannon information (S-value or surprisal) –log2(p).},
  issue = {sup1},
  keywords = {hypothesis-testing,inference,p-value},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2018.1529625},
  note = {A P-value is not an error probability (except in a useless hypothetical sense)
\par
P-values are not calibrated to amount of evidence, but S-values are.
\par
Fisher uses "null hypothesis" for any tested hypothesis, which has caused a great deal of confusion.~ Neyman preferred the term the targeted or tested hypothesis.
\par
"The S-value reveals that no parameter value inside a 95\% confidence interval has more than 4.3 bits of information against it, supporting recommendations to view the interval interior as a region of hypotheses highly compatible with the data, rather than overconfidently viewing its exterior as a region ruled out by the data."}
}

@unpublished{gre21cau,
  title = {The Causal Foundations of Applied Probability and Statistics},
  author = {Greenland, Sander},
  date = {2021-08-19},
  eprint = {2011.02677},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2011.02677},
  urldate = {2022-01-10},
  abstract = {Statistical science (as opposed to mathematical statistics) involves far more than probability theory, for it requires realistic causal models of data generators - even for purely descriptive goals. Statistical decision theory requires more causality: Rational decisions are actions taken to minimize costs while maximizing benefits, and thus require explication of causes of loss and gain. Competent statistical practice thus integrates logic, context, and probability into scientific inference and decision using narratives filled with causality. This reality was seen and accounted for intuitively by the founders of modern statistics, but was not well recognized in the ensuing statistical theory (which focused instead on the causally inert properties of probability measures). Nonetheless, both statistical foundations and basic statistics can and should be taught using formal causal models. The causal view of statistical science fits within a broader information-processing framework which illuminates and unifies frequentist, Bayesian, and related probability-based foundations of statistics. Causality theory can thus be seen as a key component connecting computation to contextual information, not extra-statistical but instead essential for sound statistical training and applications.},
  archiveprefix = {arXiv},
  keywords = {causal-inference,causality,description},
  note = {Comment: 22 pages; in press for Dechter, R., Halpern, J., and Geffner, H., eds. Probabilistic and Causal Inference: The Works of Judea Pearl. ACM books}
}

@article{gre88cor,
  title = {Correspondence Analysis of Multivariate Categorical Data by Weighted Least-Squares},
  author = {Greenacre, Michael J.},
  date = {1988},
  journaltitle = {Biometrika},
  volume = {75},
  pages = {457--467},
  citeulike-article-id = {13264177},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {correspondence-analysis,data-reduction}
}

@article{gre89,
  title = {Modeling and Variable Selection in Epidemiologic Analysis},
  author = {{Greenland}},
  date = {1989},
  journaltitle = {Am J Pub Health},
  volume = {79},
  pages = {340--349},
  citeulike-article-id = {13264178},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {general,predictive-methods,variable-selection}
}

@book{gre93eco,
  title = {Econometric {{Analysis}}},
  author = {Greene, W. H.},
  date = {1993},
  edition = {Second},
  publisher = {{Macmillan}},
  location = {{New York}},
  citeulike-article-id = {13264179},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gre94alt,
  title = {Alternative Models for Ordinal Logistic Regression},
  author = {Greenland, Sander},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1665--1677},
  citeulike-article-id = {13264180},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {ordinal-data,ordinal-logistic-models}
}

@article{gre94eco,
  title = {Ecologic Studies---{{Biases}}, Misconceptions, and Counterexamples},
  author = {Greenland, Sander and Robins, James},
  date = {1994},
  journaltitle = {Am J Epi},
  volume = {139},
  pages = {747--760},
  citeulike-article-id = {13265534},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {ecologic-studies},
  note = {nonlinearities on individual-level data may destroy estimates from ecologic data and be undetectable;nice examples of failure of ecologic analyses to be correct}
}

@article{gre95cri,
  title = {A Critical Look at Methods for Handling Missing Covariates in Epidemiologic Regression Analyses},
  author = {Greenland, S. and Finkle, W. D.},
  date = {1995},
  journaltitle = {Am J Epi},
  volume = {142},
  pages = {1255--1264},
  citeulike-article-id = {13264181},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {missing-data,simulation-setup,taxonomy}
}

@article{gre95rob,
  title = {Robust {{Bayesian}} Methods for Monitoring Clinical Trials},
  author = {Greenhouse, Joel B. and Wasserman, Larry},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1379--1391},
  citeulike-article-id = {13264182},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {bayesian-methods,robustness-to-choice-of-prior,sequential-monitoring}
}

@article{gre95sou,
  title = {Sounding {{Board}}: {{Report}} Cards on Cardiac Surgeons --- {{Assessing New York State}}'s Approach},
  author = {Green, Jesse and Wintfeld, Neil},
  date = {1995},
  journaltitle = {NEJM},
  volume = {332},
  pages = {1229--1232},
  citeulike-article-id = {13264183},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {cabg,confounding,covariable-adjustment,explained-variation,mortality-model,risk-adjustment}
}

@article{gre96eff,
  title = {Effect Sizes and p Values: {{What}} Should Be Reported and What Should Be Replicated?},
  author = {Greenwald, Anthony G. and Gonzalez, Richard and Harris, Richard and Guthrie, Donald},
  date = {1996},
  journaltitle = {Psychophysiology},
  volume = {33},
  number = {2},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-8986.1996.tb02121.x},
  pages = {175--183},
  doi = {10.1111/j.1469-8986.1996.tb02121.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.1996.tb02121.x},
  abstract = {Abstract Despite publication of many well‐argued critiques of null hypothesis testing (NHT). behavioral science researchers continue to rely heavily on this set of practices. Although we agree with most critics' catalogs of NHT's flaws, this article also takes the unusual stance of identifying virtues that may explain why NHT continues to he so extensively used. These virtues include providing results in the form of a dichotomous (yes/no) hypothesis evaluation and providing an index (p value) Mini has a justifiable mapping onto confidence in repeatability of a null hypothesis rejection. The most‐criticized flaws of NHT can be avoided when the importance of a hypothesis, rather than the p value of its test, is used to determine that a finding is worthy of report, and when p=.05 is treated as insufficient basis for confidence in the replicability of an isolated non‐null finding. Together with many recent critics of NHT, we also urge reporting of important hypothesis tests in enough descriptive detail to permit secondary uses such as meta‐analysis.},
  citeulike-article-id = {14568988},
  citeulike-attachment-1 = {greenwald₉6ₑffect₁134175.pdf; /pdf/user/harrelfe/article/14568988/1134175/greenwald₉6ₑffect₁134175.pdf; 22dc40cf97b45bb78c4c22bcc8eb512201eb6776},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1469-8986.1996.tb02121.x},
  citeulike-linkout-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.1996.tb02121.x},
  posted-at = {2018-04-16 02:40:36},
  priority = {2},
  keywords = {hypothesis-testing,misinterpretation-of-p-values,p-values}
}

@article{gre96rev,
  title = {Review of {{Observational Studies}} by {{Paul Rosenbaum}}},
  author = {Greenland, Sander},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2629--2632},
  citeulike-article-id = {13264184},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {causal-analysis,observational-data},
  note = {need for sensitivity analysis of confidence limits;observational results can be ruined by measurement error;other sources of bias;P-values are poor measures of evidence;see also review by Rob Lyerla in TAS 50:379-380, 1996}
}

@book{gre97eco,
  title = {Econometric {{Analysis}}},
  author = {Greene, W. H.},
  date = {1997},
  edition = {Third},
  publisher = {{Prentice Hall}},
  location = {{New York}},
  citeulike-article-id = {13264185},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gre97sec,
  title = {Second-Stage Least Squares versus Penalized Quasi-Likelihood for Fitting Hierarchical Models in Epidemiologic Analyses},
  author = {Greenland, Sander},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {515--526},
  citeulike-article-id = {13264186},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {hierarchical-model,penalized-mle,two-stage-model}
}

@article{gri03abn,
  title = {Abnormal Heart Rate Characteristics Preceding Neonatal Sepsis and Sepsis-like Illness},
  author = {Griffin, M. P. and O'Shea, T. M. and Bissonette, E. A. and {Harrell} and Lake, D. E. and Moorman, J. R.},
  date = {2003},
  journaltitle = {Pediatr Res},
  volume = {53},
  pages = {920--926},
  citeulike-article-id = {13265352},
  posted-at = {2014-07-14 14:09:54},
  priority = {0}
}

@article{gri04abn,
  title = {Abnormal Heart Rate Characteristics Are Associated with Neonatal Mortality},
  author = {Griffin, M. Pamela and Oshea, T. Michael and Bissonette, Eric A. and Harrell, Frank E. and Lake, Douglas E. and Moorman, J. Randall},
  date = {2004},
  journaltitle = {Pediatr Res},
  volume = {55},
  pages = {782--788},
  citeulike-article-id = {13265368},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{gri05hea,
  title = {Heart Rate Characteristics: {{Novel}} Physiomarkers to Predict Neonatal Infection and Death},
  author = {Griffin, M. Pamela and Lake, Douglas E. and Bissonette, Eric A. and Harrell, Frank E. and O'Shea, T. Michael and Moorman, J. Randall},
  date = {2005},
  journaltitle = {Pediatrics},
  volume = {116},
  pages = {1070--1074},
  citeulike-article-id = {13265445},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {heart-rate-variability,hrv,infant,mortality-prediction,physiomarker,sepsis,urinary-tract-infection}
}

@article{gri15rol,
  title = {The Role of Matching When Adjusting for Baseline Differences in the Outcome Variable of Comparative Effectiveness Studies.},
  author = {Grijalva, Carlos G. and Roumie, Christianne L. and Murff, Harvey J. and Hung, Adriana M. and Beck, Cole and Liu, Xulei and Griffin, Marie R. and Greevy, Robert A.},
  date = {2015},
  journaltitle = {J Comp Effect Res},
  volume = {4},
  number = {4},
  eprint = {26274795},
  eprinttype = {pmid},
  pages = {341--349},
  issn = {2042-6313},
  doi = {10.2217/cer.15.16},
  url = {http://dx.doi.org/10.2217/cer.15.16},
  abstract = {Evaluate performance of analytical strategies commonly used to adjust for baseline differences in continuous outcome variables for comparative effectiveness studies. Data simulations resembling a comparison of HbA1c values after initiation of antidiabetic treatments adjusting for baseline HbA1c. We evaluated change scores, analyses of covariance including linear, nonlinear with/without robust variance estimations, before and after optimal matching. We also evaluated the impact of measurement error. With increasing HbA1c baseline differences between groups, bias in effect estimates and suboptimal CI coverage probabilities increased in all approaches. These issues were further compounded by measurement error. Matching on baseline HbA1c, substantially mitigated these issues. In comparative studies with continuous outcomes, matching on baseline values of the outcome variable improves analytical performance.},
  citeulike-article-id = {14033408},
  citeulike-linkout-0 = {http://dx.doi.org/10.2217/cer.15.16},
  citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4699664/},
  citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/26274795},
  citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=26274795},
  pmcid = {PMC4699664},
  posted-at = {2016-05-11 21:24:31},
  priority = {2},
  keywords = {ctsafac}
}

@article{gri85bay,
  title = {A {{Bayesian Analysis}} of the {{Two-Period Crossover Design}} for {{Clinical Trials}}},
  author = {Grieve, A. P.},
  date = {1985},
  journaltitle = {Biometrics},
  volume = {41},
  number = {4},
  pages = {979--990},
  issn = {0006-341X},
  doi = {10.2307/2530969},
  url = {www.jstor.org/stable/2530969},
  urldate = {2019-12-08},
  abstract = {Statisticians have been critical of the use of the two-period crossover designs for clinical trials because the estimate of the treatment difference is biased when the carryover effects of the two treatments are not equal. In the standard approach, if the null hypothesis of equal carryover effects is not rejected, data from both periods are used to estimate and test for treatment differences; if the null hypothesis is rejected, data from the first period alone are used. A Bayesian analysis based on the Bayes factor against unequal carryover effects is given. Although this Bayesian approach avoids the "all-or-nothing" decision inherent in the standard approach, it recognizes that with small trials it is difficult to provide unequivocal evidence that the carryover effects of the two treatments are equal, and thus that the interpretation of the difference between treatment effects is highly dependent on a subjective assessment of the reality or not of equal carryover effects.},
  keywords = {bayes,cross-over-trials,crossover,rct}
}

@article{gri95ext,
  title = {Extending a {{Bayesian Analysis}} of the {{Two-Period Crossover}} to {{Accommodate Missing Data}}},
  author = {Grieve, Andrew P.},
  date = {1995},
  journaltitle = {Biometrika},
  volume = {82},
  number = {2},
  pages = {277--286},
  issn = {0006-3444},
  doi = {10.2307/2337407},
  url = {www.jstor.org/stable/2337407},
  urldate = {2019-12-08},
  abstract = {A procedure is developed for performing a Bayesian analysis of a simple two-period crossover design when some observations are missing in one, or both, treatment periods. The approach requires the numerical evaluation of a single integral to be performed for each posterior marginal distribution of interest. The relative efficiency of this approach to one in which patients with missing data are excluded is investigated.},
  keywords = {bayes,cross-over-trials,crossover,missing,rct}
}

@article{gri98iss,
  title = {Issues for Statisticians in Pharmaco-Economic Evaluations},
  author = {Grieve, A. P.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1715--1723},
  citeulike-article-id = {13264187},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {analysis-of-cost,bayesian-inference,cost-effectiveness,study-design}
}

@article{gro07bay,
  title = {Bayesian Sample Size Determination in Non-Sequential Clinical Trials: {{Statistical}} Aspects and Some Regulatory Considerations},
  author = {Grouin, Jean-Marie and Coste, Maylis and Bunouf, Pierre and Lecoutre, Bruno},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4914--4924},
  citeulike-article-id = {13265637},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {bayesian-methods,credible-interval-for-sample-size,distribution-of-sample-sizes,rct,regulatory-viewpoint,sample-size}
}

@article{gro12dea,
  title = {Dealing {{With}} Missing Outcome Data in Randomized Trials and Observational Studies},
  author = {Groenwold, Rolf H. H. and {Donders} and Roes, Kit C. B. and Harrell, Frank E. and Moons, Karel G. M.},
  date = {2011},
  journaltitle = {Am J Epi},
  eprint = {http://aje.oxfordjournals.org/content/early/2011/12/23/aje.kwr302.full.pdf+html},
  doi = {10.1093/aje/kwr302},
  url = {http://aje.oxfordjournals.org/content/early/2011/12/23/aje.kwr302.abstract},
  abstract = {Although missing outcome data are an important problem in randomized trials and observational studies, methods to address this issue can be difficult to apply. Using simulated data, the authors compared 3 methods to handle missing outcome data: 1) complete case analysis; 2) single imputation; and 3) multiple imputation (all 3 with and without covariate adjustment). Simulated scenarios focused on continuous or dichotomous missing outcome data from randomized trials or observational studies. When outcomes were missing at random, single and multiple imputations yielded unbiased estimates after covariate adjustment. Estimates obtained by complete case analysis with covariate adjustment were unbiased as well, with coverage close to 95\%. When outcome data were missing not at random, all methods gave biased estimates, but handling missing outcome data by means of 1 of the 3 methods reduced bias compared with a complete case analysis without covariate adjustment. Complete case analysis with covariate adjustment and multiple imputation yield similar estimates in the event of missing outcome data, as long as the same predictors of missingness are included. Hence, complete case analysis with covariate adjustment can and should be used as the analysis of choice more often. Multiple imputation, in addition, can accommodate the missing-not-at-random scenario more flexibly, making it especially suited for sensitivity analyses.},
  citeulike-article-id = {13265918},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/aje/kwr302},
  citeulike-linkout-1 = {http://aje.oxfordjournals.org/content/early/2011/12/23/aje.kwr302.abstract},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@article{gro20mac,
  title = {Machine {{Learning}} for {{Work Disability Prevention}}: {{Introduction}} to the {{Special Series}}},
  shorttitle = {Machine {{Learning}} for {{Work Disability Prevention}}},
  author = {Gross, Douglas P. and Steenstra, Ivan A. and Harrell, Frank E. and Bellinger, Colin and Zaïane, Osmar},
  date = {2020-07-04},
  journaltitle = {J Occup Rehabil},
  issn = {1573-3688},
  doi = {10.1007/s10926-020-09910-1},
  url = {https://doi.org/10.1007/s10926-020-09910-1},
  urldate = {2020-07-05},
  abstract = {Rapid development in computer technology has led to sophisticated methods of analyzing large datasets with the aim of improving human decision making. Artificial Intelligence and Machine Learning (ML) approaches hold tremendous potential for solving complex real-world problems such as those faced by stakeholders attempting to prevent work disability. These techniques are especially appealing in work disability contexts that collect large amounts of data such as workers’ compensation settings, insurance companies, large corporations, and health care organizations, among others. However, the approaches require thorough evaluation to determine if they add value to traditional statistical approaches. In this special series of articles, we examine the role and value of ML in the field of work disability prevention and occupational rehabilitation.},
  langid = {english},
  keywords = {classification,machine-learning}
}

@article{gro20maca,
  title = {Machine {{Learning}} for {{Work Disability Prevention}}: {{Introduction}} to the {{Special Series}}},
  shorttitle = {Machine {{Learning}} for {{Work Disability Prevention}}},
  author = {Gross, Douglas P. and Steenstra, Ivan A. and Harrell, Frank E. and Bellinger, Colin and Zaïane, Osmar},
  date = {2020-09},
  journaltitle = {J Occup Rehabil},
  volume = {30},
  number = {3},
  eprint = {32623556},
  eprinttype = {pmid},
  pages = {303--307},
  issn = {1573-3688},
  doi = {10.1007/s10926-020-09910-1},
  abstract = {Rapid development in computer technology has led to sophisticated methods of analyzing large datasets with the aim of improving human decision making. Artificial Intelligence and Machine Learning (ML) approaches hold tremendous potential for solving complex real-world problems such as those faced by stakeholders attempting to prevent work disability. These techniques are especially appealing in work disability contexts that collect large amounts of data such as workers' compensation settings, insurance companies, large corporations, and health care organizations, among others. However, the approaches require thorough evaluation to determine if they add value to traditional statistical approaches. In this special series of articles, we examine the role and value of ML in the field of work disability prevention and occupational rehabilitation.},
  langid = {english},
  keywords = {machine-learning}
}

@book{gro75,
  title = {Survival {{Distributions}}: {{Reliability Applications}} in the {{Biomedical Sciences}}},
  author = {Gross, A. J. and Clark, V. A.},
  date = {1975},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264188},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{gro94uni,
  title = {A Unified Method for Monitoring and Analysing Controlled Trials},
  author = {Grossman, Jason and Parmar, Mahesh K. B. and Spiegelhalter, David J.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1815--1826},
  citeulike-article-id = {13264189},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {bayesian-methods,early-termination,sequential-testing,study-design}
}

@article{gro96non,
  title = {Nonparametric Estimation and Regression Analysis with Left-Truncated and Right-Censored Data},
  author = {Gross, Shilamith T. and Lai, Tze L.},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {1166--1180},
  citeulike-article-id = {13264190},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {clear-definition-of-left-truncation,left-truncation,nonparametric-survival-distribution-estimator}
}

@article{gu17com,
  title = {Combining Item Response Theory with Multiple Imputation to Equate Health Assessment Questionnaires},
  author = {Gu, Chenyang and Gutman, Roee},
  date = {2016-12},
  journaltitle = {Biometrics},
  issn = {0006341X},
  doi = {10.1111/biom.12638},
  url = {http://dx.doi.org/10.1111/biom.12638},
  citeulike-article-id = {14225793},
  citeulike-attachment-1 = {gu17com.pdf; /pdf/user/harrelfe/article/14225793/1094361/gu17com.pdf; f2bbc3eb08fe98e7326a9bfa49fe01188fdf2419},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/biom.12638},
  posted-at = {2016-12-10 14:44:45},
  priority = {2},
  keywords = {epub-replace,equating-scales,item-response-theory,missing-data,patient-reported-outcome}
}

@article{gue12ana,
  title = {The Analysis of Binary Longitudinal Data with Time-Dependent Covariates},
  author = {Guerra, Matthew W. and Shults, Justine and Amsterdam, Jay and Ten-Have, Thomas},
  date = {2012-05-10},
  journaltitle = {Stat Med},
  volume = {31},
  number = {10},
  eprint = {22246815},
  eprinttype = {pmid},
  pages = {931--948},
  issn = {1097-0258},
  doi = {10.1002/sim.4465},
  abstract = {We consider longitudinal studies with binary outcomes that are measured repeatedly on subjects over time. The goal of our analysis was to fit a logistic model that relates the expected value of the outcomes with explanatory variables that are measured on each subject. However, additional care must be taken to adjust for the association between the repeated measurements on each subject. We propose a new maximum likelihood method for covariates that may be fixed or time varying. We also implement and make comparisons with two other approaches: generalized estimating equations, which may be more robust to misspecification of the true correlation structure, and alternating logistic regression, which models association via odds ratios that are subject to less restrictive constraints than are correlations. The proposed estimation procedure will yield consistent and asymptotically normal estimates of the regression and correlation parameters if the correlation on consecutive measurements on a subject is correctly specified. Simulations demonstrate that our approach can yield improved efficiency in estimation of the regression parameter; for equally spaced and complete data, the gains in efficiency were greatest for the parameter associated with a time-by-group interaction term and for stronger values of the correlation. For unequally spaced data and with dropout according to a missing-at-random mechanism, MARK1ML with correctly specified consecutive correlations yielded substantial improvements in terms of both bias and efficiency. We present an analysis to demonstrate application of the methods we consider. We also offer an R function for easy implementation of our approach.},
  langid = {english},
  keywords = {binary-data,serial,tdc}
}

@article{gug00inv,
  title = {The (in)Validity of Sensitivity and Specificity},
  author = {Guggenmoos-Holzmann, Irene and van Houwelingen, Hans C.},
  options = {useprefix=true},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {1783--1792},
  url = {https://www.onlinelibrary.wiley.com/doi/abs/10.1002/1097-0258%2820000715%2919%3A13%3C1783%3A%3AAID-SIM497%3E3.0.CO%3B2-B},
  keywords = {diagnosis,sensitivity,specificity,teaching-mds,testing},
  note = {death of sensitivity and specificity}
}

@article{gui00ord,
  title = {Ordinal Response Regression Models in Ecology},
  author = {Guisan, Antoine and Harrell, Frank E.},
  date = {2000},
  journaltitle = {J Veg Sci},
  volume = {11},
  pages = {617--626},
  citeulike-article-id = {13265110},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {ordinal-logistic-model,teaching}
}

@article{guo11pri,
  title = {Principal Component Analysis with Sparse Fused Loadings},
  author = {Guo, Jian and James, Gareth and Levina, Elizaveta and Michailidis, George and Zhu, Ji},
  date = {2011},
  journaltitle = {J Comp Graph Stat},
  volume = {19},
  number = {4},
  pages = {930--946},
  citeulike-article-id = {13265886},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {multivariate,pc,sparse-principal-components},
  note = {incorporates blocking structure in the variables;selects different variables for different components;encourages loadings of highly correlated variables to have same magnitude, which aids in interpretation}
}

@article{guo15dep,
  title = {In-Depth Genomic Data Analyses Revealed Complex Transcriptional and Epigenetic Dysregulations of {{BRAFV600E}} in Melanoma.},
  author = {Guo, Xingyi and Xu, Yaomin and Zhao, Zhongming},
  date = {2015-03},
  journaltitle = {Molecular cancer},
  volume = {14},
  eprint = {25890285},
  eprinttype = {pmid},
  pages = {60+},
  issn = {1476-4598},
  doi = {10.1186/s12943-015-0328-y},
  url = {http://dx.doi.org/10.1186/s12943-015-0328-y},
  abstract = {The recurrent BRAF driver mutation V600E (BRAF (V600E)) is currently one of the most clinically relevant mutations in melanoma. However, the genome-wide transcriptional and epigenetic dysregulations induced by BRAF (V600E) are still unclear. The investigation of this driver mutation's functional consequences is critical to the understanding of tumorigenesis and the development of therapeutic strategies. We performed an integrative analysis of transcriptomic and epigenomic changes disturbed by BRAF (V600E) by comparing the gene expression and methylation profiles of 34 primary cutaneous melanoma tumors harboring BRAF (V600E) with those of 27 BRAF (WT) samples available from The Cancer Genome Atlas (TCGA). A total of 711 significantly differentially expressed genes were identified as putative BRAF (V600E) target genes. Functional enrichment analyses revealed the transcription factor MITF (p\,{$<$}\,3.6 × 10(-16)) and growth factor TGFB1 (p\,{$<$}\,3.1 × 10(-9)) were the most significantly enriched up-regulators, with MITF being significantly up-regulated, whereas TGFB1 was significantly down-regulated in BRAF (V600E), suggesting that they may mediate tumorigenesis driven by BRAF (V600E). Further investigation using the MITF ChIP-Seq data confirmed that BRAF (V600E) led to an overall increased level of gene expression for the MITF targets. Furthermore, DNA methylation analysis revealed a global DNA methylation loss in BRAF (V600E) relative to BRAF (WT). This might be due to BRAF dysregulation of DNMT3A, which was identified as a potential target with significant down-regulation in BRAF (V600E). Finally, we demonstrated that BRAF (V600E) targets may play essential functional roles in cell growth and proliferation, measured by their effects on melanoma tumor growth using a short hairpin RNA silencing experimental dataset. Our integrative analysis identified a set of BRAF (V600E) target genes. Further analyses suggested a complex mechanism driven by mutation BRAF (V600E) on melanoma tumorigenesis that disturbs specific cancer-related genes, pathways, and methylation modifications.},
  citeulike-article-id = {13549755},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/s12943-015-0328-y},
  citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4373107/},
  citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/25890285},
  citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=25890285},
  day = {14},
  pmcid = {PMC4373107},
  posted-at = {2016-05-11 21:22:09},
  priority = {2},
  keywords = {ctsafac}
}

@article{guo94reg,
  title = {Regression Analysis of Multivariate Grouped Survival Data},
  author = {Guo, S. W. and Lin, D. Y.},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  pages = {632--639},
  citeulike-article-id = {13264191},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {cluster-sampling}
}

@article{gur11avo,
  title = {Avoiding Bias in Mixed Model Inference for Fixed Effects},
  author = {Gurka, Matthew J. and Edwards, Lloyd J. and Muller, Keith E.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  number = {22},
  pages = {2696--2707},
  doi = {10.1002/sim.4293},
  url = {http://dx.doi.org/10.1002/sim.4293},
  abstract = {Analysis of a large longitudinal study of children motivated our work. The results illustrate how accurate inference for fixed effects in a general linear mixed model depends on the covariance model selected for the data. Simulation studies have revealed biased inference for the fixed effects with an underspecified covariance structure, at least in small samples. One underspecification common for longitudinal data assumes a simple random intercept and conditional independence of the within-subject errors (i.e., compound symmetry). We prove that the underspecification creates bias in both small and large samples, indicating that recruiting more participants will not alleviate inflation of the Type I error rate associated with fixed effect inference. Enumerations and simulations help quantify the bias and evaluate strategies for avoiding it. When practical, backwards selection of the covariance model, starting with an unstructured pattern, provides the best protection. Tutorial papers can guide the reader in minimizing the chances of falling into the often spurious software trap of nonconvergence. In some cases, the logic of the study design and the scientific context may support a structured pattern, such as an autoregressive structure. The sandwich estimator provides a valid alternative in sufficiently large samples. Authors reporting mixed-model analyses should note possible biases in fixed effects inference because of the following: (i) the covariance model selection process; (ii) the specific covariance model chosen; or (iii) the test approximation.},
  citeulike-article-id = {13265901},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4293},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {compound-symmetry,longitudinal-data,random-effects,type-i-error}
}

@article{gus00bay,
  title = {Bayesian Regression Modeling with Interactions and Smooth Effects},
  author = {Gustafson, Paul},
  date = {2000},
  journaltitle = {J Am Stat Assoc},
  volume = {95},
  pages = {795--806},
  citeulike-article-id = {13265143},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {interaction-surface,model-averaging,model-selection,penalization,tensor-spline}
}

@article{gus06per,
  title = {The Performance of Random Coefficient Regression in Accounting for Residual Confounding},
  author = {Gustafson, Paul and Greenland, Sander},
  date = {2006},
  journaltitle = {Biometrics},
  volume = {62},
  pages = {760--768},
  citeulike-article-id = {13265538},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {bayesian-analysis,bias,confounding,epidemiology,heirarchical-models,identifiability,mixed-models,nutritional-epidemiology,observational-studies,random-coefficient-regression,random-effects,random-slopes,residual-confounding}
}

@article{gus93int,
  title = {An International Randomized Trial Comparing Four Thrombolytic Strategies for Acute Myocardial Infarction},
  author = {Investigators, The G.},
  date = {1993},
  journaltitle = {NEJM},
  volume = {329},
  pages = {673--682},
  citeulike-article-id = {13264192},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {gusto,mega-trials,t-pa}
}

@article{gwo20net,
  title = {Network Meta-Regression for Ordinal Outcomes: {{Applications}} in Comparing {{Crohn}}'s Disease Treatments},
  shorttitle = {Network Meta-Regression for Ordinal Outcomes},
  author = {Gwon, Yeongjin and Mo, May and Chen, Ming-Hui and Chi, Zhiyi and Li, Juan and Xia, Amy H. and Ibrahim, Joseph G.},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8518},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8518},
  urldate = {2020-03-13},
  abstract = {Crohn's disease (CD) is a life-long condition associated with recurrent relapses characterized by abdominal pain, weight loss, anemia, and persistent diarrhea. In the US, there are approximately 780 000 CD patients and 33 000 new cases added each year. In this article, we propose a new network meta-regression approach for modeling ordinal outcomes in order to assess the efficacy of treatments for CD. Specifically, we develop regression models based on aggregate covariates for the underlying cut points of the ordinal outcomes as well as for the variances of the random effects to capture heterogeneity across trials. Our proposed models are particularly useful for indirect comparisons of multiple treatments that have not been compared head-to-head within the network meta-analysis framework. Moreover, we introduce Pearson residuals and construct an invariant test statistic to evaluate goodness-of-fit in the setting of ordinal outcome data. A detailed case study demonstrating the usefulness of the proposed methodology is carried out using aggregate ordinal outcome data from 16 clinical trials for treating CD.},
  langid = {english},
  keywords = {meta-analysis,ordinal,random-effects},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8518}
}

@article{hac06tra,
  title = {Translation of Research Evidence from Animals to Humans},
  author = {Hackam, D. G. and Redelmeier, D. A.},
  date = {2006},
  journaltitle = {JAMA},
  volume = {296},
  pages = {1731--1732},
  citeulike-article-id = {13265703},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  note = {review of basic science literature that documents systemic methodologic shortcomings. In a personal communication on 20Oct06 the authors reported that they found a few more biostatistical problems that could not make it into the JAMA article (for space constraints);none of the articles contained a sample size calculation;none of the articles identified a primary outcome measure;none of the articles mentioned whether they tested assumptions or did distributional testing (though a few used non-parametric tests);most articles had more than 30 endpoints (but few adjusted for multiplicity, as noted in the article)}
}

@article{Hackstadt2014a,
  title = {A {{Bayesian Multivariate Receptor Model}} for {{Estimating Source Contributions}} to {{Particulate Matter Pollution}} Using {{National Databases}}},
  author = {Hackstadt, A. J. and Peng, R. D.},
  date = {2014},
  journaltitle = {Environmetrics},
  volume = {25},
  number = {7},
  pages = {513--527},
  doi = {10.1002/env.2296},
  url = {http://dx.doi.org/10.1002/env.2296},
  citeulike-article-id = {14033409},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/env.2296},
  posted-at = {2016-05-11 21:27:00},
  priority = {2}
}

@article{Hackstadt2014b,
  title = {Inference for {{Environmental Intervention Studies}} Using {{Principal Stratification}}},
  author = {Hackstadt, A. J. and Matsui, E. C. and Williams, D. L. and Diette, G. B. and Breysse, P. N. and Butz, A. M. and Peng, R. D.},
  date = {2014},
  journaltitle = {Stat Med},
  volume = {33},
  number = {28},
  pages = {4919--4933},
  doi = {10.1002/sim.6291},
  url = {http://dx.doi.org/10.1002/sim.6291},
  citeulike-article-id = {14033410},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6291},
  posted-at = {2016-05-11 21:27:00},
  priority = {2}
}

@article{had14bia,
  title = {Bias Associated with Using the Estimated Propensity Score as a Regression Covariate},
  author = {Hade, Erinn M. and Lu, Bo},
  date = {2014-01},
  journaltitle = {Stat Med},
  volume = {33},
  number = {1},
  eprint = {23787715},
  eprinttype = {pmid},
  pages = {74--87},
  issn = {1097-0258},
  doi = {10.1002/sim.5884},
  url = {http://dx.doi.org/10.1002/sim.5884},
  abstract = {The use of propensity score methods to adjust for selection bias in observational studies has become increasingly popular in public health and medical research. A substantial portion of studies using propensity score adjustment treat the propensity score as a conventional regression predictor. Through a Monte Carlo simulation study, Austin and colleagues. investigated the bias associated with treatment effect estimation when the propensity score is used as a covariate in nonlinear regression models, such as logistic regression and Cox proportional hazards models. We show that the bias exists even in a linear regression model when the estimated propensity score is used and derive the explicit form of the bias. We also conduct an extensive simulation study to compare the performance of such covariate adjustment with propensity score stratification, propensity score matching, inverse probability of treatment weighted method, and nonparametric functional estimation using splines. The simulation scenarios are designed to reflect real data analysis practice. Instead of specifying a known parametric propensity score model, we generate the data by considering various degrees of overlap of the covariate distributions between treated and control groups. Propensity score matching excels when the treated group is contained within a larger control pool, while the model-based adjustment may have an edge when treated and control groups do not have too much overlap. Overall, adjusting for the propensity score through stratification or matching followed by regression or using splines, appears to be a good practical strategy.},
  citeulike-article-id = {12445750},
  citeulike-attachment-1 = {had14bia.pdf; /pdf/user/harrelfe/article/12445750/996108/had14bia.pdf; e432263d6788007ac57fbc904f87dbcc4ccad464},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5884},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/23787715},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=23787715},
  day = {15},
  posted-at = {2014-11-29 16:49:33},
  priority = {2},
  keywords = {bias,covariable-adjustment,observational-study,propensity-score}
}

@article{had92cro,
  title = {Cross-Validation Performance of Mortality Prediction Models},
  author = {Hadorn, D. C. and Draper, D. and Rogers, W. H. and Keeler, E. B. and Brook, R. H.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {475--489},
  citeulike-article-id = {13264193},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {predictive-accuracy,validation}
}

@article{had95lar,
  title = {Large-Scale Health Outcomes Evaluation: How Should Quality of Life Be Measured? {{Part I---Calibration}} of a Brief Questionnaire and a Search for Preference Subgroups},
  author = {Hadorn, David C. and Uebersaz, John},
  date = {1995},
  journaltitle = {J Clin Epi},
  volume = {48},
  pages = {607--618},
  citeulike-article-id = {13264194},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {functional-status,qol,quality-of-life,scale-construction}
}

@article{had96rat,
  title = {Rating the Quality of Evidence for Clinical Practice Guidelines},
  author = {Hadorn, David C. and Baker, David and Hodges, James S. and Hicks, Nicholas},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {749--754},
  doi = {10.1016/0895-4356(96)00019-4},
  url = {http://dx.doi.org/10.1016/0895-4356(96)00019-4},
  citeulike-article-id = {13264195},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0895-4356(96)00019-4},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {bias,clinical-practice-guidelines,clinical-trials,evidence,observational-studies,quallity-of-studies,rct,reporting,teaching-mds}
}

@article{hai03lat,
  title = {Late-Starter Sites in Randomized Controlled Trials},
  author = {Haidich, Anna-Bettina and Ioannidis, John P. A.},
  date = {2003},
  journaltitle = {J Clin Epi},
  volume = {56},
  pages = {408--415},
  citeulike-article-id = {13265338},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {clinical-sites,enrollment,multicenter-randomized-controlled-trials,rct},
  note = {late-enrolling sites are "unlikely to make important contributions to eventual trial enrollment in large clinical trials conducted by groups with a fixed number of sites. Protracting administrative efforts to add more sites many months after a multicenter trial has started may not be useful to trial accrual."}
}

@article{hak96fac,
  title = {Factors Associated with Do-Not-Resuscitate Orders: {{Patients}}' Preferences, Prognoses, and Physicians' Judgments},
  author = {Hakim, R. B. and Teno, J. M. and Harrell, F. E. and Knaus, W. A. and {Et Al}},
  date = {1996},
  journaltitle = {Ann Int Med},
  volume = {125},
  pages = {284--293},
  citeulike-article-id = {13264196},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{hal09gen,
  title = {Using Generalized Correlation to Effect Variable Selection in Very High Dimensional Problems},
  author = {Hall, Peter and Miller, Hugh},
  date = {2009},
  journaltitle = {J Comp Graph Stat},
  volume = {18},
  number = {3},
  pages = {533--550},
  citeulike-article-id = {13265815},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {bootstrap,confidence-intervals-for-ranks,cubic-splines,errors-in-variables,generalized-correlation,hidden-explanatory-variables,instrumental-variables,linear-model,measurement-error,ranking-correlations,ranks},
  note = {fitting an overall model may hide components that have potential for linearly influencing the response;group lasso or group LARS may not detect all influential variables;using a cubic spline fit for each variable separately and computing ordinary R²;"global modeling techniques generally preclude basis expansions on the grounds that they create an even larger dimensionality problem";use bootstrap percentile prediction intervals for rankings;nice dot charts;see hal09usi}
}

@article{hal09usi,
  title = {Using the Bootstrap to Quantify the Authority of an Empirical Ranking},
  author = {Hall, Peter and Miller, Hugh},
  date = {2009},
  journaltitle = {Ann Stat},
  volume = {37},
  pages = {3929--3959},
  citeulike-article-id = {13265787},
  issue = {6B},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {confidence-interval-for-ranks,genomics,high-dimension,independent-component-bootstrap,m-out-of-n-bootstrap,ordering,overlap-interval,prediction-interval,ranks,synchronous-bootstrap},
  note = {ordinary bootstrap may not provide accurate confidence intervals for ranks;may need a different bootstrap if the number of parameters being ranked increases with n or is large;estimating m is difficult;in their first example, where m=0.355n, the ordinary bootstrap provided a lower bound to the lengths of more accurate confidence intervals of ranks;see hal09gen}
}

@article{hal10mod,
  title = {Modeling the Variability of Ranks},
  author = {Hall, Peter and Miller, Hugh},
  date = {2010},
  journaltitle = {Ann Stat},
  volume = {38},
  number = {5},
  pages = {2652--2677},
  citeulike-article-id = {13265854},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {bootstrap,performance-rankings,variability-of-ranks}
}

@article{hal16ene,
  title = {Energy Expenditure and Body Composition Changes after an Isocaloric Ketogenic Diet in Overweight and Obese Men},
  author = {Hall, Kevin D. and Chen, Kong Y. and Guo, Juen and Lam, Yan Y. and Leibel, Rudolph L. and Mayer, Laurel ES and Reitman, Marc L. and Rosenbaum, Michael and Smith, Steven R. and Walsh, B. Timothy and Ravussin, Eric},
  date = {2016-08-01},
  journaltitle = {Am J Clin Nutr},
  volume = {104},
  number = {2},
  pages = {324--333},
  issn = {0002-9165},
  doi = {10.3945/ajcn.116.133561},
  url = {https://academic.oup.com/ajcn/article/104/2/324/4564649},
  urldate = {2019-10-02},
  abstract = {ABSTRACT.  Background: The carbohydrate–insulin model of obesity posits that habitual consumption of a high-carbohydrate diet sequesters fat within adipose tiss},
  langid = {english},
  keywords = {diet,experimental-design,teaching,teaching-mds}
}

@article{hal19ult,
  title = {Ultra-{{Processed Diets Cause Excess Calorie Intake}} and {{Weight Gain}}: {{An Inpatient Randomized Controlled Trial}} of {{Ad Libitum Food Intake}}},
  shorttitle = {Ultra-{{Processed Diets Cause Excess Calorie Intake}} and {{Weight Gain}}},
  author = {Hall, Kevin D. and Ayuketah, Alexis and Brychta, Robert and Cai, Hongyi and Cassimatis, Thomas and Chen, Kong Y. and Chung, Stephanie T. and Costa, Elise and Courville, Amber and Darcey, Valerie and Fletcher, Laura A. and Forde, Ciaran G. and Gharib, Ahmed M. and Guo, Juen and Howard, Rebecca and Joseph, Paule V. and McGehee, Suzanne and Ouwerkerk, Ronald and Raisinger, Klaudia and Rozga, Irene and Stagliano, Michael and Walter, Mary and Walter, Peter J. and Yang, Shanna and Zhou, Megan},
  date = {2019-07-02},
  journaltitle = {Cell Metab.},
  volume = {30},
  number = {1},
  eprint = {31105044},
  eprinttype = {pmid},
  pages = {67-77.e3},
  issn = {1932-7420},
  doi = {10.1016/j.cmet.2019.05.008},
  abstract = {We investigated whether ultra-processed foods affect energy intake in 20 weight-stable adults, aged (mean~± SE) 31.2~± 1.6 years and BMI~= 27~± 1.5~kg/m2. Subjects were admitted to the NIH Clinical Center and randomized to receive either ultra-processed or unprocessed diets for 2~weeks immediately followed by the alternate diet for 2~weeks. Meals were designed to be matched for presented calories, energy density, macronutrients, sugar, sodium, and fiber. Subjects were instructed to consume as much or as little as desired. Energy intake was greater during the ultra-processed diet (508~± 106~kcal/day; p~= 0.0001), with increased consumption of carbohydrate (280~± 54~kcal/day; p~{$<$} 0.0001) and fat (230~± 53~kcal/day; p~= 0.0004), but not protein (-2~± 12~kcal/day; p~= 0.85). Weight changes were highly correlated with energy intake (r~= 0.8, p~{$<$} 0.0001), with participants gaining 0.9~± 0.3~kg (p~= 0.009) during the ultra-processed diet and losing 0.9~± 0.3~kg (p~= 0.007) during the unprocessed diet. Limiting consumption of ultra-processed foods may be an effective strategy for obesity prevention and treatment.},
  langid = {english},
  keywords = {crossover,diet,experimental-design,teaching,teaching-mds}
}

@article{hal71,
  title = {Estimation of the Multivariate Logistic Risk Function: {{A}} Comparison of the Discriminant Function and Maximum Likelihood Approaches},
  author = {Halperin, M. and Blackwelder, W. C. and Verter, J. I.},
  date = {1971},
  journaltitle = {J Chron Dis},
  volume = {24},
  pages = {125--158},
  citeulike-article-id = {13264197},
  posted-at = {2014-07-14 14:09:30},
  priority = {0}
}

@article{hal87,
  title = {Distribution-Free Confidence Intervals for {{Pr}}({{X1}}},
  author = {{Halperin}},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {71--80},
  citeulike-article-id = {13264198},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {distribution-free-methods}
}

@article{hal89dis,
  title = {Distribution-Free Confidence Intervals for a Parameter of {{Wilcoxon-Mann-Whitney}} Type for Ordered Categories and Progressive Censoring},
  author = {Halperin, M. and Hamdy, M. I. and Thall, P. F.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {509--521},
  citeulike-article-id = {13264199},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {censored-data,distribution-free-methods,general}
}

@article{hal89eff,
  title = {On Efficient Bootstrap Simulation},
  author = {Hall, P.},
  date = {1989},
  journaltitle = {Biometrika},
  volume = {76},
  pages = {613--617},
  citeulike-article-id = {13264200},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {distribution-free-methods,statistical-computation-algorithms}
}

@article{hal92dbm,
  title = {{{DBMS}}/{{COPY}} and {{DBMS}}/{{COPY Plus}} ({{Version}} 2.0)},
  author = {Hallahan, C.},
  date = {1992},
  journaltitle = {Ann Math Stat},
  volume = {46},
  pages = {49--52},
  citeulike-article-id = {13264201},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {software-review}
}

@article{hal96log,
  title = {Logrank, Play the Winner, Power and Ethics},
  author = {Hallstrom, Al and Brooks, Mori and Peckova, Monika},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2135--2142},
  citeulike-article-id = {13264202},
  posted-at = {2014-07-14 14:09:30},
  priority = {0},
  keywords = {adaptive-study,ethics,play-the-winner,study-design},
  note = {power of logrank largely unaffected by play the winner strategy;ethics of 1-1 randomization}
}

@article{hal98est,
  title = {On Estimating Costs for Economic Evaluation in Failure Time Studies},
  author = {Hallstrom, Alfred P. and Sullivan, Sean D.},
  date = {1998},
  journaltitle = {Med Care},
  volume = {36},
  pages = {433--436},
  citeulike-article-id = {13264203},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {analysis-of-cost,censoring,good-explanation-of-bias-in-kaplan-meier-estimator-for-time-censored-cost-data}
}

@article{haldis,
  title = {Discussion on “{{Estimating}} Vaccine Efficacy over Time after a Randomized Study Is Unblinded” by {{Anastasios A}}. {{Tsiatis}} and {{Marie Davidian}}},
  author = {Halloran, M. Elizabeth},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13540},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13540},
  urldate = {2021-08-23},
  langid = {english},
  keywords = {vaccine},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13540}
}

@article{ham21imp,
  title = {Improving the Assessment of the Probability of Success in Late Stage Drug Development},
  author = {Hampson, Lisa V. and Bornkamp, Björn and Holzhauer, Björn and Kahn, Joseph and Lange, Markus R. and Luo, Wen-Lin and Cioppa, Giovanni Della and Stott, Kelvin and Ballerstedt, Steffen},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2179},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2179},
  urldate = {2021-12-16},
  abstract = {There are several steps to confirming the safety and efficacy of a new medicine. A sequence of trials, each with its own objectives, is usually required. Quantitative risk metrics can be useful for informing decisions about whether a medicine should transition from one stage of development to the next. To obtain an estimate of the probability of regulatory approval, pharmaceutical companies may start with industry-wide success rates and then apply to these subjective adjustments to reflect program-specific information. However, this approach lacks transparency and fails to make full use of data from previous clinical trials. We describe a quantitative Bayesian approach for calculating the probability of success (PoS) at the end of phase II which incorporates internal clinical data from one or more phase IIb studies, industry-wide success rates, and expert opinion or external data if needed. Using an example, we illustrate how PoS can be calculated accounting for differences between the phase II data and future phase III trials, and discuss how the methods can be extended to accommodate accelerated drug development pathways.},
  langid = {english},
  keywords = {bayes,drug-development,drug-development-program,probability-of-success},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2179}
}

@article{ham82pir,
  title = {Pirmenol Kinetics and Effective Oral Dose},
  author = {Hammill, S. C. and Shand, D. G. and Harrell, F. E. and Zimmerman, J. M. and Reiter, M. J. and Verghese, C. and Pritchett, E. L. C.},
  date = {1982},
  journaltitle = {Clin Pharm Ther},
  volume = {32},
  pages = {686--691},
  citeulike-article-id = {13264204},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{ham89mul,
  title = {Multiple-Spell Regression Models for Duration Data},
  author = {Hamerle, Alfred},
  date = {1989},
  journaltitle = {Appl Stat},
  volume = {38},
  pages = {127--138},
  citeulike-article-id = {13264205},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {multiple-events}
}

@article{ham95id,
  title = {Identification of Comatose Patients at High Risk for Death or Severe Disability},
  author = {Hamel, M. B. and Goldman, L. and Teno, J. and Lynn, J. and Davis, R. B. and Harrell, F. E. and Connors, A. F. and Califf, R. and Kussin, P. and Bellamy, P. and Vidaillet, H. and Phillips, R. S.},
  date = {1995},
  journaltitle = {JAMA},
  volume = {273},
  pages = {1842--1848},
  citeulike-article-id = {13264206},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{ham99old,
  title = {Older Age, Aggressiveness of Care and Survival for Seriously Ill Hospitalized Adults},
  author = {Hamel, M. B. and Davis, R. B. and Teno, J. M. and Knaus, W. A. and Lynn, J. and Harrell, F. E. and Galanos, A. N. and Wu, A. and Phillips, R. S.},
  date = {1999},
  journaltitle = {Ann Int Med},
  volume = {131},
  pages = {721--728},
  citeulike-article-id = {13264207},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{han00blo,
  title = {Blood, Dirt, and Nomograms},
  author = {Hankins, Thomas L.},
  date = {2000},
  journaltitle = {Chance},
  volume = {13},
  number = {1},
  pages = {26--37},
  citeulike-article-id = {13265181},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  note = {a definitive reference on nomograms;Maurice d'Ocagne could be called the inventor of the nomogram, starting with alignment diagrams in 1884 and declaring a new science of "nomography" in 1899. d'Ocagne was at École des Ponts et Chaussées, a school for civil engineering}
}

@book{han04mea,
  title = {Measurement {{Theory}} and {{Practice}}},
  author = {Hand, D. J.},
  date = {2004},
  publisher = {{Hodder Arnold}},
  citeulike-article-id = {13265520},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{han08pro,
  title = {The Prognostic Analogue of the Propensity Score},
  author = {Hansen, Ben B.},
  date = {2008},
  journaltitle = {Biometrika},
  volume = {95},
  pages = {481--488},
  citeulike-article-id = {13265679},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {covariate-balance,matched-sampling,matching,observational-study,prognostic-score,propensity-score,quasi-experiment,regression-discontinuity,subclassification},
  note = {prognostic score (Miettinen multivariate confounder score) is especially prone to overfitting;problems with same sample estimation}
}

@article{han09bay,
  title = {Bayesian Lasso Regression},
  author = {Hans, Chris},
  date = {2009},
  journaltitle = {Biometrika},
  volume = {96},
  number = {4},
  pages = {835--845},
  citeulike-article-id = {13265788},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {bayesian-lasso,double-exponential-distribution,lasso,posterior-predictive-distribution},
  note = {advantage of using predicted mean instead of mode}
}

@article{han10eva,
  title = {Evaluating Diagnostic Tests: {{The}} Area under the {{ROC}} Curve and the Balance of Errors},
  author = {Hand, David J.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {1502--1510},
  citeulike-article-id = {13265829},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {c-index,diagnosis,diagnostic-accuracy,roc-area},
  note = {fundamental problems with ROC area due to failure to balance difference kinds of misdiagnoses effectively;proposal to use H index discussed in Hand DJ:Machine Learning 77:103-123;2009}
}

@article{han22coh,
  title = {Coherent {{Tests}} for {{Interval Null Hypotheses}}},
  author = {Hansen, Spencer and Rice, Ken},
  date = {2022-03-08},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--9},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2022.2050299},
  url = {https://doi.org/10.1080/00031305.2022.2050299},
  urldate = {2022-04-09},
  abstract = {In a celebrated 1996 article, Schervish showed that, for testing interval null hypotheses, tests typically viewed as optimal can be logically incoherent. Specifically, one may fail to reject a specific interval null, but nevertheless—testing at the same level with the same data—reject a larger null, in which the original one is nested. This result has been used to argue against the widespread practice of viewing p-values as measures of evidence. In the current work we approach tests of interval nulls using simple Bayesian decision theory, and establish straightforward conditions that ensure coherence in Schervish’s sense. From these, we go on to establish novel frequentist criteria—different to Type I error rate—that, when controlled at fixed levels, give tests that are coherent in Schervish’s sense. The results suggest that exploring frequentist properties beyond the familiar Neyman–Pearson framework may ameliorate some of statistical testing’s well-known problems.},
  keywords = {bayes,coherent,hypothesis-testing,inference,interval-null},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2022.2050299},
  note = {New way of looking at Schervish interval null hypothesis testing incoherence example
\par
Tweet: Interval H₀:\href{https://www.htmlsymbols.xyz/unicode/U+03B8}{θ}\href{https://en.wikipedia.org/wiki/%E2%88%8A}{∊}[a,b] tests can be incoherent e.g. p-value can ↓ if a ↓. Coherent only if do not respect α. ~Bayes makes all this simple: posterior P(\href{https://www.htmlsymbols.xyz/unicode/U+03B8}{θ}∈[a,b]) will be coherent, i.e., will \href{https://en.wikipedia.org/wiki/%E2%86%91_(disambiguation)}{↑} as a ↓. ~\href{https://doi.org/10.1080/00031305.2022.2050299}{libkey.io/10.1080/00031305.2022.2050299}}
}

@article{han82,
  title = {The Meaning and Use of the Area under a Receiver Operating Characteristic ({{ROC}}) Curve},
  author = {Hanley, J. A. and McNeil, B. J.},
  date = {1982},
  journaltitle = {Radiology},
  volume = {143},
  pages = {29--36},
  citeulike-article-id = {13264208},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {c-index,diagnosis,roc,teaching-mds,testing}
}

@article{han83not,
  title = {If Nothing Goes Wrong, Is Everything All Right?},
  author = {Hanley, James A. and Lippman-Hand, Abby},
  date = {1983},
  journaltitle = {JAMA},
  volume = {249},
  pages = {1743--1745},
  doi = {10.1001/jama.1983.03330370053031},
  url = {http://dx.doi.org/10.1001/jama.1983.03330370053031},
  citeulike-article-id = {13264209},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.1983.03330370053031},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {3-n-rule,confidence-interval,diagnosis}
}

@unpublished{han88sem,
  title = {Semiparametric Estimation of Duration and Competing Risk Models},
  author = {Han, A. and Hausman, J.},
  date = {1988},
  citeulike-article-id = {13264210},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  annotation = {MIT photocopy}
}

@article{han94mul,
  title = {Multistate Modelling of Liver Transplantation Data},
  author = {Hansen, B. E. and Thorogood, J. and Hermans, J. and Ploeg, R. J. and van Bockel, J. H. and van Houwelingen, J. C.},
  options = {useprefix=true},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {2517--2529},
  citeulike-article-id = {13264211},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {markov-model,multiple-events,multistate-model}
}

@article{han96pre,
  title = {Presentation of Ordinal Regression Analysis on the Original Scale},
  author = {Hannah, Murray and Quigley, Paul},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {771--775},
  citeulike-article-id = {13264212},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {ordinal-response,regression-results-on-original-scale}
}

@article{han96sta,
  title = {Statistics and the Theory of Measurement (with Discussion)},
  author = {Hand, D. J.},
  date = {1996},
  journaltitle = {J Roy Stat Soc A},
  volume = {159},
  pages = {445--492},
  citeulike-article-id = {13264213},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {measurement-scales,measurement-theory,operational-measurement,representational-measurement}
}

@book{han97con,
  title = {Construction and {{Assessment}} of {{Classification Rules}}},
  author = {Hand, D. J.},
  date = {1997},
  publisher = {{Wiley}},
  location = {{Chichester}},
  citeulike-article-id = {13265135},
  posted-at = {2014-07-14 14:09:50},
  priority = {0}
}

@article{han98ana,
  title = {Analysis of Failure Times for Multiple Infections Following Bone Marrow Transplantation: {{An}} Application of the Multiple Failure Time Proportional Hazards Model},
  author = {Hannan, Peter J. and Shu, Xiao O. and Weisdorf, Daniel and Goldman, Anne},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {2371--2380},
  citeulike-article-id = {13264214},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {multiple-events,repeated-events}
}

@article{han98dat,
  title = {Data Mining: {{Statistics}} and More?},
  author = {Hand, David J.},
  date = {1998},
  journaltitle = {Am Statistician},
  volume = {52},
  pages = {112--118},
  citeulike-article-id = {13264215},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {data-mining,knowledge-discovery,large-databases,role-of-statisticians}
}

@book{hand-crowder,
  title = {Practical {{Longitudinal Data Analysis}}},
  author = {Hand, D. and Crowder, M.},
  date = {1996},
  publisher = {{Chapman \& Hall}},
  location = {{London}},
  citeulike-article-id = {13265323},
  posted-at = {2014-07-14 14:09:54},
  priority = {0}
}

@article{hap18opt,
  title = {Optimal Sample Size Planning for the {{Wilcoxon-Mann-Whitney}} Test},
  author = {Happ, Martin and Bathke, Arne C. and Brunner, Edgar},
  date = {2018},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.7983},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7983},
  urldate = {2018-10-12},
  abstract = {There are many different proposed procedures for sample size planning for the Wilcoxon-Mann-Whitney test at given type-I and type-II error rates α and β, respectively. Most methods assume very specific models or types of data to simplify calculations (eg, ordered categorical or metric data, location shift alternatives, etc). We present a unified approach that covers metric data with and without ties, count data, ordered categorical data, and even dichotomous data. For that, we calculate the unknown theoretical quantities such as the variances under the null and relevant alternative hypothesis by considering the following “synthetic data” approach. We evaluate data whose empirical distribution functions match the theoretical distribution functions involved in the computations of the unknown theoretical quantities. Then, well-known relations for the ranks of the data are used for the calculations. In addition to computing the necessary sample size N for a fixed allocation proportion t = n1/N, where n1 is the sample size in the first group and N = n1 + n2 is the total sample size, we provide an interval for the optimal allocation rate t, which minimizes the total sample size N. It turns out that, for certain distributions, a balanced design is optimal. We give a characterization of such distributions. Furthermore, we show that the optimal choice of t depends on the ratio of the two variances, which determine the variance of the Wilcoxon-Mann-Whitney statistic under the alternative. This is different from an optimal sample size allocation in case of the normal distribution model.},
  langid = {english},
  keywords = {ordinal,proportional-odds,proportional-odds-model,sample-size,wilcoxon-test}
}

@article{hap19opt,
  title = {Optimal Sample Size Planning for the {{Wilcoxon-Mann-Whitney}} Test},
  author = {Happ, Martin and Bathke, Arne C. and Brunner, Edgar},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {3},
  pages = {363--375},
  issn = {1097-0258},
  doi = {10.1002/sim.7983},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7983},
  urldate = {2019-01-05},
  abstract = {There are many different proposed procedures for sample size planning for the Wilcoxon-Mann-Whitney test at given type-I and type-II error rates α and β, respectively. Most methods assume very specific models or types of data to simplify calculations (eg, ordered categorical or metric data, location shift alternatives, etc). We present a unified approach that covers metric data with and without ties, count data, ordered categorical data, and even dichotomous data. For that, we calculate the unknown theoretical quantities such as the variances under the null and relevant alternative hypothesis by considering the following “synthetic data” approach. We evaluate data whose empirical distribution functions match the theoretical distribution functions involved in the computations of the unknown theoretical quantities. Then, well-known relations for the ranks of the data are used for the calculations. In addition to computing the necessary sample size N for a fixed allocation proportion t = n1/N, where n1 is the sample size in the first group and N = n1 + n2 is the total sample size, we provide an interval for the optimal allocation rate t, which minimizes the total sample size N. It turns out that, for certain distributions, a balanced design is optimal. We give a characterization of such distributions. Furthermore, we show that the optimal choice of t depends on the ratio of the two variances, which determine the variance of the Wilcoxon-Mann-Whitney statistic under the alternative. This is different from an optimal sample size allocation in case of the normal distribution model.},
  langid = {english},
  keywords = {ordinal,sample-size,wilcoxon-test}
}

@online{har00ana,
  title = {Analysis of Covariance in Randomized Studies},
  author = {Harrell, Frank},
  url = {https://hbiostat.org/bbr/md/ancova.html},
  urldate = {2020-11-22}
}

@article{har01usi,
  title = {Using Full Probability Models to Compute Probabilities of Actual Interest to Decision-Makers},
  author = {Harrell, Frank E. and Shih, Tina},
  date = {2001},
  journaltitle = {Int J Tech Assess Hlth Care},
  volume = {17},
  pages = {17--26},
  citeulike-article-id = {13265138},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {bayes,bayesian,decision-support-techniques,special-issue-basesian-approach-to-technology-assessment-and-decision-making}
}

@article{har05cas,
  title = {A Case Study in Comparing Therapies Involving Informative Drop-out, Non-Ignorable Non-Compliance and Repeated Measurements},
  author = {Härkänen, T. and Knekt, P. and Virtala, E. and Lindfors, O. and {The Helsinki Psychotherapy Study Group}},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {3773--3787},
  citeulike-article-id = {13265454},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {bayesian-inference,non-ignorable-missing-data,non-ignorable-non-compliance,nonrandom-dropout,rct,repeated-measurements,serial-data,surrogate},
  note = {use of surrogate data collected during interviews of patients who dropped out}
}

@article{har06mul,
  title = {Multiple Imputation for Correcting Verification Bias},
  author = {Harel, Ofer and Zhou, Xiao-Hua},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3769--3786},
  citeulike-article-id = {13265543},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {bayesian-methods,diagnosis,imputation,missing-data,referral-bias,software,verification-bias,workup-bias},
  note = {hypercritical letter to the editor and rejoinder, 26:3046-3050; de Groot {$<$}i{$>$}et al{$<$}/i{$>$} demonstrated that the Harel and Zhou paper is invalid in 27:5880-5889 after the journal mistakenly published a letter to the editor by the original authors while the de Groot {$<$}i{$>$}et al{$<$}/i{$>$} paper was in press. See deg08mul}
}

@article{har07mul,
  title = {Multiple Imputation: {{Review}} of Theory, Implementation and Software},
  author = {Harel, Ofer and Zhou, Xiao-Hua},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3057--3077},
  citeulike-article-id = {13265605},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {diagnostic-tests,multiple-imputation,sensitivity,specificity},
  note = {failed to review aregImpute;excellent overview;ugly S code;nice description of different statistical tests including combining likelihood ratio tests (which appears to be complex, requiring an out-of-sample log likelihood computation);congeniality of imputation and analysis models;Bayesian approximation or approximate Bayesian bootstrap overview;"Although missing at random (MAR) is a non-testable assumption, it has been pointed out in the literature that we can get very close to MAR if we include enough variables in the imputation models ... it would be preferred if the missing data modelling was done by the data constructors and not by the users... MI yields valid inferences not only in congenial settings, but also in certain uncongenial ones as well---where the imputer's model (1) is more general (i.e. makes fewer assumptions) than the complete-data estimation method, or when the imputer's model makes additional assumptions that are well-founded."}
}

@article{har09des,
  title = {Design: {{S}} Functions for Biostatistical/Epidemiologic Modeling, Testing, Estimation, Validation, Graphics, Prediction, and Typesetting by Storing Enhanced Model Design Attributes in the Fit},
  author = {Harrell, Frank E.},
  date = {2009}
}

@article{har14gre,
  title = {Greport: {{R}} Functions for Graphical Reporting of Clinical Trials.},
  author = {Harrell, Frank E.},
  date = {2014},
  url = {https://hbiostat.org/R/greport}
}

@online{har17ehr,
  title = {{{EHRs}} and {{RCTs}}: {{Outcome Prediction}} vs. {{Optimal Treatment Selection}}},
  shorttitle = {{{EHRs}} and {{RCTs}}},
  author = {Harrell, Frank and Lazzeroni, Laura},
  date = {2017-06-01T00:00:00+00:00},
  url = {https://www.fharrell.com/post/ehrs-rcts/},
  urldate = {2020-11-22},
  abstract = {Frank Harrell Professor of Biostatistics Vanderbilt University School of Medicine Laura Lazzeroni Professor of Psychiatry and, by courtesy, of Medicine (Cardiovascular Medicine) and of Biomedical Data Science Stanford University School of Medicine},
  langid = {american},
  organization = {{Statistical Thinking}}
}

@online{har18vie,
  title = {Viewpoints on {{Heterogeneity}} of {{Treatment Effect}} and {{Precision Medicine}}},
  author = {Harrell, Frank},
  date = {2018-06-04T00:00:00+00:00},
  url = {https://www.fharrell.com/post/hteview/},
  urldate = {2020-11-22},
  abstract = {This article provides my reflections after the PCORI/PACE Evidence and the Individual Patient meeting on 2018-05-31.  The discussion includes a high-level view of heterogeneity of treatment effect in optimizing treatment for individual patients.},
  langid = {american},
  organization = {{Statistical Thinking}}
}

@online{har19ass,
  title = {Assessing {{Heterogeneity}} of {{Treatment Effect}}, {{Estimating Patient-Specific Efficacy}}, and {{Studying Variation}} in {{Odds}} Ratios, {{Risk Ratios}}, and {{Risk Differences}}},
  author = {Harrell, Frank},
  date = {2019-03-25T00:00:00+00:00},
  url = {https://www.fharrell.com/post/varyor/},
  urldate = {2020-11-22},
  abstract = {This article shows an example formally testing for heterogeneity of treatment effect in the GUSTO-I trial, shows how to use penalized estimation to obtain patient-specific efficacy, and studies variation across patients in three measures of treatment effect.},
  langid = {american},
  organization = {{Statistical Thinking}}
}

@article{bbr,
  title = {Biostatistics for {{Biomedical Research}}},
  author = {Harrell, Frank E. and Slaughter, James C.},
  date = {2020},
  url = {https://hbiostat.org/bbr},
  keywords = {teaching-mds}
}

@article{Hmisc,
  title = {Hmisc: {{A}} Package of Miscellaneous {{R}} Functions},
  author = {Harrell, Frank E.},
  date = {2020},
  url = {https://hbiostat.org/R/Hmisc}
}

@article{har20how,
  title = {How to {{Develop Statistical Predictive Risk Models}} in {{Oncology Nursing}} to {{Enhance Psychosocial}} and {{Supportive Care}}},
  author = {Harris, Jenny and Purssell, Edward and Ream, Emma and Jones, Anne and Armes, Jo and Cornelius, Victoria},
  date = {2020-12-01},
  journaltitle = {Seminars in Oncology Nursing},
  series = {Digital {{Platforms}} in {{Cancer Care}}},
  volume = {36},
  number = {6},
  pages = {151089},
  issn = {0749-2081},
  doi = {10.1016/j.soncn.2020.151089},
  url = {http://www.sciencedirect.com/science/article/pii/S0749208120301042},
  urldate = {2020-12-07},
  abstract = {Objectives Predictive risk models are advocated in psychosocial oncology practice to provide timely and appropriate support to those likely to experience the emotional and psychological consequences of cancer and its treatments. New digital technologies mean that large scale and routine data collection are becoming part of everyday clinical practice. Using these data to try to identify those at greatest risk for late psychosocial effects of cancer is an attractive proposition in a climate of unmet need and limited resource. In this paper, we present a framework to support the development of high-quality predictive risk models in psychosocial and supportive oncology. The aim is to provide awareness and increase accessibility of best practice literature to support researchers in psychosocial and supportive care to undertake a structured evidence-based approach. Data Sources Statistical prediction risk model publications. Conclusion In statistical modeling and data science different approaches are needed if the goal is to predict rather than explain. The deployment of a poorly developed and tested predictive risk model has the potential to do great harm. Recommendations for best practice to develop predictive risk models have been developed but there appears to be little application within psychosocial and supportive oncology care. Implications for Nursing Practice Use of best practice evidence will ensure the development and validation of predictive models that are robust as these are currently lacking. These models have the potential to enhance supportive oncology care through harnessing routine digital collection of patient-reported outcomes and the targeting of interventions according to risk characteristics.},
  langid = {english},
  keywords = {rms,teaching-mds}
}

@article{rrms,
  title = {{rms}: R Functions for Biostatistical/Epidemiologic Modeling, Testing, Estimation, Validation, Graphics, Prediction, and Typesetting by Storing Enhanced Model Design Attributes in the Fit},
  author = {Harrell, Frank E.},
  date = {2020},
  url = {https://hbiostat.org/R/rms},
  keywords = {group-rms}
}

@article{har20uti,
  title = {Utilizing {{Bayesian}} Predictive Power in Clinical Trial Design},
  author = {Harari, Ofir and Hsu, Grace and Dron, Louis and Park, Jay J. H. and Thorlund, Kristian and Mills, Edward J.},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2073},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2073},
  urldate = {2020-10-10},
  abstract = {The Bayesian paradigm provides an ideal platform to update uncertainties and carry them over into the future in the presence of data. Bayesian predictive power (BPP) reflects our belief in the eventual success of a clinical trial to meet its goals. In this paper we derive mathematical expressions for the most common types of outcomes, to make the BPP accessible to practitioners, facilitate fast computations in adaptive trial design simulations that use interim futility monitoring, and propose an organized BPP-based phase II-to-phase III design framework.},
  langid = {english},
  keywords = {bayes,design,design-of-rct,futility,rct,study-design,study-design-and-stopping-rules},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2073}
}

@article{har20utia,
  title = {Utilizing {{Bayesian}} Predictive Power in Clinical Trial Design},
  author = {Harari, Ofir and Hsu, Grace and Dron, Louis and Park, Jay J. H. and Thorlund, Kristian and Mills, Edward J.},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  publisher = {{Wiley}},
  issn = {1539-1604},
  doi = {10.1002/pst.2073},
  url = {https://dx.doi.org/10.1002/pst.2073},
  keywords = {bayes,futility,predictive-distribution,predictive-power,rct}
}

@online{har20vio,
  title = {Violation of {{Proportional Odds}} Is {{Not Fatal}}},
  author = {Harrell, Frank},
  date = {2020-09-20T00:00:00+00:00},
  url = {https://www.fharrell.com/post/po/},
  urldate = {2020-11-22},
  abstract = {Many researchers worry about violations of the proportional hazards assumption when comparing treatments in a randomized study.  Besides the fact that this frequently makes them turn to a much worse approach, the harm done by violations of the proportional odds assumption usually do not prevent the proportional odds model from providing a reasonable treatment effect assessment.},
  langid = {american},
  organization = {{Statistical Thinking}}
}

@article{har21bay,
  title = {Bayesian {{Inference Is Unaffected}} by {{Selection}}: {{Fact}} or {{Fiction}}?},
  shorttitle = {Bayesian {{Inference Is Unaffected}} by {{Selection}}},
  author = {Harville, David A.},
  date = {2021},
  journaltitle = {The American Statistician},
  series = {Mv {{Ba}}},
  volume = {0},
  number = {0},
  pages = {1--7},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2020.1858963},
  url = {https://doi.org/10.1080/00031305.2020.1858963},
  urldate = {2021-01-06},
  abstract = {The problem considered is that of making inferences about the value of a parameter vector θ based on the value of an observable random vector y that is subject to selection of the form y ∈ S (for a known subset S). According to conventional wisdom, a Bayesian approach (unlike a frequentist approach) requires no adjustment for selection, which is generally regarded as counterintuitive and even paradoxical. An alternative considered herein consists (when taking a Bayesian approach in the face of selection) of basing the inferences for the value of θ on the posterior distribution derived from the conditional (on y ∈ S ) joint distribution of y and θ . That leads to an adjustment in the likelihood function that is reinterpretable as an adjustment to the prior distribution and ultimately leads to a different posterior distribution. And it serves to make the inferences specific to settings that are subject to selection of the same kind as the setting that gave rise to the data. Moreover, even in the absence of any real selection, this approach can be used to make the inferences specific to a meaningful subset of y-values.},
  keywords = {bayes,multiplicity,prior,selection-bias},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2020.1858963}
}

@online{har21sta,
  title = {Statistical Methods for Composite Endpoints},
  author = {Hara, Hironori and van Klaveren, David and Kogame, Norihiro and Chichareon, Ply and Modolo, Rodrigo and Tomaniak, Mariusz and Ono, Masafumi and Kawashima, Hideyuki and Takahashi, Kuniaki and Capodanno, Davide and Onuma, Yoshinobu and Serruys, Patrick W.},
  date = {2021},
  doi = {10.4244/EIJ-D-19-00953},
  url = {https://eurointervention.pcronline.com/article/the-a-b-c-of-multiple-statistical-methods-for-composite-endpoints},
  urldate = {2021-04-03},
  abstract = {The Official Journal of EuroPCR and the European Association of Percutaneous Cardiovascular Interventions (EAPCI)},
  langid = {english},
  organization = {{EuroIntervention}},
  keywords = {composite-endpoint,compound-endpoints,key,multiple-endpoints,rct}
}

@article{har21uti,
  title = {Utilizing {{Bayesian}} Predictive Power in Clinical Trial Design},
  author = {Harari, Ofir and Hsu, Grace and Dron, Louis and Park, Jay J. H. and Thorlund, Kristian and Mills, Edward J.},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {20},
  number = {2},
  pages = {256--271},
  issn = {1539-1612},
  doi = {10.1002/pst.2073},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2073},
  urldate = {2021-03-07},
  abstract = {The Bayesian paradigm provides an ideal platform to update uncertainties and carry them over into the future in the presence of data. Bayesian predictive power (BPP) reflects our belief in the eventual success of a clinical trial to meet its goals. In this paper we derive mathematical expressions for the most common types of outcomes, to make the BPP accessible to practitioners, facilitate fast computations in adaptive trial design simulations that use interim futility monitoring, and propose an organized BPP-based phase II-to-phase III design framework.},
  langid = {english},
  keywords = {bayes,predictive-power,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2073}
}

@inproceedings{har73exp,
  title = {Expandable System for Routine Cardiac Catheterization},
  booktitle = {Proceedings of the {{Advancement}} of {{Medical Instrumentation}}},
  author = {Harrell, F. E. and Strand, E. M.},
  date = {1973-03},
  volume = {7},
  citeulike-article-id = {13264216},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har77pro,
  title = {Producing {{SAS}} Files from Large Master Files for a Clinical Research Project},
  booktitle = {Proceedings of the {{Second Annual Conference}} of the {{SAS Users}}' {{Group International}}},
  author = {Harrell, F. E.},
  date = {1977},
  pages = {98--100},
  location = {{Raleigh NC}},
  citeulike-article-id = {13264217},
  organization = {SAS Institute},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har78cap,
  title = {Capabilities of {{SAS}} as a Clinical Research Data Management and Analysis System},
  booktitle = {Proceedings of the {{Third Annual Conference}} of the {{SAS Users}}' {{Group International}}},
  author = {{Jr}},
  date = {1978},
  pages = {155--158},
  location = {{Raleigh NC}},
  citeulike-article-id = {13264218},
  organization = {SAS Institute},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har79sta,
  title = {Statistical Inference for Censored Bivariate Normal Distributions Based on Induced Order Statistics},
  author = {Harrell, F. E. and Sen, P. K.},
  date = {1979},
  journaltitle = {Biometrika},
  volume = {66},
  pages = {293--298},
  citeulike-article-id = {13264219},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har79sur,
  title = {Survival in Medically Treated Coronary Artery Disease},
  author = {Harris, P. J. and Harrell, F. E. and Lee, K. L. and Behar, V. S. and Rosati, R. A.},
  date = {1979},
  journaltitle = {Circ},
  volume = {60},
  pages = {1259--1269},
  citeulike-article-id = {13264220},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har80non,
  title = {Nonfatal Myocardial Infarction in Medically Treated Patients with Coronary Artery Disease},
  author = {Harris, P. J. and Harrell, F. E. and Lee, K. L. and Rosati, R. A.},
  date = {1980},
  journaltitle = {Am J Card},
  volume = {46},
  pages = {937--942},
  citeulike-article-id = {13264221},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har80out,
  title = {Outcome in Medically Treated Coronary Artery Disease. {{Ischemic}} Events: Nonfatal Infarction and Death},
  author = {Harris, P. J. and Lee, K. L. and Harrell, F. E. and Behar, V. S. and Rosati, R. A.},
  date = {1980},
  journaltitle = {Circ},
  volume = {62},
  pages = {718--726},
  citeulike-article-id = {13264222},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har80pro,
  title = {The Prognostic Significance of 50\% Coronary Stenosis in Medically Treated Patients with Coronary Artery Disease},
  author = {Harris, P. J. and Behar, V. S. and Conley, M. J. and Harrell, F. E. and Lee, K. L. and Peter, R. H. and Kong, Y. and Rosati, R. A.},
  date = {1980},
  journaltitle = {Circ},
  volume = {62},
  pages = {240--248},
  citeulike-article-id = {13264223},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har80proc,
  title = {Procedures for Large Regression Problems Requiring Maximum Likelihood Estimation},
  booktitle = {Proceedings of the {{Fifth Annual Conference}} of the {{SAS Users}}' {{Group International}}},
  author = {Harrell, F. E. and Lee, K. L. and McKinnis, R. A.},
  date = {1980},
  pages = {199--202},
  location = {{Cary NC}},
  citeulike-article-id = {13264224},
  organization = {SAS Institute},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har81enh,
  title = {Enhancements in Logistic and Proportional Hazard Regression Procedures},
  booktitle = {Proceedings of the {{Sixth Annual Conference}} of the {{SAS Users}}' {{Group International}}},
  author = {Harrell, F. E. and Lee, K. L. and McKinnis, R. A.},
  date = {1981},
  pages = {166--168},
  location = {{Cary NC}},
  citeulike-article-id = {13264225},
  organization = {SAS Institute},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har81sas,
  title = {A {{SAS}} Response Surface Design and Analysis Package},
  booktitle = {Proceedings of the {{Sixth Annual Conference}} of the {{SAS Users}}' {{Group International}}},
  author = {Harrell, F. E.},
  date = {1981},
  pages = {100--103},
  location = {{Cary NC}},
  citeulike-article-id = {13264226},
  organization = {SAS Institute},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har82,
  title = {Evaluating the Yield of Medical Tests},
  author = {Harrell, F. E. and Califf, R. M. and Pryor, D. B. and Lee, K. L. and Rosati, R. A.},
  date = {1982},
  journaltitle = {JAMA},
  volume = {247},
  pages = {2543--2546},
  citeulike-article-id = {13264227},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  note = {should have reference efr67two}
}

@article{har82cla,
  title = {A Class of Rank Test Procedures for Censored Survival Data},
  author = {Harrington, D. P. and Fleming, T. R.},
  date = {1982},
  journaltitle = {Biometrika},
  volume = {69},
  pages = {553--566},
  citeulike-article-id = {13264228},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har82new,
  title = {A New Distribution-Free Quantile Estimator},
  author = {Harrell, F. E. and Davis, C. E.},
  date = {1982},
  journaltitle = {Biometrika},
  volume = {69},
  pages = {635--640},
  citeulike-article-id = {13264229},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  note = {see hut00exa}
}

@inproceedings{har83dat,
  title = {Data Analysis Considerations and Survival Analysis Programs},
  booktitle = {Computer {{Science}} and {{Statistics}}: {{The Interface}}},
  author = {Harrell, F. E.},
  editor = {Gentle, J. E.},
  date = {1983},
  pages = {93--96},
  publisher = {{North-Holland}},
  location = {{Amsterdam}},
  citeulike-article-id = {13264230},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har83dat2,
  title = {The {{DATACHK Procedure}}},
  booktitle = {{{SUGI Supplemental Library User}}'s {{Guide}}},
  author = {Harrell, F. E.},
  editor = {Joyner, S.},
  date = {1983},
  pages = {35--37},
  publisher = {{SAS Institute}},
  location = {{Cary NC}},
  citeulike-article-id = {13264231},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har83pctl,
  title = {The {{PCTL Procedure}}},
  booktitle = {{{SUGI Supplemental Library User}}'s {{Guide}}},
  author = {Harrell, F. E.},
  editor = {Joyner, S.},
  date = {1983},
  pages = {429--435},
  publisher = {{SAS Institute}},
  location = {{Cary NC}},
  citeulike-article-id = {13264232},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har84,
  title = {Regression Modeling Strategies for Improved Prognostic Prediction},
  author = {Harrell, F. E. and Lee, K. L. and Califf, R. M. and Pryor, D. B. and Rosati, R. A.},
  date = {1984},
  journaltitle = {Stat Med},
  volume = {3},
  pages = {143--152},
  citeulike-article-id = {13264233},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har85com,
  title = {A Comparison of the Discrimination of Discriminant Analysis and Logistic Regression under Multivariate Normality},
  booktitle = {Biostatistics: {{Statistics}} in {{Biomedical}}, {{Public Health}}, and {{Environmental Sciences}}. {{The Bernard G}}. {{Greenberg Volume}}},
  author = {Harrell, F. E. and Lee, K. L.},
  editor = {Sen, P. K.},
  date = {1985},
  pages = {333--343},
  publisher = {{North-Holland}},
  location = {{Amsterdam}},
  citeulike-article-id = {13264234},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har85log,
  title = {The {{LOGIST}} Procedure},
  booktitle = {Changes and {{Enhancements}} in the {{Version}} 5 {{SUGI Supplemental Library}}, {{Technical Report S-131}}},
  author = {Harrell, F. E.},
  date = {1985},
  pages = {15--20},
  publisher = {{SAS Institute}},
  location = {{Cary NC}},
  citeulike-article-id = {13264235},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har85phg,
  title = {The {{PHGLM}} Procedure},
  booktitle = {Changes and {{Enhancements}} in the {{Version}} 5 {{SUGI Supplemental Library}}, {{Technical Report S-131}}},
  author = {Harrell, F. E.},
  date = {1985},
  pages = {61--63},
  publisher = {{SAS Institute}},
  location = {{Cary NC}},
  citeulike-article-id = {13264236},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har85pra,
  title = {The Practical Value of Logistic Regression},
  booktitle = {Proceedings of the {{Tenth Annual SAS Users Group International Conference}}},
  author = {Harrell, F. E. and Lee, K. L.},
  date = {1985},
  pages = {1031--1036},
  citeulike-article-id = {13264237},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har85reg,
  title = {Regression Models for Prognostic Prediction: {{Advantages}}, Problems, and Suggested Solutions},
  author = {Harrell, F. E. and Lee, K. L. and Matchar, D. B. and Reichert, T. A.},
  date = {1985},
  journaltitle = {Ca Trt Rep},
  volume = {69},
  pages = {1071--1077},
  citeulike-article-id = {13264238},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har86log,
  title = {The {{LOGIST Procedure}}},
  booktitle = {{{SUGI Supplemental Library Users Guide}}},
  author = {Harrell, F. E.},
  date = {1986},
  edition = {Version 5},
  pages = {269--293},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary, NC}},
  citeulike-article-id = {13264239},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har86phg,
  title = {The {{PHGLM Procedure}}},
  booktitle = {{{SUGI Supplemental Library Users Guide}}},
  author = {Harrell, F. E.},
  date = {1986},
  edition = {Version 5},
  pages = {437--466},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary, NC}},
  citeulike-article-id = {13264240},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har86ver,
  title = {Verifying Assumptions of the {{Cox}} Proportional Hazards Model},
  booktitle = {Proceedings of the {{Eleventh Annual SAS Users Group International Conference}}},
  author = {Harrell, F. E. and Lee, K. L.},
  date = {1986},
  pages = {823--828},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary, NC}},
  citeulike-article-id = {13264241},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har87,
  title = {Graphical Methods for the Analysis of Survival Data},
  booktitle = {Proceedings of the {{Twelfth Annual SAS Users Group International Conference}}},
  author = {Harrell, F. E. and Pollock, B. G. and Lee, K. L.},
  date = {1987},
  pages = {1107--1115},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary, NC}},
  citeulike-article-id = {13264242},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har87sea,
  title = {The Seasonal Risk of Pediatric/Juvenile Acute Lymphocytic Leukemia in the {{United States}}},
  author = {Harris, R. E. and Harrell, F. E. and Patil, K. D. and Al-Rashid, R.},
  date = {1987},
  journaltitle = {J Chron Dis},
  volume = {40},
  pages = {915--923},
  citeulike-article-id = {13264243},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har87sim,
  title = {Simple Tests of Global Association in the Logistic Model},
  author = {Harrell, F. E. and Lee, K. L.},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {87},
  citeulike-article-id = {13264244},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  annotation = {Refereed letter to the editor}
}

@unpublished{har87usi,
  title = {Using Logistic Model Calibration to Assess the Quality of Probability Predictions},
  author = {Harrell, F. E. and Lee, K. L.},
  date = {1987},
  citeulike-article-id = {13264252},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  annotation = {Unpublished manuscript}
}

@article{har88,
  title = {Regression Models in Clinical Studies: {{Determining}} Relationships between Predictors and Response},
  author = {Harrell, F. E. and Lee, K. L. and Pollock, B. G.},
  date = {1988},
  journaltitle = {J Nat Cancer Inst},
  volume = {80},
  pages = {1198--1202},
  citeulike-article-id = {13264245},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har88dat,
  title = {A {{DataEase}} to {{SAS}} Interface},
  booktitle = {Proceedings of the {{Thirteenth Annual Conference}} of the {{SAS User}}'s {{Group International}}},
  author = {Harrell, F. E. and Muhlbaier, L. H.},
  date = {1988},
  pages = {170--174},
  publisher = {{SAS Institute}},
  location = {{Cary NC}},
  citeulike-article-id = {13264246},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har88log,
  title = {The {{LOGIST Procedure}}},
  booktitle = {Changes and {{Enhancements}} to the {{SAS System}}, {{Release}} 5.18. {{Technical Report P-175}}},
  author = {Harrell, F. E. and Peterson, B.},
  date = {1988},
  pages = {266--285},
  publisher = {{SAS Institute}},
  location = {{Cary NC}},
  citeulike-article-id = {13264247},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@inproceedings{har88sur,
  title = {A Survey of Microcomputer Survival Analysis Software},
  booktitle = {Proceedings of the {{Section}} on {{Statistical Education}}},
  author = {Harrell, F. E.},
  date = {1988},
  pages = {16--25},
  publisher = {{American Statistical Association}},
  location = {{Alexandria Va}},
  citeulike-article-id = {13264248},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@incollection{har89ana,
  title = {Analysis of {{SAT}} Trends for {{Durham}} Schools},
  booktitle = {Report of the {{Merger Issues Task Force}}, {{Durham County}}},
  author = {Harrell, F. E.},
  date = {1989},
  citeulike-article-id = {13264249},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har90sup,
  title = {Statistical Methods in {{SUPPORT}}},
  author = {Harrell, F. E. and Marcus, S. E. and Layde, P. M. and Broste, S. K. and Cook, E. F. and Wagner, D. P. and Muhlbaier, L. H. and Peck, S. L.},
  date = {1990},
  journaltitle = {J Clin Epi},
  volume = {43},
  citeulike-article-id = {13264250},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@unpublished{har91com,
  title = {Comparison of Strategies for Validating Binary Logistic Regression Models},
  author = {Harrell, F. E.},
  date = {1991},
  citeulike-article-id = {13264251},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  annotation = {Unpublished manuscript}
}

@article{har92mor,
  title = {Mortality after Coronary Angioplasty and Coronary Artery Bypass Surgery ({{The}} National {{Medicare}} Experience)},
  author = {Hartz, Arthur J. and Kuhn, Evelyn M. and Pryor, David B. and Krakauer, Henry and Young, Mark and Heudebert, Gustavo and Rimm, Alfred A.},
  date = {1992},
  journaltitle = {Am J Card},
  volume = {70},
  pages = {179--185},
  citeulike-article-id = {13264253},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {cabg,confounding,outcomes-research,ptca,risk-adjustment,sensitivity-analysis},
  note = {example of bad outcomes research}
}

@article{har94disc,
  title = {Discussion of Paper by {{Spiegelhalter}}, {{Freedman}}, and {{Parmar}}},
  author = {Harrell, F. E.},
  date = {1994},
  journaltitle = {J Roy Stat Soc A},
  volume = {157},
  pages = {405},
  citeulike-article-id = {13264254},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@book{har95sta,
  title = {Statistical {{Bases}} of {{Reference Values}} in {{Laboratory Medicine}}},
  author = {Harris, Eugene K. and Boyd, James C.},
  date = {1995},
  publisher = {{Marcel Dekker}},
  location = {{New York}},
  citeulike-article-id = {13265290},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-chemistry,clinical-lab-data,reference-ranges,reference-values},
  note = {"conventional reference limits will be replaced, this time by patient-specific predictive models and values. The effects of genetic mechanisms and environmental influences will be automatically reflected in individual serial records. As we mentioned, the problem of tranferrability will look especially large here, again putting very stringent demands on analytical accuracy"}
}

@article{har96disc,
  title = {Discussion of Paper by {{Goldstein}} and {{Spiegelhalter}}},
  author = {Harrell, F. E.},
  date = {1996},
  journaltitle = {J Roy Stat Soc A},
  volume = {159},
  pages = {433},
  citeulike-article-id = {13264255},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har96mul,
  title = {Multivariable Prognostic Models: {{Issues}} in Developing Models, Evaluating Assumptions and Adequacy, and Measuring and Reducing Errors},
  author = {Harrell, Frank E. and Lee, Kerry L. and Mark, Daniel B.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {361--387},
  citeulike-article-id = {13264256},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {calibration,multivariable-modeling,predictive-accuracy,teaching-mds,validation}
}

@article{har96reg,
  title = {Regression Coefficients and Scoring Rules},
  author = {Harrell, Frank E.},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {819},
  doi = {10.1016/0895-4356(95)00068-2},
  url = {http://dx.doi.org/10.1016/0895-4356(95)00068-2},
  citeulike-article-id = {13264257},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0895-4356(95)00068-2},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {cabg-mortality-model,charlson-index,comorbidity,parsonnet-model},
  annotation = {Refereed letter to the editor},
  note = {creating clinical indexes or scores from regression coefficients}
}

@report{har96sta,
  title = {Statistical Methods for Economic Evaluation of Health Care},
  author = {Harrell, Frank E.},
  date = {1996},
  institution = {{Presented at the Seventeenth Meeting of the International Society for Clinical Biostatistics, Budapest, Hungary 29 Aug 96}},
  citeulike-article-id = {13264258},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {analysis-of-costs,cox-model,economic-evaluation}
}

@article{har97sur,
  title = {A Survey of Microcomputer Survival Analysis Software: {{The}} Need for an Integrated Framework},
  author = {Harrell, F. E. and Goldstein, R.},
  date = {1997},
  journaltitle = {Am Statistician},
  volume = {51},
  pages = {360--373},
  citeulike-article-id = {13264259},
  posted-at = {2014-07-14 14:09:31},
  priority = {0}
}

@article{har98det,
  title = {Detecting and Describing Heterogeneity in Meta-Analysis},
  author = {Hardy, Rebecca J. and Thompson, Simon G.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {841--856},
  citeulike-article-id = {13264260},
  posted-at = {2014-07-14 14:09:31},
  priority = {0},
  keywords = {diagnostic-for-choosing-random-vs-fixed-effects-model,heterogeneity,meta-analysis,power}
}

@article{har98dev,
  title = {Development of a Clinical Prediction Model for an Ordinal Outcome: {{The World Health Organization ARI Multicentre Study}} of Clinical Signs and Etiologic Agents of Pneumonia, Sepsis, and Meningitis in Young Infants},
  author = {Harrell, Frank E. and Margolis, Peter A. and Gove, Sandy and Mason, Karen E. and Mulholland, E. Kim and Lehmann, Deborah and Muhe, Lulu and Gatchalian, Salvacion and Eichenwald, Heinz F.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {909--944},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0258(19980430)17:8%3C909::AID-SIM753%3E3.0.CO;2-O/abstract},
  citeulike-article-id = {13264261},
  citeulike-linkout-0 = {http://dx.doi.org/},
  citeulike-linkout-1 = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0258(19980430)17:8%3C909::AID-SIM753%3E3.0.CO;2-O/abstract},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {cart,continuation-ratio-model,data-reduction,diagnosis,differential-penalization,imputation,model-approximation,nomogram,ordinal-response,penalized-maximum-likelihood-estimation,predictive-accuracy,proportional-odds-model,scaling,screening,shrinkage,validation,variable-clustering,verification-bias}
}

@article{har98ina,
  title = {The Inappropriate Use of Hypothesis Testing to Infer Safety of Calcium Channel Blockers},
  author = {Harrell, F. E.},
  date = {1998},
  journaltitle = {Cardiovasc Drugs Ther},
  volume = {12},
  pages = {151--153},
  citeulike-article-id = {13264262},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  annotation = {Editorial}
}

@article{har98one,
  title = {One-Sided Cross-Validation},
  author = {Hart, Jeffrey D. and Yi, Seongbaek},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {620--631},
  citeulike-article-id = {13264263},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {average-squared-error,data-driven-smoothing,low-precision-of-smoothing-parameters-chosen-by-ordinary-cross-validation,mean-average-squared-error,optimal-bandwidths,prediction}
}

@unpublished{har99sem,
  title = {Semiparametric Modeling of Health Care Cost and Resource Utilization},
  author = {Harrell, Frank E.},
  date = {1999},
  citeulike-article-id = {13265093},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  annotation = {Available from  hesweb1.­med.­virginia.­edu/­biostat/­presentations}
}

@book{has08ele,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H.},
  date = {2008},
  edition = {second},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265716},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {data-mining,machine-learning},
  annotation = {ISBN-10: 0387848576; ISBN-13: 978-0387848570}
}

@article{has20res,
  title = {Restricted Mean Survival Time as a Summary Measure of Time-to-Event Outcome},
  author = {Hasegawa, Takahiro and Misawa, Saori and Nakagawa, Shintaro and Tanaka, Shinichi and Tanase, Takanori and Ugai, Hiroyuki and Wakana, Akira and Yodo, Yasuhide and Tsuchiya, Satoru and Suganami, Hideki},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2004},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2004},
  urldate = {2020-02-23},
  abstract = {Many clinical research studies evaluate a time-to-event outcome, illustrate survival functions, and conventionally report estimated hazard ratios to express the magnitude of the treatment effect when comparing between groups. However, it may not be straightforward to interpret the hazard ratio clinically and statistically when the proportional hazards assumption is invalid. In some recent papers published in clinical journals, the use of restricted mean survival time (RMST) or τ-year mean survival time is discussed as one of the alternative summary measures for the time-to-event outcome. The RMST is defined as the expected value of time to event limited to a specific time point corresponding to the area under the survival curve up to the specific time point. This article summarizes the necessary information to conduct statistical analysis using the RMST, including the definition and statistical properties of the RMST, adjusted analysis methods, sample size calculation, information fraction for the RMST difference, and clinical and statistical meaning and interpretation. Additionally, we discuss how to set the specific time point to define the RMST from two main points of view. We also provide developed SAS codes to determine the sample size required to detect an expected RMST difference with appropriate power and reconstruct individual survival data to estimate an RMST reference value from a reported survival curve.},
  langid = {english},
  keywords = {non-ph,non-proportional-hazards,restricted-mean-life,survival}
}

@article{has87clo,
  title = {A Closer Look at the Deviance},
  author = {{Hastie}},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {16--20},
  citeulike-article-id = {13264264},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {maximum-likelihood}
}

@article{has87gen,
  title = {Generalized Additive Models: Some Applications},
  author = {{Hastie}},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {371--376},
  citeulike-article-id = {13264265},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {graphical-methods,maximum-likelihood}
}

@article{has87non,
  title = {Non-Parametric Logistic and Proportional Odds Regression},
  author = {Hastie, T. and Tibshirani, R.},
  date = {1987},
  journaltitle = {Appl Stat},
  volume = {36},
  pages = {260--276},
  citeulike-article-id = {13264266},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,graphical-methods,logistic-model}
}

@article{has89,
  title = {Regression with an Ordered Categorical Response},
  author = {Hastie, T. J. and Botha, J. L. and Schnitzler, C. M.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {785--794},
  citeulike-article-id = {13264267},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {graphical-methods,logistic-ordinal-model}
}

@book{has90,
  title = {Generalized {{Additive Models}}},
  author = {Hastie, T. and Tibshirani, R.},
  date = {1990},
  publisher = {{Chapman and Hall}},
  location = {{London}},
  citeulike-article-id = {13264268},
  posted-at = {2014-07-14 14:09:32},
  priority = {0}
}

@article{has90exp,
  title = {Exploring the Nature of Covariate Effects in the Proportional Hazards Model},
  author = {Hastie, T. and Tibshirani, R.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {1005--1016},
  citeulike-article-id = {13264269},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {graphical-methods,survival-analysis-proportional-hazards-model}
}

@book{has90gen,
  title = {Generalized {{Additive Models}}},
  author = {Hastie, Trevor J. and Tibshirani, Robert J.},
  date = {1990},
  publisher = {{Chapman \& Hall/CRC}},
  location = {{Boca Raton, FL}},
  citeulike-article-id = {13265714},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  annotation = {ISBN 9780412343902}
}

@article{has94dis,
  title = {Discussion of “{{The}} Use of Polynomial Splines and Their Tensor Products in Multivariate Function Estimation” by {{C}}. {{J}}. {{Stone}}},
  author = {Hastie, Trevor},
  date = {1994},
  journaltitle = {Appl Stat},
  volume = {22},
  pages = {177--179},
  citeulike-article-id = {13264270},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {s-language,splines,tensor-splines}
}

@article{has95pen,
  title = {Penalized Discriminant Analysis},
  author = {Hastie, Trevor and Buja, Andreas and Tibshirani, Robert},
  date = {1995},
  journaltitle = {Appl Stat},
  volume = {23},
  pages = {73--102},
  citeulike-article-id = {13264271},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {canonical-correlation,canonical-variates,optimal-scoring,penalized-estimation}
}

@article{has97bay,
  title = {Bayesian Analysis for a Single 2 2 Table},
  author = {Hashemi, Lobat and Nandram, Balgobin and Goldberg, Robert},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1311--1328},
  citeulike-article-id = {13264272},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {2x2-table,bayesian-inference,binomial,odds-ratio,risk-ratio}
}

@article{hat93tec,
  title = {A Technique for Summarizing Longitudinal Data},
  author = {Hathaway, Dale K. and D'Agostino, Ralph B.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2169--2178},
  citeulike-article-id = {13264273},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {growth-curves,multiple-response-data,multivariate,repeated-measures}
}

@article{hau77,
  title = {Wald's Test as Applied to Hypotheses in Logit Analysis},
  author = {Hauck, W. W. and Donner, A.},
  date = {1977},
  journaltitle = {J Am Stat Assoc},
  volume = {72},
  pages = {851--863},
  citeulike-article-id = {13264274},
  posted-at = {2014-07-14 14:09:32},
  priority = {0}
}

@article{hau91,
  title = {A Consequence of Omitted Covariates When Estimating Odds Ratios},
  author = {Hauck, W. W. and Neuhaus, J. M. and Kalbfleisch, J. D. and Anderson, S.},
  date = {1991},
  journaltitle = {J Clin Epi},
  volume = {44},
  pages = {77--81},
  citeulike-article-id = {13264275},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {confounding,general,missing-covariable,odds-ratio,omitted-covariable,regression}
}

@article{hau98sho,
  title = {Should We Adjust for Covariates in Nonlinear Regression Analyses of Randomized Trials?},
  author = {Hauck, Walter W. and Anderson, Sharon and Marcus, Sue M.},
  date = {1998},
  journaltitle = {Controlled Clin Trials},
  volume = {19},
  pages = {249--256},
  doi = {10.1016/S0197-2456(97)00147-5},
  url = {http://dx.doi.org/10.1016/S0197-2456(97)00147-5},
  citeulike-article-id = {13264276},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0197-2456(97)00147-5},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {ancova,attenuation-of-treatment-effect-estimate,balance,baseline,bias,covariable-adjustment,covariate-adjustment,efficiency,rct,study-design,subject-specific-vs-population-averaged-estimates},
  note = {"For use in a clinician-patient context, there is only a single person, that patient, of interest. The subject-specific measure then best reflects the risks or benefits for that patient. Gail has noted this previously [ENAR Presidential Invited Address, April 1990], arguing that one goal of a clinical trial ought to be to predict the direction and size of a treatment benefit for a patient with specific covariate values. In contrast, population-averaged estimates of treatment effect compare outcomes in groups of patients. The groups being compared are determined by whatever covariates are included in the model. The treatment effect is then a comparison of average outcomes, where the averaging is over all omitted covariates."}
}

@article{hau99som,
  title = {Some Issues in the Design and Analysis of Equivalence Trials},
  author = {Hauck, Walter W. and Anderson, Sharon},
  date = {1999},
  journaltitle = {Drug Info J},
  volume = {33},
  pages = {109--118},
  citeulike-article-id = {13264277},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {adherence,choice-of-delta,confidence-interval,equivalence-trial,imputation,intent-to-treat,mcar,missing-data}
}

@article{hav90,
  title = {Yate's Correction for Continuity and the Analysis of 2x2 Contingency Tables},
  author = {Haviland, M. G.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {363--367},
  citeulike-article-id = {13264278},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {binary-random-var,categorical-data,discriminant-analysis,logistic-model}
}

@article{haw21use,
  title = {Use of {{Confidence Intervals}} in {{Interpreting Nonstatistically Significant Results}}},
  author = {Hawkins, Alexander T. and Samuels, Lauren R.},
  date = {2021-11-23},
  journaltitle = {JAMA},
  volume = {326},
  number = {20},
  eprint = {34812882},
  eprinttype = {pmid},
  pages = {2068--2069},
  issn = {1538-3598},
  doi = {10.1001/jama.2021.16172},
  langid = {english},
  keywords = {clinical-significance,confidence-interval,confidence-intervals,statistical-significance,teaching-mds}
}

@article{hay05est,
  title = {An Estimator for Treatment Comparisons among Survivors in Randomized Trials},
  author = {Hayden, Douglas and Pauler, Donna K. and Schoenfeld, David},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  pages = {305--310},
  citeulike-article-id = {13265410},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {counterfactual,explainable-nonrandom-survival,sace,survival-bias,survivor-average-causal-effect}
}

@article{hay88,
  title = {Methods for Assessing Whether Change Depends on Initial Value},
  author = {Hayes, R. J.},
  date = {1988},
  journaltitle = {Stat Med},
  volume = {7},
  pages = {915--927},
  citeulike-article-id = {13264279},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {analysis-change,change-scores,general,measurement,medical,research-methods}
}

@article{he12dia,
  title = {Diagnosing Imputation Models by Applying Target Analyses to Posterior Replicates of Completed Data},
  author = {He, Yulei and Zaslavsky, Alan M.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {1},
  pages = {1--18},
  doi = {10.1002/sim.4413},
  url = {http://dx.doi.org/10.1002/sim.4413},
  abstract = {Multiple imputation fills in missing data with posterior predictive draws from imputation models. To assess the adequacy of imputation models, we can compare completed data with their replicates simulated under the imputation model. We apply analyses of substantive interest to both datasets and use posterior predictive checks of the differences of these estimates to quantify the evidence of model inadequacy. We can further integrate out the imputed missing data and their replicates over the completed-data analyses to reduce variance in the comparison. In many cases, the checking procedure can be easily implemented using standard imputation software by treating re-imputations under the model as posterior predictive replicates. Thus, it can be applied for non-Bayesian imputation methods. We also sketch several strategies for applying the method in the context of practical imputation analyses. We illustrate the method using two real data applications and study its property using a simulation.},
  citeulike-article-id = {13265919},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4413},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {completed-data,conservatism,imputation-software,missing-data,model-uncongeniality,normal-approximation,posterior-predictive-p-value,re-imputation}
}

@article{he12pra,
  title = {Practical {{Considerations}} and {{Strategies}} for {{Executing Adaptive Clinical Trials}}},
  author = {He, Weili and Kuznetsova, Olga M. and Harmer, Mark and Leahy, Cathy and Anderson, Keaven and Dossin, Nicole and Li, Lina and Bolognese, James and Tymofyeyev, Yevgen and Schindler, Jerald},
  date = {2012},
  journaltitle = {Drug Info J},
  volume = {46},
  number = {2},
  eprint = {http://dij.sagepub.com/content/46/2/160.full.pdf+html},
  pages = {160--174},
  doi = {10.1177/0092861512436580},
  url = {http://dij.sagepub.com/content/46/2/160.abstract},
  abstract = {There is great potential for clinical trials designed with adaptive features to result in more efficient decision making within a drug development program. However, clinical trials with adaptive features are more complex to implement than traditional designs such as fixed-sample or group sequential. Workarounds and/or inefficiencies in adaptive design (AD) trial execution may result in human and material wastes. Further, they may result in the introduction of operational biases that may potentially negate any gains in designing an AD trial and may even render trial results not interpretable. In this article, we present and share our experience and best practices in AD trial implementation in the areas of resource planning, randomization considerations including the importance of randomization schemes on clinical supply, Interactive Voice Randomization System vendor capability assessment and quality control, clinical supply strategy considerations, enrollment management and patient enrollment modeling and simulation, data quality and interim analysis planning, managing blinding and unblinding, and the use of a data monitoring committee.},
  citeulike-article-id = {13265925},
  citeulike-linkout-0 = {http://dx.doi.org/10.1177/0092861512436580},
  citeulike-linkout-1 = {http://dij.sagepub.com/content/46/2/160.abstract},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {adaptive,rct}
}

@article{he14acc,
  title = {On the Accuracy of Classifying Hospitals on Their Performance Measures},
  author = {He, Yulei and Selck, Frederic and Normand, Sharon-Lise T.},
  date = {2014-03},
  journaltitle = {Stat Med},
  volume = {33},
  number = {7},
  pages = {1081--1103},
  doi = {10.1002/sim.6012},
  url = {http://dx.doi.org/10.1002/sim.6012},
  abstract = {The evaluation, comparison, and public report of health care provider performance is essential to improving the quality of health care. Hospitals, as one type of provider, are often classified into quality tiers (e.g., top or suboptimal) based on their performance data for various purposes. However, potential misclassification might lead to detrimental effects for both consumers and payers. Although such risk has been highlighted by applied health services researchers, a systematic investigation of statistical approaches has been lacking. We assess and compare the expected accuracy of several commonly used classification methods: unadjusted hospital-level averages, shrinkage estimators under a random-effects model accommodating between-hospital variation, and two others based on posterior probabilities. Assuming that performance data follow a classic one-way random-effects model with unequal sample size per hospital, we derive accuracy formulae for these classification approaches and gain insight into how the misclassification might be affected by various factors such as reliability of the data, hospital-level sample size distribution, and cutoff values between quality tiers. The case of binary performance data is also explored using Monte Carlo simulation strategies. We apply the methods to real data and discuss the practical implications.},
  citeulike-article-id = {13448163},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6012},
  day = {30},
  posted-at = {2014-11-29 16:33:28},
  priority = {2},
  keywords = {accuracy,bayesian-inference,provider-profiling,reliability}
}

@article{he97lin,
  title = {Linear Regression after Spline Transformation},
  author = {He, Xuming and Shen, Liji},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {474--481},
  citeulike-article-id = {13264280},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {b-spline,box-cox,canonical-correlation,canonical-variate,see-shi98not,transformation,transforming-left-hand-side}
}

@article{hea05sur,
  title = {Survival Model Predictive Accuracy and {{ROC}} Curves},
  author = {Heagerty, Patrick J. and Zheng, Yingye},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  pages = {92--105},
  citeulike-article-id = {13265409},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {cox-regression,discrimination,ph-model,prediction,predictive-accuracy,sensitivity,specificity,time-dependent-roc-curves}
}

@article{hed94ran,
  title = {A Random-Effects Ordinal Regression Model for Multilevel Analysis},
  author = {Hedeker, Donald and Gibbons, Robert D.},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  number = {4},
  pages = {933--944},
  citeulike-article-id = {13265793},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {clustering,longitudinal-data-analysis,maximum-marginal-likelihood,mixed-effects-model,ordinal-response,proportional-odds-model,repeated-measures,serial-data}
}

@article{hee87rob,
  title = {Robustness of the Two Independent Samples T-Test When Applied to Ordinal Scaled Data},
  author = {Heeren, Timothy and D'Agostino, Ralph},
  date = {1987},
  journaltitle = {Stat Med},
  volume = {6},
  pages = {79--90},
  citeulike-article-id = {13264281},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {ordinal-response}
}

@article{hei02sol,
  title = {A Solution to the Problem of Separation in Logistic Regression},
  author = {Heinze, Georg and Schemper, Michael},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  number = {16},
  eprint = {12210625},
  eprinttype = {pubmed},
  pages = {2409--2419},
  citeulike-article-id = {13265962},
  citeulike-linkout-0 = {http://www.ncbi.nlm.nih.gov/pubmed/12210625},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{hei06imp,
  title = {Imputation of Missing Values Is Superior to Complete Case Analysis and the Missing-Indicator Method in Multivariable Diagnostic Research: {{A}} Clinical Example},
  author = {van der Heijden, Geert J. M. G. and {Donders} and Stijnen, Theo and Moons, Karel G. M.},
  options = {useprefix=true},
  date = {2006},
  journaltitle = {J Clin Epi},
  volume = {59},
  pages = {1102--1109},
  doi = {10.1016/j.jclinepi.2006.01.015},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2006.01.015},
  citeulike-article-id = {13265493},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2006.01.015},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {bias,complete-case-analysis,extra-categories,imputation,missing-data,missingness-indicator,precision,single-imputation,teaching-mds},
  note = {Invalidity of adding a new category or an indicator variable for missing values even with MCAR}
}

@article{hei96dis,
  title = {Distinguishing “{{Missing}} at {{Random}}” and “{{Missing Completely}} at {{Random}}”},
  author = {Heitjan, Daniel F. and Basu, Srabashi},
  date = {1996},
  journaltitle = {Am Statistician},
  volume = {50},
  pages = {207--213},
  citeulike-article-id = {13264282},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {missing-data-theory}
}

@article{hei97bay,
  title = {Bayesian Interim Analysis of Phase {{II}} Cancer Clinical Trials},
  author = {Heitjan, Daniel F.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1791--1802},
  citeulike-article-id = {13264283},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {bayesian-inference,choice-of-prior,phase-ii,study-design,use-of-theoretical-expert}
}

@article{hel01dat,
  title = {Data Quality Issues in Electronic Data Capture},
  author = {Helms, Ron},
  date = {2001},
  journaltitle = {Drug Info J},
  pages = {827--838},
  citeulike-article-id = {13265236},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {correct-data-value,data-management,data-quality,data-quality-assessment,electronic-data-capture,error-rate-estimate,initial-data-record,statistician-frustration}
}

@article{hel11ctsa,
  title = {A {{CTSA Agenda}} to {{Advance Methods}} for {{Comparative Effectiveness Research}}},
  author = {Helfand, Mark and Tunis, Sean and Whitlock, Evelyn P. and Pauker, Stephen G. and Basu, Anirban and Chilingerian, Jon and Harrell, Frank E. and Meltzer, David O. and Montori, Victor M. and Shepard, Donald S. and Kent, David M. and of the National CTSA Strategic Goal Committee on Comparative Effectiveness Research, The Methods Work Group},
  options = {useprefix=true},
  date = {2011},
  journaltitle = {Clin Trans Sci},
  volume = {4},
  number = {3},
  pages = {188--198},
  publisher = {Blackwell Publishing Inc},
  doi = {10.1111/j.1752-8062.2011.00282.x},
  url = {http://dx.doi.org/10.1111/j.1752-8062.2011.00282.x},
  citeulike-article-id = {13265884},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1752-8062.2011.00282.x},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {clinical-research-methods,comparative-effectiveness,patient-centered-outcomes-research,translational-science}
}

@article{hel16inf,
  title = {Inference for the Difference in the Area under the {{ROC}} Curve Derived from Nested Binary Regression Models},
  author = {Heller, Glenn and Seshan, Venkatraman E. and Moskowitz, Chaya S. and Gönen, Mithat},
  date = {2016-09},
  journaltitle = {Biostatistics},
  pages = {kxw045+},
  issn = {1465-4644},
  doi = {10.1093/biostatistics/kxw045},
  url = {http://dx.doi.org/10.1093/biostatistics/kxw045},
  citeulike-article-id = {14321176},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biostatistics/kxw045},
  day = {21},
  posted-at = {2017-03-27 19:20:32},
  priority = {2},
  keywords = {c-index,deficiencies-of-roc-area,roc,roc-area},
  note = {difference in AUROC does not give rise to a chi-square distribution if no predictors are associated with outcome (linear combo of chi-sq)}
}

@article{hem18sta,
  title = {Standard Errors and Confidence Intervals for Variable Importance in Random Forest Regression, Classification, and Survival},
  author = {Hemant, Ishwaran and Min, Lu},
  journaltitle = {Stat Med},
  volume = {0},
  number = {0},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7803},
  doi = {10.1002/sim.7803},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7803},
  abstract = {Random forests are a popular nonparametric tree ensemble procedure with broad applications to data analysis. While its widespread popularity stems from its prediction performance, an equally important feature is that it provides a fully nonparametric measure of variable importance (VIMP). A current limitation of VIMP, however, is that no systematic method exists for estimating its variance. As a solution, we propose a subsampling approach that can be used to estimate the variance of VIMP and for constructing confidence intervals. The method is general enough that it can be applied to many useful settings, including regression, classification, and survival problems. Using extensive simulations, we demonstrate the effectiveness of the subsampling estimator and in particular find that the delete‐d jackknife variance estimator, a close cousin, is especially effective under low subsampling rates due to its bias correction properties. These 2 estimators are highly competitive when compared with the .164 bootstrap estimator, a modified bootstrap procedure designed to deal with ties in out‐of‐sample data. Most importantly, subsampling is computationally fast, thus making it especially attractive for big data settings.},
  citeulike-article-id = {14600146},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7803},
  citeulike-linkout-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7803},
  posted-at = {2018-06-06 17:06:25},
  priority = {2},
  keywords = {bootstrap,machine-learning,variable-importance}
}

@article{hem20use,
  title = {Use of Multiple Period, Cluster Randomised, Crossover Trial Designs for Comparative Effectiveness Research},
  author = {Hemming, Karla and Taljaard, Monica and Weijer, Charles and Forbes, Andrew B.},
  date = {2020-11-04},
  journaltitle = {BMJ},
  volume = {371},
  eprint = {33148538},
  eprinttype = {pmid},
  pages = {m3800},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.m3800},
  url = {https://www.bmj.com/content/371/bmj.m3800},
  urldate = {2021-09-05},
  abstract = {{$<$}p{$>$}Many treatments are adopted into clinical practice without a solid evidence base and might be used heterogeneously across settings. Rigorous randomised controlled trials are therefore needed to inform decisions about the comparative effectiveness of treatments in common use. The mainstay of comparative effectiveness research is pragmatic trial design, which emphasises broad eligibility criteria, simple logistics, routinely collected outcome data, and cost efficient designs. Although treatment differences at the individual level might be small, they can become important when aggregated across large populations. To detect these small differences, very large trials are often required. In multiple period, cluster randomised, crossover trials, the study design randomises clusters (eg, hospitals) to exposure to different interventions in a randomly determined order, and is an attractive design for comparative effectiveness research. The trial design can be highly statistically efficient, compared with other competing designs, and can have many logistical advantages. Several prominent examples of this trial design have been published recently, yet practical guidance is lacking on how best to design these trials to ensure that they provide robust evidence. Some considerations include how to determine the frequency and number of crossovers, the importance of a time balanced design, how to determine the required sample size, and how to analyse appropriately. The justification for using this design (over a design randomising on the level of individual patients) also raises ethical concerns when used to evaluate individual level interventions without the prospective informed consent of individual participants. In this article, we outline the key methodological and ethical requirements needed for the robust design of multiple period, cluster randomised, crossover trials.{$<$}/p{$>$}},
  langid = {english},
  keywords = {cluster-randomization,cluster-randomized-trial,crossover,crossover-study,design,rct}
}

@article{hen01acc,
  title = {Accuracy of Point Predictions in Survival Analysis},
  author = {Henderson, Robin and Jones, Margaret and Stare, Janez},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {3083--3096},
  citeulike-article-id = {13265240},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {descrimination,predictive-accuracy,prognosis},
  note = {probability of severe error, e.g. off by factor of 2 in predicting survival time}
}

@article{hen16saf,
  title = {Safety Data from Randomized Controlled Trials: Applying Models for Recurrent Events},
  author = {Hengelbrock, Johannes and Gillhaus, Johanna and Kloss, Sebastian and Leverkus, Friedhelm},
  date = {2016-01},
  journaltitle = {Pharm Stat},
  pages = {n/a},
  doi = {10.1002/pst.1757},
  url = {http://dx.doi.org/10.1002/pst.1757},
  abstract = {Simple descriptive listings and inference statistics based on 2×2 tables are still the most common way of summarizing and reporting adverse events data from randomized controlled trials, although these methods do not account for differences in observation times between treatment groups. Using standard methods from survival analysis such as the Cox model or Kaplan–Meier estimates would overcome this problem but limit the analysis to the first safety-related event of each subject. As an alternative, we discuss two models for recurrent events data—the Andersen–Gill and Prentice–Williams–Peterson model—regarding their applicability to safety data from randomized controlled trials. We argue that these models can be used to estimate two different quantities: a direct treatment effect on the risk of an event (Prentice–Williams–Peterson) and a total treatment effect as sum of the direct effect and the treatment's indirect effect via the event history (Anderson–Gill). Using simulated data, we illustrate the difference between these treatment effects and analyze the performance of both models in different scenarios. Because both models are limited to the analysis of cause-specific hazards if competing risks are present, we suggest to incorporate estimates of the mean frequency of events in the analysis to additionally allow the comparison of treatment effects on absolute event probabilities. We demonstrate the application of both models and the mean frequency function to safety endpoints with an illustrative analysis of data from a randomized phase-III study. Copyright  2016 John Wiley \& Sons, Ltd.},
  citeulike-article-id = {14070913},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1757},
  day = {1},
  posted-at = {2016-06-17 12:46:38},
  priority = {2},
  keywords = {pharmaceutical-safety,recurrent-events}
}

@article{hen90,
  title = {A Problem with the Likelihood Ratio Test for a Change-Point Hazard Rate Model},
  author = {{Henderson}},
  date = {1990},
  journaltitle = {Biometrika},
  volume = {77},
  pages = {835--843},
  citeulike-article-id = {13264284},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {maximum-likelihood,survival-analysis-non-regression}
}

@article{hen92hie,
  title = {Hierarchical Spline Models for Conditional Quantiles and the Demand for Electricity},
  author = {Hendricks, W. and Koenker, R.},
  date = {1992},
  journaltitle = {J Am Stat Assoc},
  volume = {87},
  pages = {58--68},
  citeulike-article-id = {13264285},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {quantile,spline}
}

@book{hen95gra,
  title = {Graphing Data},
  author = {Henry, Gary T.},
  date = {1995},
  publisher = {{Sage}},
  location = {{Newbury Park, CA}},
  citeulike-article-id = {13265232},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {graphics}
}

@article{hen95pro,
  title = {Problems and Prediction in Survival-Data Analysis},
  author = {Henderson, Robin},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {161--184},
  citeulike-article-id = {13264286},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {bayesian-estimation,clear-explanation,cox-model,explained-variation,general,loss-function-characteristics,partial-likelihood,ph-model,prediction,predictive-accuracy,review-of-survival-analysis,semiparametric-aft-models,survival-estimation},
  note = {predicting survival times and probabilities from Cox model}
}

@article{her00mar,
  title = {Marginal Structural Models to Estimate the Causal Effect of {{Zidovudine}} on the Survival of {{HIV-positive}} Men},
  author = {Hernan, Miguel A. and Brumback, Babette and Robins, James M.},
  date = {2000},
  journaltitle = {Epi},
  volume = {11},
  pages = {561--570},
  citeulike-article-id = {13265200},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {causal-inference,counterfactuals,cox-model,marginal-structural-model,repeated-measures,survival-analysis,time-dependent-confounding}
}

@article{her01mar,
  title = {Marginal Structural Models to Estimate the Joint Causal Effect of Nonrandomized Treatments},
  author = {Hernan, Miguel A. and Brumback, Babette and Robins, James M.},
  date = {2001},
  journaltitle = {J Am Stat Assoc},
  volume = {86},
  pages = {440--448},
  citeulike-article-id = {13265201},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {causal-inference,confounding,conterfactuals,dependent-censoring,intermediate-variables,semiparametric-models,survival-analysis}
}

@article{her04cov,
  title = {Covariate Adjustment in Randomized Controlled Trials with Dichotomous Outcomes Increases Statistical Power and Reduces Sample Size Requirements},
  author = {Hernández, Adrián V. and Steyerberg, Ewout W. and Habbema, J. D. F.},
  date = {2004},
  journaltitle = {J Clin Epi},
  volume = {57},
  pages = {454--460},
  citeulike-article-id = {13265385},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {covariate-adjustment,logistic-regression,randomized-controlled-trials,rct,sample-size,statistical-power,type-i-error}
}

@article{her06ran,
  title = {Randomized {{Controlled Trials With Time-to-Event Outcomes}}: {{How Much Does Prespecified Covariate Adjustment Increase Power}}?},
  author = {Hernández, Adrián V. and Eijkemans, Marinus J. C. and Steyerberg, Ewout W.},
  date = {2006-01},
  journaltitle = {Annals of Epi},
  volume = {16},
  number = {1},
  eprint = {16275011},
  eprinttype = {pmid},
  pages = {41--48},
  issn = {10472797},
  doi = {10.1016/j.annepidem.2005.09.007},
  url = {http://dx.doi.org/10.1016/j.annepidem.2005.09.007},
  abstract = {We evaluated the effects of various strategies of covariate adjustment on type I error, power, and potential reduction in sample size in randomized controlled trials (RCTs) with time-to-event outcomes. We used Cox models in simulated data sets with different treatment effects (hazard ratios [HRs] = 1, 1.4, and 1.7), covariate effects (HRs = 1, 2, and 5), covariate prevalences (10\% and 50\%), and censoring levels (no, low, and high). Treatment and a single covariate were dichotomous. We examined the sample size that gives the same power as an unadjusted analysis for three strategies: prespecified, significant predictive, and significant imbalance. Type I error generally was at the nominal level. The power to detect a true treatment effect was greater with adjusted than unadjusted analyses, especially with prespecified and significant-predictive strategies. Potential reductions in sample size with a covariate HR between 2 and 5 were between 15\% and 44\% (covariate prevalence 50\%) and between 4\% and 12\% (covariate prevalence 10\%). The significant-imbalance strategy yielded small reductions. The reduction was greater with stronger covariate effects, but was independent of treatment effect, sample size, and censoring level. Adjustment for one predictive baseline characteristic yields greater power to detect a true treatment effect than unadjusted analysis, without inflation of type I error and with potentially moderate reductions in sample size. Analysis of RCTs with time-to-event outcomes should adjust for predictive covariates.},
  citeulike-article-id = {4119367},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.annepidem.2005.09.007},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/16275011},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=16275011},
  posted-at = {2015-04-13 21:35:49},
  priority = {2},
  keywords = {covariable-adjustment,covariate-adjustment,time-to-event}
}

@article{her06sub,
  title = {Subgroup Analyses in Therapeutic Cardiovascular Clinical Trials: {{Are}} Most of Them Misleading?},
  author = {Hernandez, Adrian V. and Boersma, Eric and Murray, Gordon D. and Habbema, J. D. F. and Steyerberg, Ewout W.},
  date = {2006},
  journaltitle = {Am Heart J},
  volume = {151},
  pages = {257--264},
  doi = {10.1016/j.ahj.2005.04.020},
  url = {http://dx.doi.org/10.1016/j.ahj.2005.04.020},
  citeulike-article-id = {13265462},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ahj.2005.04.020},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {rct,subgroup-analysis,teaching-mds},
  note = {"Conclusions: Subgroup analyses in recent cardiovascular RCTs were reported with several shortcomings, including a lack of prespecification and testing of a large number of subgroups without the use of the statistically appropriate test for interaction. Reporting of subgroup analysis needs to be substantially improved because emphasis on these secondary results may mislead treatment decisions."}
}

@article{her07bay,
  title = {Bayesian Modeling of Multiple Episode Occurrence and Severity with a Terminating Event},
  author = {Herring, Amy H. and Yang, Juan},
  date = {2007},
  journaltitle = {Biometrics},
  volume = {63},
  pages = {381--388},
  citeulike-article-id = {13265599},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {bayesian-analysis,data-augmentation,dependent-censoring,dynamic-latent-variables,frequency-and-intensity-of-episodes,multiple-event-times,pregnancy}
}

@article{her07sta,
  title = {Statistical Education for Medical Students---{{Concepts}} Are What Remain When the Details Are Forgotten},
  author = {Herman, Amir and Notzer, Netta and Libman, Zipi and Braunstein, Rony and Steinberg, David M.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4344--4351},
  citeulike-article-id = {13265629},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {medical-students,statistical-curriculum,statistical-education,survey,teaching-mds},
  note = {"Although the medical students show very good knowledge at the end of their first-year course, it is clear that several years later they lack basic understanding of statistical concepts. This can be attributed to the fact that, contrary to other medical-oriented skills, statistical concepts are not repeated throughout the medical curriculum. As a result, the students' ability to understand and criticize scientific medical articles is limited and many are not able to apply statistical ideas to their own thesis research.";some authors feel that statistics should be taught through examples of true implementation of statistics;"Use of statistical software should be done judiciously, to avoid extensive hand calculation, but without taking too much time to learn the technical details of the software package." (this is with regard to the first stat course for medical students). "The second course should focus on critical reading and understanding of medical articles... The third course should be given during the fifth year ... and be devoted to applying statistical tools.";see critical letter to editor by Nigel Smeeton, 27:2267-2272;2008}
}

@article{her08coo,
  title = {Coordinating Data Monitoring Committees and Adaptive Clinical Trial Designs},
  author = {Herson, Jay},
  date = {2008},
  journaltitle = {Drug Info J},
  volume = {42},
  pages = {297--301},
  citeulike-article-id = {13265684},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {adaptive-design,blinding,communication,dmc,dsmb,rct},
  note = {logistics of implementing study design changes during the trial}
}

@article{her11dif,
  title = {Different Methods of Allocation to Groups in Randomized Trials Are Associated with Different Levels of Bias. {{A}} Meta-Epidemiological Study},
  author = {Herbison, Peter and Hay-Smith, Jean and Gillespie, William J.},
  date = {2011},
  journaltitle = {J Clin Epi},
  volume = {64},
  number = {10},
  pages = {1070--1075},
  doi = {10.1016/j.jclinepi.2010.12.018},
  url = {http://www.sciencedirect.com/science/article/pii/S0895435611000163},
  abstract = {Objective Insecure hiding of the treatment allocation in randomized trials is associated with bias. It is less certain how much bias is associated with different methods of treatment allocation.  Study Design and Setting  Meta-epidemiological study of 389 randomized trials from 19 systematic reviews and 65 meta-analyses with differing methods of treatment allocation. Pooled ratios of odds ratios (RORs) and 95\% confidence intervals (95\% CI) were calculated from trials with different methods of treatment allocation. An ROR less than one shows exaggeration of treatment effect.  Results  There is no evidence that the use of sealed envelopes with enhancement was different from central randomization (ROR 1.02, 95\% CI: 0.85–1.23). Sealed envelopes without enhancement were associated with an exaggeration of the estimate of effect (ROR 0.87, 95\% CI: 0.76–1.00). Where allocation concealment for double-blind trials was unclear, the ROR is 0.86 (95\% CI: 0.78–0.96) and if not hidden, the ROR is 0.89 (95\% CI: 0.70–1.15).  Conclusion  Sealed envelopes with some form of enhancement (opaque, sequentially numbered, and so forth) may give adequate concealment. Description of a study as "double blind" does not imply a lack of bias when concealment of allocation is unclear."},
  citeulike-article-id = {13265903},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2010.12.018},
  citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/pii/S0895435611000163},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {allocation-concealment,bias,blinding,meta-analysis,meta-epidemiology,randomized-trials}
}

@article{her90,
  title = {An Analysis of Gestational Age, Neonatal Size and Neonatal Death Using Nonparametric Logistic Regression},
  author = {Herman, A. A. and Hastie, T. J.},
  date = {1990},
  journaltitle = {J Clin Epi},
  volume = {43},
  pages = {1179--1190},
  citeulike-article-id = {13264287},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {distribution-free-methods,logistic-model-extensions}
}

@article{her90res,
  title = {The Restricted Cubic Spline Hazard Model},
  author = {Herndon, James E. and Harrell, Frank E.},
  date = {1990},
  journaltitle = {Comm Stat Th Meth},
  volume = {19},
  pages = {639--663},
  citeulike-article-id = {13264288},
  posted-at = {2014-07-14 14:09:32},
  priority = {0}
}

@article{her95res,
  title = {The Restricted Cubic Spline as Baseline Hazard in the Proportional Hazards Model with Step Function Time-Dependent Covariables},
  author = {Herndon, James E. and Harrell, Frank E.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2119--2129},
  citeulike-article-id = {13264289},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {ph-model,restricted-cubic-spline,spline,tdc}
}

@article{her97val,
  title = {Validity and Efficiency of Approximation Methods for Tied Survival Times in {{Cox}} Regression},
  author = {Hertz-Picciotto, Irva and Rockhill, Beverly},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {1151--1156},
  citeulike-article-id = {13264290},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {breslow-approximation,cox-model,discrete-failure-times,efron-approximation,simulation-setup,tied-failure-times}
}

@article{hes94ass,
  title = {Assessing Time-by-Covariate Interactions in Proportional Hazards Regression Models Using Cubic Spline Functions},
  author = {Hess, Kenneth R.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1045--1062},
  citeulike-article-id = {13264291},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {graphical-methods,ph,spline,tdc}
}

@article{hes95gra,
  title = {Graphical Methods for Assessing Violations of the Proportional Hazards Assumption in {{Cox}} Regression},
  author = {Hess, Kenneth R.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1707--1723},
  citeulike-article-id = {13264292},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {assessing-ph,cox-ph-model,graphical-methods,residual-plots}
}

@article{hia90cos,
  title = {The Cost of Acquired Immunodeficiency Syndrome in {{Northern California}}},
  author = {Hiatt, Robert A. and Quesenberry, Charles P. and Selby, Joseph V. and Fireman, Bruce H. and Knight, Anthony},
  date = {1990},
  journaltitle = {Arc Int Med},
  volume = {150},
  pages = {833--838},
  citeulike-article-id = {13264293},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {analysis-of-financial-data,censoring-on-alive,charges,costs,lifetime-costs}
}

@article{hic88cur,
  title = {Current Prognosis of Ischemic Mitral Regurgitation: Implications for Future Management},
  author = {Hickey, M. S. and Smith, L. R. and Muhlbaier, L. H. and Harrell, F. E. and Reves, J. G. and Hinohara, T. and Califf, R. M. and Pryor, D. B. and Rankin, J. S.},
  date = {1988},
  journaltitle = {Circ},
  volume = {78 Suppl I},
  pages = {51--59},
  citeulike-article-id = {13264294},
  posted-at = {2014-07-14 14:09:32},
  priority = {0}
}

@article{hie10pro,
  title = {On the Prognostic Value of Survival Models with Application to Gene Expression Signatures},
  author = {Hielscher, T. and Zucknick, M. and Werft, W. and Benner, A.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {818--829},
  citeulike-article-id = {13265805},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {censored-data,explained-variation-of-survival-models,graphics,high-dimensional-r2,predictive-accuracy,software},
  note = {a model for excellent graphics and analysis of simulation results, including variable clustering}
}

@article{hig02bei,
  title = {Being Sceptical about Meta-Analyses: A {{Bayesian}} Perspective on Magnesium Trials in Myocardial Infarction},
  shorttitle = {Being Sceptical about Meta-Analyses},
  author = {Higgins, Julian PT and Spiegelhalter, David J.},
  date = {2002-02-01},
  journaltitle = {Int J Epidemiol},
  volume = {31},
  number = {1},
  pages = {96--104},
  issn = {0300-5771},
  doi = {10.1093/ije/31.1.96},
  url = {https://academic.oup.com/ije/article/31/1/96/655931},
  urldate = {2019-09-07},
  abstract = {Abstract.  Background There has been extensive discussion of the apparent conflict between meta-analyses and a mega-trial investigating the benefits of intraven},
  langid = {english},
  keywords = {empirical-bayes,hierarchical-bayes-model,hierarchical-model,meta-analysis},
  note = {magnesium}
}

@article{hij20ass,
  title = {Association of {{Different Estimates}} of {{Renal Function With Cardiovascular Mortality}} and {{Bleeding}} in {{Atrial Fibrillation}}},
  author = {{Hijazi Ziad} and {Granger Christopher B.} and {Hohnloser Stefan H.} and {Westerbergh Johan} and {Lindbäck Johan} and {Alexander John H.} and {Keltai Matyas} and {Parkhomenko Alexander} and {López-Sendón José L.} and {Lopes Renato D.} and {Siegbahn Agneta} and {Wallentin Lars}},
  date = {2020-09-15},
  journaltitle = {Journal of the American Heart Association},
  volume = {9},
  number = {18},
  pages = {e017155},
  publisher = {{American Heart Association}},
  doi = {10.1161/JAHA.120.017155},
  url = {http://www.ahajournals.org/doi/10.1161/JAHA.120.017155},
  urldate = {2021-01-27},
  abstract = {BackgroundWe compared different methods of estimated glomerular filtration rate (eGFR) and their association with cardiovascular death and major bleeding in 14~980 patients with atrial fibrillation in the ARISTOTLE (Apixaban for Reduction in Stroke and Other Thromboembolic Events in Atrial Fibrillation) trial.Methods and ResultseGFR was calculated using equations based on creatinine (Cockcroft‐Gault, Modification of Diet in Renal Disease, and Chronic Kidney Disease Epidemiology Collaboration [CKD‐EPI]) and/or cystatin C (CKD‐EPICysC and CKD‐EPICysC+Creatinine). These 5 eGFR equations, as well as the individual variables that are used in these equations, were assessed for correlation and discriminatory ability for cardiovascular death and major bleeding. The median age was 70.0~years, and 35.6\% were women. The median eGFR was highest with Cockcroft‐Gault (74.1 mL/min) and CKD‐EPICysC (74.2 mL/min), and lowest with Modification of Diet in Renal Disease (66.5 mL/min). Correlation between methods ranged from 0.49 (Cockroft‐Gault and CKD‐EPICysC) to 0.99 (Modification of Diet in Renal Disease and CKD‐EPI). Among the eGFR equations, those based on cystatin C yielded the highest C indices for cardiovascular death and major bleeding: 0.628 (CKD‐EPICysC) and 0.612 (CKD‐EPICysC+Creatinine), respectively. A model based on the variables within the different eGFR equations (age, sex, weight, creatinine, and cystatin C) yielded the highest discriminatory value for both outcomes, with a C index of 0.673 and 0.656, respectively.ConclusionsIn patients with atrial fibrillation on anticoagulation, correlation between eGFR calculated using different methods varied substantially. Cystatin C–based eGFRs seem to provide the most robust information for predicting death and bleeding. A model based on the individual variables within the eGFR equations, however, provided the highest discriminatory value. Our findings may help refine risk stratification in patients with atrial fibrillation and define how renal function should be determined in future atrial fibrillation studies.RegistrationURL: https://www.clini\hspace{0pt}caltr\hspace{0pt}ials.gov; Unique identifier: NCT00412984.},
  keywords = {measurement,medical,nephrology}
}

@article{hil03eff,
  title = {Effect Measures in Biostatistics},
  author = {Hilden, Jorgen},
  date = {2003},
  journaltitle = {J Clin Epi},
  volume = {56},
  pages = {391--393},
  citeulike-article-id = {13265329},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {effect-measures},
  annotation = {Letter to the editor},
  note = {see the rebuttal which follows by Sander Greenland}
}

@article{hil13int,
  title = {Intravenous Glial Growth Factor 2 ({{GGF2}}) Isoform of Neuregulin-{{1Î}}² Improves Left Ventricular Function, Gene and Protein Expression in Rats after Myocardial Infarction},
  author = {Hill, M. F. and Patel, A. V. and Murphy, A. and Smith, H. M. and Galindo, C. L. and Pentassuglia, L. and Peng, X. and Lenneman, C. G. and Odiete, O. and Friedman, D. B. and Kronenberg, M. W. and Zheng, S. and Zhao, Z. and Song, Y. and Harrell, F. E. and Srinivas, M. and Ganguly, A. and Iaci, J. and Parry, T. J. and Caggiano, A. O. and Sawyer, D. B.},
  date = {2013},
  journaltitle = {PLoS ONE},
  volume = {8},
  number = {2},
  doi = {doi:\%2010.1371/journal.pone.0055741},
  url = {http://dx.doi.org/doi:%2010.1371/journal.pone.0055741},
  citeulike-article-id = {13265987},
  citeulike-linkout-0 = {http://dx.doi.org/doi:%2010.1371/journal.pone.0055741},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{hil14not,
  title = {A Note on the Evaluation of Novel Biomarkers: Do Not Rely on Integrated Discrimination Improvement and Net Reclassification Index.},
  author = {Hilden, Jørgen and Gerds, Thomas A.},
  date = {2014-08},
  journaltitle = {Stat Med},
  volume = {33},
  number = {19},
  eprint = {23553436},
  eprinttype = {pmid},
  pages = {3405--3414},
  publisher = {John Wiley & Sons, Ltd},
  issn = {1097-0258},
  doi = {10.1002/sim.5804},
  url = {http://dx.doi.org/10.1002/sim.5804},
  abstract = {The 'integrated discrimination improvement' (IDI) and the 'net reclassification index' (NRI) are statistics proposed as measures of the incremental prognostic impact that a new biomarker will have when added to an existing prediction model for a binary outcome. By design, both measures were meant to be intuitively appropriate, and the IDI and NRI formulae do look intuitively plausible. Both have become increasingly popular. We shall argue, however, that their use is not always safe. If IDI and NRI are used to measure gain in prediction performance, then poorly calibrated models may appear advantageous, and in a simulation study, even the model that actually generates the data (and hence is the best possible model) can be improved on without adding measured information. We illustrate these shortcomings in actual cancer data as well as by Monte Carlo simulations. In these examples, we contrast IDI and NRI with the area under ROC and the Brier score. Unlike IDI and NRI, these traditional measures have the characteristic that prognostic performance cannot be accidentally or deliberately inflated. Copyright  2013 John Wiley \& Sons, Ltd.},
  citeulike-article-id = {12313020},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5804},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/23553436},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=23553436},
  day = {30},
  posted-at = {2015-04-14 13:58:18},
  priority = {2},
  keywords = {accuracy,reclassification-table}
}

@article{hil95res,
  title = {Residual Plots for the Censored Data Linear Regression Model},
  author = {Hillis, Stephen L.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2023--2036},
  citeulike-article-id = {13264295},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {aft-model,buckley-james-model,censored-least-squares,residual-plots}
}

@article{hil96pra,
  title = {Practical P-Value Adjustment for Optimally Selected Cutpoints},
  author = {Hilsenbeck, S. G. and Clark, G. M.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {103--112},
  citeulike-article-id = {13264296},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {cutpoints,dichotimizing-continuous-variables,teaching-mds}
}

@article{hin86rel,
  title = {Relation between Electrocardiographic and Enzymatic Methods of Estimating Acute Myocardial Infarct Size},
  author = {Hindman, N. and Grande, P. and Harrell, F. E. and Anderson, C. and Harrison, D. and Ideker, R. E. and Selvester, R. H. and Wagner, G. S.},
  date = {1986},
  journaltitle = {Am J Card},
  volume = {58},
  pages = {31--35},
  citeulike-article-id = {13265362},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{hin87can,
  title = {Canonical Likelihoods: {{A}} New Likelihood Treatment of Nuisance Parameters},
  author = {{Hinde}},
  date = {1987},
  journaltitle = {Biometrika},
  volume = {74},
  pages = {45--58},
  citeulike-article-id = {13264297},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {maximum-likelihood}
}

@article{hin87qui,
  title = {Quick Graphical Power-Law Transformation Selection},
  author = {Hines WGS, Hines R. J. O.},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {21--24},
  citeulike-article-id = {13264298},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {general,graphical-methods,regression}
}

@article{hin98vio,
  title = {Violin Plots: {{A}} Box Plot-Density Trace Synergism},
  author = {Hintze, Jerry L. and Nelson, Ray D.},
  date = {1998},
  journaltitle = {Am Statistician},
  volume = {52},
  pages = {181--184},
  citeulike-article-id = {13264299},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {box-plot,density,depends-on-choice-of-bin-width-for-estimating-density-trace,graphics}
}

@article{hip07reg,
  title = {Regression with Missing {{Ys}}: {{An}} Improved Strategy for Analyzing Multiple Imputed Data},
  author = {von Hippel, Paul T.},
  options = {useprefix=true},
  date = {2007},
  journaltitle = {Soc Meth},
  volume = {37},
  number = {1},
  pages = {83--117},
  abstract = {When fitting a generalized linear model--such as linear regression, logistic regression, or hierarchical linear modeling--analysts often wonder how to handle missing values of the dependent variable Y. If missing values have been filled in using multiple imputation, the usual advice is to use the imputed Y values in analysis. We show, however, that using imputed Ys can add needless noise to the estimates. Better estimates can usually be obtained using a modified strategy that we call multiple imputation, then deletion (MID). Under MID, all cases are used for imputation, but following imputation cases with imputed Y values are excluded from the analysis. When there is something wrong with the imputed Y values, MID protects the estimates from the problematic imputations. And when the imputed Y values are acceptable, MID usually offers somewhat more efficient estimates than an ordinary MI strategy. From Peter Lachenbruch: Going back to Bruce Weaver's comment, I've finished reading van Hippel's paper and the argument is 1. Use all variables to impute all others - this will include the y variable - i.e. a y that is present carries information on the missing x values. 2. After the imputation step, remove all cases in which the y value is missing. The reason for this is that these cases carry no information about the regression of y on the x values. The math for this is outlined in van Hippel's paper. The y values do carry information about the x values (whether missing or not) and so can be used for the imputation. Once imputation is complete, the imputed y values carry no information for the regression - and add nothing further. Thus, by deleting these observations, we obtain a slightly better prediction. In his paper, the simulations are based on normal distributions, and the improvement is small. Nothing was said about imputation and prediction for non-normal (e.g., binary or poisson) cases. Still an open question. 3. For the query posted by Irene Zeng: Missing at baseline is always a pain in the neck, but if you have plenty of other times, you can impute the baseline and then use your Kaplan-Meier estimate (or a proportional hazards model). Using means is almost always a bad idea, and even worse is last observation carried forward (or first observation carried backward).},
  citeulike-article-id = {13265799},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {missing-data,missing-y,multiple-imputation}
}

@unpublished{hip16num,
  title = {The Number of Imputations Should Increase Quadratically with the Fraction of Missing Information},
  author = {von Hippel, Paul T.},
  options = {useprefix=true},
  date = {2016-08},
  eprint = {1608.05406},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1608.05406},
  abstract = {Users of multiple imputation often want to know how many imputations they need. An old answer is that 3 to 10 imputations usually suffice, but this recommendation only addresses the efficiency of point estimates. If users also want replicable standard errors, users often need more imputations. A popular rule is that the required number of imputations increases linearly with the fraction of missing information, but we show that, in fact, the number of imputations increases quadratically with the fraction of missing information. This quadratic relationship implies that users should add imputations until the degrees of freedom in the standard errors exceeds some threshold (e.g., 200). We suggest a two-step procedure in which the user conducts a pilot analysis using a small number of imputations and then uses the results to calculate the number of imputations that are needed for a final analysis to have the desired degrees of freedom.},
  archiveprefix = {arXiv},
  citeulike-article-id = {14314910},
  citeulike-attachment-1 = {hip16num.pdf; /pdf/user/harrelfe/article/14314910/1105156/hip16num.pdf; 7e463a20e640452205c2d55ceb271213ef8fe059},
  citeulike-linkout-0 = {http://arxiv.org/abs/1608.05406},
  citeulike-linkout-1 = {http://arxiv.org/pdf/1608.05406},
  day = {17},
  posted-at = {2017-03-20 20:44:10},
  priority = {0},
  keywords = {missing-data,multiple-imputation}
}

@article{hir87,
  title = {Computing Distributions for Exact Logistic Regression},
  author = {Hirji KF, Patel N. R.},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {1110--1117},
  citeulike-article-id = {13264300},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,statistical-computation-algorithms}
}

@article{hjo90,
  title = {Goodness of Fit Tests in Models for Life History Data Based on Cumulative Hazard Rates},
  author = {Nl, Hjort},
  date = {1990},
  journaltitle = {Ann Stat},
  volume = {18},
  pages = {1221--1258},
  citeulike-article-id = {13264301},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {general,survival-analysis-regression}
}

@article{hla09cri,
  title = {Criteria for Evaluation of Novel Markers of Cardiovascular Risk: A Scientific Statement from the {{American Heart Association}}},
  author = {Hlatky, M. A. and Greenland, P. and Arnett, D. K. and Ballantyne, C. M. and Criqui, M. H. and Elkind, M. S. and Go, A. S. and Harrell, F. E. and Hong, Y. and Howard, B. V. and Howard, V. J. and Hsue, P. Y. and Kramer, C. M. and McConnell, J. P. and Normand, S. L. and O'Donnell, C. J. and Smith, S. C. and Wilson, P. W.},
  date = {2009},
  journaltitle = {Circ},
  volume = {119},
  number = {17},
  pages = {2408--2416},
  citeulike-article-id = {13265779},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {biomarker-research,post--vs-pre-test-probability,predictive-accuracy},
  annotation = {American Heart Association Expert Panel on Subclinical Atherosclerotic Diseases and Emerging Risk Factors and the Stroke Council},
  note = {graph with different symbols for diseased and non-diseased}
}

@article{hla83nat,
  title = {Natural History of Patients with Single-Vessel Disease Suitable for Percutaneous Transluminal Coronary Angioplasty},
  author = {Hlatky, M. A. and Califf, R. M. and Kong, Y. and Harrell, F. E. and Rosati, R. A.},
  date = {1983},
  journaltitle = {Am J Card},
  volume = {52},
  pages = {225--229},
  citeulike-article-id = {13264302},
  posted-at = {2014-07-14 14:09:32},
  priority = {0}
}

@article{hla84fac,
  title = {Factors Affecting the Sensitivity and Specificity of Exercise Electrocardiography. {{Multivariable}} Analysis},
  author = {Hlatky, M. A. and Pryor, D. B. and Harrell, F. E. and Califf, R. M. and Mark, D. B. and Rosati, R. A.},
  date = {1984},
  journaltitle = {Am J Med},
  volume = {77},
  pages = {64--71},
  url = {http://www.sciencedirect.com/science/article/pii/0002934384904376#},
  citeulike-article-id = {13264303},
  citeulike-attachment-1 = {hlatky₈4<sub>f</sub>actors₉76652.pdf; /pdf/user/harrelfe/article/13264303/976652/hlatky₈4<sub>f</sub>actors₉76652.pdf; d9105c885bc73798ea3b8e6abc911d672f938291},
  citeulike-linkout-0 = {http://www.sciencedirect.com/science/article/pii/0002934384904376#},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {diagnosis,non-constancy-of-sensitivity-and-specificity,sensitivity,specificity,teaching-mds}
}

@article{hla84tyi,
  title = {Tying Clinical Research to Patient Care by Use of an Observational Database},
  author = {Hlatky, M. A. and Lee, K. L. and Harrell, F. E. and Califf, R. M. and Pryor, D. B. and Mark, D. B. and Rosati, R. A.},
  date = {1984},
  journaltitle = {Stat Med},
  volume = {3},
  pages = {375--384},
  citeulike-article-id = {13264304},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {observational-study}
}

@article{hla87ret,
  title = {Rethinking Sensitivity and Specificity},
  author = {Hlatky, M. A. and Mark, D. B. and Harrell, F. E. and Lee, K. L. and Califf, R. M. and Pryor, D. B.},
  date = {1987},
  journaltitle = {Am J Card},
  volume = {59},
  pages = {1195--1198},
  citeulike-article-id = {13264305},
  posted-at = {2014-07-14 14:09:32},
  priority = {0}
}

@article{hla88com,
  title = {Comparison of Predictions Based on Observational Data with the Results of Randomized Controlled Clinical Trials of Coronary Atery Bypass Surgery},
  author = {Hlatky, M. A. and Califf, R. M. and Harrell, F. E. and {Others}},
  date = {1988},
  journaltitle = {J Am Coll Cardiol},
  volume = {11},
  pages = {237--245},
  citeulike-article-id = {13264306},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  annotation = {See commentary in L. B. Russell  Stat in Med 18:3235-3244, 1999}
}

@article{hla90cli,
  title = {Clinical Judgment and Therapeutic Decision Making},
  author = {Hlatky, M. A. and Califf, R. M. and Harrell, F. E. and Lee, K. L. and Mark, D. B. and Muhlbaier, L. H. and Pryor, D. B.},
  date = {1990},
  journaltitle = {J Am Coll Cardiol},
  volume = {15},
  pages = {1--14},
  citeulike-article-id = {13264307},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  annotation = {Also published in \emph{An Era of Cardiovascular Medicine}, Suzanne B. Knoebel, MD and Simon Dack, MD, editors. Chapter 26, 303-315, 1991.}
}

@article{hla97lon,
  title = {Long-Term Cost-Effectiveness of Alternative Management Strategies for Patients with Life-Threatening Ventricular Arrhythmias},
  author = {Hlatky, Mark A. and Boothroyd, Derek B. and Johnstone, Iain M. and Marcus, Frank I. and Hahn, Elizabeth and Hartz, Vernon and Mason, Jay W. and Investigators, The E.},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {185--193},
  citeulike-article-id = {13264308},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {analysis-of-cost,bootstrap,c-e,cost-effectiveness-ratio},
  note = {nice display of joint variation of numerator and denominator, using the bootstrap;use of administrative databases to supplement clinical trial data for economic analysis;using bootstrap to estimate probability that c-e ratio is below a threshold}
}

@article{hoc88sha,
  title = {A Sharper {{Bonferroni}} Procedure for Multiple Tests of Significance},
  author = {Hochberg, Yosef},
  date = {1988},
  journaltitle = {Biometrika},
  volume = {75},
  pages = {800--802},
  citeulike-article-id = {13264310},
  posted-at = {2014-07-14 14:09:32},
  priority = {0},
  keywords = {bonferroni,multiple-comparisons,p-value-adjustment}
}

@article{hoc90mor,
  title = {More Powerful Procedures for Multiple Significance Testing},
  author = {Hochberg, Yosef and Benjamini, Yoav},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {811--818},
  citeulike-article-id = {13264311},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {multiple-comparisons,p-values}
}

@article{hoe48cla,
  title = {A Class of Statistics with Asymptotically Normal Distributions},
  author = {Hoeffding, Wassily},
  date = {1948},
  journaltitle = {Ann Math Stat},
  volume = {19},
  pages = {293--325},
  citeulike-article-id = {13265814},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  note = {Partially reprinted in: Kotz, S., Johnson, N.L. (1992) Breakthroughs in Statistics, Vol I, pp 308-334. Springer-Verlag. ISBN 0-387-94037-5}
}

@article{hoe48non,
  title = {A Non-Parametric Test of Independence},
  author = {Hoeffding, W.},
  date = {1948},
  journaltitle = {Ann Math Stat},
  volume = {19},
  pages = {546--557},
  citeulike-article-id = {13264312},
  posted-at = {2014-07-14 14:09:33},
  priority = {0}
}

@article{hof21mul,
  title = {The Multiplicity of Analysis Strategies Jeopardizes Replicability: Lessons Learned across Disciplines},
  shorttitle = {The Multiplicity of Analysis Strategies Jeopardizes Replicability},
  author = {Hoffmann, Sabine and Schönbrodt, Felix and Elsas, Ralf and Wilson, Rory and Strasser, Ulrich and Boulesteix, Anne-Laure},
  date = {2021},
  journaltitle = {Royal Society Open Science},
  volume = {8},
  number = {4},
  pages = {201925},
  publisher = {{Royal Society}},
  doi = {10.1098/rsos.201925},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsos.201925},
  urldate = {2021-06-18},
  abstract = {For a given research question, there are usually a large variety of possible analysis strategies acceptable according to the scientific standards of the field, and there are concerns that this multiplicity of analysis strategies plays an important role in the non-replicability of research findings. Here, we define a general framework on common sources of uncertainty arising in computational analyses that lead to this multiplicity, and apply this framework within an overview of approaches proposed across disciplines to address the issue. Armed with this framework, and a set of recommendations derived therefrom, researchers will be able to recognize strategies applicable to their field and use them to generate findings more likely to be replicated in future studies, ultimately improving the credibility of the scientific process.},
  keywords = {model,reproducibility}
}

@inproceedings{hof85sim,
  title = {Simulated Temporal Models for Proportional Hazards Models with Time Varying Covariates},
  booktitle = {Proceedings of the {{Statistical Computing Section ASA}}},
  author = {Hoffman, R. G.},
  date = {1985},
  pages = {390--395},
  citeulike-article-id = {13264313},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {tdc}
}

@article{hof99sim,
  title = {Simpson on Board the {{Titanic}}? {{Interactive}} Methods for Dealing with Multivariate Categorical Data.},
  author = {Hofmann, Heike},
  date = {1999},
  journaltitle = {Stat Comp Graphics News ASA},
  volume = {9},
  number = {2},
  pages = {16--19},
  citeulike-article-id = {13265153},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {graphical-analysis-of-titanic},
  annotation = {http://stat-computing.org/newsletter/issues/scgn-09-2.pdf}
}

@article{hog97mix,
  title = {Mixture Models for the Joint Distribution of Repeated Measures and Event Times},
  author = {Hogan, Joseph W. and Laird, Nan M.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {239--257},
  citeulike-article-id = {13264314},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {informative-censoring,longitudinal-data,multiple-events,outcome-related-dropout,repeated-measures}
}

@article{hog97mod,
  title = {Model-Based Approaches to Analysing Incomplete Longitudinal and Failure Time Data},
  author = {Hogan, Joseph W. and Laird, Nan M.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {259--272},
  citeulike-article-id = {13264315},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {informative-censoring,longitudinal-data,multiple-events,outcome-related-dropout,repeated-measures}
}

@article{hol04con,
  title = {Confidence Intervals for the Effect of a Prognostic Factor after Selection of an `optimal' Cutpoint},
  author = {Holländer, Norbert and Sauerbrei, Willi and Schumacher, Martin},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  pages = {1701--1713},
  doi = {10.1002/sim.1611},
  url = {http://dx.doi.org/10.1002/sim.1611},
  citeulike-article-id = {13265374},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.1611},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {categorization,cutpoints,teaching-mds},
  note = {true type I error can be much greater than nominal level;one example where nominal is 0.05 and true is 0.5;minimum P-value method;CART;recursive partitioning;bootstrap method for correcting confidence interval;based on heuristic shrinkage coefficient;"It should be noted, however, that the optimal cutpoint approach has disadvantages. One of these is that in almost every study where this method is applied, another cutpoint will emerge. This makes comparisons across studies extremely difficult or even impossible. Altman et al. point out this problem for studies of the prognostic relevance of the S-phase fraction in breast cancer published in the literature. They identified 19 different cutpoints used in the literature; some of them were solely used because they emerged as the `optimal' cutpoint in a specific data set. In a meta-analysis on the relationship between cathepsin-D content and disease-free survival in node-negative breast cancer patients, 12 studies were in included with 12 different cutpoints ... Interestingly, neither cathepsin-D nor the S-phase fraction are recommended to be used as prognostic markers in breast cancer in the recent update of the American Society of Clinical Oncology."; dichotomization; categorizing continuous variables; refs alt94dan, sch94out, alt98sub}
}

@article{hol14eff,
  title = {Effect of {{Flexible Sigmoidoscopy Screening}} on {{Colorectal Cancer Incidence}} and {{Mortality}}},
  author = {Holme, Øyvind and Løberg, Magnus and Kalager, Mette and Bretthauer, Michael and Hernán, Miguel A. and Aas, Eline and Eide, Tor J. and Skovlund, Eva and Schneede, Jørn and Tveit, Kjell M. and Hoff, Geir},
  date = {2014-08},
  journaltitle = {JAMA},
  volume = {312},
  number = {6},
  pages = {606+},
  issn = {0098-7484},
  doi = {10.1001/jama.2014.8266},
  url = {http://dx.doi.org/10.1001/jama.2014.8266},
  citeulike-article-id = {14560777},
  citeulike-attachment-1 = {hol14eff.pdf; /pdf/user/harrelfe/article/14560777/1133295/hol14eff.pdf; 92ee32858e9312f8168bf0b1e1d9fb2e0ae5be7e},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.2014.8266},
  day = {13},
  posted-at = {2018-04-03 17:32:45},
  priority = {2},
  keywords = {compliance,instrumental-variables,nonadherence,rct}
}

@article{hol97is,
  title = {Is There a Gain from “Chance Corrected” Measures of Diagnostic Validity?},
  author = {Holle, Rolf and Windeler, Jürgen},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {117--120},
  citeulike-article-id = {13264316},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {accuracy,chance-corrected-roc-curve,chance-corrected-sensitivity-and-specificity,chance-correction,diagnosis,kappa}
}

@article{hol97lik,
  title = {Likelihood Ratio-Based Confidence Bands for Survival Functions},
  author = {Hollander, Myles and McKeague, Ian W. and Yang, Jie},
  date = {1997},
  journaltitle = {J Am Stat Assoc},
  volume = {92},
  pages = {215--226},
  citeulike-article-id = {13264317},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {maximum-likelihood-based-confidence-bands,simultaneous-confidence-bands-for-st}
}

@book{hollwolf,
  title = {Nonparametric {{Statistical Methods}}},
  author = {Hollander, Myles and Wolfe, Douglas A.},
  date = {1999},
  edition = {second},
  publisher = {{Wiley}},
  citeulike-article-id = {13265373},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{hom01cli,
  title = {Clinical Trials with an Adaptive Choice of Hypotheses},
  author = {Hommel, G. and Kropf, S.},
  date = {2001},
  journaltitle = {Drug Info J},
  volume = {33},
  pages = {1205--1218},
  citeulike-article-id = {13265504},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{hom89,
  title = {A Comparison of Two Modified {{Bonferroni}} Procedures},
  author = {Hommel, G.},
  date = {1989},
  journaltitle = {Biometrika},
  volume = {76},
  pages = {624--625},
  citeulike-article-id = {13264318},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {miscellaneous}
}

@article{hon90car,
  title = {Cardiac Rupture, Mortality, and the Timing of Thrombolytic Therapy: {{A}} Meta-Analysis},
  author = {Honan, M. B. and Harrell, F. E. and Reimer, K. A. and Califf, R. M. and Mark, D. B. and Pryor, D. B. and Hlatky, M. A.},
  date = {1990},
  journaltitle = {J Am Coll Cardiol},
  volume = {16},
  pages = {359--367},
  citeulike-article-id = {13264319},
  posted-at = {2014-07-14 14:09:33},
  priority = {0}
}

@article{hoo14ass,
  title = {Assessing Calibration of Multinomial Risk Prediction Models},
  author = {Van Hoorde, Kirsten and Vergouwe, Yvonne and Timmerman, Dirk and Van Huffel, Sabine and Steyerberg, Ewout W. and Van Calster, Ben},
  date = {2014-07},
  journaltitle = {Stat Med},
  volume = {33},
  number = {15},
  pages = {2585--2596},
  doi = {10.1002/sim.6114},
  url = {http://dx.doi.org/10.1002/sim.6114},
  abstract = {Calibration, that is, whether observed outcomes agree with predicted risks, is important when evaluating risk prediction models. For dichotomous outcomes, several tools exist to assess different aspects of model calibration, such as calibration-in-the-large, logistic recalibration, and (non-)parametric calibration plots. We aim to extend these tools to prediction models for polytomous outcomes. We focus on models developed using multinomial logistic regression (MLR): outcome Y with k categories is predicted using k\,−\,1 equations comparing each category i (i\,=\,2,\,...\,,k) with reference category 1 using a set of predictors, resulting in k\,−\,1 linear predictors. We propose a multinomial logistic recalibration framework that involves an MLR fit where Y is predicted using the k\,−\,1 linear predictors from the prediction model. A non-parametric alternative may use vector splines for the effects of the linear predictors. The parametric and non-parametric frameworks can be used to generate multinomial calibration plots. Further, the parametric framework can be used for the estimation and statistical testing of calibration intercepts and slopes. Two illustrative case studies are presented, one on the diagnosis of malignancy of ovarian tumors and one on residual mass diagnosis in testicular cancer patients treated with cisplatin-based chemotherapy. The risk prediction models were developed on data from 2037 and 544 patients and externally validated on 1107 and 550 patients, respectively. We conclude that calibration tools can be extended to polytomous outcomes. The polytomous calibration plots are particularly informative through the visual summary of the calibration performance.},
  citeulike-article-id = {13325627},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6114},
  day = {10},
  posted-at = {2014-11-29 16:22:44},
  priority = {2},
  keywords = {calibration,polytomous-logistic-model,polytomous-regression,polytomous-response}
}

@article{hoo16sam,
  title = {Sample Size Calculation for Stepped Wedge and Other Longitudinal Cluster Randomised Trials},
  author = {Hooper, Richard and Teerenstra, Steven and de Hoop, Esther and Eldridge, Sandra},
  options = {useprefix=true},
  date = {2016-11},
  journaltitle = {Stat Med},
  volume = {35},
  number = {26},
  pages = {4718--4728},
  issn = {02776715},
  doi = {10.1002/sim.7028},
  url = {http://dx.doi.org/10.1002/sim.7028},
  citeulike-article-id = {14240458},
  citeulike-attachment-1 = {hoo16sam.pdf; /pdf/user/harrelfe/article/14240458/1096090/hoo16sam.pdf; 0b093f61893704521c9dab12d1f74515f5846b2d},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7028},
  day = {20},
  posted-at = {2016-12-29 15:56:09},
  priority = {0},
  keywords = {cluster-randomization,crossover,crossover-study,stepped-wedge}
}

@article{hoo18ana,
  title = {Analysis of Cluster Randomised Trials with an Assessment of Outcome at Baseline},
  author = {Hooper, Richard and Forbes, Andrew and Hemming, Karla and Takeda, Andrea and Beresford, Lee},
  date = {2018-03},
  journaltitle = {BMJ},
  volume = {360},
  eprint = {29559436},
  eprinttype = {pmid},
  pages = {k1121+},
  publisher = {British Medical Journal Publishing Group},
  issn = {1756-1833},
  doi = {10.1136/bmj.k1121},
  url = {http://dx.doi.org/10.1136/bmj.k1121},
  citeulike-article-id = {14555037},
  citeulike-attachment-1 = {hoo18ana.pdf; /pdf/user/harrelfe/article/14555037/1132673/hoo18ana.pdf; d7bde895f15041d6c80b564d9e45881f15598967},
  citeulike-linkout-0 = {http://dx.doi.org/10.1136/bmj.k1121},
  citeulike-linkout-1 = {http://www.bmj.com/content/360/bmj.k1121.abstract},
  citeulike-linkout-2 = {http://www.bmj.com/content/360/bmj.k1121.full.pdf},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/29559436},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=29559436},
  day = {20},
  posted-at = {2018-03-23 13:02:00},
  priority = {2},
  keywords = {ancova,cluster-randomization,cluster-randomized-trial,rct}
}

@article{hoo20han,
  title = {Handling Missing Predictor Values When Validating and Applying a Prediction Model to New Patients},
  author = {Hoogland, Jeroen and van Barreveld, Marit and Debray, Thomas P. A. and Reitsma, Johannes B. and Verstraelen, Tom E. and Dijkgraaf, Marcel G. W. and Zwinderman, Aeilko H.},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8682},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8682},
  urldate = {2020-07-23},
  abstract = {Missing data present challenges for development and real-world application of clinical prediction models. While these challenges have received considerable attention in the development setting, there is only sparse research on the handling of missing data in applied settings. The main unique feature of handling missing data in these settings is that missing data methods have to be performed for a single new individual, precluding direct application of mainstay methods used during model development. Correspondingly, we propose that it is desirable to perform model validation using missing data methods that transfer to practice in single new patients. This article compares existing and new methods to account for missing data for a new individual in the context of prediction. These methods are based on (i) submodels based on observed data only, (ii) marginalization over the missing variables, or (iii) imputation based on fully conditional specification (also known as chained equations). They were compared in an internal validation setting to highlight the use of missing data methods that transfer to practice while validating a model. As a reference, they were compared to the use of multiple imputation by chained equations in a set of test patients, because this has been used in validation studies in the past. The methods were evaluated in a simulation study where performance was measured by means of optimism corrected C-statistic and mean squared prediction error. Furthermore, they were applied in data from a large Dutch cohort of prophylactic implantable cardioverter defibrillator patients.},
  langid = {english},
  keywords = {missing,prediction},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8682}
}

@article{hoo21key,
  title = {Key Concepts in Clinical Epidemiology: {{Stepped}} Wedge Trials},
  shorttitle = {Key Concepts in Clinical Epidemiology},
  author = {Hooper, Richard},
  date = {2021-04-19},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.04.003},
  url = {https://www.jclinepi.com/article/S0895-4356(21)00119-0/abstract},
  urldate = {2021-04-21},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}p{$>$}A stepped wedge trial evaluates an intervention that is implemented over a number of time periods according to a staggered timetable. Stepped wedge trials are usually cluster randomised, the intervention being delivered at some geographical, service or other cluster level. There is considerable variety in the design and conduct of stepped wedge trials in practice. The analysis of a stepped wedge trial often assumes that the effect of the intervention is maintained at a constant level once it has been implemented. It is important when estimating this effect to adjust for a period effect or underlying secular trend, since time is confounded with intervention, and to account for the clustering of outcomes. The advantage often cited for a stepped wedge design is that every cluster ends up getting the intervention, though in any trial design we can offer the intervention preferentially to control clusters after the trial has finished. The real advantage of a stepped wedge design is likely to be practicality or statistical efficiency.{$<$}/p{$>$}},
  langid = {english},
  keywords = {cluster-randomization,cluster-randomized-trial,rct,stepped-wedge}
}

@article{hoo21tut,
  title = {A Tutorial on Individualized Treatment Effect Prediction from Randomized Trials with a Binary Endpoint},
  author = {Hoogland, Jeroen and IntHout, Joanna and Belias, Michail and Rovers, Maroeska M. and Riley, Richard D. and Jr, Frank E. Harrell and Moons, Karel G. M. and Debray, Thomas P. A. and Reitsma, Johannes B.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9154},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9154},
  urldate = {2021-08-17},
  abstract = {Randomized trials typically estimate average relative treatment effects, but decisions on the benefit of a treatment are possibly better informed by more individualized predictions of the absolute treatment effect. In case of a binary outcome, these predictions of absolute individualized treatment effect require knowledge of the individual's risk without treatment and incorporation of a possibly differential treatment effect (ie, varying with patient characteristics). In this article, we lay out the causal structure of individualized treatment effect in terms of potential outcomes and describe the required assumptions that underlie a causal interpretation of its prediction. Subsequently, we describe regression models and model estimation techniques that can be used to move from average to more individualized treatment effect predictions. We focus mainly on logistic regression-based methods that are both well-known and naturally provide the required probabilistic estimates. We incorporate key components from both causal inference and prediction research to arrive at individualized treatment effect predictions. While the separate components are well known, their successful amalgamation is very much an ongoing field of research. We cut the problem down to its essentials in the setting of a randomized trial, discuss the importance of a clear definition of the estimand of interest, provide insight into the required assumptions, and give guidance with respect to modeling and estimation options. Simulated data illustrate the potential of different modeling options across scenarios that vary both average treatment effect and treatment effect heterogeneity. Two applied examples illustrate individualized treatment effect prediction in randomized trial data.},
  langid = {english},
  keywords = {accuracy,personalized-medicine,prediction,treatment-comparisons},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9154}
}

@article{hor01cli,
  title = {The Clinical Trial: {{Deceitful}}, Disputable, Unbelievable, Unhelpful, and Shameful---{{What}} Next?},
  author = {Horton, Richard},
  date = {2001},
  journaltitle = {Controlled Clin Trials},
  volume = {22},
  pages = {593--604},
  citeulike-article-id = {13265250},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {absolute,bad,fraud,rct,relative}
}

@article{hor01mul,
  title = {Multiple Imputation in Practice: {{Comparison}} of Software Packages for Regression Models with Missing Variables},
  author = {Horton, Nicholas J. and Lipsitz, Stuart R.},
  date = {2001},
  journaltitle = {Am Statistician},
  volume = {55},
  pages = {244--254},
  citeulike-article-id = {13265216},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {good-overview-of-multiple-imputation-including-predictive-mean-matching,mice,s-plus,sas,solas}
}

@article{hor03pot,
  title = {A Potential for Bias When Rounding in Multiple Imputation},
  author = {Horton, Nicholas J. and Lipsitz, Stuart R. and Parzen, Michael},
  date = {2003},
  journaltitle = {Am Statistician},
  volume = {57},
  pages = {229--236},
  citeulike-article-id = {13265353},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  note = {bias caused by assuming a Gaussian imputation model for binary predictors, when predicted values are rounded to the nearest integer; no bias if insert continuous predicted value into logistic response model; nice derivation of expected values after imputing, with an without rounding}
}

@article{hor07muc,
  title = {Much Ado about Nothing: {{A}} Comparison of Missing Data Methods and Software to Fit Incomplete Data Regression Models},
  author = {Horton, Nicholas J. and Kleinman, Ken P.},
  date = {2007},
  journaltitle = {Am Statistician},
  volume = {61},
  number = {1},
  pages = {79--90},
  citeulike-article-id = {13265552},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {comparison-of-several-software-packages-including-aregimpute-in-hmisc,conditional-gaussian,health-services-research,maximum-likelihood,multiple-imputation,psychiatric-epidemiology}
}

@article{hor92gen,
  title = {A Generalized Moments Specification Test of the Proportional Hazards Model},
  author = {Horowitz, J. L. and Neumann, G. R.},
  date = {1992},
  journaltitle = {J Am Stat Assoc},
  volume = {87},
  pages = {234--240},
  citeulike-article-id = {13264320},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {ph-model,test-of-ph}
}

@article{hor95des,
  title = {Designing a Cost-Effective Clinical Trial},
  author = {Hornberger, John C. and Brown, Byron W. and Halpern, Jerry},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2249--2259},
  doi = {10.1002/sim.4780142008},
  url = {http://dx.doi.org/10.1002/sim.4780142008},
  citeulike-article-id = {13264321},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780142008},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {bayes,bayesian-methods,c-e,cost-benefit,cost-effectiveness,economics,loss-function,rct,study-design,target-population}
}

@article{hos80goo,
  title = {Goodness-of-Fit Tests for the Multiple Logistic Regression Model},
  author = {Hosmer, David W. and Lemeshow, Stanley},
  date = {1980},
  journaltitle = {Comm Stat Th Meth},
  volume = {9},
  pages = {1043--1069},
  citeulike-article-id = {13264322},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {global-test,goodness-of-fit,logistic-model}
}

@book{hos89,
  title = {Applied {{Logistic Regression}}},
  author = {Hosmer, D. W. and Lemeshow, S.},
  date = {1989},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264323},
  posted-at = {2014-07-14 14:09:33},
  priority = {0}
}

@article{hos89bes,
  title = {Best Subsets Logistic Regression},
  author = {Hosmer, D. W. and Jovanovic, B. and Lemeshow, S.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {1265--1270},
  citeulike-article-id = {13264324},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,variable-selection}
}

@article{hos90,
  title = {L-Moments: {{Analysis}} and Estimation of Distributions Using Linear Combinations of Order Statistics},
  author = {Hosking, J. R. M.},
  date = {1990},
  journaltitle = {JRSS B},
  volume = {51},
  pages = {105--124},
  citeulike-article-id = {13264325},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {order-statistics,quantiles}
}

@article{hos95con,
  title = {Confidence Interval Estimates of an Index of Quality Performance Based on Logistic Regression Models},
  author = {Hosmer, David W. and Lemeshow, Stanley},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2161--2172},
  citeulike-article-id = {13264326},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {expected-mortality,mortality-models,outlier-tests},
  annotation = {See letter to editor 16:1301-3,1997},
  note = {group predictions from binary logistic model}
}

@article{hos97com,
  title = {A Comparison of Goodness-of-Fit Tests for the Logistic Regression Model},
  author = {Hosmer, D. W. and Hosmer, T. and le Cessie, S. and Lemeshow, S.},
  options = {useprefix=true},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {965--980},
  citeulike-article-id = {13264327},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {cumulative-sum-test,goodness-of-fit-for-binary-logistic-model,goodness-of-link-function,hosmer-lemeshow-test,simulation-setup},
  note = {difficulty with Hosmer-Lemeshow statistic being dependent on how groups are defined;sum of squares test (see cop89unw); invalidity of naive test based on deviance; see sta09sim}
}

@article{hot08sim,
  title = {Simultaneous Inference in General Parametric Models},
  author = {Hothorn, Torsten and Bretz, Frank and Westfall, Peter},
  date = {2008},
  journaltitle = {Biometrical J},
  volume = {50},
  number = {3},
  pages = {346--363},
  doi = {10.1002/bimj.200810425},
  url = {http://dx.doi.org/10.1002/bimj.200810425},
  abstract = {Simultaneous inference is a common problem in many areas of application. If multiple null hypotheses are tested simultaneously, the probability of rejecting erroneously at least one of them increases beyond the pre-specified significance level. Simultaneous inference procedures have to be used which adjust for multiplicity and thus control the overall type I error rate. In this paper we describe simultaneous inference procedures in general parametric models, where the experimental questions are specified through a linear combination of elemental model parameters. The framework described here is quite general and extends the canonical theory of multiple comparison procedures in ANOVA models to linear regression problems, generalized linear models, linear mixed effects models, the Cox model, robust linear models, etc. Several examples using a variety of different statistical models illustrate the breadth of the results. For the analyses we use the R add-on package multcomp, which provides a convenient interface to the general approach adopted here.},
  citeulike-article-id = {13265941},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/bimj.200810425},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {adjusted-p--values,multiple-comparisons,multiple-tests,multivariate-normal-distribution,robust-statistics,simultaneous-confidence-intervals}
}

@article{hou88log,
  title = {Logistic Regression, a Review},
  author = {van Houwelingen, J. C. and le Cessie, S.},
  options = {useprefix=true},
  date = {1988},
  journaltitle = {Statistica Neerlandica},
  volume = {42},
  pages = {215--232},
  citeulike-article-id = {13264328},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {logistic-model}
}

@article{hou90pre,
  title = {Predictive Value of Statistical Models},
  author = {van Houwelingen, J. C. and le Cessie, S.},
  options = {useprefix=true},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {1303--1325},
  citeulike-article-id = {13264329},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {maximum-likelihood,optimism,predictive-accuracy,validation}
}

@article{hou94cos,
  title = {Costs, Effects, and {{C}}/{{E}} Ratios alongside a Clinical Trial},
  author = {{vanHout}, B. A. and Al, M. J. and Gordon, G. S. and Rutten, F. F. H.},
  date = {1994},
  journaltitle = {Economic Evaluation},
  volume = {3},
  pages = {309--319},
  citeulike-article-id = {13264330},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {c-e},
  note = {calculate what they call the C-E Acceptability Curve. That curve is plotted as the probability that the C-E Ratio is LE the C-E Ratio by the C-E Ratio}
}

@article{hou95con,
  title = {Construction, Validation and Updating of a Prognostic Model for Kidney Graft Survival},
  author = {van Houwelingen, Hans C. and Thorogood, Jane},
  options = {useprefix=true},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1999--2008},
  citeulike-article-id = {13264331},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {calibration,empirical-bayes,overfitting,parametric-survival-model,random-effects,shrinkage,validation,variable-selection}
}

@article{hou99fun,
  title = {Fundamentals of Survival Data},
  author = {Hougaard, Philip},
  date = {1999},
  journaltitle = {Biometrics},
  volume = {55},
  pages = {13--22},
  citeulike-article-id = {13265170},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {accelerated-failure-time-vs-ph-model,censoring,fundamental-importance-of-hazard-function,tdc,truncation}
}

@book{how89sci,
  title = {Scientific {{Reasoning}}: {{The Bayesian Approach}}},
  author = {Howson, C. and Urbach, P.},
  date = {1989},
  publisher = {{Open Court}},
  location = {{La Salle, IL}},
  citeulike-article-id = {13264332},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {bayesian-inference,scientific-reasoning},
  note = {Written by two philosophers, and has no pretense of being objective.}
}

@article{how982x2,
  title = {The 2 2 Table: {{A}} Discussion from a {{Bayesian}} Viewpoint},
  author = {Howard, J. V.},
  date = {1998},
  journaltitle = {Stat Sci},
  volume = {13},
  pages = {351--367},
  citeulike-article-id = {13264333},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {bayesian-inference,conditioning,fishers-exact-test,necessity-for-dependent-priors,odds-ratio}
}

@article{hsi83,
  title = {Some Test Statistics for Use in Multistate Survival Analysis},
  author = {Hsieh FY, Tormey D. C.},
  date = {1983},
  journaltitle = {Biometrika},
  volume = {70},
  pages = {111--119},
  citeulike-article-id = {13264334},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {general,medical,survival-analysis-non-regression}
}

@article{hsi88sam,
  title = {Sample Size Formulae for Intervention Studies with the Cluster as Unit of Randomization},
  author = {Hsieh, F. Y.},
  date = {1988},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {1195--1201},
  citeulike-article-id = {13264335},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {cluster-sampling,dependent-observations,sample-size}
}

@article{hsi89,
  title = {Sample Size Tables for Logistic Regression},
  author = {Hsieh, F. Y.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {795--803},
  citeulike-article-id = {13264336},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,sample-size-estimation}
}

@article{hsi92com,
  title = {Comparing Sample Size Formulae for Trials with Unbalanced Allocation Using the Logrank Test},
  author = {Hsieh, F. Y.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1091--1098},
  citeulike-article-id = {13264337},
  posted-at = {2014-07-14 14:09:33},
  priority = {0}
}

@article{hsi98sim,
  title = {A Simple Method of Sample Size Calculation for Linear and Logistic Regression},
  author = {Hsieh, F. Y. and Bloch, Daniel A. and Larsen, Michael D.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1623--1634},
  citeulike-article-id = {13264338},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {binary-logistic-model,sample-size}
}

@article{hsu97hie,
  title = {Hierarchical {{Bayesian}} Semiparametric Procedures for Logistic Regression},
  author = {Hsu, John S. J. and Leonard, Tom},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {85--93},
  citeulike-article-id = {13264339},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {bayesian-logistic-model,bayesian-smoothing,hierarchical-model,semiparametric-model}
}

@article{hu06pro,
  title = {Properties of {{R}}² Statistics for Logistic Regression},
  author = {Hu, Bo and Palta, Mari and Shao, Jun},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {1383--1395},
  citeulike-article-id = {13265486},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {asymptotic-confidence-intervals,confidence-interval,ginis-concentration-measure,misspecification,predictive-value,squared-pearson-correlation,studied-sums-of-squares-r2}
}

@article{hu07sta,
  title = {Statistical Methods for Active Extension Trials},
  author = {Hu, Zonghui and Follmann, Dean},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {2433--2448},
  citeulike-article-id = {13265578},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {active-extension-trials,ancova,change,change-score,maximum-likelihood,pretest-posttest-design},
  note = {second phase in which all subjects receive the new treatment}
}

@article{hua02cal,
  title = {Calibration Regression of Censored Lifetime Medical Cost},
  author = {Huang, Yigian},
  date = {2002},
  journaltitle = {J Am Stat Assoc},
  volume = {97},
  pages = {318--327},
  citeulike-article-id = {13265271},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {accelerated-failure-time-model,analysis-of-cost,cost-effectiveness,dependent-censoring,joint-modeling-of-cost-and-survival-time,semiparametric-model}
}

@article{hua02non,
  title = {A Nonparametric Method for Combining Multilaboratory Data},
  author = {Huang, Jie and Brunelle, Rocco},
  date = {2002},
  journaltitle = {Drug Info J},
  volume = {36},
  pages = {395--406},
  citeulike-article-id = {13265284},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-safety,empirical-distribution,pharmaceutical-safety,reference-ranges,standardization},
  note = {adjusting for lab differences using the empirical CDF transform}
}

@article{hua02pen,
  title = {Penalized Partial Likelihood Regression for Right-Censored Data with Bootstrap Selection of the Penalty Parameter},
  author = {Huang, Jie and Harrington, David},
  date = {2002},
  journaltitle = {Biometrics},
  volume = {58},
  pages = {781--791},
  citeulike-article-id = {13265303},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {cross-validation,lasso,model-based-bootstrap,penalized-maximum-likelihood,penalized-partial-likelihood,penalty-parameter,ph,proportional-hazards-model},
  note = {improvement to lasso; theoretical results on MSE improvement with biased (shrunken) estimators; use of bootstrap for choosing penalty parameter; conditional semiparametric bootstrap of Davison and Hinkley; uses bootstrap estimated MSE (average squared difference in linear predictor between bootstrap and MLE averaged over observations and bootstrap reps); variance of penalized regression estimates assumes fixed lambda though}
}

@article{hua03fre,
  title = {Frequency of Recurrent Events at Failure Times: {{Modeling}} and Inference},
  author = {Huang, Yijian and Wang, Mei-Chang},
  date = {2003},
  journaltitle = {J Am Stat Assoc},
  volume = {98},
  pages = {663--670},
  citeulike-article-id = {13265359},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {accelerated-failure-time-model,censored-data,count-data,dependent-risks,log-linear-model,logrank-test,marked-point-process,monotone-estimating-function,multivariate-failure-time,nonsmooth-estimating-function,proproportional-rates-model,semiparametric-model,terminating-events},
  note = {example: multiple hospitalizations and death;joint model for recurring events and failure time}
}

@article{hua05adj,
  title = {Adjusting {{O}}'{{Brien}}'s Test to Control Type {{I}} Error for the Generalized Nonparametric {{Behrens-Fisher}} Problem},
  author = {Huang, Peng and Tilley, Barbara C. and Woolson, Robert F. and Lipsitz, Stuart},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  pages = {532--539},
  citeulike-article-id = {13265420},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {bonferroni,global-statistical-test,multiple-endpoints,multivariate-test,nonparametric,obrien,rank-sum-test,rct},
  annotation = {see Stat in Med 30 p. 597, 2011 errata}
}

@article{hua16ine,
  title = {Inequality in Treatment Benefits: {{Can}} We Determine If a New Treatment Benefits the Many or the Few?},
  author = {Huang, Emily J. and Fang, Ethan X. and Hanley, Daniel F. and Rosenblum, Michael},
  date = {2016-12},
  journaltitle = {Biostatistics},
  pages = {kxw049+},
  issn = {1465-4644},
  doi = {10.1093/biostatistics/kxw049},
  url = {http://dx.doi.org/10.1093/biostatistics/kxw049},
  citeulike-article-id = {14321174},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biostatistics/kxw049},
  day = {26},
  posted-at = {2017-03-27 19:14:19},
  priority = {2},
  keywords = {individual-response,interaction,personalized-medicine},
  note = {shows that proportion who benefit from therapy is not identifiable and there are only fairly broad limits}
}

@article{hua20hig,
  title = {High-Dimensional Regression with Ordered Multiple Categorical Predictors},
  author = {Huang, Lei and Hang, Weiqiang and Chao, Yue},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8400},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8400},
  urldate = {2019-11-29},
  abstract = {Models for the ordered multiple categorical (OMC) response variable have already been extensively established and widely applied, but few studies have investigated linear regression problems with OMC predictors, especially in high-dimensional situations. In such settings, the pseudocategories of the discrete variable and other irrelevant explanatory variables need to be automatically selected. This paper introduces a transformation method of dummy variables for such OMC predictors, an L1 penalty regression method is proposed based on the transformation. Model selection consistency of the proposed method is derived under some common assumptions for high-dimensional situation. Both simulation studies and real data analysis present good performance of this method, showing its wide applicability in relevant regression analysis.},
  langid = {english},
  keywords = {ordinal,ordinal-covariate}
}

@article{hua20tut,
  title = {A Tutorial on Calibration Measurements and Calibration Models for Clinical Prediction Models},
  author = {Huang, Yingxiang and Li, Wentao and Macheret, Fima and Gabriel, Rodney A. and Ohno-Machado, Lucila},
  date = {2020-04-01},
  journaltitle = {J Am Med Inform Assoc},
  volume = {27},
  number = {4},
  pages = {621--633},
  publisher = {{Oxford Academic}},
  doi = {10.1093/jamia/ocz228},
  url = {https://academic.oup.com/jamia/article/27/4/621/5762806},
  urldate = {2020-03-20},
  abstract = {Abstract.  Our primary objective is to provide the clinical informatics community with an introductory tutorial on calibration measurements and calibration mode},
  langid = {english},
  keywords = {calibration,clinical-prediction,predictive-accuracy}
}

@incollection{hub67beh,
  title = {The Behavior of Maximum Likelihood Estimates under Nonstandard Conditions},
  booktitle = {Proceedings of the {{Fifth Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}},
  author = {Huber, Peter J.},
  date = {1967},
  volume = {1: Statistics},
  pages = {221--233},
  publisher = {{University of California Press}},
  location = {{Berkeley, CA}},
  citeulike-article-id = {13264340},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {maximum-likelihood-estimation,robust-estimators}
}

@inproceedings{hud85sof,
  title = {Software for Survival Analysis. {{A}} Comparative Survey ({{German}})},
  booktitle = {Proceedings of the {{Statistik-Software Third Conference}} on the {{Scientific Use}} of {{Statistical Software}}},
  author = {Hudec, M. and Hitz, M. and Muellner, W.},
  date = {1985},
  pages = {203--213},
  publisher = {{Gustav Fischer Verlag}},
  location = {{Stuttgart}},
  citeulike-article-id = {13264341},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {software-review}
}

@article{hug92pre,
  title = {Prediction of Short-Term Survival with an Application in Primary Biliary Cirrhosis},
  author = {Hughes, M. D. and Raskino, C. L. and Pocock, S. J. and Biagini, M. R. and Burroughs, A. K.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1731--1745},
  citeulike-article-id = {13264342},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {tdc}
}

@article{hug93rep,
  title = {Reporting {{Bayesian}} Analyses of Clinical Trials},
  author = {Hughes, Michael D.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {1651--1663},
  citeulike-article-id = {13264343},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {bayesian-inference,skeptical-priors,study-design}
}

@book{hul13des,
  title = {Designing {{Clinical Research}}},
  author = {Hulley, Stephen B and Cummings, Steven R and Browner, Warren S and Grady, Deborah G and Newman, Thomas B},
  date = {2013-07-10},
  edition = {Fourth edition},
  publisher = {{LWW}},
  location = {{Philadelphia}},
  abstract = {Designing Clinical Research has been extensively revised and continues to set the standard as a practical guide for doctors, nurses, pharmacists, and other health professionals involved in all forms of clinical, translational, and public health research. It presents advanced epidemiologic concepts in a reader-friendly way, and suggests common sense approaches to the challenging judgments involved in designing, funding, and implementing.New to this edition:Expanded and updated content in every chapter, with new material on: • non-inferiority trials for comparative effectiveness research • incidence-density case-control studies • confounding and effect modification • diagnostic test studies to inform prediction rules • ethical aspects of whole genome sequencing • automated data management approaches • new NIH grant-writing requirementsColor format, and Electronic access, powered by Inkling as a free companion to the text • viewable through your browser or as a download to tablet or smartphone • the complete text with optimized navigation • note-sharing, highlighting and bookmarking capability • cross-linking of references and content • rapid search options linked to the new glossary},
  isbn = {978-1-60831-804-9},
  langid = {english},
  pagetotal = {378},
  keywords = {study-design}
}

@article{hun01imp,
  title = {Imputation Strategies for Missing Data in a School-Based Multi-Center Study: The {{Pathways}} Study},
  author = {Hunsberger, Sally and Murray, David and Davis, C and Fabsitz, Richard R.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {305--316},
  citeulike-article-id = {13265178},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {imputation-in-study-analysis-plan,multiple-imputation,strategy-for-imputation,worst-rank-method}
}

@article{hun16det,
  title = {Detection of Gene-Gene Interactions Using Multistage Sparse and Low-Rank Regression},
  author = {Hung, Hung and Lin, Yu-Ting and Chen, Penweng and Wang, Chen-Chien and Huang, Su-Yun and Tzeng, Jung-Ying},
  date = {2016-03},
  journaltitle = {Biometrics},
  volume = {72},
  number = {1},
  pages = {85--94},
  issn = {0006341X},
  doi = {10.1111/biom.12374},
  url = {http://dx.doi.org/10.1111/biom.12374},
  citeulike-article-id = {14095622},
  citeulike-attachment-1 = {hun16det.pdf; /pdf/user/harrelfe/article/14095622/1077472/hun16det.pdf; 60cee87cb3f9d26bca4015212be63e50af3edf67},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/biom.12374},
  posted-at = {2016-07-14 20:45:46},
  priority = {0},
  keywords = {high-dimensional-data,interaction,reduced-rank,sparse-data}
}

@article{hur89reg,
  title = {Regression and Time Series Model Selection in Small Samples},
  author = {Hurvich, Clifford M. and Tsai, Chih-Ling},
  date = {1989},
  journaltitle = {Biometrika},
  volume = {76},
  pages = {297--307},
  citeulike-article-id = {13264344},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {aic,bic,maximum-likelihood,model-selection,predictive-accuracy,variable-selection}
}

@article{hur90,
  title = {The Impact of Model Selection on Inference in Linear Regression},
  author = {Hurvich, C. M. and Tsai, C. L.},
  date = {1990},
  journaltitle = {Am Statistician},
  volume = {44},
  pages = {214--217},
  citeulike-article-id = {13264345},
  posted-at = {2014-07-14 14:09:33},
  priority = {0}
}

@article{hur95mod,
  title = {Model Selection for Extended Quasi-Likelihood Models in Small Samples},
  author = {Hurvich, Clifford M. and Tsai, Chih-Ling},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {1077--1084},
  citeulike-article-id = {13264346},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {aic,kullback-leibler-information,model-selection,variable-selection}
}

@article{hus85sur,
  title = {{{SURVPAK}}: {{An}} Interactive Survival Analysis Package},
  author = {Huster, W. and Enterline, J.},
  date = {1985},
  journaltitle = {Ann Math Stat},
  volume = {39},
  pages = {311},
  citeulike-article-id = {13264347},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {software-review}
}

@article{hus99sta,
  title = {Statistical and Operational Issues Arising in an Interim Analysis When the Study Will Continue},
  author = {Huster, William and Shah, Aarti and Kaiser, Gary and Dere, Will and DiMarchi, Richard},
  date = {1999},
  journaltitle = {Drug Info J},
  volume = {33},
  pages = {869--875},
  citeulike-article-id = {13264348},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {surrogate-endpoint},
  note = {interim analysis not changing conduct of study;information flow across groups of evaluators}
}

@article{hut00exa,
  title = {The Exact Bootstrap Mean and Variance of an {{L-estimator}}},
  author = {Hutson, Alan D. and Ernst, Michael D.},
  date = {2000},
  journaltitle = {J Roy Stat Soc B},
  volume = {62},
  pages = {89--94},
  citeulike-article-id = {13265124},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {bootstrap,bootstrap-order-statistic,l-statistic,quantile-estimator}
}

@article{hut22dis,
  title = {Discarding {{Dichotomization}}: {{Retrieving Data}} in the {{Service}} of {{Patient Care}}},
  shorttitle = {Discarding {{Dichotomization}}},
  author = {Hutchison, Alan L. and Cifu, Adam S. and Pillai, Anjana A.},
  date = {2022},
  journaltitle = {Clinical Liver Disease},
  volume = {19},
  number = {1},
  pages = {12--16},
  issn = {2046-2484},
  doi = {10.1002/cld.1159},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cld.1159},
  urldate = {2022-01-26},
  abstract = {Content available: Author Interview and Audio Recording},
  langid = {english},
  keywords = {categorization,cutpoint,cutpoints,dichotomization,information-loss,medical,teaching-mds},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cld.1159}
}

@article{hwa96est,
  title = {Estimation of Expected Quality Adjusted Survival by Cross-Sectional Survey},
  author = {Hwang, Jing-Shiang and Tsauo, Jau-Yih and Wang, Jung-Der},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {93--102},
  citeulike-article-id = {13264349},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {adjusted-survival-time,multiple-endpoints,qaly,quality-of-life}
}

@article{ich98,
  title = {Guideline {{E-9}}: {{Statistical Principles}} for {{Clinical Trials}}},
  author = {{International Conference on Harmonisation}},
  date = {1998},
  citeulike-article-id = {13264350},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {pharmaceutical,rct,statistical-sop}
}

@article{ich99,
  title = {Statistical Principles for Clinical Trials: {{ICH}} Harmonized Tripartite Guideline},
  author = {{ICH E9 Expert Working Group}},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1905--1942},
  citeulike-article-id = {13264351},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {rct,teaching}
}

@book{iestat,
  title = {International {{Encyclopedia}} of {{Statistics}}},
  editor = {Kruskal, William H. and Tanur, Judith M.},
  date = {1978},
  publisher = {{The Free Press}},
  location = {{New York}},
  citeulike-article-id = {13265238},
  posted-at = {2014-07-14 14:09:52},
  priority = {0}
}

@incollection{iez94ris,
  title = {Dimensions of {{Risk}}},
  booktitle = {Risk {{Adjustment}} for {{Measuring Health Outcomes}}},
  author = {Iezzoni, Lisa I.},
  editor = {Iezzoni, Lisa I.},
  date = {1994},
  pages = {29--118},
  publisher = {{Foundation of the American College of Healthcare Executives}},
  location = {{Ann Arbor, MI}},
  chapter = {2},
  citeulike-article-id = {13264352},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  note = {dimensions of risk factors to include in models}
}

@article{ima08tow,
  title = {Towards a Common Framework for Statistical Analysis and Development},
  author = {Imai, Kosuke and King, Gary and Lau, Olivia},
  date = {2008},
  journaltitle = {J Comp Graph Stat},
  volume = {17},
  number = {4},
  pages = {892--913},
  citeulike-article-id = {13265735},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {generalized-models,r},
  note = {R zelig package;unified framework for many types of models and inputs, including stratified datasets (e.g., multiply imputated datasets), matched data, multilevel data with elegant specification of which variables pertain to which stages;multiple linked models with elegant specification of forced common parameters;easy framework for implementing new models such as a bivariate probit model;advantages of R;generation of dynamic GUIs;statistical computing;statistical model language}
}

@article{imb00rol,
  title = {The Role of the Propensity Score in Estimating Dose-Response Functions},
  author = {Imbens, G.},
  date = {2000},
  journaltitle = {Biometrika},
  volume = {87},
  pages = {706--710},
  url = {http://konstanza.ingentaselect.com/vl=2884470/cl=22/nw=1/rpsv/ij/oup/00063444/v87n3/s17/p706},
  citeulike-article-id = {13265382},
  citeulike-linkout-0 = {http://konstanza.ingentaselect.com/vl=2884470/cl=22/nw=1/rpsv/ij/oup/00063444/v87n3/s17/p706},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {causal-inference,dose-response-function,multivalued-treatment,obsevational-study,propensity-score,unconfoundedness}
}

@article{ing22vis,
  title = {Visualizing {{Variable Importance}} and {{Variable Interaction Effects}} in {{Machine Learning Models}}},
  author = {Inglis, Alan and Parnell, Andrew and Hurley, Catherine B.},
  date = {2022-01-04},
  journaltitle = {Journal of Computational and Graphical Statistics},
  issn = {1061-8600},
  url = {https://www.tandfonline.com/doi/abs/10.1080/10618600.2021.2007935},
  urldate = {2022-01-07},
  abstract = {(2022). Visualizing Variable Importance and Variable Interaction Effects in Machine Learning Models. Journal of Computational and Graphical Statistics. Ahead of Print.},
  langid = {english},
  keywords = {graphics,interaction,machine-learning,rms,variable-importance}
}

@inproceedings{int93usi,
  title = {Using Neural-Networks for Interpretation of Nonlinear Models},
  booktitle = {Proceedings of the {{Statistical Computing Section}}, {{ASA}}},
  author = {Intrator, Orna and Intrator, Nathan},
  date = {1993},
  publisher = {{American Statistical Association}},
  location = {{Alexandria, Virginia}},
  citeulike-article-id = {13264353},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {neural-networks}
}

@article{ioa01evo,
  title = {Evolution of Treatment Effects over Time: Empirical Insight from Recursive Cumulative Metaanalyses},
  author = {Ioannidis, J. P. A. and Lau, J.},
  date = {2001},
  journaltitle = {PNAS},
  volume = {98},
  pages = {831--836},
  citeulike-article-id = {13265556},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  note = {coined the phrase "regression to the truth";discussed by McAlister FA, Mohamed R AHJ 153:156-158;2007}
}

@article{ioa02sta,
  title = {Standardized Retrieval of Side Effects Data for Meta-Analysis of Safety Outcomes: {{A}} Feasibility Study in Acute Sinusitis},
  author = {Ioannidis, John P. A. and Chew, Priscilla and Lau, Joseph},
  date = {2002},
  journaltitle = {J Clin Epi},
  volume = {55},
  pages = {619--626},
  citeulike-article-id = {13265285},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {acute-sinusitis,aes,antibiotics,clinical-safety,meta-analysis,pharmaceutical-safety,side-effects,systematic-review},
  note = {combining data from multiple clinical trials with nonstandard reporting of AEs}
}

@article{ioa07mol,
  title = {Is Molecular Profiling Ready for Use in Clinical Decision Making?},
  author = {Ioannidis, John P. A.},
  date = {2007},
  journaltitle = {The Oncologist},
  volume = {12},
  pages = {301--311},
  citeulike-article-id = {13265584},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {biomarker-research},
  note = {many statistical problems listed}
}

@article{ioa12ext,
  title = {Extrapolating from Animals to Humans.},
  author = {Ioannidis, John P.},
  date = {2012-09},
  journaltitle = {Sci Trans Med},
  volume = {4},
  number = {151},
  eprint = {22972841},
  eprinttype = {pmid},
  issn = {1946-6242},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/22972841},
  abstract = {Because of a variety of caveats, the safety and effectiveness of interventions in human subjects can only be speculated from animal studies. Careful synthesis of data from multiple animal studies is needed to begin to assess the likelihood of successful cross-species translation (Fay et al., this issue).},
  citeulike-article-id = {13512167},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/22972841},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=22972841},
  day = {12},
  posted-at = {2015-02-08 19:05:23},
  priority = {0},
  keywords = {animal,bad-science,blinding,experimental-design,randomization}
}

@article{ioa97imp,
  title = {The Impact of High-Risk Patients on the Results of Clinical Trials},
  author = {Ioannidis, John P. A. and Lau, Joseph},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {1089--1098},
  doi = {10.1016/S0895-4356(97)00149-2},
  url = {http://dx.doi.org/10.1016/S0895-4356(97)00149-2},
  citeulike-article-id = {13264354},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0895-4356(97)00149-2},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {clinical-trials,generalizability,publication-bias,rct,reporting,teaching-mds},
  note = {high risk patients can dominate clinical trials results;high risk patients may be imbalanced even if overall study is balanced;magnesium;differential treatment effect by patient risk;GUSTO;small vs. large trials vs. meta-analysis}
}

@article{ion10exp,
  title = {Expectations, Validity, and Reality in Omics},
  author = {Ionnidis, John P. A.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {945--949},
  citeulike-article-id = {13265846},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {gene-expression-profiling,genomics,metabolomics,omics,personalized-medicine,pharmacogenomics,proteomics,transcriptomics,validity},
  note = {"Each new field has a rapid exponential growth of its literature over 5--8 years (`new field phase'), followed by an `established field' phase when growth rates are more modest, and then an `over-maturity' phase, where the rates of growth are similar to the growth of the scientific literature at large or even smaller. There is a parallel in the spread of an infectious epidemic that emerges rapidly and gets established when a large number of scientists (and articles) are infected with these concepts. Then momentum decreases, although many scientists remain infected and continue to work on this field. New omics infections continuously arise in the scientific community.";"A large number of personal genomic tests are already sold in the market, mostly with direct to consumer advertisement and for `recreational genomics' purposes (translate: information for the fun of information)."}
}

@book{irr,
  title = {Implementing {{Reproducible Research}}},
  author = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
  editor = {Stodden, Victoria and Leisch, Friedrich and Peng, Roger D.},
  date = {2014},
  publisher = {{CRC Press/Taylor and Francis}},
  location = {{Boca Raton, FL}},
  url = {http://www.worldcat.org/isbn/9781466561595},
  abstract = {In computational science, reproducibility requires that researchers make code and data available to others so that the data can be analyzed in a similar manner as in the original publication. Code must be available to be distributed, data must be accessible in a readable format, and a platform must be available for widely distributing the data and code. In addition, both data and code need to be licensed permissively enough so that others can reproduce the work without a substantial legal burden. Implementing Reproducible Research covers many of the elements necessary for conducting and distrib.},
  citeulike-article-id = {13171746},
  citeulike-linkout-0 = {http://www.worldcat.org/isbn/9781466561595},
  citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9781466561595},
  citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9781466561595&index=books&linkCode=qs},
  citeulike-linkout-3 = {http://www.librarything.com/isbn/9781466561595},
  citeulike-linkout-4 = {http://www.worldcat.org/oclc/859168552},
  isbn = {978-1-4665-6159-5},
  posted-at = {2015-02-28 22:35:13},
  priority = {2},
  keywords = {reporting,reproducibility,statistical-computing,statistical-report}
}

@article{irw94gui,
  title = {Guidelines for Meta-Analyses Evaluating Diagnostic Tests},
  author = {Irwig, L. and Tosteson, A. and Gatsonis, C. and Lau, J. and Colditz, G. and Chalmers, T. C. and Mosteller, F.},
  date = {1994},
  journaltitle = {Ann Int Med},
  volume = {120},
  pages = {667--676},
  citeulike-article-id = {13264355},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {diagnosis,meta-analysis,publication-bias,teaching-mds,testing}
}

@article{isa19fda,
  title = {Is the {{FDA}} Too Conservative or Too Aggressive?: {{A Bayesian}} Decision Analysis of Clinical Trial Design},
  shorttitle = {Is the {{FDA}} Too Conservative or Too Aggressive?},
  author = {Isakov, Leah and Lo, Andrew W. and Montazerhodjat, Vahid},
  date = {2019-07-01},
  journaltitle = {Journal of Econometrics},
  series = {Annals {{Issue}} in {{Honor}} of {{Jerry A}}. {{Hausman}}},
  volume = {211},
  number = {1},
  pages = {117--136},
  issn = {0304-4076},
  doi = {10.1016/j.jeconom.2018.12.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0304407618302380},
  urldate = {2022-01-20},
  abstract = {Implicit in the drug-approval process is a host of decisions—target patient population, control group, primary endpoint, sample size, follow-up period, etc.—all of which determine the trade-off between Type I and Type II error. We explore the application of Bayesian decision analysis (BDA) to minimize the expected cost of drug approval, where the relative costs of the two types of errors are calibrated using U.S.~Burden of Disease Study 2010 data. The results for conventional fixed-sample randomized clinical-trial designs suggest that for terminal illnesses with no existing therapies such as pancreatic cancer, the standard threshold of 2.5\% is substantially more conservative than the BDA-optimal threshold of 23.9\% to 27.8\%. For relatively less deadly conditions such as prostate cancer, 2.5\% is more risk-tolerant or aggressive than the BDA-optimal threshold of 1.2\% to 1.5\%. We compute BDA-optimal sizes for 25 of the most lethal diseases and show how a BDA-informed approval process can incorporate all stakeholders’ views in a systematic, transparent, internally consistent, and repeatable manner.},
  langid = {english},
  keywords = {alpha-spending,bayes,decision-theory,drug-development,type-i-error}
}

@article{ish19sta,
  title = {Standard Errors and Confidence Intervals for Variable Importance in Random Forest Regression, Classification, and Survival},
  author = {Ishwaran, Hemant and Lu, Min},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {4},
  pages = {558--582},
  issn = {1097-0258},
  doi = {10.1002/sim.7803},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7803},
  urldate = {2019-01-19},
  abstract = {Random forests are a popular nonparametric tree ensemble procedure with broad applications to data analysis. While its widespread popularity stems from its prediction performance, an equally important feature is that it provides a fully nonparametric measure of variable importance (VIMP). A current limitation of VIMP, however, is that no systematic method exists for estimating its variance. As a solution, we propose a subsampling approach that can be used to estimate the variance of VIMP and for constructing confidence intervals. The method is general enough that it can be applied to many useful settings, including regression, classification, and survival problems. Using extensive simulations, we demonstrate the effectiveness of the subsampling estimator and in particular find that the delete-d jackknife variance estimator, a close cousin, is especially effective under low subsampling rates due to its bias correction properties. These 2 estimators are highly competitive when compared with the .164 bootstrap estimator, a modified bootstrap procedure designed to deal with ties in out-of-sample data. Most importantly, subsampling is computationally fast, thus making it especially attractive for big data settings.},
  langid = {english},
  keywords = {variable-importance}
}

@article{isis2,
  title = {Randomised Trial of Intravenous Streptokinase, Oral Aspirin, Both, or Neither among 17187 Cases of Suspected Acute Myocardial Infarction: {{ISIS-2}}},
  author = {{ISIS-2 Collaborative Group}},
  date = {1988},
  journaltitle = {Lancet},
  volume = {2},
  pages = {349--360},
  citeulike-article-id = {13264356},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {blobogram,constancy-of-odds-ratios,heterogeneity,rct,subgroup-analysis,thrombolytic,thrombolytic-therapy}
}

@article{iwa97use,
  title = {A User's Review of Commercial Sample Size Software for Design of Biomedical Studies Using Survival Data. ({{Addendum Cnt Clin Trials}} 18:184, 1997; 18:274, 1997)},
  author = {Iwane, Marika and Palensky, Jolie and Plante, Kathryn},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {65--83},
  citeulike-article-id = {13264357},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {dropouts-and-dropins,non-adherence,power-and-sample-size-calculation,software-review}
}

@article{jac08sta,
  title = {Displaying Uncertainty with Shading},
  author = {Jackson, Christopher H.},
  date = {2008},
  journaltitle = {Am Statistician},
  volume = {62},
  number = {4},
  pages = {340--347},
  citeulike-article-id = {13265706},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {excellent-graphical-examples,shading,statistical-graphics}
}

@book{jac91use,
  title = {A {{User}}'s {{Guide}} to {{Principal Components}}},
  author = {Jackson, J. Edward},
  date = {1991},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264358},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {data-reduction,principal-components}
}

@book{jac97sta,
  title = {Statistical {{Graphics}} for {{Univariate}} and {{Bivariate Data}}},
  author = {Jacoby, William G.},
  date = {1997},
  series = {Quantitative {{Applications}} in the {{Social Sciences}}},
  publisher = {{SAGE Publications}},
  location = {{Thousand Oaks, CA}},
  citeulike-article-id = {13265692},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {graphics},
  note = {discusses Cleveland and Tufte}
}

@article{jan05new,
  title = {A New Logistic Regression Approach for the Evaluation of Diagnostic Test Results},
  author = {Janssens, A. C. J. W. and Deng, Yazhong and Borsboom, G. J. J. M. and Eijkemans, M. J. C. and Habbema, J. D. F. and Steyerberg, Ewout W.},
  date = {2005},
  journaltitle = {Med Decis Mak},
  volume = {25},
  pages = {168--177},
  citeulike-article-id = {13265406},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {background-risk,baseline-risk,comparing-pre-and-post-test-probabilities,diagnosis,differences-in-coefficients-after-adding-test-variables-to-model,incremental-value,likelihood-ratio,logistic-regression}
}

@article{jan06ana,
  title = {Analyzing Incomplete Discrete Longitudinal Clinical Trial Data},
  author = {Jansen, Ivy and Beunckens, Caroline and Molenberghs, Geert and Verbeke, Geert and Mallinckrodt, Craig},
  date = {2006},
  journaltitle = {Stat Sci},
  volume = {21},
  pages = {52--69},
  citeulike-article-id = {13265475},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {complete-case-analysis,gee,glmm,ignorability,locf,missing-at-random,missing-completely-at-random,missing-data,missing-not-at-random,sensitivity-analysis},
  note = {LOCF assumes unchanging profile after dropout, an assumption too strong to hold in general}
}

@article{jan09dea,
  title = {Dealing with Missing Predictor Values When Applying Clinical Prediction Models},
  author = {Janssen, K. J. and Vergouwe, Y. and Donders, A. R. and Harrell, F. E. and Chen, Q. and Grobbee, D. E. and {Moons}},
  date = {2009},
  journaltitle = {Clin Chem},
  volume = {55},
  number = {5},
  pages = {994--1001},
  citeulike-article-id = {13265778},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {imputation,missing-data,prospective-prediction}
}

@article{jan10mis,
  title = {Missing Covariate Data in Medical Research: {{To}} Impute Is Better than to Ignore},
  author = {Janssen, K. J. and Donders, A. R. and Harrell, F. E. and Vergouwe, Y. and Chen, Q. and Grobbee, D. E. and Moons, K. G.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {721--727},
  citeulike-article-id = {13265802},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {imputation,limit-on-fraction-of-missing-data,missing-data}
}

@article{jan10pre,
  title = {Prediction Rules Must Be Developed According to Methodological Guidelines},
  author = {Janssen, K. J. and Moons, K. G. and Harrell, F. E.},
  date = {2010},
  journaltitle = {Ann Int Med},
  volume = {152},
  number = {4},
  pages = {263},
  citeulike-article-id = {13265803},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  annotation = {letter to the editor; author reply p. 263-4}
}

@article{jat19nee,
  title = {The {{Need}} for {{Combined Assessment}} of {{Multiple Outcomes}} in {{Noninferiority Trials}} in {{Oncology}}},
  author = {Jatoi, Ismail and Gail, Mitchell H.},
  date = {2019-12-12},
  journaltitle = {JAMA Oncol},
  doi = {10.1001/jamaoncol.2019.5361},
  url = {https://jamanetwork.com/journals/jamaoncology/fullarticle/2757388},
  urldate = {2019-12-15},
  abstract = {{$<$}p{$>$}Noninferiority trials in oncology assess novel therapies with the potential for slightly worse recurrence or death outcomes (ie, the margin of noninferiority) than standard therapies. This poses a dilemma because, in the absence of potential health outcome advantages, these trials may not provide the treatment equipoise required for an ethical study. Any new treatment with the potential for slightly worse recurrence or death outcomes should have countervailing health outcome advantages, but these are rarely taken into account in the design of noninferiority trials. This article presents the argument that not only the potentially worse health outcomes but also the potential benefits of the novel therapy should be considered when designing, analyzing, and reporting noninferiority trials. Some approaches to study design and analysis that consider both primary and secondary end points are discussed, and reporting the joint distributions of end points for the novel and standard treatments is recommended.{$<$}/p{$>$}},
  langid = {english},
  keywords = {multiple-endpoints,noninferiority-design,rct,utilities}
}

@article{jen03mid,
  title = {Mid-Course Sample Size Modification in Clinical Trials Based on the Observed Treatment Effect},
  author = {Jennison, C. and Turnbull, B. W.},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {971--993},
  citeulike-article-id = {13265511},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{jen19for,
  title = {Forcing Dichotomous Disease Classification from Reference Standards Lead to Bias in Diagnostic Accuracy Estimates: A Simulation Study},
  shorttitle = {Forcing Dichotomous Disease Classification from Reference Standards Lead to Bias in Diagnostic Accuracy Estimates},
  author = {Jenniskens, Kevin and Naaktgeboren, Christiana A. and Reitsma, Johannes B. and Hooft, Lotty and Moons, Karel G. M. and van Smeden, Maarten},
  date = {2019-03-20},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2019.03.002},
  url = {https://www.jclinepi.com/article/S0895-4356(18)30692-9/abstract},
  urldate = {2019-03-23},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To study the impact of ignoring uncertainty by forcing dichotomous classification (presence or absence) of the target disease on estimates of diagnostic accuracy of an index test.{$<$}/p{$><$}h3{$>$}Study Design and Setting{$<$}/h3{$><$}p{$>$}We evaluated the bias in estimated index test accuracy when forcing an expert panel to make a dichotomous target disease classification for each individual. Data for various scenarios with expert panels were simulated by varying the number and accuracy of "component reference tests" available to the expert panel, index test sensitivity and specificity, and target disease prevalence.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Index test accuracy estimates are likely to be biased when there is uncertainty surrounding the presence or absence of the target disease. Direction and amount of bias depend on the number and accuracy of component reference tests, target disease prevalence and the true values of index test sensitivity and specificity.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}In this simulation, forcing expert panels to make a dichotomous decision on target disease classification in the presence of uncertainty, leads to biased estimates of index test accuracy. Empirical studies are needed to demonstrate whether this bias can be reduced by assigning a probability of target disease presence for each individual, or using advanced statistical methods to account for uncertainty in target disease classification.{$<$}/p{$>$}},
  langid = {english},
  keywords = {diagnosis,dichotimizing-continuous-variables,dichotomization,information-loss}
}

@article{jen86jud,
  title = {Judging {{Inference Adequacy}} in {{Logistic Regression}}},
  author = {Jennings, Dennis E.},
  date = {1986},
  journaltitle = {JASA},
  volume = {81},
  number = {394},
  eprint = {http://amstat.tandfonline.com/doi/pdf/10.1080/01621459.1986.10478292},
  pages = {471--476},
  publisher = {Taylor & Francis},
  doi = {10.1080/01621459.1986.10478292},
  url = {http://amstat.tandfonline.com/doi/abs/10.1080/01621459.1986.10478292},
  abstract = {Abstract Inference for logistic regression based on the information matrix may be poor. This is noted in two examples in which confidence regions are examined. A measure to detect such inadequacies is presented; it judges the quadratic approximation to the likelihood surface, which justifies the usual procedure.},
  citeulike-article-id = {14516413},
  citeulike-attachment-1 = {jennings₈6<sub>j</sub>udging₁126896.pdf; /pdf/user/harrelfe/article/14516413/1126896/jennings₈6<sub>j</sub>udging₁126896.pdf; 1dbeca613b3a33b55c2ac67d014b1916d86b4f4b},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1986.10478292},
  citeulike-linkout-1 = {http://amstat.tandfonline.com/doi/abs/10.1080/01621459.1986.10478292},
  posted-at = {2018-01-14 00:06:47},
  priority = {0},
  keywords = {binary-logistic-model,confidence-intervals,logistic-model,maximum-likelihood}
}

@article{jen89,
  title = {Interim Analyses: The Repeated Confidence Interval Approach (with Discussion)},
  author = {{Jennison}},
  date = {1989},
  journaltitle = {JRSS B},
  volume = {51},
  pages = {305--361},
  citeulike-article-id = {13264359},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {sequential-methods,study-design-and-stopping-rules}
}

@article{jen90sta,
  title = {Statistical Approaches to Interim Monitoring of Medical Trials: {{A}} Review and Commentary},
  author = {{Jennison}},
  date = {1990},
  journaltitle = {Stat Sci},
  volume = {5},
  pages = {299--317},
  citeulike-article-id = {13264360},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {bayesian-methods,confidence-limits,repeated-confidence-intervals,sequential-methods,study-design-and-stopping-rules},
  note = {dealing with final estimates and confidence limits}
}

@article{jen93gro,
  title = {Group Sequential Tests for Bivariate Response: {{Interim}} Analyses of Clinical Trials with Both Efficacy and Safety Endpoints},
  author = {Jennison, Christopher and Turnbull, Bruce W.},
  date = {1993},
  journaltitle = {Biometrics},
  volume = {49},
  pages = {741--752},
  citeulike-article-id = {13264361},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {sequential-testing,study-design}
}

@article{jen93seq,
  title = {Sequential Equivalence Testing and Repeated Confidence Intervals, with Applications to Normal and Binary Responses},
  author = {Jennison, Christopher and Turnbull, Bruce W.},
  date = {1993},
  journaltitle = {Biometrics},
  volume = {49},
  pages = {31--43},
  citeulike-article-id = {13264362},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {early-termination,equivalence-testing,pharmaceutical,sequential-methods}
}

@article{jhu00app,
  title = {Applications of Bootstrap Methods for Categorical Data Analysis},
  author = {Jhun, Myoungshic and Jeong, Hyeong-Chul},
  date = {2000},
  journaltitle = {Comp Stat Data Analysis},
  volume = {35},
  pages = {83--91},
  citeulike-article-id = {13265167},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {bootstrap,multinomial,simulatenous-confidence-intervals-based-on-bootstrap-chi2-statistics}
}

@article{jia03est,
  title = {Estimating the Distribution of Nonterminal Event Time in the Presence of Mortality or Informative Dropout},
  author = {Jiang, Hongyu and Chapell, Rick and Fine, Jason P.},
  date = {2003},
  journaltitle = {Controlled Clin Trials},
  volume = {24},
  pages = {135--146},
  citeulike-article-id = {13265315},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {bivariate-survival-time,clayton-model,dependent-censoring,informative-censoring,nice-description-of-the-problem,nonterminating-event,semicompeting-risks-data,simulation-setup,terminating-event}
}

@article{jia09com,
  title = {Common Predictor Effects for Multivariate Longitudinal Data},
  author = {Jia, Juan and Weiss, Robert E.},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {1793--1804},
  citeulike-article-id = {13265759},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {clustering,common-effect,dimension-reduction,hierarchical-linear-model,hiv,longitudinal-data,model-selection,multivariate-regression},
  note = {"Given a set of outcomes likely to share common covariate effects, we propose the clustered outcome common predictor effect model and offer a two step iterative algorithm to fit the model using available software for univariate longitudinal data ... We propose model selection tools to let the data select outcome clusters."}
}

@article{jia13int,
  title = {Interquantile {{Shrinkage}} in {{Regression Models}}},
  author = {Jiang, Liewen and Wang, Huixia J. and Bondell, Howard D.},
  date = {2013},
  journaltitle = {J Comp Graph Stat},
  volume = {22},
  number = {4},
  eprint = {http://amstat.tandfonline.com/doi/pdf/10.1080/10618600.2012.707454},
  pages = {970--986},
  doi = {10.1080/10618600.2012.707454},
  url = {http://amstat.tandfonline.com/doi/abs/10.1080/10618600.2012.707454},
  abstract = {Conventional analysis using quantile regression typically focuses on fitting the regression model at different quantiles separately. However, in situations where the quantile coefficients share some common feature, joint modeling of multiple quantiles to accommodate the commonality often leads to more efficient estimation. One example of common features is that a predictor may have a constant effect over one region of quantile levels but varying effects in other regions. To automatically perform estimation and detection of the interquantile commonality, we develop two penalization methods. When the quantile slope coefficients indeed do not change across quantile levels, the proposed methods will shrink the slopes toward constant and thus improve the estimation efficiency. We establish the oracle properties of the two proposed penalization methods. Through numerical investigations, we demonstrate that the proposed methods lead to estimations with competitive or higher efficiency than the standard quantile regression estimation in finite samples. Supplementary materials for the article are available online.},
  citeulike-article-id = {13265984},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/10618600.2012.707454},
  citeulike-linkout-1 = {http://amstat.tandfonline.com/doi/abs/10.1080/10618600.2012.707454},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {quantile-regression,robust-regression,shrinkage}
}

@article{jia17joi,
  title = {Joint Modeling of Multiple Ordinal Adherence Outcomes via Generalized Estimating Equations with Flexible Correlation Structure},
  author = {Jiang, Zhen and Liu, Yimeng and Wahed, Abdus S. and Molenberghs, Geert},
  date = {2018-03},
  journaltitle = {Stat Med},
  volume = {37},
  number = {6},
  pages = {983--995},
  doi = {10.1002/sim.7560},
  url = {http://dx.doi.org/10.1002/sim.7560},
  abstract = {Adherence to medication is critical in achieving effectiveness of many treatments. Factors that influence adherence behavior have been the subject of many clinical studies. Analyzing adherence is complicated because it is often measured on multiple drugs over a period, resulting in a multivariate longitudinal outcome. This paper is motivated by the Viral Resistance to Antiviral Therapy of Chronic Hepatitis C study, where adherence is measured on two drugs as a bivariate ordinal longitudinal outcome. To analyze such outcome, we propose a joint model assuming the multivariate ordinal outcome arose from a partitioned latent multivariate normal process. We also provide a flexible multilevel association structure covering both between and within outcome correlation. In simulation studies, we show that the joint model provides unbiased estimators for regression parameters, which are more efficient than those obtained through fitting separate model for each outcome. The joint method also yields unbiased estimators for the correlation parameters when the correlation structure is correctly specified. Finally, we analyze the Viral Resistance to Antiviral Therapy of Chronic Hepatitis C adherence data and discuss the findings.},
  citeulike-article-id = {14502199},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7560},
  day = {15},
  posted-at = {2017-12-13 13:12:21},
  priority = {2},
  keywords = {gee,longitudinal-data,multiple-endpoints,ordinal-response,serial-data}
}

@article{jia20com,
  title = {Comparing {{Bayesian}} Early Stopping Boundaries for Phase {{II}} Clinical Trials},
  author = {Jiang, Liyun and Yan, Fangrong and Thall, Peter F. and Huang, Xuelin},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2046},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2046},
  urldate = {2020-08-02},
  abstract = {When designing phase II clinical trials, it is important to construct interim monitoring rules that achieve a balance between reliable early stopping for futility or safety and maintaining a high true positive probability (TPP), which is the probability of not stopping if the new treatment is truly safe and effective. We define and compare several methods for specifying early stopping boundaries as functions of interim sample size, rather than as fixed cut-offs, using Bayesian posterior probabilities as decision criteria. We consider boundaries with constant, linear, or exponential shapes. For design optimization criteria, we use the TPP and mean number of patients enrolled in the trial. Simulations to evaluate and compare the designs' operating characteristics under a range of scenarios show that, while there is no uniformly optimal boundary, an appropriately calibrated exponential shape maintains high TPP while limiting the number of patients assigned to a treatment with an inferior response rate or an excessive toxicity rate.},
  langid = {english},
  keywords = {bayes,futility,phase-ii,safety,sequential,stopping-boundaries},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2046}
}

@article{jin06lea,
  title = {On Least-Squares Regression with Censored Data},
  author = {Jin, Zhezhen and Lin, D. Y. and Ying, Zhiliang},
  date = {2006},
  journaltitle = {Biometrika},
  volume = {93},
  pages = {147--161},
  citeulike-article-id = {13265485},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {accelerated-failure-time-model,buckley-james-estimator,gehan-statistic,linear-model,linear-programming,rank-estimator,resampling,semiparametric-model,survival-data,variance-estimation}
}

@article{jof99pro,
  title = {Invited Commentary: {{Propensity}} Scores},
  author = {Joffe, Marshall M. and Rosenbaum, Paul R.},
  date = {1999},
  journaltitle = {Am J Epi},
  volume = {150},
  pages = {327--333},
  citeulike-article-id = {13264363},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {propensity-score,teaching}
}

@book{johBookcon,
  title = {Distributions in {{Statistics}}: {{Continuous Univariate Distributions}}},
  author = {Johnson, N. L. and Kotz, S. and Balakrishnan, N.},
  date = {1994},
  edition = {Second},
  volume = {1},
  publisher = {{Wiley-Interscience}},
  location = {{New York}},
  citeulike-article-id = {13264364},
  posted-at = {2014-07-14 14:09:33},
  priority = {0}
}

@article{jol72dis,
  title = {Discarding Variables in a Principal Component Analysis. {{I}}. {{Artificial}} Data},
  author = {Jolliffe, I. T.},
  date = {1972},
  journaltitle = {Appl Stat},
  volume = {21},
  pages = {160--173},
  citeulike-article-id = {13265540},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {data-reduction,redundancy-analysis,simplifying-principal-components}
}

@book{jolBookpca,
  title = {Principal {{Component Analysis}}},
  author = {Jolliffe, I. T.},
  date = {2010},
  edition = {Second},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13264365},
  posted-at = {2014-07-14 14:09:33},
  priority = {0}
}

@article{jon06con,
  title = {Continuous Time {{Markov}} Models for Binary Longitudinal Data},
  author = {Jones, Richard H. and Xu, Stanley and Grunwald, Gary K.},
  date = {2006-06},
  journaltitle = {Biom J},
  volume = {48},
  number = {3},
  eprint = {16845905},
  eprinttype = {pmid},
  pages = {411--419},
  issn = {0323-3847},
  doi = {10.1002/bimj.200510224},
  abstract = {Longitudinal data usually consist of a number of short time series. A group of subjects or groups of subjects are followed over time and observations are often taken at unequally spaced time points, and may be at different times for different subjects. When the errors and random effects are Gaussian, the likelihood of these unbalanced linear mixed models can be directly calculated, and nonlinear optimization used to obtain maximum likelihood estimates of the fixed regression coefficients and parameters in the variance components. For binary longitudinal data, a two state, non-homogeneous continuous time Markov process approach is used to model serial correlation within subjects. Formulating the model as a continuous time Markov process allows the observations to be equally or unequally spaced. Fixed and time varying covariates can be included in the model, and the continuous time model allows the estimation of the odds ratio for an exposure variable based on the steady state distribution. Exact likelihoods can be calculated. The initial probability distribution on the first observation on each subject is estimated using logistic regression that can involve covariates, and this estimation is embedded in the overall estimation. These models are applied to an intervention study designed to reduce children's sun exposure.},
  langid = {english},
  keywords = {binary-data,continuous-time-markov-chain,markov-model,serial},
  note = {Explicit handling of continuous time through an exponential decay.~ Likelihood involves a combination of logit and complementary log-log links, so is a bit complex and doesn't clearly extend to ordinal Y.}
}

@article{jon11bay,
  title = {Bayesian Information Criterion for Longitudinal and Clustered Data},
  author = {Jones, Richard H.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  number = {25},
  pages = {3050--3056},
  doi = {10.1002/sim.4323},
  url = {http://dx.doi.org/10.1002/sim.4323},
  abstract = {When a number of models are fit to the same data set, one method of choosing the `best' model is to select the model for which Akaike's information criterion (AIC) is lowest. AIC applies when maximum likelihood is used to estimate the unknown parameters in the model. The value of −2 log likelihood for each model fit is penalized by adding twice the number of estimated parameters. The number of estimated parameters includes both the linear parameters and parameters in the covariance structure. Another criterion for model selection is the Bayesian information criterion (BIC). BIC penalizes −2 log likelihood by adding the number of estimated parameters multiplied by the log of the sample size. For large sample sizes, BIC penalizes −2 log likelihood much more than AIC making it harder to enter new parameters into the model. An assumption in BIC is that the observations are independent. In mixed models, the observations are not independent. This paper develops a method for calculating the `effective sample size' for mixed models based on Fisher's information. The effective sample size replaces the sample size in BIC and can vary from the number of subjects to the number of observations. A number of error models are considered based on a general mixed model including unstructured, compound symmetry (random intercept), first-order autoregression with observational error and random intercept and slope.},
  citeulike-article-id = {13265909},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4323},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {aic,effective-sample-size,information-criteria,longitudinal-data,maximum-likelihood,mixed-models,serial-data}
}

@article{jon11ide,
  title = {The Identification of “Unusual” Health-Care Providers {{From}} a Hierarchical Model},
  author = {Jones, Hayley E. and Spiegelhalter, David J.},
  date = {2011},
  journaltitle = {Am Statistician},
  volume = {65},
  number = {3},
  eprint = {http://pubs.amstat.org/doi/pdf/10.1198/tast.2011.10190},
  pages = {154--163},
  doi = {10.1198/tast.2011.10190},
  url = {http://pubs.amstat.org/doi/abs/10.1198/tast.2011.10190},
  abstract = {It has become common to adopt a hierarchical model structure when comparing the performance of multiple health-care providers. This structure allows some variation in such measures, beyond that explained by sampling variation, to be ” normal,” in recognition of the fact that risk-adjustment is never perfect. The shrinkage estimates arising from such a model structure also have appealing properties. It is not immediately clear, however, how ” unusual” providers, that is, any with particularly high or low rates, can be identified based on such a model. Given that some variation in underlying rates is assumed to be the norm, we argue that it is not generally appropriate to identify a provider as interesting based only on evidence of it lying above or below the population mean. We note with concern, however, that this practice is not uncommon. We examine in detail three possible strategies for identifying unusual providers, carefully distinguishing between statistical ” outliers” and ” extremes.” A two-level normal model is used for mathematical simplicity, but we note that much of the discussion also applies to alternative data structures. Further, we emphasize throughout that each approach can be viewed as resulting from a Bayesian or a classical perspective. Three worked examples provide additional insight.},
  citeulike-article-id = {13265897},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/tast.2011.10190},
  citeulike-linkout-1 = {http://pubs.amstat.org/doi/abs/10.1198/tast.2011.10190},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {outliers,posterior-tail-areas,provider-profiling,scorecarding,unusual-performance}
}

@article{jon19sam,
  title = {Sample Size Considerations and Predictive Performance of Multinomial Logistic Prediction Models},
  author = {de Jong, Valentijn M. T. and Eijkemans, Marinus J. C. and van Calster, Ben and Timmerman, Dirk and Moons, Karel G. M. and Steyerberg, Ewout W. and van Smeden, Maarten},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8063},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8063},
  urldate = {2019-01-07},
  abstract = {Multinomial Logistic Regression (MLR) has been advocated for developing clinical prediction models that distinguish between three or more unordered outcomes. We present a full-factorial simulation study to examine the predictive performance of MLR models in relation to the relative size of outcome categories, number of predictors and the number of events per variable. It is shown that MLR estimated by Maximum Likelihood yields overfitted prediction models in small to medium sized data. In most cases, the calibration and overall predictive performance of the multinomial prediction model is improved by using penalized MLR. Our simulation study also highlights the importance of events per variable in the multinomial context as well as the total sample size. As expected, our study demonstrates the need for optimism correction of the predictive performance measures when developing the multinomial logistic prediction model. We recommend the use of penalized MLR when prediction models are developed in small data sets or in medium sized data sets with a small total sample size (ie, when the sizes of the outcome categories are balanced). Finally, we present a case study in which we illustrate the development and validation of penalized and unpenalized multinomial prediction models for predicting malignancy of ovarian cancer.},
  langid = {english},
  keywords = {multinomial,polytomous-logistic-model,sample-size}
}

@article{jon89,
  title = {A General Class of Nonparametric Tests for Survival Analysis},
  author = {Jones MP, Crowley J.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {157--170},
  citeulike-article-id = {13264366},
  posted-at = {2014-07-14 14:09:33},
  priority = {0},
  keywords = {censored-data,general,survival-analysis-regression}
}

@article{jon90,
  title = {Asymptotic Properties of a General Class of Nonparametric Tests for Survival Analysis},
  author = {Jones MP, Crowley J.},
  date = {1990},
  journaltitle = {Ann Stat},
  volume = {18},
  pages = {1203--1220},
  citeulike-article-id = {13264367},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {distribution-free-methods,survival-analysis-non-regression}
}

@article{jon91une,
  title = {Unequally {{Spaced Longitudinal Data}} with {{AR}}(1) {{Serial Correlation}}},
  author = {Jones, Richard H. and Boadi-Boateng, Francis},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  number = {1},
  eprint = {2532504},
  eprinttype = {jstor},
  pages = {161--175},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006-341X},
  doi = {10.2307/2532504},
  abstract = {This paper discusses longitudinal data analysis when each subject is observed at different unequally spaced time points. Observations within subjects are assumed to be either uncorrelated or to have a continuous-time first-order autoregressive structure, possibly with observation error. The random coefficients are assumed to have an arbitrary between-subject covariance matrix. Covariates can be included in the fixed effects part of the model. Exact maximum likelihood estimates of the unknown parameters are computed using the Kalman filter to evaluate the likelihood, which is then maximized with a nonlinear optimization program. An example is presented where a large number of subjects are each observed at a small number of observation times. Hypothesis tests for selecting the best model are carried out using Wald's test on contrasts or likelihood ratio tests based on fitting full and restricted models.},
  keywords = {autoregressive-correlation-structure,serial}
}

@article{jon92dis,
  title = {Displaying the Important Features of Large Collections of Similar Curves},
  author = {Jones, M. C. and Rice, John A.},
  date = {1992},
  journaltitle = {Am Statistician},
  volume = {46},
  pages = {140--145},
  citeulike-article-id = {13265417},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {graphics,profile,representative-curves,typical}
}

@article{jon96ind,
  title = {Indicator and Stratification Methods for Missing Explanatory Variables in Multiple Linear Regression},
  author = {Jones, Michael P.},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {222--230},
  citeulike-article-id = {13265085},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {dummy-variables-for-missing,unsatisfactory-performance}
}

@article{jon96tri,
  title = {Trials to Assess Equivalence: {{The}} Importance of Rigorous Methods},
  author = {Jones, B. and Jarvis, P. and Ebbutt, A. F.},
  date = {1996},
  journaltitle = {BMJ},
  volume = {313},
  pages = {36--39},
  doi = {10.1136/bmj.313.7048.36},
  url = {http://dx.doi.org/10.1136/bmj.313.7048.36},
  citeulike-article-id = {13264368},
  citeulike-linkout-0 = {http://dx.doi.org/10.1136/bmj.313.7048.36},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {equivalence,equivalence-testing,pharmaceutical-studies,rct,study-design,teaching-mds}
}

@article{jon97cla,
  title = {A Class of Semiparametric Regressions for the Accelerated Failure Time Model},
  author = {Jones, Michael P.},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {73--84},
  citeulike-article-id = {13264369},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {kendall-rank-correlation,linear-rank-statistic,semiparametric-accelerated-failure-time-model}
}

@article{jon98com,
  title = {A Comparison of Various Estimators of a Treatment Difference for a Multi-Centre Clinical Trial},
  author = {Jones, B. and Teather, D. and Wang, J. and Lewis, J. A.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1767--1777},
  citeulike-article-id = {13264370},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {multi-center-rct,power,type-iii-test}
}

@article{jor08met,
  title = {Methodological Quality of Pharmacogenetic Studies: {{Issues}} of Concern},
  author = {Jorgensen, Andrea L. and Williamson, Paula R.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {6547--6569},
  citeulike-article-id = {13265764},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {compliance,genetic-association-studies,methodological-quality,outcome-reporting-bias,pharmacogenetics,systematic-reviews},
  note = {problems related to gene choices, sample size, study design, reliability of genotypes, missing genotype data, population stratification, Hardy-Weinberg equilibrium, mode of inheritance, choice of outcomes, compliance; excellent brief glossary of genetic terms}
}

@article{jos04sel,
  title = {Selection Bias Found in Interpreting Analyses with Missing Data for the Prehospital Index for Trauma},
  author = {Joseph, Lawrence and Belisle, Patrick and Tamim, Hala and Sampalis, John S.},
  date = {2004},
  journaltitle = {J Clin Epi},
  volume = {57},
  pages = {147--153},
  citeulike-article-id = {13265364},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {bayesian-methods,missing-data,multiple-imputation,polytomous-regression,robustness-of-multiple-imputation,simulation-setup,single-imputation,trauma}
}

@article{jos97baya,
  title = {Bayesian Sample Size Determination for Normal Means and Differences between Normal Means},
  author = {Joseph, Lawrence and Bélisle, Patrick},
  date = {1997},
  journaltitle = {The Statistician},
  volume = {46},
  pages = {209--226},
  citeulike-article-id = {13265276},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {bayes,bayesian-sample-size-estimation,credible-interval,normal-case,optimal-design,sample-size}
}

@article{jos97bayb,
  title = {Bayesian and Mixed {{Bayesian}}/Likelihood Criteria for Sample Size Determination},
  author = {Joseph, Lawrence and Du Berger, Roxane and Bélisle, Patrick},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {769--781},
  citeulike-article-id = {13264371},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {bayesian-inference,sample-size-calculation,study-design}
}

@article{jos97int,
  title = {Interval-Based versus Decision Theoretic Criteria for the Choice of Sample Size},
  author = {Joseph, Lawrence and Wolfson, David B.},
  date = {1997},
  journaltitle = {The Statistician},
  volume = {46},
  pages = {145--149},
  citeulike-article-id = {13265275},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {bayes,bayesian-sample-size-estimation,decision-theory,highest-posterior-density,sample-size}
}

@article{jov01usi,
  title = {Using Information on Realized Effects to Determine Prospective Causal Effects},
  author = {Joffe, Marshall M.},
  date = {2001},
  journaltitle = {J Roy Stat Soc B},
  volume = {63},
  pages = {759--774},
  citeulike-article-id = {13265243},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {cancer-screening,causal-inference,mammography,observational-studies,problems-with-counterfactuals,readable-discussion}
}

@article{jov97loo,
  title = {A Look at the Rule of Three},
  author = {Jovanovic, B. D. and Levy, P. S.},
  date = {1997},
  journaltitle = {Am Statistician},
  volume = {51},
  pages = {137--139},
  citeulike-article-id = {13264372},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {3-n-rule}
}

@article{jud07var,
  title = {Variable Selection and Raking in Propensity Scoring},
  author = {Judkins, David R. and Morganstein, David and Zador, Paul and Piesse, Andrea and Barrett, Brandon and Mukhopadhyay, Pushpal},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {1022--1033},
  citeulike-article-id = {13265561},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {calibration,causal-inference,health-communication,program-evaluation,propensity-score},
  note = {"articles dating back ... have pointed to situations where variance reduction can be achieved by making the models richer than strictly required to achieve bias elimination. In practice, this suggests a double benefit to overfitting in that both the risk of bias and variance are made smaller. We show that this double benefit is available only when the number of potential covariates is small relative to the sample size and when the covariates are related to outcomes.";ordinal treatment intensity modeled with ordinal logistic model;overfitting of the propensity model is beneficial if the extra variables are correlated with the outcome;if there are "only 10 cases per available covariate, dramatic overfitting can easily occur that will rob the analysis of all power to detect effects";polytomous model when PO violated;raking requires large sample sizes and categorical covariates}
}

@article{jul08pro,
  title = {Profile-Specific Survival Estimates: {{Making}} Reports of Clinical Trials More Patient-Relevant},
  author = {Julien, Marilyse and Hanley, James A.},
  date = {2008},
  journaltitle = {CT},
  volume = {5},
  pages = {107--115},
  doi = {10.1177/1740774508089511},
  url = {http://dx.doi.org/10.1177/1740774508089511},
  citeulike-article-id = {13265661},
  citeulike-linkout-0 = {http://dx.doi.org/10.1177/1740774508089511},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {clinical-prediction,personalized-medicine,prognosis,rct,reporting,teaching-mds},
  note = {limitations of clinical trial reports of crude summaries;nomogram;use of Design package;extended nomogram with absolute treatment effect axes}
}

@article{jul96sam,
  title = {Sample Size Calculations for Ordered Categorical Data (Letter to the Editor)},
  author = {Julious, Steven A. and Campbell, Michael J.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1065--1066},
  citeulike-article-id = {13264373},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  note = {Shows closeness of Whitehead formula to usual formulas for binary case;see whi93sam}
}

@article{jus99ass,
  title = {Assessing the Generalizability of Prognostic Information},
  author = {Justice, Amy C. and Covinsky, Kenneth E. and Berlin, Jesse A.},
  date = {1999},
  journaltitle = {Ann Int Med},
  volume = {130},
  pages = {515--524},
  citeulike-article-id = {13265148},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {external-validation,generalizability,multivariable-modeling,prognosis,reporting,survival-analysis,teaching-mds,validation,validation-criteria}
}

@article{kac21bay,
  title = {Bayesian Sensitivity Analyses for Longitudinal Data with Dropouts That Are Potentially Missing Not at Random: {{A}} High Dimensional Pattern-Mixture Mode},
  shorttitle = {Bayesian Sensitivity Analyses for Longitudinal Data with Dropouts That Are Potentially Missing Not at Random},
  author = {Kaciroti, Niko A. and Little, Roderick J. A.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9083},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9083},
  urldate = {2021-06-03},
  abstract = {Randomized clinical trials with outcome measured longitudinally are frequently analyzed using either random effect models or generalized estimating equations. Both approaches assume that the dropout mechanism is missing at random (MAR) or missing completely at random (MCAR). We propose a Bayesian pattern-mixture model to incorporate missingness mechanisms that might be missing not at random (MNAR), where the distribution of the outcome measure at the follow-up time tk, conditional on the prior history, differs across the patterns of missing data. We then perform sensitivity analysis on estimates of the parameters of interest. The sensitivity parameters relate the distribution of the outcome of interest between subjects from a missing-data pattern at time tk with that of the observed subjects at time tk. The large number of the sensitivity parameters is reduced by treating them as random with a prior distribution having some pre-specified mean and variance, which are varied to explore the sensitivity of inferences. The missing at random (MAR) mechanism is a special case of the proposed model, allowing a sensitivity analysis of deviations from MAR. The proposed approach is applied to data from the Trial of Preventing Hypertension.},
  langid = {english},
  keywords = {bayes,dropout,longitudinal,missing-not-at-random,sensitivity-analysis,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9083}
}

@article{kad96rep,
  title = {Reply to Letter by {{O}}'{{Rourke}}},
  author = {Kadane, Joseph B.},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {352},
  citeulike-article-id = {13264374},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {bayesian-inference},
  note = {On posterior being a function of the prior}
}

@article{kah15rer,
  title = {A Re-Randomisation Design for Clinical Trials},
  author = {Kahan, Brennan C. and Forbes, Andrew B. and Doré, Caroline J. and Morris, Tim P.},
  date = {2015},
  journaltitle = {BMC Med Res Methodol},
  volume = {15},
  number = {1},
  pages = {96},
  doi = {10.1186/s12874-015-0082-2},
  url = {https://doi.org/10.1186/s12874-015-0082-2},
  abstract = {Recruitment to clinical trials is often problematic, with many trials failing to recruit to their target sample size. As a result, patient care may be based on suboptimal evidence from underpowered trials or non-randomised studies.},
  citeulike-article-id = {14548734},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/s12874-015-0082-2},
  citeulike-linkout-1 = {https://doi.org/10.1186/s12874-015-0082-2},
  day = {05},
  posted-at = {2018-03-14 15:09:48},
  priority = {2},
  keywords = {adaptive-design,randomization,rct}
}

@article{kai12ine,
  title = {Inefficiency of Randomization Methods That Balance on Stratum Margins and Improvements with Permuted Blocks and a Sequential Method},
  author = {Kaiser, Lee D.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {16},
  pages = {1699--1706},
  doi = {10.1002/sim.5345},
  url = {http://dx.doi.org/10.1002/sim.5345},
  abstract = {Stratified permuted blocks randomization is commonly applied in clinical trials, but other randomization methods that attempt to balance treatment counts marginally for the stratification variables are able to accommodate more stratification variables. When the analysis stratifies on the cells formed by crossing the stratification variables, these other randomization methods yield treatment effect estimates with larger variance than does stratified permuted blocks. When it is truly necessary to balance the randomization on many stratification variables, it is shown how this inefficiency can be improved by using a sequential randomization method where the first level balances on the crossing of the strata used in the analysis and further stratification variables fall lower in the sequential hierarchy.},
  citeulike-article-id = {13265931},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5345},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {dynamic-randomization,permuted-blocks-randomization,pocock-and-simon-method,sequential-randomization,study-design}
}

@article{kai87,
  title = {Numerical and Graphical Data Summary Using {{O-statistics}}},
  author = {Kaigh WD, Driscoll M. F.},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {25--32},
  citeulike-article-id = {13264375},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {graphical-methods,order-statistics,quantiles}
}

@article{kai89,
  title = {Adjusting for Baseline: {{Change}} or Percentage Change?},
  author = {Kaiser, Lee},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {1183--1190},
  doi = {10.1002/sim.4780081002},
  url = {http://dx.doi.org/10.1002/sim.4780081002},
  citeulike-article-id = {13264376},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780081002},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {change,measurement,measuring-change,miscellaneous,one-sample-problem,percent-change,research-methods,teaching-mds}
}

@article{kak19bay,
  title = {Bayesian Sample-Size Determination Methods Considering Both Worthwhileness and Unpromisingness for Exploratory Two-Arm Randomized Clinical Trials with Binary Endpoints},
  author = {Kakizume, Tomoyuki and Zhang, Fanghong and Kawasaki, Yohei and Daimon, Takashi},
  date = {2019},
  journaltitle = {Pharmaceutical Statistics},
  volume = {0},
  number = {0},
  issn = {1539-1612},
  doi = {10.1002/pst.1971},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1971},
  urldate = {2019-09-15},
  abstract = {A randomized exploratory clinical trial comparing an experimental treatment with a control treatment on a binary endpoint is often conducted to make a go or no-go decision. Such an exploratory trial needs to have an adequate sample size such that it will provide convincing evidence that the experimental treatment is either worthwhile or unpromising relative to the control treatment. In this paper, we propose three new sample-size determination methods for an exploratory trial, which utilize the posterior probabilities calculated from predefined efficacy and inefficacy criteria leading to a declaration of the worthwhileness or unpromisingness of the experimental treatment. Simulation studies, including numerical investigation, showed that all three methods could declare the experimental treatment as worthwhile or unpromising with a high probability when the true response probability of the experimental treatment group is higher or lower, respectively, than that of the control treatment group.},
  langid = {english},
  keywords = {bayes,sample-size}
}

@article{kal73,
  title = {Marginal Likelihood Based on {{Cox}}'s Regression and Life Model},
  author = {Kalbfleisch, J. D. and Prentice, R. L.},
  date = {1973},
  journaltitle = {Biometrika},
  volume = {60},
  pages = {267--278},
  citeulike-article-id = {13264377},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@book{kal80,
  title = {The {{Statistical Analysis}} of {{Failure Time Data}}},
  author = {Kalbfleisch, J. D. and Prentice, R. L.},
  date = {1980},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264378},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kal86tre,
  title = {The Treatment of Missing Survey Data},
  author = {Kalton, Graham and Kasprzyk, Dan},
  date = {1986},
  journaltitle = {Surv Meth},
  volume = {12},
  pages = {1--16},
  citeulike-article-id = {13264379},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  note = {imputation method where one finds an observation having a predicted value of the variable in question that is closest to the predicted value of the observation with the missing value, then the missing value is replaced by its predicted value plus the residual for the matching observation}
}

@article{kal88,
  title = {Efficiency of Balanced Treatment Allocation for Survival Analysis},
  author = {Kalish, L. A. and Harrington, D. P.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {815--821},
  citeulike-article-id = {13264380},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {study-design-and-stopping-rules,survival-analysis-proportional-hazards-model}
}

@article{kal88est,
  title = {Estimation of Reliability in Field-Performance Studies, with Discussion},
  author = {Kalbfleisch, J. D. and {Prentice}},
  date = {1988},
  journaltitle = {Technometrics},
  volume = {30},
  pages = {365--388},
  citeulike-article-id = {13264381},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kal97tre,
  title = {Treatment-by-Center Interaction: {{What}} Is the Issue?},
  author = {Källén, Anders},
  date = {1997},
  journaltitle = {Drug Info J},
  volume = {31},
  pages = {927--936},
  citeulike-article-id = {13264382},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {treatment-x-center-interaction,type-iii-sum-of-squares}
}

@article{kal99dat,
  title = {Data-Driven Rank Tests for Independence},
  author = {Kallenberg, Wilbert C. M. and Ledwina, Teresa},
  date = {1999},
  journaltitle = {J Am Stat Assoc},
  volume = {94},
  pages = {285--301},
  citeulike-article-id = {13264383},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {hoeffding-test,spearman},
  note = {general test of independence;power of Hoeffding and Spearman test;may have low power with weaker linear correlation}
}

@article{kan15sim,
  title = {Simultaneous Control of Error Rates in {{fMRI}} Data Analysis.},
  author = {Kang, Hakmook and Blume, Jeffrey D. and Ombao, Hernando and Badre, David},
  date = {2015-12},
  journaltitle = {NeuroImage},
  volume = {123},
  eprint = {26272730},
  eprinttype = {pmid},
  pages = {102--113},
  issn = {1095-9572},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26272730},
  abstract = {The key idea of statistical hypothesis testing is to fix, and thereby control, the Type I error (false positive) rate across samples of any size. Multiple comparisons inflate the global (family-wise) Type I error rate and the traditional solution to maintaining control of the error rate is to increase the local (comparison-wise) Type II error (false negative) rates. However, in the analysis of human brain imaging data, the number of comparisons is so large that this solution breaks down: the local Type II error rate ends up being so large that scientifically meaningful analysis is precluded. Here we propose a novel solution to this problem: allow the Type I error rate to converge to zero along with the Type II error rate. It works because when the Type I error rate per comparison is very small, the accumulation (or global) Type I error rate is also small. This solution is achieved by employing the likelihood paradigm, which uses likelihood ratios to measure the strength of evidence on a voxel-by-voxel basis. In this paper, we provide theoretical and empirical justification for a likelihood approach to the analysis of human brain imaging data. In addition, we present extensive simulations that show the likelihood approach is viable, leading to "cleaner"-looking brain maps and operational superiority (lower average error rate). Finally, we include a case study on cognitive control related activation in the prefrontal cortex of the human brain. Copyright  2015 Elsevier Inc. All rights reserved.},
  citeulike-article-id = {14033818},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26272730},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26272730},
  posted-at = {2016-05-12 13:08:02},
  priority = {2},
  keywords = {ctsafac}
}

@article{kap14sam,
  title = {Sample Size Determination for Longitudinal Designs with Binary Response},
  author = {Kapur, Kush and Bhaumik, Runa and Charlene Tang, X. and Hur, Kwan and Reda, Domenic J. and Bhaumik, Dulal K.},
  date = {2014-09},
  journaltitle = {Stat Med},
  volume = {33},
  number = {22},
  pages = {3781--3800},
  doi = {10.1002/sim.6203},
  url = {http://dx.doi.org/10.1002/sim.6203},
  abstract = {In this article, we develop appropriate statistical methods for determining the required sample size while comparing the efficacy of an intervention to a control with repeated binary response outcomes. Our proposed methodology incorporates the complexity of the hierarchical nature of underlying designs and provides solutions when varying attrition rates are present over time. We explore how the between-subject variability and attrition rates jointly influence the computation of sample size formula. Our procedure also shows how efficient estimation methods play a crucial role in power analysis. A practical guideline is provided when information regarding individual variance component is unavailable. The validity of our methods is established by extensive simulation studies. Results are illustrated with the help of two randomized clinical trials in the areas of contraception and insomnia.},
  citeulike-article-id = {13448111},
  citeulike-attachment-1 = {kap14sam.pdf; /pdf/user/harrelfe/article/13448111/996103/kap14sam.pdf; 5631fa37d3e83cacf197dc94de3aee92aa3ef6d9},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6203},
  day = {30},
  posted-at = {2014-11-29 16:03:42},
  priority = {2},
  keywords = {longitudinal-data,mixed-effects-model,sample-size,serial-data,study-design}
}

@article{kap19ran,
  title = {Randomized {{Trial}} of {{Three Anticonvulsant Medications}} for {{Status Epilepticus}}},
  author = {Kapur, Jaideep and Elm, Jordan and Chamberlain, James M. and Barsan, William and Cloyd, James and Lowenstein, Daniel and Shinnar, Shlomo and Conwit, Robin and Meinzer, Caitlyn and Cock, Hannah and Fountain, Nathan and Connor, Jason T. and Silbergleit, Robert},
  date = {2019-11-28},
  journaltitle = {New England Journal of Medicine},
  volume = {381},
  number = {22},
  pages = {2103--2113},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa1905795},
  url = {https://doi.org/10.1056/NEJMoa1905795},
  urldate = {2019-11-29},
  keywords = {bayes,rct}
}

@article{kap58,
  title = {Nonparametric Estimation from Incomplete Observations},
  author = {Kaplan, E. L. and Meier, P.},
  date = {1958},
  journaltitle = {J Am Stat Assoc},
  volume = {53},
  pages = {457--481},
  citeulike-article-id = {13264384},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kar09vis,
  title = {Visualizing Covariates in Proportional Hazards Model},
  author = {Karvanen, Juha and Harrell, Frank E.},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {1957--1966},
  citeulike-article-id = {13265769},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {coronary-heart-disease,covariate-effects,predictor-effects,rank-hazard-plot,relative-importance,statistical-graphics,survival-analysis,visualization}
}

@article{kar19opt,
  title = {Optimizing {{Sample Size Allocation}} and {{Power}} in a {{Bayesian Two-Stage Drop-the-Losers Design}}},
  author = {Karanevich, Alex and Meier, Richard and Graw, Stefan and McGlothlin, Anna and Gajewski, Byron},
  date = {2019-05-03},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--10},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2019.1610065},
  url = {https://doi.org/10.1080/00031305.2019.1610065},
  urldate = {2020-09-20},
  abstract = {When a researcher desires to test several treatment arms against a control arm, a two-stage adaptive design can be more efficient than a single-stage design where patients are equally allocated to all treatment arms and the control. We see this type of approach in clinical trials as a seamless Phase II–Phase III design. These designs require more statistical support and are less straightforward to plan and analyze than a standard single-stage design. To diminish the barriers associated with a Bayesian two-stage drop-the-losers design, we built a user-friendly point-and-click graphical user interface with R Shiny to aid researchers in planning such designs by allowing them to easily obtain trial operating characteristics, estimate statistical power and sample size, and optimize patient allocation in each stage to maximize power. We assume that endpoints are distributed normally with unknown but common variance between treatments. We recommend this software as an easy way to engage statisticians and researchers in two-stage designs as well as to actively investigate the power of two-stage designs relative to more traditional approaches. The software is freely available at https://github.com/stefangraw/Allocation-Power-Optimizer.},
  keywords = {adaptive,bayes,sample-size},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2019.1610065}
}

@article{kar87res,
  title = {Restricted Mean Life with Adjustment for Covariates},
  author = {Karrison, Theodore},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {1169--1176},
  citeulike-article-id = {13264385},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {restricted-mean-life}
}

@article{kar97use,
  title = {Use of {{Irwin}}'s Restricted Mean as an Index for Comparing Survival in Different Treatment Groups---{{Interpretation}} and Power Considerations},
  author = {Karrison, Theodore G.},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {151--167},
  citeulike-article-id = {13264386},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {covariates,early-vs-late-survival-differences,mean-restricted-life,non-ph,piecewise-exponential-distribution,power,simulation-setup},
  note = {nice power comparisons with Wilcoxon;power with and without covariable adjustment}
}

@article{kas18inf,
  title = {Information Content of Cluster–Period Cells in Stepped Wedge Trials},
  author = {Kasza, Jessica and Forbes, Andrew B.},
  date = {2018},
  journaltitle = {Biometrics},
  volume = {0},
  number = {0},
  issn = {1541-0420},
  doi = {10.1111/biom.12959},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12959},
  urldate = {2018-08-29},
  abstract = {Stepped wedge and other multiple-period cluster randomized trials, which collect data from multiple clusters across multiple time periods, are being conducted with increasing frequency; statistical research into these designs has not kept apace. In particular, some stepped wedge designs with missing cluster–period “cells” have been proposed without any formal justification. Indeed there are no general guidelines regarding which cells of a stepped wedge design contribute the least information toward estimation of the treatment effect, and correspondingly which may be preferentially omitted. In this article, we define a metric of the information content of cluster–period cells, entire treatment sequences, and entire periods of the standard stepped wedge design as the increase in variance of the estimator of the treatment effect when that cell, sequence, or period is omitted. We show that the most information-rich cells are those that occur immediately before or after treatment switches, but also that there are additional cells that contribute almost as much to the estimation of the treatment effect. However, the information content patterns depend on the assumed correlation structure for the repeated measurements within a cluster.},
  langid = {english},
  keywords = {cluster-randomization,rct,stepped-wedge}
}

@article{kas19tre,
  title = {Beyond “{{Treatment Versus Control}}”: {{How Bayesian Analysis Makes Factorial Experiments Feasible}} in {{Education Research}}},
  shorttitle = {Beyond “{{Treatment Versus Control}}”},
  author = {Kassler, Daniel and Nichols-Barrer, Ira and Finucane, Mariel},
  date = {2019-01-10},
  journaltitle = {Eval Rev},
  pages = {0193841X18818903},
  issn = {0193-841X},
  doi = {10.1177/0193841X18818903},
  url = {https://doi.org/10.1177/0193841X18818903},
  urldate = {2019-08-13},
  abstract = {Background:Researchers often wish to test a large set of related interventions or approaches to implementation. A factorial experiment accomplishes this by examining not only basic treatment?control comparisons but also the effects of multiple implementation ?factors? such as different dosages or implementation strategies and the interactions between these factor levels. However, traditional methods of statistical inference may require prohibitively large sample sizes to perform complex factorial experiments.Objectives:We present a Bayesian approach to factorial design. Through the use of hierarchical priors and partial pooling, we show how Bayesian analysis substantially increases the precision of estimates in complex experiments with many factors and factor levels, while controlling the risk of false positives from multiple comparisons.Research design:Using an experiment we performed for the U.S. Department of Education as a motivating example, we perform power calculations for both classical and Bayesian methods. We repeatedly simulate factorial experiments with a variety of sample sizes and numbers of treatment arms to estimate the minimum detectable effect (MDE) for each combination.Results:The Bayesian approach yields substantially lower MDEs when compared with classical methods for complex factorial experiments. For example, to test 72 treatment arms (five factors with two or three levels each), a classical experiment requires nearly twice the sample size as a Bayesian experiment to obtain a given MDE.Conclusions:Bayesian methods are a valuable tool for researchers interested in studying complex interventions. They make factorial experiments with many treatment arms vastly more feasible.},
  langid = {english},
  keywords = {bayes,hierarchical-model,interaction,sample-size}
}

@article{kas20sam,
  title = {Sample Size and Power Calculations for Open Cohort Longitudinal Cluster Randomized Trials},
  author = {Kasza, Jessica and Hooper, Richard and Copas, Andrew and Forbes, Andrew B.},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8519},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8519},
  urldate = {2020-03-06},
  abstract = {When calculating sample size or power for stepped wedge or other types of longitudinal cluster randomized trials, it is critical that the planned sampling structure be accurately specified. One common assumption is that participants will provide measurements in each trial period, that is, a closed cohort, and another is that each participant provides only one measurement during the course of the trial. However some studies have an “open cohort” sampling structure, where participants may provide measurements in variable numbers of periods. To date, sample size calculations for longitudinal cluster randomized trials have not accommodated open cohorts. Feldman and McKinlay (1994) provided some guidance, stating that the participant-level autocorrelation could be varied to account for the degree of overlap in different periods of the study, but did not indicate precisely how to do so. We present sample size and power formulas that allow for open cohorts and discuss the impact of the degree of “openness” on sample size and power. We consider designs where the number of participants in each cluster will be maintained throughout the trial, but individual participants may provide differing numbers of measurements. Our results are a unification of closed cohort and repeated cross-sectional sample results of Hooper et al (2016), and indicate precisely how participant autocorrelation of Feldman and McKinlay should be varied to account for an open cohort sampling structure. We discuss different types of open cohort sampling schemes and how open cohort sampling structure impacts on power in the presence of decaying within-cluster correlations and autoregressive participant-level errors.},
  langid = {english},
  keywords = {cluster-randomization,cluster-randomized-trial,longitudinal,sample-size},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8519}
}

@article{kas95bay,
  title = {Bayes Factors},
  author = {Kass, Robert E. and Raftery, Adrian E.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {773--795},
  citeulike-article-id = {13264387},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {aic,akaike,bic,complexity,model-validation,predictive-accuracy,schwarz,variable-selection}
}

@article{kas95ref,
  title = {A Reference {{Bayesian}} Test for Nested Hypotheses and Its Relationship to the {{Schwarz}} Criterion},
  author = {Kass, Robert E. and Wasserman, Larry},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {928--934},
  citeulike-article-id = {13264388},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {bayes-factor,bic,model-selection,schwarz-criterion,variable-selection}
}

@article{kas96sel,
  title = {The Selection of Prior Distributions by Formal Rules},
  author = {Kass, Robert E. and Wasserman, Larry},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {1343--1370},
  citeulike-article-id = {13264389},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {automatic-priors-using-formal-rules,bayesian-inference,choice-of-prior}
}

@article{kas98met,
  title = {A Meta-Analysis of the Effects of Dietary Protein Restriction on the Rate of Decline in Renal Function},
  author = {Kasiske, Bertram L. and Lakatua, John D. A. and Ma, Jennie Z. and Louis, Thomas A.},
  date = {1998},
  journaltitle = {Am J Kidney Dis},
  volume = {31},
  pages = {954--961},
  citeulike-article-id = {13264390},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {multiple-imputation,publication-bias,teaching-mds},
  note = {excellent example of meta-analysis;covariable modeling on grouped data; randomized vs. non-randomized study as covariable; follow-up time as covariable}
}

@article{kat03com,
  title = {A Competing-Risks Nomogram for Sarcoma-Specific Death Following Local Recurrence},
  author = {Kattan, Michael W. and Heller, Glenn and Brennan, Murray F.},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {3515--3525},
  citeulike-article-id = {13265357},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  note = {great explanation of competing risks and limitations of doing simple cause-specific analyses;conditional cumulative incidence function;nomogram;graphical presentation of model;nomograms with multiple prediction axes;avoids problem of requiring two prognostic indexes for conditional cumulative incidence function by using the subdistribution hazard function, which is the instantaneous rate of dying from the cause of interest at time t given alive at time t or died at a previous time from another cause}
}

@article{kat03mul,
  title = {Multivariable Analysis: {{A}} Primer for Readers of Medical Research},
  author = {Katz, Mitchell H.},
  date = {2003},
  journaltitle = {Ann Int Med},
  volume = {138},
  pages = {644--650},
  doi = {10.7326/0003-4819-138-8-200304150-00012},
  url = {http://dx.doi.org/10.7326/0003-4819-138-8-200304150-00012},
  citeulike-article-id = {13265324},
  citeulike-linkout-0 = {http://dx.doi.org/10.7326/0003-4819-138-8-200304150-00012},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {multivariable-modeling,teaching-mds},
  note = {good descriptions and background to modeling;bad advice on categorizing continuous variables and not enough warning about stepwise variable selection;slight error in discussing independent censoring}
}

@book{kat06mul,
  title = {Multivariable {{Analysis}}: {{A Practical Guide}} for {{Clinicians}}},
  author = {Katz, Mitchell H.},
  date = {2006},
  edition = {Second},
  publisher = {{Cambridge University Press}},
  citeulike-article-id = {13265149},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  note = {review in Stat in Med 20:1151-2; 2001}
}

@article{kat10wha,
  title = {What Is a Real Nomogram?},
  author = {Kattan, Michael W. and Marasco, Joe},
  date = {2010-02},
  journaltitle = {Sem Onc},
  volume = {37},
  number = {1},
  pages = {23--26},
  citeulike-article-id = {13265795},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {clinical-prediction,graphics,nomogram},
  note = {nice examples;advantages of using nomograms for clinical prediction vs. black boxes}
}

@article{kat16we,
  title = {We Should Not Be so Quick to Abandon the Use of Domain Experts and Full Models (Letter Commenting: {{J Clin Epidemiol}}. 2015;{{71C}}:76--85.)},
  shorttitle = {We Should Not Be so Quick to Abandon the Use of Domain Experts and Full Models (Letter Commenting},
  author = {Kattan, Michael W. and Harrell, Frank E.},
  date = {2016-07},
  journaltitle = {J Clin Epidemiol},
  volume = {75},
  eprint = {26939928},
  eprinttype = {pmid},
  pages = {131},
  issn = {1878-5921},
  doi = {10.1016/j.jclinepi.2016.02.010},
  langid = {english},
  keywords = {rms}
}

@article{kau04inc,
  title = {Incremental Value of Cardiac Imaging in Patients Presenting to the Emergency Department with Chest Pain and without {{ST-segment}} Elevation: A Multicenter Study},
  author = {Kaul, Sanjiv and Senior, Roxy and Firschke, Christian and Wang, Xin-Qun and Lindner, Jonathan and Villanueva, Flordeliza S. and Firozan, Soroosh and Kontos, Michael C. and Taylor, Allen and Nixon, Ian J. and Watson, Denny D. and Harrell, Frank E.},
  date = {2004},
  journaltitle = {Am Heart J},
  volume = {148},
  pages = {129--136},
  url = {http://authors.elsevier.com/sd/article/S0002870304001012},
  citeulike-article-id = {13265372},
  citeulike-linkout-0 = {http://authors.elsevier.com/sd/article/S0002870304001012},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{kaw19var,
  title = {Variants in {{BMI-Associated Genes}} and {{Adrenergic Genes}} Are Not {{Associated}} with {{Gestational Weight Trajectory}}},
  author = {Kawai, Vivian K. and Nwosu, Samuel K. and Kurnik, Daniel and Harrell, Frank E. and Stein, C. Michael},
  date = {2019-07},
  journaltitle = {Obesity (Silver Spring)},
  volume = {27},
  number = {7},
  eprint = {31116007},
  eprinttype = {pmid},
  pages = {1184--1189},
  issn = {1930-739X},
  doi = {10.1002/oby.22505},
  abstract = {OBJECTIVE: The aim of this study is to define the association between a genetic risk score (GRS) that combined the effect of multiple BMI-associated variants and gestational weight trajectory. Because pregnancy is a state of sympathetic activation, the association between gestational weight trajectory and variants in adrenergic pathways previously associated with weight was examined. METHODS: In a previously defined cohort of pregnant women with (n\,=\,1,504) and without gestational diabetes (GDM) (n\,=\,435), weight trajectory was calculated using all weights during pregnancy. A GRS for BMI (GRSBMI ) was calculated using 31 common variants associated with BMI, and 10 variants in the adrenergic pathways were genotyped. Clinical and genetic factors were studied using generalized linear models. RESULTS: Prepregnancy BMI was associated with the GRSBMI (P\,=\,9.3\,×\,10-11 ) and parity (P\,=\,4.54\,×\,10-17 ). The GRSBMI was associated with gestational weight trajectory in women with and without GDM (P\,=\,0.041 and P\,{$<$}\,0.0001, respectively); however, when prepregnancy BMI was included in the models, the associations disappeared (P\,{$>$}\,0.05). Variants in adrenergic genes were not associated with gestational weight trajectory. CONCLUSIONS: A GRS for BMI was associated with prepregnancy BMI but was not independently associated with gestational weight trajectory in women with and without GDM. Selected variants in adrenergic genes were not associated with gestational weight trajectory.},
  langid = {english},
  pmcid = {PMC6591076},
  keywords = {bmi,collaboration,genetics}
}

@article{kay20imp,
  title = {Imputation of Missing Covariate in Randomized Controlled Trials with a Continuous Outcome: {{Scoping}} Review and New Results},
  shorttitle = {Imputation of Missing Covariate in Randomized Controlled Trials with a Continuous Outcome},
  author = {Kayembe, Mutamba T. and Jolani, Shahab and Tan, Frans E. S. and van Breukelen, Gerard J. P.},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {19},
  number = {6},
  pages = {840--860},
  issn = {1539-1612},
  doi = {10.1002/pst.2041},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2041},
  urldate = {2020-12-08},
  abstract = {In this article, we first review the literature on dealing with missing values on a covariate in randomized studies and summarize what has been done and what is lacking to date. We then investigate the situation with a continuous outcome and a missing binary covariate in more details through simulations, comparing the performance of multiple imputation (MI) with various simple alternative methods. This is finally extended to the case of time-to-event outcome. The simulations consider five different missingness scenarios: missing completely at random (MCAR), at random (MAR) with missingness depending only on the treatment, and missing not at random (MNAR) with missingness depending on the covariate itself (MNAR1), missingness depending on both the treatment and covariate (MNAR2), and missingness depending on the treatment, covariate and their interaction (MNAR3). Here, we distinguish two different cases: (1) when the covariate is measured before randomization (best practice), where only MCAR and MNAR1 are plausible, and (2) when it is measured after randomization but before treatment (which sometimes occurs in nonpharmaceutical research), where the other three missingness mechanisms can also occur. The proposed methods are compared based on the treatment effect estimate and its standard error. The simulation results suggest that the patterns of results are very similar for all missingness scenarios in case (1) and also in case (2) except for MNAR3. Furthermore, in each scenario for continuous outcome, there is at least one simple method that performs at least as well as MI, while for time-to-event outcome MI is best.},
  langid = {english},
  keywords = {covariable-adjustment,missing,missing-covariable-values,multiple-imputation,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2041}
}

@article{kay86ass,
  title = {Assessing the Fit of the Logistic Model: {{A}} Case Study of Children with the Haemolytic Uraemic Syndrome},
  author = {Kay, Richard and Little, Sarah},
  date = {1986},
  journaltitle = {Appl Stat},
  volume = {35},
  pages = {16--30},
  citeulike-article-id = {13264391},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {assumption-checking,graphical-methods,logistic-binary-model,residuals}
}

@article{kay86tre,
  title = {Treatment Effects in Competing-Risks Analysis of Prostate Cancer Data},
  author = {Kay, Richard},
  date = {1986},
  journaltitle = {Biometrics},
  volume = {42},
  pages = {203--211},
  citeulike-article-id = {13264392},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {assessment-of-ph,cause-specific-hazard,competing-risks,hazard-ratio-plots,interaction}
}

@article{kay87com,
  title = {Comparison of the Survival of {{Amiodarone-treated}} Patients with Coronary Artery Disease and Malignant Ventricular Arrhythmias with That of a Control Group with Coronary Artery Disease},
  author = {Kay, G. N. and Pryor, D. B. and Lee, K. L. and Harrell, F. E. and Pressley, J. C. and Gilbert, M. R. and German, L. D.},
  date = {1987},
  journaltitle = {J Am Coll Cardiol},
  volume = {9},
  pages = {877--881},
  citeulike-article-id = {13264393},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kee17bay,
  title = {Bayesian Sensitivity Analysis for Causal Effects from 2 Tables in the Presence of Unmeasured Confounding with Application to Presidential Campaign Visits},
  author = {Keele, Luke and Quinn, Kevin M.},
  date = {2017-12},
  journaltitle = {Ann App Stat},
  volume = {11},
  number = {4},
  pages = {1974--1997},
  doi = {10.1214/17-AOAS1048},
  url = {https://doi.org/10.1214/17-AOAS1048},
  citeulike-article-id = {14546623},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/17-AOAS1048},
  citeulike-linkout-1 = {https://doi.org/10.1214/17-AOAS1048},
  posted-at = {2018-03-09 20:04:17},
  priority = {2},
  keywords = {bayes,bayesian-inference,causal-inference,confounding,sensitivity-analysis}
}

@article{kee18str,
  title = {Strategies for Composite Estimands in Confirmatory Clinical Trials: {{Examples}} from Trials in Nasal Polyps and Steroid Reduction},
  shorttitle = {Strategies for Composite Estimands in Confirmatory Clinical Trials},
  author = {Keene, Oliver N.},
  date = {2018},
  journaltitle = {Pharmaceutical Statistics},
  volume = {0},
  number = {0},
  issn = {1539-1612},
  doi = {10.1002/pst.1909},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1909},
  urldate = {2018-11-10},
  abstract = {The draft addendum to the ICH E9 regulatory guideline asks for explicit definition of the treatment effect to be estimated in clinical trials. The draft guideline also introduces the concept of intercurrent events to describe events that occur post-randomisation that may affect efficacy assessment. Composite estimands allow incorporation of intercurrent events in the definition of the endpoint. A common example of an intercurrent event is discontinuation of randomised treatment and use of a composite strategy would assess treatment effect based on a variable that combines the outcome variable of interest with discontinuation of randomised treatment. Use of a composite estimand may avoid the need for imputation which would be required by a treatment policy estimand. The draft guideline gives the example of a binary approach for specifying a composite estimand. When the variable is measured on a non-binary scale, other options are available where the intercurrent event is given an extreme unfavourable value, for example comparison of median values or analysis based on categories of response. This paper reviews approaches to deriving a composite estimand and contrasts the use of this estimand to the treatment policy estimand. The benefits of using each strategy are discussed and examples of the use of the different approaches are given for a clinical trial in nasal polyposis and a steroid reduction trial in severe asthma.},
  langid = {english},
  keywords = {compound-endpoints,intercurrent-event,multiple-endpoints,rct}
}

@article{kee19str,
  title = {Strategies for Composite Estimands in Confirmatory Clinical Trials: {{Examples}} from Trials in Nasal Polyps and Steroid Reduction},
  shorttitle = {Strategies for Composite Estimands in Confirmatory Clinical Trials},
  author = {Keene, Oliver N.},
  date = {2019},
  journaltitle = {Pharmaceutical Statistics},
  volume = {18},
  number = {1},
  pages = {78--84},
  issn = {1539-1612},
  doi = {10.1002/pst.1909},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1909},
  urldate = {2019-01-26},
  abstract = {The draft addendum to the ICH E9 regulatory guideline asks for explicit definition of the treatment effect to be estimated in clinical trials. The draft guideline also introduces the concept of intercurrent events to describe events that occur post-randomisation that may affect efficacy assessment. Composite estimands allow incorporation of intercurrent events in the definition of the endpoint. A common example of an intercurrent event is discontinuation of randomised treatment and use of a composite strategy would assess treatment effect based on a variable that combines the outcome variable of interest with discontinuation of randomised treatment. Use of a composite estimand may avoid the need for imputation which would be required by a treatment policy estimand. The draft guideline gives the example of a binary approach for specifying a composite estimand. When the variable is measured on a non-binary scale, other options are available where the intercurrent event is given an extreme unfavourable value, for example comparison of median values or analysis based on categories of response. This paper reviews approaches to deriving a composite estimand and contrasts the use of this estimand to the treatment policy estimand. The benefits of using each strategy are discussed and examples of the use of the different approaches are given for a clinical trial in nasal polyposis and a steroid reduction trial in severe asthma.},
  langid = {english},
  keywords = {composite-endpoints,compound-endpoints,drug-development,multiple-endpoints}
}

@article{kei87,
  title = {Confirmatory Analysis of Survival Data Using Left Truncation of the Life Times of Primary Survivors},
  author = {Keiding, N. and Bayer, T. and Steen, Watt-Boolsen},
  date = {1987},
  journaltitle = {Stat Res Unit UCop},
  volume = {0},
  citeulike-article-id = {13264394},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {general,predictive-accuracy,survival-analysis-regression}
}

@article{kel00sur,
  title = {Survival Analysis for Recurrent Event Data: {{An}} Application to Childhood Infectious Diseases},
  author = {Kelly, Patrick J. and Lim, Lynette},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {13--33},
  citeulike-article-id = {13265091},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {comparisons,several-models-for-multiple-events}
}

@article{kel02res,
  title = {Residual-Based Tree-Structured Survival Analysis},
  author = {Kele¸s, Sündüz and Segal, Mark R.},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {313--326},
  citeulike-article-id = {13265257},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {cart,censored-data,log-rank-test,martingale-residuals,recursive-partitioning,residuals,survival-analysis}
}

@article{kel87,
  title = {The Independent Pairs Assumption in Hypothesis Tests Based on Rank Correlation Coefficients},
  author = {Keller-McNulty, M.},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {40--41},
  citeulike-article-id = {13264395},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {distribution-free-methods,study-design-and-stopping-rules}
}

@article{ken07lim,
  title = {Limitations of Applying Summary Results of Clinical Trials to Individual Patients},
  author = {Kent, David M. and Hayward, Rodney},
  date = {2007},
  journaltitle = {JAMA},
  volume = {298},
  pages = {1209--1212},
  doi = {10.1001/jama.298.10.1209},
  url = {http://dx.doi.org/10.1001/jama.298.10.1209},
  citeulike-article-id = {13265618},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.298.10.1209},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {generalizability,rct},
  note = {variation in absolute risk reduction in RCTs;failure of subgroup analysis;covariable adjustment;covariate adjustment;nice summary of individual patient absolute benefit vs. patient risk}
}

@article{ken07opp,
  title = {Opportunities for Biostatistics Students: {{Training}} and Fellowship Grants from the {{National Institutes}} of {{Health}}},
  author = {Kennedy, Richard E. and Yeatts, Sharon D. and Archer, Kellie J. and Gennings, Chris and Ramakrishnam, Viswanathan},
  date = {2007},
  journaltitle = {Am Statistician},
  volume = {61},
  pages = {120--126},
  citeulike-article-id = {13265572},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {biostatistics-program,government-support-of-research,graduate-program,grant-application,research-proposal,research-training}
}

@article{ken10sho,
  title = {Should Baseline Be a Covariate or Dependent Variable in Analyses of Change from Baseline in Clinical Trials? (Letter to the Editor)},
  author = {Kenward, Michael G. and White, Ian R. and Carpener, James R.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {1455--1456},
  citeulike-article-id = {13265830},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {change-from-baseline,longitudinal-data,rct,treatment-of-baseline-variable},
  note = {sharp rebuke of liu09sho}
}

@article{ken17whe,
  title = {When the {{Alpha}} Is the {{Omega}}: {{P-Values}}, “{{Substantial Evidence}},” and the 0.05 {{Standard}} at {{FDA}}},
  shorttitle = {When the {{Alpha}} Is the {{Omega}}},
  author = {Kennedy-Shaffer, Lee},
  date = {2017},
  journaltitle = {Food Drug Law J},
  volume = {72},
  number = {4},
  eprint = {30294197},
  eprinttype = {pmid},
  pages = {595--635},
  issn = {1064-590X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6169785/},
  urldate = {2020-08-06},
  abstract = {A prominent feature of statistical reasoning for nearly a century, the p-value plays an especially vital role in the clinical testing of new drugs. Over the last fifty years, the U.S. Food and Drug Administration (FDA) has relied on p-values and significance testing to demonstrate the efficacy of new drugs in the premarket approval process. This article seeks to illuminate the history of this statistic and explain how the statistical significance threshold of 0.05, commonly decried as an arbitrary cutoff, is a useful tool that came to be the cornerstone of FDA decision-making.},
  pmcid = {PMC6169785},
  keywords = {drug-development,fda,p-value,regulatory-viewpoint}
}

@article{ken20nov,
  title = {Novel Methods for the Analysis of Stepped Wedge Cluster Randomized Trials},
  author = {Kennedy‐Shaffer, Lee and de Gruttola, Victor and Lipsitch, Marc},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8451},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8451},
  urldate = {2019-12-27},
  abstract = {Stepped wedge cluster randomized trials (SW-CRTs) have become increasingly popular and are used for a variety of interventions and outcomes, often chosen for their feasibility advantages. SW-CRTs must account for time trends in the outcome because of the staggered rollout of the intervention. Robust inference procedures and nonparametric analysis methods have recently been proposed to handle such trends without requiring strong parametric modeling assumptions, but these are less powerful than model-based approaches. We propose several novel analysis methods that reduce reliance on modeling assumptions while preserving some of the increased power provided by the use of mixed effects models. In one method, we use the synthetic control approach to find the best matching clusters for a given intervention cluster. Another method makes use of within-cluster crossover information to construct an overall estimator. We also consider methods that combine these approaches to further improve power. We test these methods on simulated SW-CRTs, describing scenarios in which these methods have increased power compared with existing nonparametric methods while preserving nominal validity when mixed effects models are misspecified. We also demonstrate theoretical properties of these estimators with less restrictive assumptions than mixed effects models. Finally, we propose avenues for future research on the use of these methods; motivation for such research arises from their flexibility, which allows the identification of specific causal contrasts of interest, their robustness, and the potential for incorporating covariates to further increase power. Investigators conducting SW-CRTs might well consider such methods when common modeling assumptions may not hold.},
  langid = {english},
  keywords = {cluster,crossover,rct,stepped-wedge}
}

@article{ken88mea,
  title = {Measures of Dependence for Censored Survival Data},
  author = {Kent, John T. and O'Quigley, John},
  date = {1988},
  journaltitle = {Biometrika},
  volume = {75},
  pages = {525--534},
  citeulike-article-id = {13264396},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kes98com,
  title = {A Comparison of Two Approaches for Selecting Covariance Structures in the Analysis of Repeated Measurements},
  author = {Keselman, H. J. and Algina, J. and Kowalchuk, R. K. and Wolfinger, R. D.},
  date = {1998},
  journaltitle = {Comm Stat - Sim Comp},
  volume = {27},
  pages = {591--604},
  citeulike-article-id = {13265468},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  note = {use of AIC and BIC for selecting the covariance structure in repeated measurements;serial data;longitudinal data;when chosing from 11 covariance patterns, AIC selected the correct structure 0.47 of the time; BIC was correct in 0.35}
}

@article{kha20app,
  title = {Application of the {{Reverse Fragility Index}} to {{Statistically Nonsignificant Randomized Clinical Trial Results}}},
  author = {Khan, Muhammad Shahzeb and Fonarow, Gregg C. and Friede, Tim and Lateef, Noman and Khan, Safi U. and Anker, Stefan D. and Harrell, Frank E. and Butler, Javed},
  date = {2020-08-03},
  journaltitle = {JAMA Netw Open},
  volume = {3},
  number = {8},
  pages = {e2012469-e2012469},
  publisher = {{American Medical Association}},
  doi = {10.1001/jamanetworkopen.2020.12469},
  url = {https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2769028},
  urldate = {2020-08-08},
  abstract = {{$<$}h3{$>$}Importance{$<$}/h3{$><$}p{$>$}Interpreting randomized clinical trials (RCTs) and their clinical relevance is challenging when\emph{P}values are either marginally above or below the\emph{P} = .05 threshold.{$<$}/p{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To use the concept of reverse fragility index (RFI) to provide a measure of confidence in the neutrality of RCT results when assessed from the clinical perspective.{$<$}/p{$><$}h3{$>$}Design, Setting, and Participants{$<$}/h3{$><$}p{$>$}In this cross-sectional study, a MEDLINE search was conducted for RCTs published from January 1, 2013, to December 31, 2018, in\emph{JAMA}, the\emph{New England Journal of Medicine}(\emph{NEJM}), and\emph{The Lancet.}Eligible studies were phase 3 and 4 trials with 1:1 randomization and statistically nonsignificant binary primary end points. Data analysis was performed from August 1, 2019, to August 31, 2019.{$<$}/p{$><$}h3{$>$}Exposures{$<$}/h3{$><$}p{$>$}Single vs multicenter enrollment, total number of events, private vs government funding, placebo vs active control, and time to event vs frequency data.{$<$}/p{$><$}h3{$>$}Main Outcomes and Measures{$<$}/h3{$><$}p{$>$}The primary outcome was the median RFI with interquartile range (IQR) at the\emph{P} = .05 threshold. Secondary outcomes were the number of RCTs in which the number of participants lost to follow-up was greater than the RFI; the median RFI with IQR at different\emph{P}value thresholds; the median reverse fragility quotient with IQR; and the correlation between sample sizes, number of events, and\emph{P}values of the RCT and RFI.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Of the 167 RCTs included, 76 (46\%) were published in the\emph{NEJM}, 50 (30\%) in\emph{JAMA,}and 41 (24\%) in\emph{The Lancet.}The median (IQR) sample size was 970 (470-3427) participants, and the median (IQR) number of events was 251 (105-570). The median (IQR) RFI at the\emph{P} = .05 threshold was 8 (5-13). Fifty-seven RCTs (34\%) had an RFI of 5 or lower, and in 68 RCTs (41\%) the number of participants lost to follow-up was greater than the RFI. Trials with\emph{P}values ranging from\emph{P} = .06 to\emph{P} = .10 had a median (IQR) RFI of 3 (2-4). When compared, median (IQR) RFIs were not statistically significant for single-center vs multicenter enrollment (5 [4-13] vs 8 [5-13];\emph{P} = .41), private vs government-funded studies (9 [5-13] vs 8 [5-13];\emph{P} = .34), and time-to-event primary end points vs frequency data (9 [5-14] vs 7 [4-13];\emph{P} = .43). The median (IQR) RFI at the\emph{P} = .01 threshold was 12 (7-19) and at the\emph{P} = .005 threshold was 14 (9-21).{$<$}/p{$><$}h3{$>$}Conclusions and Relevance{$<$}/h3{$><$}p{$>$}This cross-sectional study found that a relatively small number of events (median of 8) had to change to move the primary end point of an RCT from nonsignificant to statistically significant. These findings emphasize the nuance required when interpreting trial results that did not meet prespecified significance thresholds.{$<$}/p{$>$}},
  langid = {english},
  keywords = {p-value,rct,sensitivity-analysis}
}

@article{kha20appa,
  title = {Application of the {{Reverse Fragility Index}} to {{Statistically Nonsignificant Randomized Clinical Trial Results}}},
  author = {Khan, Muhammad Shahzeb and Fonarow, Gregg C. and Friede, Tim and Lateef, Noman and Khan, Safi U. and Anker, Stefan D. and Harrell, Frank E. and Butler, Javed},
  date = {2020-08-03},
  journaltitle = {JAMA Netw Open},
  volume = {3},
  number = {8},
  eprint = {32756927},
  eprinttype = {pmid},
  pages = {e2012469},
  issn = {2574-3805},
  doi = {10.1001/jamanetworkopen.2020.12469},
  abstract = {Importance: Interpreting randomized clinical trials (RCTs) and their clinical relevance is challenging when P values are either marginally above or below the P\,=\,.05 threshold. Objective: To use the concept of reverse fragility index (RFI) to provide a measure of confidence in the neutrality of RCT results when assessed from the clinical perspective. Design, Setting, and Participants: In this cross-sectional study, a MEDLINE search was conducted for RCTs published from January 1, 2013, to December 31, 2018, in JAMA, the New England Journal of Medicine (NEJM), and The Lancet. Eligible studies were phase 3 and 4 trials with 1:1 randomization and statistically nonsignificant binary primary end points. Data analysis was performed from August 1, 2019, to August 31, 2019. Exposures: Single vs multicenter enrollment, total number of events, private vs government funding, placebo vs active control, and time to event vs frequency data. Main Outcomes and Measures: The primary outcome was the median RFI with interquartile range (IQR) at the P\,=\,.05 threshold. Secondary outcomes were the number of RCTs in which the number of participants lost to follow-up was greater than the RFI; the median RFI with IQR at different P value thresholds; the median reverse fragility quotient with IQR; and the correlation between sample sizes, number of events, and P values of the RCT and RFI. Results: Of the 167 RCTs included, 76 (46\%) were published in the NEJM, 50 (30\%) in JAMA, and 41 (24\%) in The Lancet. The median (IQR) sample size was 970 (470-3427) participants, and the median (IQR) number of events was 251 (105-570). The median (IQR) RFI at the P\,=\,.05 threshold was 8 (5-13). Fifty-seven RCTs (34\%) had an RFI of 5 or lower, and in 68 RCTs (41\%) the number of participants lost to follow-up was greater than the RFI. Trials with P values ranging from P\,=\,.06 to P\,=\,.10 had a median (IQR) RFI of 3 (2-4). When compared, median (IQR) RFIs were not statistically significant for single-center vs multicenter enrollment (5 [4-13] vs 8 [5-13]; P\,=\,.41), private vs government-funded studies (9 [5-13] vs 8 [5-13]; P\,=\,.34), and time-to-event primary end points vs frequency data (9 [5-14] vs 7 [4-13]; P\,=\,.43). The median (IQR) RFI at the P\,=\,.01 threshold was 12 (7-19) and at the P\,=\,.005 threshold was 14 (9-21). Conclusions and Relevance: This cross-sectional study found that a relatively small number of events (median of 8) had to change to move the primary end point of an RCT from nonsignificant to statistically significant. These findings emphasize the nuance required when interpreting trial results that did not meet prespecified significance thresholds.},
  langid = {english},
  pmcid = {PMC7407075},
  keywords = {methodology}
}

@article{kha20doe,
  title = {Does {{Neck Disability Index Correlate With}} 12-{{Month Satisfaction After Elective Surgery}} for {{Cervical Radiculopathy}}? {{Results From}} a {{National Spine Registry}}},
  shorttitle = {Does {{Neck Disability Index Correlate With}} 12-{{Month Satisfaction After Elective Surgery}} for {{Cervical Radiculopathy}}?},
  author = {Khan, Inamullah and Sivaganesan, Ahilan and Archer, Kristin R. and Bydon, Mohamad and McGirt, Matthew J. and Nian, Hui and Harrell, Frank E. and Foley, Kevin T. and Mummaneni, Praveen V. and Bisson, Erica F. and Shaffrey, Christopher and Harbaugh, Robert and Asher, Anthony L. and Devin, Clinton J. and {QOD Vanguard Sites}},
  date = {2020-05-01},
  journaltitle = {Neurosurgery},
  volume = {86},
  number = {5},
  eprint = {31268151},
  eprinttype = {pmid},
  pages = {736--741},
  issn = {1524-4040},
  doi = {10.1093/neuros/nyz231},
  abstract = {BACKGROUND: Modern healthcare reforms focus on identifying and measuring the quality and value of care. Patient satisfaction is particularly important in the management of degenerative cervical radiculopathy (DCR) since it leads to significant neck pain and disability primarily affecting the patients' quality of life. OBJECTIVE: To determine the association of baseline and 12-mo Neck Disability Index (NDI) with patient satisfaction after elective surgery for DCR. METHODS: The Quality Outcomes Database cervical module was queried for patients who underwent elective surgery for DCR. A multivariable proportional odds regression model was fitted with 12-mo satisfaction as the outcome. The covariates for this model included patients' demographics, surgical characteristics, and baseline and 12-mo patient reported outcomes (PROs). Wald-statistics were calculated to determine the relative importance of each independent variable for 12-mo patient satisfaction. RESULTS: The analysis included 2206 patients who underwent elective surgery for DCR. In multivariable analysis, after adjusting for baseline and surgery specific variables, the 12-mo NDI score showed the highest association with 12-mo satisfaction (Waldχ2-df~=~99.17, 58.1\% of total χ2). The level of satisfaction increases with decrease in 12-mo NDI score regardless of the baseline NDI score. CONCLUSION: Our study identifies 12-mo NDI score as a very influential driver of 12-mo patient satisfaction after surgery for DCR. In addition, there are lesser contributions from other 12-mo PROs, baseline Numeric Rating Scale for arm pain and American Society of Anesthesiologists (ASA) grade. The baseline level of disability was found to be irrelevant to patients. They seemed to only value their current level of disability, compared to baseline, in rating satisfaction with surgical outcome.},
  langid = {english},
  keywords = {collaboration}
}

@article{kha21ind,
  title = {Individual Differences in the Perception of Probability},
  author = {Khaw, Mel W. and Stevens, Luminita and Woodford, Michael},
  date = {2021-04-01},
  journaltitle = {PLOS Computational Biology},
  volume = {17},
  number = {4},
  pages = {e1008871},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008871},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008871},
  urldate = {2021-05-09},
  abstract = {In recent studies of humans estimating non-stationary probabilities, estimates appear to be unbiased on average, across the full range of probability values to be estimated. This finding is surprising given that experiments measuring probability estimation in other contexts have often identified conservatism: individuals tend to overestimate low probability events and underestimate high probability events. In other contexts, repulsive biases have also been documented, with individuals producing judgments that tend toward extreme values instead. Using extensive data from a probability estimation task that produces unbiased performance on average, we find substantial biases at the individual level; we document the coexistence of both conservative and repulsive biases in the same experimental context. Individual biases persist despite extensive experience with the task, and are also correlated with other behavioral differences, such as individual variation in response speed and adjustment rates. We conclude that the rich computational demands of our task give rise to a variety of behavioral patterns, and that the apparent unbiasedness of the pooled data is an artifact of the aggregation of heterogeneous biases.},
  langid = {english},
  keywords = {probability,probability-assessment}
}

@article{kie05not,
  title = {A {{Note}} on Adaptively Changing the Hierarchy of Hypotheses in Clinical Trials with Flexible Design},
  author = {Kieser, M.},
  date = {2005},
  journaltitle = {Drug Info J},
  volume = {39},
  pages = {215--223},
  citeulike-article-id = {13265505},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{kim15eva,
  title = {Evaluating Model-Based Imputation Methods for Missing Covariates in Regression Models with Interactions},
  author = {Kim, Soeun and Sugar, Catherine A. and Belin, Thomas R.},
  date = {2015-05},
  journaltitle = {Stat Med},
  volume = {34},
  number = {11},
  pages = {1876--1888},
  issn = {02776715},
  doi = {10.1002/sim.6435},
  url = {http://dx.doi.org/10.1002/sim.6435},
  citeulike-article-id = {14187481},
  citeulike-attachment-1 = {kim15eva.pdf; /pdf/user/harrelfe/article/14187481/1092190/kim15eva.pdf; 4be86f74f7f1789874b294012e2bb59b030815b3},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6435},
  day = {20},
  posted-at = {2016-11-20 14:05:06},
  priority = {0},
  keywords = {interaction,missing-data}
}

@article{kim19sel,
  title = {On the Self-Triggering {{Cox}} Model for Recurrent Event Data},
  author = {Kim, Jung In and Lin, Feng-Chang and Fine, Jason P.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8285},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8285},
  urldate = {2019-08-10},
  abstract = {Recurrent event data frequently occur in longitudinal studies when subjects experience more than one event during the observation period. Often, the occurrence of subsequent events is associated with the experience of previous events. Such dependence is commonly ignored in the application of standard recurrent event methodology. In this paper, we utilize a Cox-type regression model with time-varying triggering effect depending on the number and timing of previous events to enhance both model fit and prediction. Parameter estimation and statistical inference is achieved via the partial likelihood. A statistical test procedure is provided to assess the existence of the triggering effects. We demonstrate our approach via comprehensive simulation studies and a real data analysis on chronic pseudomonas infections in young cystic fibrosis patients. Our model provides significantly better predictions than standard recurrent event models.},
  langid = {english},
  keywords = {recurrent-events}
}

@article{kin00qua,
  title = {A Quantifiable Alternative to Double Data Entry},
  author = {King, D. W. and Lashey, R. A.},
  date = {2000},
  journaltitle = {Controlled Clin Trials},
  volume = {21},
  pages = {94--102},
  doi = {10.1016/S0197-2456(00)00042-8},
  url = {http://dx.doi.org/10.1016/S0197-2456(00)00042-8},
  citeulike-article-id = {13265265},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0197-2456(00)00042-8},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-trials,data-management,double-data-entry,rct}
}

@article{kin02pre,
  title = {A Preliminary Investigation of Maximum Likelihood Logistic Regression versus Exact Logistic Regression},
  author = {King, Elizabeth N. and Ryan, Thomas P.},
  date = {2002},
  journaltitle = {Am Statistician},
  volume = {56},
  pages = {163--170},
  citeulike-article-id = {13265289},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {complete-separation,maximum-likelihood,near-separation,rare-events,sparse-data},
  note = {maximum likelihood is not reliable for very low incidence response variables with binary logistic regression;exact methods are more accurate for this case but are not completely satisfying;paper strongly questioned in two letters to editor May 2003 Vol 57 No 2 - say authors should have used LR tests and not use observed point estimates in complete separation tests; one letter questioned simulation setup if Y was fixed; see several other letters in August 2003 Vol 57 No 3}
}

@article{kin11con,
  title = {Constrictive Bronchiolitis in Soldiers Returning from {{Iraq}} and {{Afghanistan}}},
  author = {King, Matthew S. and Eisenberg, Rosana and Newman, John H. and Tolle, James J. and Harrell, Frank E. and Nan, Hui and Ninan, Mathew and Lambright, Eric S. and Sheller, James R. and Johnson, Joyce E. and Miller, Robert F.},
  date = {2011},
  journaltitle = {NEJM},
  volume = {365},
  pages = {222--30},
  citeulike-article-id = {13265885},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  note = {CTSA}
}

@article{kin19gen,
  title = {A General Semiparametric {{Bayesian}} Discrete-Time Recurrent Events Model},
  author = {King, Adam J. and Weiss, Robert E.},
  date = {2019},
  journaltitle = {Biostatistics},
  doi = {10.1093/biostatistics/kxz029},
  url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz029/5542991},
  urldate = {2019-08-04},
  abstract = {SUMMARY.  Event time variables are often recorded in a discrete fashion, especially in the case of patient-reported outcomes. This work is motivated by a study},
  langid = {english},
  keywords = {bayes,competing-risk,recurrent-event-with-competing-risk,recurrent-events}
}

@article{kin20lon,
  title = {Longitudinal {{Principal Component Analysis With}} an {{Application}} to {{Marketing Data}}},
  author = {Kinson, Christopher and Tang, Xiwei and Zuo, Zhen and Qu, Annie},
  date = {2020-04-02},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {29},
  number = {2},
  pages = {335--350},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1080/10618600.2019.1677244},
  url = {https://doi.org/10.1080/10618600.2019.1677244},
  urldate = {2020-09-20},
  abstract = {We propose a longitudinal principal component analysis method for multivariate longitudinal data using a random-effects eigen-decomposition, where the eigen-decomposition uses longitudinal information through nonparametric splines and the multivariate random effects incorporate significant store-wise heterogeneity. Our method can effectively analyze large marketing data containing sales information for products from hundreds of stores over an 11-year time period. The proposed method leads to more accurate estimation and interpretation compared to existing approaches. We illustrate our method through simulation studies and an application to marketing data from IRI. Supplementary materials for this article are available online.},
  keywords = {data-reduction,longitudinal,pc,pca,serial},
  annotation = {\_eprint: https://doi.org/10.1080/10618600.2019.1677244}
}

@article{kin83rea,
  title = {“{{Reactive}} Gliosis” in the Medulla Oblongata of Victims of the Sudden Infant Death Syndrome},
  author = {Kinney, H. C. and Burger, P. C. and Harrell, F. E. and Hudson, R. P.},
  date = {1983},
  journaltitle = {Pediatrics},
  volume = {72},
  pages = {181--187},
  citeulike-article-id = {13264397},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@inproceedings{kip89rel,
  title = {Relevancy Criterion for Discriminating among Alternative Model Specifications},
  booktitle = {Proceedings of the 21st {{Symposium}} on the {{Interface}} between {{Computer Science}} and {{Statistics}}},
  author = {Kipnis, V.},
  editor = {Berk, K. and Malone, L.},
  date = {1989},
  pages = {376--381},
  publisher = {{American Statistical Association}},
  location = {{Alexandria, VA}},
  citeulike-article-id = {13264398},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {validation}
}

@article{kir91gui,
  title = {Guidelines and Indications for Coronary Artery Bypass Graft Surgery ---{{A}} Report of the {{American College}} of {{Cardiology}} / {{American Heart Association Task Force}} on {{Assessment}} of {{Diagnostic}} and {{Therapeutic Cardiovascular Procedures}}, {{Subcommittee}} on {{Coronary Artery Bypass Graft Surgery}}},
  author = {Kirklin, J. W. and Akins, C. W. and Blackstone, E. H. and Booth, D. C. and Califf, R. M. and Cohen, L. S. and Hall, R. and Harrell, F. E. and {Et Al}},
  date = {1991},
  journaltitle = {J Am Coll Cardiol},
  volume = {17},
  pages = {543--589},
  citeulike-article-id = {13264399},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kit05gro,
  title = {Group Sequential Clinical Trials for Longitudinal Data with Analyses Using Summary Statistics},
  author = {Kittelson, John M. and Sharples, Katrina and Emerson, Scott S.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2457--2475},
  doi = {10.1002/sim.2127},
  url = {http://dx.doi.org/10.1002/sim.2127},
  citeulike-article-id = {13265434},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2127},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {area-under-curve,clinical-trials,longitudinal-endpoint,mixed-effects-model,rct,serial-data,software,summary-measures}
}

@article{kiu96wor,
  title = {A {{World Wide Web-based}} User Interface for a Data Management System for Use in Multi-Institutional Clinical Trials --- {{Development}} and Experimental Operation of an Automated Patient Registration and Random Allocation System},
  author = {Kiuchi, Takahiro and Ohashi, Yasuo and Konishi, Masaru and Bandai, Yasutsugu and Kosuge, Tomoo and Kakizoe, Tadao},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {476--493},
  citeulike-article-id = {13264400},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {clinical-trial-data-management,database-management,internet,randomization,rct,www}
}

@article{kla15est,
  title = {Estimates of Absolute Treatment Benefit for Individual Patients Required Careful Modeling of Statistical Interactions},
  author = {van Klaveren, David and Vergouwe, Yvonne and Farooq, Vasim and Serruys, Patrick W. and Steyerberg, Ewout W.},
  options = {useprefix=true},
  date = {2015-11},
  journaltitle = {J Clin Epi},
  volume = {68},
  number = {11},
  pages = {1366--1374},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2015.02.012},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2015.02.012},
  abstract = {Objectives We aimed to compare modeling approaches to estimate the individual survival benefit of treatment with either coronary artery bypass graft surgery (CABG) or percutaneous coronary intervention (PCI) for patients with complex coronary artery disease. Study Design and Setting We estimated survival with Cox regression models that included the treatment variable (CABG/PCI) interacting with either an internally developed overall prognostic index (PI) or with individual prognostic factors. We analyzed data of patients who were randomized in the Synergy between Percutaneous Coronary Intervention with Taxus and Cardiac Surgery trial (1,800 patients, 178 deaths). Results A negligible interaction with the PI (P = 0.51) led to 4-year survival estimates in favor of CABG for all patients. In contrast, individual interactions indicated substantial relative treatment effect heterogeneity (overall interaction P = 0.004), and estimates of 4-year survival were numerically in favor of CABG for 1,275 of 1,800 patients (71\%; 519 with 95\% confidence). To test the more complex model with individual interactions, we first used penalized regression, resulting in smaller but largely consistent individual estimates of the survival difference between CABG and PCI. Second, strong treatment interactions were confirmed at external validation in 2,891 patients from a multinational registry. Conclusion Modeling strategies that omit interactions may result in misleading estimates of absolute treatment benefit for individual patients with the potential hazard of suboptimal decision making.},
  citeulike-article-id = {13992504},
  citeulike-attachment-1 = {kla15est.pdf; /pdf/user/harrelfe/article/13992504/1061538/kla15est.pdf; 7a5e156d4c9a492e0ed2b33832d93763ea97fd70},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2015.02.012},
  posted-at = {2016-04-01 14:58:37},
  priority = {3},
  keywords = {absolute-benefit,absolute-vs-relative-treatment-effect,interaction}
}

@article{kla19mod,
  title = {Models with Interactions Overestimated Heterogeneity of Treatment Effects and Were Prone to Treatment Mistargeting},
  author = {van Klaveren, David and Balan, Theodor A. and Steyerberg, Ewout W. and Kent, David M.},
  date = {2019-06-10},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2019.05.029},
  url = {https://www.jclinepi.com/article/S0895-4356(18)31007-2/abstract},
  urldate = {2019-06-10},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objectives{$<$}/h3{$><$}p{$>$}We aimed to compare the performance of different regression modelling approaches for the prediction of heterogeneous treatment effects.{$<$}/p{$><$}h3{$>$}Study Design and Setting{$<$}/h3{$><$}p{$>$}We simulated trial samples (n=3,600; 80\% power for a treatment odds ratio of 0.8) from a superpopulation (N=1.000.000) with 12 binary risk predictors, both without and with 6 true treatment interactions. We assessed predictions of treatment benefit for four regression models: a "risk model" (with a constant effect of treatment assignment) and three "effect models" (including interactions of risk predictors with treatment assignment). Three novel performance measures were evaluated: calibration-for-benefit (i.e. observed versus predicted risk difference in treated versus untreated), discrimination-for-benefit, and prediction error-for-benefit.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}The risk-modeling approach was well-calibrated for benefit while effect models were consistently overfit, even with doubled sample sizes. Penalized regression reduced miscalibration of the effect models considerably. In terms of discrimination and prediction error, the risk-modeling approach was superior in the absence of true treatment effect interactions, while penalized regression was optimal in the presence of true treatment interactions.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}A risk-modeling approach yields models consistently well-calibrated for benefit. Effect-modeling may improve discrimination-for-benefit in the presence of true interactions, but is prone to overfitting. Hence, effect models – including only plausible interactions – should be fitted using penalized regression.{$<$}/p{$>$}},
  langid = {english},
  keywords = {hte,interaction,penalized-mle}
}

@article{kla97mer,
  title = {The Merits of Matching in Community Intervention Trials: {{A}} Cautionary Tale},
  author = {Klar, Neil and Donner, Allan},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1753--1764},
  citeulike-article-id = {13264401},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {cluster-randomization,community-trials,health-services-research-study-design,problems-with-matching-clusters}
}

@book{kle10dru,
  title = {Drug {{Safety Data}}: {{How}} to {{Analyze}}, {{Summarize}}, and {{Interpret}} to {{Determine Risk}}},
  author = {Klepper, Michael and Cobert, Barton},
  date = {2010},
  publisher = {{Jones \& Bartlett Learning}},
  location = {{Sudbury MA}},
  citeulike-article-id = {13265906},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {clinical-safety,dmc,dsmb,pharmaceutical-safety,rct,statistical-report},
  annotation = {see review DIJ 45:109-110;2011}
}

@article{kle18mix,
  title = {Mixed Binary-Continuous Copula Regression Models with Application to Adverse Birth Outcomes},
  author = {Klein, Nadja and Kneib, Thomas and Marra, Giampiero and Radice, Rosalba and Rokicki, Slawa and McGovern, Mark E.},
  date = {2018},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.7985},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7985},
  urldate = {2018-11-10},
  abstract = {Bivariate copula regression allows for the flexible combination of two arbitrary, continuous marginal distributions with regression effects being placed on potentially all parameters of the resulting bivariate joint response distribution. Motivated by the risk factors for adverse birth outcomes, many of which are dichotomous, we consider mixed binary-continuous responses that extend the bivariate continuous framework to the situation where one response variable is discrete (more precisely, binary) whereas the other response remains continuous. Utilizing the latent continuous representation of binary regression models, we implement a penalized likelihood–based approach for the resulting class of copula regression models and employ it in the context of modeling gestational age and the presence/absence of low birth weight. The analysis demonstrates the advantage of the flexible specification of regression impacts including nonlinear effects of continuous covariates and spatial effects. Our results imply that racial and spatial inequalities in the risk factors for infant mortality are even greater than previously suggested.},
  langid = {english},
  keywords = {compound-endpoints,copula,multiple-endpoints}
}

@article{kle19mix,
  title = {Mixed Binary-Continuous Copula Regression Models with Application to Adverse Birth Outcomes},
  author = {Klein, Nadja and Kneib, Thomas and Marra, Giampiero and Radice, Rosalba and Rokicki, Slawa and McGovern, Mark E.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {3},
  pages = {413--436},
  issn = {1097-0258},
  doi = {10.1002/sim.7985},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7985},
  urldate = {2019-01-05},
  abstract = {Bivariate copula regression allows for the flexible combination of two arbitrary, continuous marginal distributions with regression effects being placed on potentially all parameters of the resulting bivariate joint response distribution. Motivated by the risk factors for adverse birth outcomes, many of which are dichotomous, we consider mixed binary-continuous responses that extend the bivariate continuous framework to the situation where one response variable is discrete (more precisely, binary) whereas the other response remains continuous. Utilizing the latent continuous representation of binary regression models, we implement a penalized likelihood–based approach for the resulting class of copula regression models and employ it in the context of modeling gestational age and the presence/absence of low birth weight. The analysis demonstrates the advantage of the flexible specification of regression impacts including nonlinear effects of continuous covariates and spatial effects. Our results imply that racial and spatial inequalities in the risk factors for infant mortality are even greater than previously suggested.},
  langid = {english},
  keywords = {copula,multiple-endpoints}
}

@book{kle82,
  title = {Epidemiologic {{Research}}: {{Principles}} and {{Quantitative Methods}}},
  author = {Kleinbaum, D. G. and Kupper, L. L. and Morgenstern, H.},
  date = {1982},
  publisher = {{Van Nostrand Reinhold}},
  location = {{New York}},
  citeulike-article-id = {13264402},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@book{kle88,
  title = {Applied {{Regression Analysis}} and {{Other Multivariable Methods}}},
  author = {Kleinbaum, D. G. and Kupper, L. L. and Muller, K. E.},
  date = {1988},
  publisher = {{PWS-Kent}},
  location = {{Boston}},
  citeulike-article-id = {13264403},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kle93plo,
  title = {Plotting Summary Predictions in Multistate Survival Models: {{Probabilities}} of Relapse and Death in Remission for Bone Marrow Transplantation Patients},
  author = {Klein, John P. and Keiding, Niels and Copelan, Edward A.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2314--2332},
  citeulike-article-id = {13264404},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {competing-risks,multiple-events}
}

@article{kle97fac,
  title = {Facilitated Analysis of Data on Drug Regimen Compliance},
  author = {de Klerk, Erik and Van Der Linden, Sjef and Van Der Heijde, Desiree and Urquhart, John},
  options = {useprefix=true},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1653--1664},
  citeulike-article-id = {13264405},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {compliance,drug-dosing-history}
}

@book{kle97sur,
  title = {Survival {{Analysis}}: {{Techniques}} for {{Censored}} and {{Truncated Data}}},
  author = {Klein, John P. and Moeschberger, Melvin L.},
  date = {1997},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13264406},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{Klu04met,
  title = {Methods to Assess Intended Effects of Drug Treatment in Observational Studies Are Reviewed},
  author = {Klungel, Olaf H. and Martens, Edwin P. and Psaty, Bruce M. and Grobbee, Diederik E. and Sullivan, Sean D. and Stricker, Bruno H. and Leufkens, Hubert G. M. and de Boer, A.},
  options = {useprefix=true},
  date = {2004},
  journaltitle = {J Clin Epi},
  volume = {57},
  pages = {1223--1231},
  citeulike-article-id = {13265397},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {instrumental-variables,multivariate-confounder-score,observational-treatment-comparisons,propensity-score,selection-models}
}

@article{kna91apa,
  title = {The {{APACHE III}} Prognostic System. {{Risk}} Prediction of Hospital Mortality for Critically Ill Hospitalized Adults},
  author = {Knaus, W. A. and Wagner, D. P. and Draper, E. A. and Zimmerman, J. E. and Bergner, M. and Bastos, P. G. and Sirio, C. A. and Murphy, D. J. and Lotring, T. and Damiano, A. and Harrell, F. E.},
  date = {1991},
  journaltitle = {Chest},
  volume = {100},
  pages = {1619--1636},
  citeulike-article-id = {13264407},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kna93cli,
  title = {The Clinical Evaluation of New Drugs for Sepsis: {{A}} Prospective Study Design Based on Survival Analysis},
  author = {Knaus, William A. and Harrell, Frank E. and Fisher, Charles J. and Wagner, Douglas P. and Opan, Steven M. and Sadoff, Jerald C. and Draper, Elizabeth A. and Walawander, Cynthia A. and Conboy, Kathleen and Grasela, Thaddeus H.},
  date = {1993},
  journaltitle = {JAMA},
  volume = {270},
  pages = {1233--1241},
  doi = {10.1001/jama.270.10.1233},
  url = {http://dx.doi.org/10.1001/jama.270.10.1233},
  citeulike-article-id = {13264408},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.270.10.1233},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {bootstrap,calibration,clinical-trials,interaction,log-normal-model,rct,risk-models,study-design,validation}
}

@article{kna94wha,
  title = {What Determines Prognosis in Sepsis? {{Evidence}} for a Comprehensive Individual Patient Risk Assessment Approach to the Design and Analysis of Clinical Trials},
  author = {Knaus, W. A. and Wagner, D. P. and Harrell, F. E. and Draper, E. A.},
  date = {1994},
  journaltitle = {Theoretical Surg},
  volume = {9},
  pages = {20--27},
  citeulike-article-id = {13264409},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kna95ris,
  title = {Risk Assessment in Recent Clinical Trials in Sepsis / {{SIRS}}: {{Lessons}} Learned and Future Directions},
  author = {Knaus, W. A. and Wagner, D. P. and Sun, X. and Harrell, F. E. and Hedstrom, J. S.},
  date = {1995},
  journaltitle = {J Endotox Res},
  volume = {2},
  pages = {169--175},
  citeulike-article-id = {13264410},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kna95sup,
  title = {The {{SUPPORT}} Prognostic Model: {{Objective}} Estimates of Survival for Seriously Ill Hospitalized Adults},
  author = {Knaus, W. A. and Harrell, F. E. and Lynn, J. and Goldman, L. and Phillips, R. S. and Connors, A. F. and Dawson, N. V. and Fulkerson, W. J. and Califf, R. M. and Desbiens, N. and Layde, P. and Oye, R. K. and Bellamy, P. E. and Hakim, R. B. and Wagner, D. P.},
  date = {1995},
  journaltitle = {Ann Int Med},
  volume = {122},
  pages = {191--203},
  doi = {10.7326/0003-4819-122-3-199502010-00007},
  url = {http://dx.doi.org/10.7326/0003-4819-122-3-199502010-00007},
  citeulike-article-id = {13264411},
  citeulike-linkout-0 = {http://dx.doi.org/10.7326/0003-4819-122-3-199502010-00007},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {clinical-prediction,model-validation,multivariable-modeling,prognostic-model,reporting,spline-examples,survival-analysis,teaching-mds,validation}
}

@article{kna96use,
  title = {Use of Predicted Risk of Mortality to Evaluate the Efficacy of Anticytokine Therapy in Sepsis},
  author = {Knaus, W. A. and Harrell, F. E. and LaBrecque, J. F. and Wagner, D. P. and Pribble, J. P. and Draper, E. A. and Fisher, C. J. and Soll, J. and {The rhIL-1ra Sepsis Syndrome Study Group}},
  date = {1996},
  journaltitle = {Crit Care Med},
  volume = {24},
  pages = {46--56},
  citeulike-article-id = {13264412},
  posted-at = {2014-07-14 14:09:34},
  priority = {0}
}

@article{kna98gui,
  title = {Guidelines for Quality Assurance in Multicenter Trials: {{A}} Position Paper},
  author = {Knatterud, Genell L. and Rockhold, Frank W. and George, Stephen L. and Barton, Franca B. and Davis, C. Edward and Fairweather, William R. and Honohan, Tom and Mowery, Richard and O'Neill, Robert},
  date = {1998},
  journaltitle = {Controlled Clin Trials},
  volume = {19},
  pages = {477--493},
  citeulike-article-id = {13264413},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {quality-assurance,rct,study-design}
}

@book{knitr,
  title = {Knitr: {{A}} General-Purpose Package for Dynamic Report Generation in {{R}}},
  author = {Xie, Yihui},
  date = {2015},
  url = {http://CRAN.R-project.org/package=knitr},
  citeulike-article-id = {13265942},
  citeulike-linkout-0 = {http://CRAN.R-project.org/package=knitr},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  annotation = {R package version 1.11}
}

@book{knitrbook,
  title = {Dynamic {{Documents}} with {{R}} and Knitr, Second Edition},
  author = {Xie, Yihui},
  date = {2015},
  edition = {second},
  publisher = {{Chapman and Hall}},
  citeulike-article-id = {13265943},
  isbn = {978-1-4987-1696-3},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@article{kno10unp,
  title = {Unpredictable Bias When Using the Missing Indicator Method or Complete Case Analysis for Missing Confounder Values: An Empirical Example},
  author = {Knol, Mirjam J. and Janssen, Kristel J. M. and Donders, Rogier T. and Egberts, Antoine C. G. and Heerding, E. Rob and Grobbee, Diederick E. and Moons, Karel G. M. and Geerlings, Mirjam I.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {728--736},
  citeulike-article-id = {13265820},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {complete-case-analysis,missing-data,missing-indicator-method,multiple-imputation}
}

@article{kno91non,
  title = {Nonparametric Analysis of Covariance for Comparing Change in Randomized Studies with Baseline Values Subject to Error},
  author = {Knoke, J. D.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {523--533},
  citeulike-article-id = {13264414},
  posted-at = {2014-07-14 14:09:34},
  priority = {0},
  keywords = {change}
}

@incollection{knu92lit,
  title = {Literate Programming},
  booktitle = {{{CSLI Lecture Notes}}},
  author = {Knuth, Donald E.},
  date = {1992},
  number = {27},
  publisher = {{Center for the Study of Language and Information}},
  citeulike-article-id = {13265523},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@incollection{koc85two,
  title = {A Two-Stage Procedure for the Analysis of Ordinal Categorical Data},
  booktitle = {{{BIOSTATISTICS}}: {{Statistics}} in {{Biomedical}}, {{Public Health}} and {{Environmental Sciences}}},
  author = {Koch, Gary G. and Amara, Ingrid A. and Singer, Julio M.},
  editor = {Sen, P. K.},
  date = {1985},
  publisher = {{Elsevier Science Publishers B. V. (North-Holland)}},
  location = {{Amsterdam}},
  citeulike-article-id = {13264415},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {farm,ordinal-logistic-model,test-of-proportional-odds}
}

@article{koe78reg,
  title = {Regression Quantiles},
  author = {Koenker, R. and Bassett, G.},
  date = {1978},
  journaltitle = {Econometrica},
  volume = {46},
  pages = {33--50},
  citeulike-article-id = {13265400},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {quantile-regression}
}

@article{koe87as229,
  title = {Algorithm {{AS}} 229: {{Computing}} Regression Quantiles},
  author = {Koenker, Roger W. and D'Orey, Vasco},
  date = {1987},
  journaltitle = {Appl Stat},
  volume = {36},
  pages = {383--393},
  citeulike-article-id = {13264416},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {parametric-linear-programming,robust-estimation,sample-survey,sampling-weights}
}

@report{koe96rep,
  title = {Reproducible Econometric Research},
  author = {Koenker, Roger},
  date = {1996},
  institution = {{University of Illinois}},
  location = {{www.econ.uiuc.edu}},
  citeulike-article-id = {13264417},
  posted-at = {2014-07-14 14:09:35},
  priority = {0}
}

@book{koeqr,
  title = {Quantile {{Regression}}},
  author = {Koenker, Roger},
  date = {2005},
  publisher = {{Cambridge University Press}},
  location = {{New York}},
  citeulike-article-id = {13265924},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  annotation = {ISBN-10: 0-521-60827-9; ISBN-13: 978-0-521-60827-5}
}

@article{kol12com,
  title = {Competing Risks and the Clinical Community: Irrelevance or Ignorance?},
  author = {Koller, Michael T. and Raatz, Heike and Steyerberg, Ewout W. and Wolbers, Marcel},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {11-12},
  pages = {1089--1097},
  doi = {10.1002/sim.4384},
  url = {http://dx.doi.org/10.1002/sim.4384},
  abstract = {Life expectancy has dramatically increased in industrialized nations over the last 200 hundred years. The aging of populations carries over to clinical research and leads to an increasing representation of elderly and multimorbid individuals in study populations. Clinical research in these populations is complicated by the fact that individuals are likely to experience several potential disease endpoints that prevent some disease-specific endpoint of interest from occurrence. Large developments in competing risks methodology have been achieved over the last decades, but we assume that recognition of competing risks in the clinical community is still marginal. It is the aim of this article to address translational aspects of competing risks to the clinical community. We describe clinical populations where competing risks issues may arise. We then discuss the importance of agreement between the competing risks methodology and the study aim, in particular the distinction between etiologic and prognostic research questions. In a review of 50 clinical studies performed in individuals susceptible to competing risks published in high-impact clinical journals, we found competing risks issues in 70\% of all articles. Better recognition of issues related to competing risks and of statistical methods that deal with competing risks in accordance with the aim of the study is needed.},
  citeulike-article-id = {13265930},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4384},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {cause-specific-hazard,clinical-interpretation,competing-risks,quality-of-reporting,review,subdistribution-hazard}
}

@article{kol16eva,
  title = {Evaluation of a {{Prediction Model}} for the {{Development}} of {{Atrial Fibrillation}} in a {{Repository}} of {{Electronic Medical Records}}},
  author = {Kolek, Matthew J. and Graves, Amy J. and Xu, Meng and Bian, Aihua and Teixeira, Pedro L. and Shoemaker, M. Benjamin and Parvez, Babar and Xu, Hua and Heckbert, Susan R. and Ellinor, Patrick T. and Benjamin, Emelia J. and Alonso, Alvaro and Denny, Joshua C. and Moons, Karel G. M. and Shintani, Ayumi K. and Harrell, Frank E. and Roden, Dan M. and Darbar, Dawood},
  date = {2016-12},
  journaltitle = {JAMA Card},
  volume = {1},
  number = {9},
  pages = {1007+},
  issn = {2380-6583},
  doi = {10.1001/jamacardio.2016.3366},
  url = {http://dx.doi.org/10.1001/jamacardio.2016.3366},
  citeulike-article-id = {14232071},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jamacardio.2016.3366},
  day = {01},
  posted-at = {2016-12-22 14:15:05},
  priority = {2},
  keywords = {clinical-prediction,validation}
}

@article{kol95com,
  title = {A Comparison of Size and Power Calculations for the {{Wilcoxon}} Statistic for Ordered Categorical Data},
  author = {Kolassa, J. E.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1577--1581},
  citeulike-article-id = {13265213},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  note = {point out problems with whi93sam when sample sizes small or PO is violated;see jul96sam}
}

@book{kon08inf,
  title = {Information {{Criteria}} and {{Statistical Modeling}}},
  author = {Konishi, Sadanori and Kitagawa, Genshiro},
  date = {2008},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265782},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  annotation = {ISBN 978-0-387-71886-6}
}

@article{kon08sem,
  title = {A Semiparametric Response Surface Model for Assessing Drug Interaction},
  author = {Kong, Maiying and Lee, Jack J.},
  date = {2008},
  journaltitle = {Biometrics},
  volume = {64},
  pages = {396--405},
  citeulike-article-id = {13265665},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {additivity,antagonism,drug-combinations,loewe-additivity-model,pharmaceutical,synergy,thin-plate-splines,wild-bootstrap}
}

@article{kon16vit,
  title = {Vitamin {{D Supplementation Modulates T Cell-Mediated Immunity}} in {{Humans}}: {{Results}} from a {{Randomized Control Trial}}.},
  author = {Konijeti, Gauree Gupta G. and Arora, Pankaj and Boylan, Matthew R. and Song, Yanna and Huang, Shi and Harrell, Frank and Newton-Cheh, Christopher and O'Neill, Dillon and Korzenik, Joshua and Wang, Thomas J. and Chan, Andrew T.},
  date = {2016-02},
  journaltitle = {The Journal of clinical endocrinology and metabolism},
  volume = {101},
  number = {2},
  eprint = {26653112},
  eprinttype = {pmid},
  pages = {533--538},
  issn = {1945-7197},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26653112},
  abstract = {Although studies have linked vitamin D deficiency with immune-mediated diseases, data demonstrating a direct effect on T-cell function are sparse. Our objective was to determine whether oral vitamin D3 influences T-cell activation in humans with vitamin D deficiency. This was a single-center ancillary study within Vitamin D Therapy in Individuals at High Risk of Hypertension, a double-blind, multicenter, randomized controlled trial. This study was undertaken in a single academic medical center. Adults with vitamin D deficiency and untreated pre- or early stage I hypertension were included. In Vitamin D Therapy in Individuals at High Risk of Hypertension, participants were randomized to either low- (400 IU daily) or high- (4000 IU daily) dose oral vitamin D3 for 6 months. In this ancillary study of 38 patients, we measured CD4+ T-cell activation estimated by intracellular ATP release after stimulation of whole blood with plant lectin phytohemagglutinin collected at baseline (pretreatment) and 2-month follow-up. Determining whether ATP level changes were significantly different between treatment groups was the main outcome measure. Treatment with 4000 IU of vitamin D3 decreased intracellular CD4+ ATP release by 95.5 ng/ml (interquartile range, -219.5 to 105.8). In contrast, 400 IU of vitamin D3 decreased intracellular CD4+ ATP release by 0.5 ng/ml (interquartile range, -69.2 to 148.5). In a proportional odds model, high-dose vitamin D3 was more likely than low-dose vitamin D3 to decrease CD4+ ATP release (odds ratio, 3.43; 95\% confidence interval, 1.06-1.11). In this ancillary study of a randomized controlled trial, we found that high-dose vitamin D3 significantly reduced CD4+ T-cell activation compared to low-dose vitamin D3, providing human evidence that vitamin D can influence cell-mediated immunity.},
  citeulike-article-id = {14102483},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26653112},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26653112},
  posted-at = {2016-07-26 21:02:14},
  priority = {2},
  keywords = {collaboration}
}

@article{kon89cli,
  title = {Clinical Experience and Predicting Survival in Coronary Disease},
  author = {Kong, D. F. and Lee, K. L. and Harrell, F. E. and Boswick, J. M. and Mark, D. B. and Hlatky, M. A. and Califf, R. M. and Pryor, D. B.},
  date = {1989},
  journaltitle = {Arc Int Med},
  volume = {149},
  pages = {1177--1181},
  citeulike-article-id = {13264418},
  posted-at = {2014-07-14 14:09:35},
  priority = {0}
}

@report{koo92log,
  title = {Logspline Density Estimation for Censored Data},
  author = {Kooperberg, Charles and Stone, Charles J.},
  date = {1992},
  number = {226},
  institution = {{Department of Statistics, University of Washington}},
  location = {{GN-22, Seattle, Washington 98195}},
  citeulike-article-id = {13264419},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {censored-data,hazard-estimation,smoothing,splines}
}

@article{koo95haz,
  title = {Hazard Regression},
  author = {Kooperberg, Charles and Stone, Charles J. and Truong, Young K.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {78--94},
  citeulike-article-id = {13264420},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {aic,bic,linear-splines,penalty}
}

@article{koo97haz,
  title = {Hazard Regression with Interval-Censored Data},
  author = {Kooperberg, Charles and Clarkson, Douglas B.},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {1485--1494},
  citeulike-article-id = {13264421},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {hare,interval-censoring,spline}
}

@article{kop19pow,
  title = {Power Gains by Using External Information in Clinical Trials Are Typically Not Possible When Requiring Strict Type {{I}} Error Control},
  author = {Kopp‐Schneider, Annette and Calderazzo, Silvia and Wiesenfarth, Manuel},
  date = {2019},
  journaltitle = {Biometrical Journal},
  volume = {0},
  number = {0},
  issn = {1521-4036},
  doi = {10.1002/bimj.201800395},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201800395},
  urldate = {2019-07-07},
  abstract = {In the era of precision medicine, novel designs are developed to deal with flexible clinical trials that incorporate many treatment strategies for multiple diseases in one trial setting. This situation often leads to small sample sizes in disease-treatment combinations and has fostered the discussion about the benefits of borrowing of external or historical information for decision-making in these trials. Several methods have been proposed that dynamically discount the amount of information borrowed from historical data based on the conformity between historical and current data. Specifically, Bayesian methods have been recommended and numerous investigations have been performed to characterize the properties of the various borrowing mechanisms with respect to the gain to be expected in the trials. However, there is common understanding that the risk of type I error inflation exists when information is borrowed and many simulation studies are carried out to quantify this effect. To add transparency to the debate, we show that if prior information is conditioned upon and a uniformly most powerful test exists, strict control of type I error implies that no power gain is possible under any mechanism of incorporation of prior information, including dynamic borrowing. The basis of the argument is to consider the test decision function as a function of the current data even when external information is included. We exemplify this finding in the case of a pediatric arm appended to an adult trial and dichotomous outcome for various methods of dynamic borrowing from adult information to the pediatric arm. In conclusion, if use of relevant external data is desired, the requirement of strict type I error control has to be replaced by more appropriate metrics.},
  langid = {english},
  keywords = {bayes,borrow-information,historical-data,power,prior}
}

@article{kor90mea,
  title = {Measures of Explained Variation for Survival Data},
  author = {Korn, Edward L. and Simon, Richard},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {487--503},
  citeulike-article-id = {13264422},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {nonparametrics,predictive-accuracy,survival-analysis}
}

@article{kor90ran,
  title = {The Rank Difference Test: {{A}} New and Meaningful Alternative to the {{Wilcoxon}} Signed Ranks Test for Ordinal Data},
  shorttitle = {The Rank Difference Test},
  author = {Kornbrot, Diana Eugenie},
  date = {1990},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  volume = {43},
  number = {2},
  pages = {241--264},
  issn = {2044-8317},
  doi = {10.1111/j.2044-8317.1990.tb00939.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8317.1990.tb00939.x},
  urldate = {2021-11-19},
  abstract = {A new distribution free inferential procedure for comparing paired observations, called the ‘rank difference test’, is presented. The new procedure is based on ranks, and is applicable as a robust alternative to the related f test in all situations where the Wilcoxon signed ranks test is applicable. In additions it may be applied to ordinal data or operational measures which do not meet the assumptions underlying the Wilcoxon. Since the rank difference statistic, D, can take on half-integer, as well as integer, values, it has continuity advantages over the Wilcoxon for small samples. The exact null distribution of the rank difference test statistic, D, is derived and tabulated for samples sizes from 2 to 7 pairs. The null distribution of the rank difference test statistic is shown to be asymptotically the same as that of the Wilcoxon test statistic for large sample sizes. Permutation methods are used to derive the null distribution for sample sizes from 8 to 20 based on 400000 simulations for each sample size. The practical application of the rank difference test is evaluated by comparing its power and performance with that of the Wilcoxon, the sign test and the related t test, for several classic sets of data in the literature, and for several sets of simulated data.},
  langid = {english},
  keywords = {nonparametric,one-sample-problem,paired-data,wilcoxon-test},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8317.1990.tb00939.x}
}

@article{kor91,
  title = {Explained Residual Variation, Explained Risk, and Goodness of Fit},
  author = {Korn, Edward L. and Simon, Richard},
  date = {1991},
  journaltitle = {Am Statistician},
  volume = {45},
  pages = {201--206},
  citeulike-article-id = {13264423},
  posted-at = {2014-07-14 14:09:35},
  priority = {0}
}

@article{kor91epi,
  title = {Epidemiologic Studies Utilizing Surveys: {{Accounting}} for the Sampling Design},
  author = {Korn, Edward L. and Graubard, Barry I.},
  date = {1991},
  journaltitle = {Am J Pub Health},
  volume = {81},
  pages = {1166--1173},
  citeulike-article-id = {13264424},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {cluster-sampling,clustered-data,design-effects,sample-survey,sample-weights,sampling}
}

@article{kor92app,
  title = {Applications of Crude Incidence Curves},
  author = {Korn, Edward L. and Dorey, Frederick J.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {813--829},
  citeulike-article-id = {13264425},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {competing-risks}
}

@article{kor93est,
  title = {On Estimating the Distribution Function for Quality of Life in Cancer Clinical Trials},
  author = {Korn, Edward L.},
  date = {1993},
  journaltitle = {Biometrika},
  volume = {80},
  pages = {535--542},
  citeulike-article-id = {13264426},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {bibliography,informative-censoring,multiple-endpoints,qol}
}

@article{kor95,
  title = {Analysis of Large Health Surveys: {{Accounting}} for the Sampling Design},
  author = {Korn, E. L. and Graubard, B. I.},
  date = {1995},
  journaltitle = {J Roy Stat Soc A},
  volume = {158},
  pages = {263--295},
  citeulike-article-id = {13264427},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {sample-weights,sampling-design}
}

@article{kor95exa,
  title = {Examples of Differing Weighted and Unweighted Estimates from a Sample Survey},
  author = {Korn, Edward L. and Graubard, Barry I.},
  date = {1995},
  journaltitle = {Am Statistician},
  volume = {49},
  pages = {291--295},
  citeulike-article-id = {13264428},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {complex-sample-surveys,sample-weights}
}

@article{kor96dat,
  title = {Data Monitoring Committees and Problems of Lower-than-Expected Accrual or Event Rates},
  author = {Korn, Edward L. and Simon, Richard},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {527--536},
  doi = {10.1016/S0197-2456(96)00088-8},
  url = {http://dx.doi.org/10.1016/S0197-2456(96)00088-8},
  citeulike-article-id = {13264429},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0197-2456(96)00088-8},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {clinical-trials,conditional-power,data-and-safety-monitoring,dsmb,event-rates,interim-analysis,rct,stochastic-curtailment,study-design}
}

@article{kor98sta,
  title = {Scatterplots with Survey Data},
  author = {Korn, Edward L. and Graubard, Barry I.},
  date = {1998},
  journaltitle = {Am Statistician},
  volume = {52},
  pages = {58--69},
  citeulike-article-id = {13264430},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {added-variable-plot,bubble-plot,conditional-percentile,graphics,imputation,influential-points,kernel-smoothing,nonparametric-regression,partial-residual-plot,survey-data,wample-weights}
}

@article{kot12use,
  title = {Use of the Stepped Wedge Design Cannot Be Recommended: {{A}} Critical Appraisal and Comparison with the Classic Cluster Randomized Controlled Trial Design},
  author = {Kotz, Daniel and Spigt, Mark and Arts, Ilja C. W. and Crutzen, Rik and Viechtbauer, Wolfgang},
  date = {2012},
  journaltitle = {J Clin Epi},
  volume = {65},
  number = {12},
  pages = {1249--1252},
  doi = {10.1016/j.jclinepi.2012.06.004},
  url = {http://www.sciencedirect.com/science/article/pii/S0895435612001710},
  citeulike-article-id = {13265945},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2012.06.004},
  citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/pii/S0895435612001710},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {cluster-randomization,cluster-randomized-trial,rct,stepped-wedge},
  note = {See discussion at https://groups.google.com/forum/?fromgroups=\#!topic/MedStats/OYIdty\_XUlM}
}

@article{kov13fit,
  title = {Fitting {{Additive Binomial Regression Models}} with the {{R Package}} Blm},
  author = {Kovalchik, Stephanie and Varadhan, Ravi},
  date = {2013-09},
  journaltitle = {J Stat Software},
  volume = {54},
  number = {1},
  url = {http://www.jstatsoft.org/v54/i01},
  citeulike-article-id = {13265983},
  citeulike-linkout-0 = {http://www.jstatsoft.org/v54/i01},
  day = {3},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {additive-risk,binary-regression}
}

@article{kow07mod,
  title = {Model-Based Drug Development - {{A}} New Paradigm for Efficient Drug Development},
  author = {Kowalski, Kenneth G. and Ewy, Wayne and Hutmacher, Matthew M. and Miller, Raymond and Krishnaswami, Sriram},
  date = {2007-22},
  journaltitle = {Biopharm Rep ASA},
  volume = {15},
  number = {2},
  pages = {2--22},
  citeulike-article-id = {13265579},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {drug-development,model},
  note = {great brief presentation of pharmacology of drug development and drug development in general;RCT;pharmaceutical;model-based research;clinical trial simulation;PK/PD models;meta-analysis of competitor data;trial performance metrics;see br\_sum07.pdf}
}

@article{koy05fra,
  title = {A Framework for Two-Stage Adaptive Procedures to Simultaneously Test Non-Inferiority and Superiority},
  author = {Koyama, T. and Sampson, A. R. and Gleser, L. J.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2439--2456},
  citeulike-article-id = {13265508},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@unpublished{koy06pro,
  title = {Proper Inference Procedure from {{Simon}}'s Two-Stage Design},
  author = {Koyama, Tatsuki},
  date = {2006},
  citeulike-article-id = {13265527},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  annotation = {unpublished technical report}
}

@book{kra05bas,
  title = {The {{Basics}} of {{{\textsc{S-Plus}}}}},
  author = {Krause, Andreas and Olson, Melvin},
  date = {2000},
  edition = {Fourth},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13264434},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {basic,s-plus,teaching}
}

@article{kra88ass,
  title = {Assessment of 2x2 Associations: Generalization of Signal-Detection Methodology},
  author = {Hc, Kraemer},
  date = {1988},
  journaltitle = {Am Statistician},
  volume = {42},
  pages = {37--49},
  citeulike-article-id = {13264431},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {diagnosis,predictive-accuracy,testing}
}

@article{kra88kap,
  title = {Kappa Coefficients in Epidemiology: {{An}} Appraisal of a Reappraisal},
  author = {Kraemer, H. C. and Block, D. A.},
  date = {1988},
  journaltitle = {J Clin Epi},
  volume = {41},
  pages = {959--968},
  citeulike-article-id = {13264432},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {categorical-data}
}

@article{kra90,
  title = {Random Assignment in Clinical Trials: Issues in Planning ({{Infant Health}} and {{Development Program}})},
  author = {Kraemer, H. C. and Fendt, K. H.},
  date = {1990},
  journaltitle = {J Clin Epi},
  volume = {43},
  pages = {1157--1167},
  citeulike-article-id = {13264433},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {study-design-and-stopping-rules}
}

@article{kra99nul,
  title = {The Null Hypothesis Testing Controversy in Psychology},
  author = {Krantz, David H.},
  date = {1999},
  journaltitle = {J Am Stat Assoc},
  volume = {44},
  pages = {1372--1381},
  citeulike-article-id = {13264435},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  note = {problems with P-values and hypothesis tests;some criticism of psychology}
}

@article{kri02num,
  title = {Number Needed to Treat: Easily Understood and Intuitively Meaningful? {{Theoretical}} Considerations and a Randomized Trial},
  author = {Kristiansen, Ivar S. and Gyrd-Hansen, Dorte and Nexøe, Jørgen and Nielsen, Jesper B.},
  date = {2002},
  journaltitle = {J Clin Epi},
  volume = {55},
  pages = {888--892},
  citeulike-article-id = {13265298},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {chronic-diseases,evidence-based-medicine,nnt,number-needed-to-treat,rct,risk-communication},
  note = {"NNT does not convey information on the proportion of patients being helped by an intervention or the size of the delay of the adverse event intended to be prevented. ... The shortcomings and misunderstandings are not unique to NNT, but may be present for other measures such as RRR, ARR, and gain in life expectancy. Doctors may do well to accept that decision making under uncertainty is difficult. The decision maker ought to know baseline risk, ARR/NNT, as well as preferences for future health gains. Can one single measure of benefit - 'a simple yardstick' - convey all the necessary information? The answer is probably negative. If one measure could perform this role, it is unlikely to be NNT." See also Altman (BMJ 1998, vol 317, p 1309).}
}

@article{kri09cir,
  title = {Circular Analysis in Systems Neuroscience: The Dangers of Double Dipping},
  author = {Kriegeskorte, Nikolaus and Simmons, W. Kyle and Bellgowan, Patrick S. F. and Baker, Chris I.},
  date = {2009},
  journaltitle = {Nat Neurosci},
  volume = {12},
  number = {5},
  pages = {535--540},
  citeulike-article-id = {13265748},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {bad-science,bad-statistical-practice,double-dipping},
  note = {getting away from the data;"However, double dipping (the use of the same data for selection and selective analysis) will result in distored descriptive statistics and invalid statistical inference whenever the test statistics are not inherently independent of the selection criteria under the null hypothesis. Non-independent selective analysis is incorrect and should not be acceptable in neuroscientific publications. ... The problem arises so frequently because the desired selection criterion is often identical with or related to the desired results statistics for the selective analysis. ... Distortions arising from selection tend to make results look more consistent with the selection criteria, which often reflect the hypothesis being tested. Circularity is therefore the error that beautifies results, rendering them more attractive to authors, reviewers and editors, and thus more competitive for publication. These implicit incentives may create a preference for circular practices so long as the community condones them. ... Common practices need to be adjusted. In particular, selection criteria should be demonstrated to be independent of further analyses."; implies that split sample validation is a good idea; did not understand the volatility of split-sample methods and was not aware of bootstrap correction of apparent results; pointed out ramifications of fortuitous agreements of training and test samples on a finding}
}

@article{kro08why,
  title = {Why {{Bland-Altman}} Plots Should Use {{X}}, Not ({{Y}}+{{X}})/2 When {{X}} Is a Reference Method},
  author = {Krouwer, Jan S.},
  date = {2008-02},
  journaltitle = {Stat Med},
  volume = {27},
  number = {5},
  eprint = {17907247},
  eprinttype = {pmid},
  pages = {778--780},
  publisher = {John Wiley & Sons, Ltd.},
  location = {Krouwer Consulting, 26 Parks Drive, Sherborn, MA 01770, U.S.A.},
  issn = {0277-6715},
  doi = {10.1002/sim.3086},
  url = {http://dx.doi.org/10.1002/sim.3086},
  citeulike-article-id = {2518693},
  citeulike-attachment-1 = {kro08why.pdf; /pdf/user/harrelfe/article/2518693/1125878/kro08why.pdf; 2e83f6bd58e277c47020373a4d7764325e9c96d9},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3086},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/17907247},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=17907247},
  day = {28},
  posted-at = {2017-12-29 14:19:45},
  priority = {0},
  keywords = {change,smooth-bland-altman-plots}
}

@article{kro90,
  title = {Piecewise Comparison of Survival Functions in Stratified Proportional Hazards Models},
  author = {Kronborg, D. and Aaby, P.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {375--380},
  citeulike-article-id = {13264436},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model,testing-proportional-hazards}
}

@article{kro93spu,
  title = {Spurious Correlation and the Fallacy of the Ratio Standard Revisited},
  author = {Kronmal, R. A.},
  date = {1993},
  journaltitle = {J Roy Stat Soc A},
  volume = {156},
  pages = {379--392},
  citeulike-article-id = {13264437},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {change,ratio},
  note = {spurious correlation in using ratio variables even if all component variables of ratios are uncorrelated; division of only the dependent variable by an independent variable can result in regression coefficient estimates for the other independent variables that result in inappropriate conclusions;use of a ratio as an independent variable can result in inadequate adjustment for component variables of the ratio;ratio variables should only be used in a full model containing all the component variables;results of regression analyses incorporating ratios are not readily comparable across studies}
}

@article{kru13bay,
  title = {Bayesian Estimation Supersedes the t Test.},
  author = {Kruschke, John K.},
  date = {2013-05},
  journaltitle = {J Exp Psych},
  volume = {142},
  number = {2},
  eprint = {22774788},
  eprinttype = {pmid},
  pages = {573--603},
  issn = {1939-2222},
  doi = {10.1037/a0029146},
  url = {http://dx.doi.org/10.1037/a0029146},
  abstract = {Bayesian estimation for 2 groups provides complete distributions of credible values for the effect size, group means and their difference, standard deviations and their difference, and the normality of the data. The method handles outliers. The decision rule can accept the null value (unlike traditional t tests) when certainty in the estimate is high (unlike Bayesian model comparison using Bayes factors). The method also yields precise estimates of statistical power for various research goals. The software and programs are free and run on Macintosh, Windows, and Linux platforms. PsycINFO Database Record (c) 2013 APA, all rights reserved.},
  citeulike-article-id = {11639960},
  citeulike-attachment-1 = {kru13bay.pdf; /pdf/user/harrelfe/article/11639960/1136836/kru13bay.pdf; dea60927efbd1f284b4132eae3461ea7ce0fb62a},
  citeulike-linkout-0 = {http://dx.doi.org/10.1037/a0029146},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/22774788},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=22774788},
  day = {9},
  posted-at = {2018-05-18 03:54:13},
  priority = {4},
  keywords = {basic,bayes,bayesian-inference,teaching-mds,tutorial}
}

@book{kru15doi,
  title = {Doing {{Bayesian Data Analysis}}: {{A Tutorial}} with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John K.},
  date = {2015},
  edition = {Second Edition},
  publisher = {{Academic Press}},
  location = {{Waltham MA}},
  url = {http://www.sciencedirect.com/science/book/9780124058880},
  citeulike-article-id = {14172337},
  citeulike-linkout-0 = {http://www.sciencedirect.com/science/book/9780124058880},
  isbn = {978-0-12-405888-0},
  posted-at = {2016-10-26 21:46:24},
  priority = {4},
  keywords = {bayes,bayesian-inference,bayesian-methods,teaching-mds}
}

@article{kru17bay,
  title = {Bayesian Data Analysis for Newcomers},
  booktitle = {Psychonomic Bulletin & Review},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  date = {2017},
  pages = {1--23},
  publisher = {Springer US},
  doi = {10.3758/s13423-017-1272-1},
  url = {http://dx.doi.org/10.3758/s13423-017-1272-1},
  citeulike-article-id = {14379017},
  citeulike-attachment-1 = {kru17bay.pdf; /pdf/user/harrelfe/article/14379017/1112234/kru17bay.pdf; 667a350e04440965997f085062e0249269d20ce3},
  citeulike-linkout-0 = {http://dx.doi.org/10.3758/s13423-017-1272-1},
  citeulike-linkout-1 = {http://link.springer.com/article/10.3758/s13423-017-1272-1},
  posted-at = {2017-06-19 02:27:08},
  priority = {0},
  keywords = {bayesian-inference,teaching,teaching-mds},
  note = {Excellent for teaching Bayesian methods and explaining the advantages}
}

@article{kru87,
  title = {Relative Importance by Averaging over Orderings},
  author = {{Kruskal}},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {6--10},
  citeulike-article-id = {13264438},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {general,regression,variable-selection}
}

@article{kru94fro,
  title = {From Signal/Noise to Information Content/Noise. {{Reconsidering}} the Statistical Analysis of Continuous {{ST-segment}} Data Streams with Gaps: {{Potential}} Optimization of Application-Specific Information Content Using Left, Right, and Interval Censoring},
  author = {Krucoff, M. W. and Green, C. L. and Harrell, F. E. and Simoons, M. L. and Wilderman, N. M. and Trollinger, K. M. and Sawchak, S. T. and Pope, J. E. and Shah, A. and Granger, C. B. and {Et Al}},
  date = {1994},
  journaltitle = {J Electrocard},
  volume = {27 Suppl},
  pages = {233--237},
  citeulike-article-id = {13264439},
  posted-at = {2014-07-14 14:09:35},
  priority = {0}
}

@article{krz87,
  title = {Cross-Validation in Principal Component Analysis},
  author = {Wj, Krzanowski},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {575--584},
  citeulike-article-id = {13264440},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {multivariate-analysis}
}

@article{kun01imp,
  title = {Implementing Randomization Procedures in the {{Asthma Clinical Research Network}}},
  author = {Kunselman, Susan J. and Armstrong, Trina J. and Britton, Terry B. and Forand, Pamela E.},
  date = {2001},
  journaltitle = {Controlled Clin Trials},
  volume = {22},
  pages = {181S-195S},
  citeulike-article-id = {13265249},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {adaptive-allocation,data-management-system,dynamic-allocation,maintaining-masking-of-study-statistician,permuted-blocks,randomization-procedures,s-plus-to-generate-randomization-assignments,stratification,treatment-allocation}
}

@article{kun21reva,
  title = {A {{Review}} of {{Bayesian Perspectives}} on {{Sample Size Derivation}} for {{Confirmatory Trials}}},
  author = {Kunzmann, Kevin and Grayling, Michael J. and Lee, Kim May and Robertson, David S. and Rufibach, Kaspar and Wason, James M. S.},
  date = {2021-03-22},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--9},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2021.1901782},
  url = {https://doi.org/10.1080/00031305.2021.1901782},
  urldate = {2021-04-23},
  abstract = {Sample size derivation is a crucial element of planning any confirmatory trial. The required sample size is typically derived based on constraints on the maximal acceptable Type I error rate and minimal desired power. Power depends on the unknown true effect and tends to be calculated either for the smallest relevant effect or a likely point alternative. The former might be problematic if the minimal relevant effect is close to the null, thus requiring an excessively large sample size, while the latter is dubious since it does not account for the a priori uncertainty about the likely alternative effect. A Bayesian perspective on sample size derivation for a frequentist trial can reconcile arguments about the relative a priori plausibility of alternative effects with ideas based on the relevance of effect sizes. Many suggestions as to how such “hybrid” approaches could be implemented in practice have been put forward. However, key quantities are often defined in subtly different ways in the literature. Starting from the traditional entirely frequentist approach to sample size derivation, we derive consistent definitions for the most commonly used hybrid quantities and highlight connections, before discussing and demonstrating their use in sample size derivation for clinical trials.},
  keywords = {bayes,design,rct,sample-size},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2021.1901782}
}

@article{kur08for,
  title = {Formulating Tightest Bounds on Causal Effects in Studies with Unmeasured Confounders},
  author = {Kuroki, Manabu and Cai, Zhihong},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {6597--6611},
  citeulike-article-id = {13265765},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {causal-risk-difference,linear-programming,monotonicity-assumption,potential-response-model}
}

@article{kur09lon,
  title = {Longitudinal Data with Follow-up Truncated by Death: {{Match}} the Analysis Method to Research Aims},
  author = {Kurland, Brenda F. and Johnson, Laura L. and Engleston, Brian L. and Diehr, Paula H.},
  date = {2009},
  journaltitle = {Stat Sci},
  volume = {24},
  number = {2},
  pages = {211--222},
  citeulike-article-id = {13265823},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {censoring,generalized-estimating-equations,longitudinal-data,missing-data,quality-of-life,random-effects-models,truncation-by-death}
}

@article{kur18cop,
  title = {A Copula Model for Joint Modeling of Longitudinal and Time-Invariant Mixed Outcomes},
  author = {Kürüm, Esra and Jeske, Daniel R. and Behrendt, Carolyn E. and Lee, Peter},
  date = {2018},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.7855},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7855},
  urldate = {2018-07-08},
  abstract = {Motivated by a preclinical study in a mouse model of breast cancer, we suggest a joint modeling framework for outcomes of mixed type and measurement structures (longitudinal versus single time/time-invariant). We present an approach based on the time-varying copula models, which is used to jointly model longitudinal outcomes of mixed types via a time-varying copula, and extend the scope of these models to handle outcomes with mixed measurement structures. Our framework allows the parameters corresponding to the longitudinal outcome to be time varying and thereby enabling researchers to investigate how the response-predictor relationships change with time. We investigate the finite sample performance of this new approach via a Monte Carlo simulation study and illustrate its usefulness by an empirical analysis of the motivating preclinical study, comparing the effect of various treatments on tumor volume (longitudinal continuous response) and the number of days until tumor volume triples (time-invariant count response). Through the real-life application and the simulation study, we demonstrate that, compared with marginal modeling, the joint modeling framework offers more precision in the estimation of model parameters.},
  langid = {english},
  keywords = {copula,longitudinal,multiple-endpoints,multivariate,serial}
}

@article{kwo03cho,
  title = {Choice of Parametric Models in Survival Analysis: Applications to Monotherapy for Epilepsy and Cerebral Palsy},
  author = {Kwong, G. P. S. and Hutton, J. L.},
  date = {2003},
  journaltitle = {Appl Stat},
  volume = {52},
  pages = {153--168},
  citeulike-article-id = {13265340},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {accelerated-life,choice-of-parametric-survival-models,misspecification,model-choice,orthogonality,proportional-hazards,robustness-of-accelerated-failure-time-models-to-model-misspecification,survival-analysis}
}

@article{la19bay,
  title = {Bayesian Sequential Integration within a Preclinical Pharmacokinetic and Pharmacodynamic Modeling Framework: {{Lessons}} Learned},
  shorttitle = {Bayesian Sequential Integration within a Preclinical Pharmacokinetic and Pharmacodynamic Modeling Framework},
  author = {La Gamba, Fabiola and Jacobs, Tom and Geys, Helena and Jaki, Thomas and Serroyen, Jan and Ursino, Moreno and Russu, Alberto and Faes, Christel},
  date = {2019-04-01},
  journaltitle = {Pharmaceutical Statistics},
  volume = {0},
  number = {0},
  issn = {1539-1604},
  doi = {10.1002/pst.1941},
  url = {https://onlinelibrary.wiley.com/doi/full/10.1002/pst.1941},
  urldate = {2019-04-02},
  abstract = {The present manuscript aims to discuss the implications of sequential knowledge integration of small preclinical trials in a Bayesian pharmacokinetic and pharmacodynamic (PK-PD) framework. While, at first sight, a Bayesian PK-PD framework seems to be a natural framework to allow for sequential knowledge integration, the scope of this paper is to highlight some often-overlooked challenges while at the same time providing some guidances in the many and overwhelming choices that need to be made. Challenges as well as opportunities will be discussed that are related to the impact of (1) the prior specification, (2) the choice of random effects, (3) the type of sequential integration method. In addition, it will be shown how the success of a sequential integration strategy is highly dependent on a carefully chosen experimental design when small trials are analyzed.},
  keywords = {bayes,drug-development,pharmaceutical,pk}
}

@article{laa85equ,
  title = {The Equivalence of Two Models for Ordinal Data},
  author = {Läärä, E. and Matthews, J. N. S.},
  date = {1985},
  journaltitle = {Biometrika},
  volume = {72},
  pages = {206--7},
  citeulike-article-id = {13264441},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {complementary-log-log,continuation-ratio,ordinal-logistic-model}
}

@article{lab87met,
  title = {Meta-Analysis in Clinical Research},
  author = {L'Abbe, L. A. and Detsky, A. S. and O'Rourke, K.},
  date = {1987},
  journaltitle = {Ann Int Med},
  volume = {107},
  pages = {224--233},
  citeulike-article-id = {13264442},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {meta-analysis,publication-bias,teaching-mds}
}

@article{lac03pro,
  title = {Proper Metrics for Clinical Trials: Transformations and Other Procedures to Remove Non-Normality Effects},
  author = {Lachenbruch, Peter A.},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {3823--3842},
  citeulike-article-id = {13265360},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {non-normality,ordinal-logistic-model-for-continuous-response,simulation-setup,size-and-power-of-t-test,testing-for-normality,wilcoxon-and-box-cox-likelihood-ratio-test}
}

@article{lac05rev,
  title = {A Review of Methods for Futility Stopping Based on Conditional Power},
  author = {Lachin, John},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2747--2764},
  citeulike-article-id = {13265656},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {browning-motion,conditional-power,futility,interim-analysis,rct,stochastic-curtailment}
}

@article{lac11pow,
  title = {Power and Sample Size Evaluation for the {{Cochran}}–{{Mantel}}–{{Haenszel}} Mean Score ({{Wilcoxon}} Rank Sum) Test and the {{Cochran}}–{{Armitage}} Test for Trend},
  author = {Lachin, John M.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  number = {25},
  pages = {3057--3066},
  doi = {10.1002/sim.4330},
  url = {http://dx.doi.org/10.1002/sim.4330},
  abstract = {The power of a chi-square test, and thus the required sample size, are a function of the noncentrality parameter that can be obtained as the limiting expectation of the test statistic under an alternative hypothesis specification. Herein, we apply this principle to derive simple expressions for two tests that are commonly applied to discrete ordinal data. The Wilcoxon rank sum test for the equality of distributions in two groups is algebraically equivalent to the Mann–Whitney test. The Kruskal–Wallis test applies to multiple groups. These tests are equivalent to a Cochran–Mantel–Haenszel mean score test using rank scores for a set of C-discrete categories. Although various authors have assessed the power function of the Wilcoxon and Mann–Whitney tests, herein it is shown that the power of these tests with discrete observations, that is, with tied ranks, is readily provided by the power function of the corresponding Cochran--Mantel--Haenszel mean scores test for two and R\,{$>$}\,2 groups. These expressions yield results virtually identical to those derived previously for rank scores and also apply to other score functions. The Cochran–Armitage test for trend assesses whether there is an monotonically increasing or decreasing trend in the proportions with a positive outcome or response over the C-ordered categories of an ordinal independent variable, for example, dose. Herein, it is shown that the power of the test is a function of the slope of the response probabilities over the ordinal scores assigned to the groups that yields simple expressions for the power of the test.},
  citeulike-article-id = {13265910},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4330},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {cochranarmitage-test-for-trend,cochranmantelhaenszel-mean-score-test,kruskalwallis-test,power,sample-size,wilcoxon-rank-sum-test}
}

@article{lac76ana,
  title = {Analysis of Data with Clumping at Zero},
  author = {Lachenbruch, Peter A.},
  date = {1976},
  journaltitle = {Biometrical J},
  volume = {18},
  pages = {351--356},
  citeulike-article-id = {13264443},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {two-stage-test}
}

@article{lac86eva,
  title = {Evaluation of Sample Size and Power for Analyses of Survival with Allowance for Nonuniform Patient Entry, Losses to Follow-up, Noncompliance, and Stratification.},
  author = {Lachin, John M. and Foulkes, Mary A.},
  date = {1986},
  journaltitle = {Biometrics},
  volume = {42},
  pages = {507--519},
  citeulike-article-id = {13264444},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {dropin,dropout,nonadherence,noncompliance,power,sample-size,study-design,survival}
}

@article{lac96dis,
  title = {Distribution-Free Marginal Analysis of Repeated Measures},
  author = {Lachin, John M.},
  date = {1996},
  journaltitle = {Drug Info J},
  volume = {30},
  pages = {1017--1028},
  citeulike-article-id = {13264445},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {repeated-measures,serial-measurements}
}

@article{lac97odd,
  title = {The Odds Ratio (Letter to the Editor)},
  author = {Lachenbruch, Peter A.},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {381--382},
  citeulike-article-id = {13264446},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {diagnosis,odds-ratio,or,testing},
  note = {OR is product of the "odds of being correct when the test is positive and the odds of being correct when the test is negative"}
}

@article{lag84pro,
  title = {Properties of Proportional Hazards Score Tests under Misspecified Regression Models},
  author = {Lagakos, S. W. and Schoenfeld, D. A.},
  date = {1984},
  journaltitle = {Biometrics},
  volume = {40},
  pages = {1037--1048},
  citeulike-article-id = {13264447},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {covariable-adjustment,size-of-test-preserved-if-covariables-omitted}
}

@article{lag88,
  title = {The Loss in Efficiency from Misspecifying Covariates in Proportional Hazards Regression Models},
  author = {Lagakos, S. W.},
  date = {1988},
  journaltitle = {Biometrika},
  volume = {75},
  pages = {156--160},
  citeulike-article-id = {13264448},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model,testing-proportional-hazards}
}

@article{lai07rep,
  title = {Reproducible Research: {{Moving}} toward Research the Public Can Really Trust},
  author = {Laine, Christine and Goodman, Steven N. and Griswold, Michael E. and Sox, Harold C.},
  date = {2007},
  journaltitle = {Ann Int Med},
  volume = {146},
  pages = {450--453},
  citeulike-article-id = {13265768},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  note = {asks submitters to state whether or not they are willing to make the study protocol, data, and statistical code available to others and under what terms this will be allowed;answer does not affect review process}
}

@article{lai82ran,
  title = {Random-Effects Models for Longitudinal Data},
  author = {Laird, N. M. and Ware, J. H.},
  date = {1982},
  journaltitle = {Biometrics},
  volume = {38},
  pages = {963--974},
  citeulike-article-id = {13264449},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {clustered-data,multiple-events,repeated-measures}
}

@article{lak21bay,
  title = {Bayesian Adaptive Design for Clinical Trials in {{Duchenne}} Muscular Dystrophy},
  author = {Lake, Stephen L. and Quintana, Melanie A. and Broglio, Kristine and Panagoulias, Jennifer and Berry, Scott M. and Panzara, Michael A.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9021},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9021},
  urldate = {2021-05-08},
  abstract = {A Bayesian adaptive design is proposed for a clinical trial in Duchenne muscular dystrophy. The trial was designed to demonstrate treatment efficacy on an ambulatory-based clinical endpoint and to identify early success on a biomarker (dystrophin protein levels) that can serve as a basis for accelerated approval in the United States. The trial incorporates placebo augmentation using placebo data from past clinical trials. A thorough simulation study was conducted to understand the operating characteristics of the trial. This trial design was selected for the US FDA Complex Innovative Trial Design Pilot Meeting Program and the experience in that program is summarized.},
  langid = {english},
  keywords = {adaptive,bayes,biomarker,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9021}
}

@article{lak88,
  title = {Sample Sizes Based on the Log-Rank Statistic in Complex Clinical Trials},
  author = {Lakatos, Edward},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {229--241},
  citeulike-article-id = {13264450},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {sample-size-estimation,study-design-and-stopping-rules}
}

@article{lal20dis,
  title = {Discovering Structure in Multiple Outcomes Models for Tests of Childhood Neurodevelopment},
  author = {LaLonde, Amy and Love, Tanzy and Thurston, Sally W. and Davidson, Philip W.},
  date = {2020},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13174},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13174},
  urldate = {2019-11-29},
  abstract = {Bayesian model–based clustering provides a powerful and flexible tool that can be incorporated into regression models to better understand the grouping of observations. Using data from the Seychelles Child Development Study, we explore the effect of prenatal methylmercury exposure on 20 neurodevelopmental outcomes measured in 9-year-old children. Rather than cluster individual subjects, we cluster the outcomes within a multiple outcomes model. By using information in the data to nest the outcomes into groups called domains, the model more accurately reflects the shared characteristics of neurodevelopmental domains and improves estimation of the overall and outcome-specific exposure effects by shrinking effects within and between domains selected by the data. The Bayesian paradigm allows for sampling from the posterior distribution of the grouping parameters; thus, inference can be made about group membership and their defining characteristics. We avoid the often difficult and highly subjective requirement of a priori identification of the total number of groups by incorporating a Dirichlet process prior to form a fully Bayesian multiple outcomes model.},
  langid = {english},
  keywords = {bayes,clustering,multiple-endpoints}
}

@article{lam05bay,
  title = {Bayesian Proportional Hazards Model with Time-Varying Regression Coefficients: A Penalized {{Poisson}} Regression Approach.},
  author = {Lambert, Philippe and Eilers, Paul H.},
  date = {2005-12},
  journaltitle = {Stat Med},
  volume = {24},
  number = {24},
  eprint = {16320263},
  eprinttype = {pmid},
  pages = {3977--3989},
  issn = {0277-6715},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/16320263},
  abstract = {One can fruitfully approach survival problems without covariates in an actuarial way. In narrow time bins, the number of people at risk is counted together with the number of events. The relationship between time and probability of an event can then be estimated with a parametric or semi-parametric model. The number of events observed in each bin is described using a Poisson distribution with the log mean specified using a flexible penalized B-splines model with a large number of equidistant knots. Regression on pertinent covariates can easily be performed using the same log-linear model, leading to the classical proportional hazard model. We propose to extend that model by allowing the regression coefficients to vary in a smooth way with time. Penalized B-splines models will be proposed for each of these coefficients. We show how the regression parameters and the penalty weights can be estimated efficiently using Bayesian inference tools based on the Metropolis-adjusted Langevin algorithm. Copyright 2005 John Wiley \& Sons, Ltd.},
  citeulike-article-id = {13349286},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/16320263},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=16320263},
  day = {30},
  posted-at = {2014-09-06 14:32:13},
  priority = {2},
  keywords = {b-spline,mcmc,p-splines,penalized-splines},
  note = {actuarial analysis binning data and using Poisson distribution for number of events in each bin}
}

@article{lam05how,
  title = {How Vague Is Vague? {{A}} Simulation Study of the Impact of the Use of Vague Prior Distributions in {{MCMC}} Using {{WinBUGS}}},
  author = {Lambert, Paul C. and Sutton, Alex J. and Burton, Paul R. and Abrams, Keith R. and Jones, David R.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2401--2428},
  citeulike-article-id = {13265432},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {bayesian-methods,graphics,mcmc,prior-distributions,simulation-study},
  note = {uninformative prior distributions showed large effects of results for scale parameters in meta-analysis with small numbers of studies;beautiful graphical summaries of results}
}

@article{lam12lea,
  title = {Learning from Our {{GWAS}} Mistakes: From Experimental Design to Scientific Method},
  author = {Lambert, Christophe G. and Black, Laura J.},
  date = {2012},
  journaltitle = {Biostat},
  volume = {13},
  number = {2},
  pages = {195--203},
  doi = {10.1093/biostatistics/kxr055},
  url = {http://dx.doi.org/10.1093/biostatistics/kxr055},
  citeulike-article-id = {13265926},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biostatistics/kxr055},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {batch-effects,experimental-design,falsifiability,gwas,order-effects,popper,systemic-hypothesis-falsification},
  note = {"In the traditional scientific method, a hypothesis is a proposed explanation for a phenomenon, but scientists use the hypothesis to deduce additional predicted effects which, if observed, can corroborate the hypothesis but not prove it and, if not observed as predicted, can falsify the hypothesis. A single observation can falsify a traditional scientific hyothesis.";Platt strong inference}
}

@article{lam95ove,
  title = {Overdispersion Diagnostics for Generalized Linear Models},
  author = {Lambert, Diane and Roeder, Kathryn},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {1225--1236},
  citeulike-article-id = {13264451},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {c-plot,glm-diagnostics,overdispersion,random-coefficients,relative-variance-plots,residuals,variance-inflation}
}

@article{lan84gra,
  title = {Graphical Methods for Assessing Logistic Regression Models (with Discussion)},
  author = {Landwehr, J. M. and Pregibon, D. and Shoemaker, A. C.},
  date = {1984},
  journaltitle = {J Am Stat Assoc},
  volume = {79},
  pages = {61--83},
  citeulike-article-id = {13264452},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {graphical-methods,logistic-model,residuals,transformation}
}

@article{lan88,
  title = {The {{B-value}}: {{A}} Tool for Monitoring Studies},
  author = {Lan KKG, Wittes J.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {579--585},
  citeulike-article-id = {13264453},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {sequential-methods,study-design-and-stopping-rules}
}

@article{lan90,
  title = {Linear Rank Tests for Survival Data: Equivalence of Two Formulations},
  author = {Lan KKG, Wittes J.},
  date = {1990},
  journaltitle = {Am Statistician},
  volume = {44},
  pages = {23--25},
  citeulike-article-id = {13264454},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {distribution-free-methods,survival-analysis-non-regression}
}

@book{lan90eco,
  title = {The {{Econometric Analysis}} of {{Transition Data}}},
  author = {Lancaster, T.},
  date = {1990},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  citeulike-article-id = {13264455},
  posted-at = {2014-07-14 14:09:35},
  priority = {0}
}

@article{lan93use,
  title = {Use of Spending Functions for Occasional or Continuous Monitoring of Data in Clinical Trials},
  author = {Lan, K. K. Gordon and Rosenberger, William F. and Lachin, John M.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2219--2231},
  doi = {10.1002/sim.4780122307},
  url = {http://dx.doi.org/10.1002/sim.4780122307},
  citeulike-article-id = {13264456},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780122307},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {clinical-trials,interim-analysis,monitoring,rct,sequential-methods,stopping-rules,study-design}
}

@article{lan94sim,
  title = {Simultaneous Confidence Intervals in Multiple Regression},
  author = {Lane, Thomas P. and DuMouchel, William H.},
  date = {1994},
  journaltitle = {Am Statistician},
  volume = {48},
  pages = {315--321},
  citeulike-article-id = {13264457},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {general,regression,simultaneous-confidence-intervals}
}

@article{lan95non,
  title = {Non-Parametric Methods for Analysing Recurrent Complications of Varying Severity},
  author = {Lancar, Rémi and Kramar, Andrew and Haie-Meder, Christine},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2701--2712},
  citeulike-article-id = {13264458},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {multiple-events,recurrent-events,repeated-events,severity-of-event}
}

@book{lan97how,
  title = {How to {{Report Stat Med}}: {{Annotated Guidelines}} for {{Authors}}, {{Editors}}, and {{Reviewers}}},
  author = {Lang, Thomas A. and Secic, Michelle},
  date = {1997},
  publisher = {{American College of Physicians}},
  location = {{Philadelphia}},
  citeulike-article-id = {13264459},
  isbn = {0-9431 2644-4},
  posted-at = {2014-07-14 14:09:35},
  priority = {0},
  keywords = {general,publication-bias,statistical-review,teaching-mds},
  annotation = {ISBN 0-9431-2644-4},
  note = {statistical review of medical articles; see Chapter 11 for publication bias}
}

@article{lan98pan,
  title = {Panel Data with Survival: {{Hospitalization}} of {{HIV-positive}} Patients},
  author = {Lancaster, Tony and Intrator, Orna},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {46--53},
  citeulike-article-id = {13264460},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {analysis-of-cost,bivariate-survival,joint-modeling-of-cost-and-survival,joint-modeling-of-hospitalization-and-survival,longitudinal-panel-data,mixture-frailty-models,resource-utilization}
}

@article{lap17eff,
  title = {Effect of {{Therapeutic Hypothermia Initiated After}} 6 {{Hours}} of {{Age}} on {{Death}} or {{Disability Among Newborns With Hypoxic-Ischemic Encephalopathy}}},
  author = {Laptook, Abbot R. and Shankaran, Seetha and Tyson, Jon E. and Munoz, Breda and Bell, Edward F. and Goldberg, Ronald N. and Parikh, Nehal A. and Ambalavanan, Namasivayam and Pedroza, Claudia and Pappas, Athina and Das, Abhik and Chaudhary, Aasma S. and Ehrenkranz, Richard A. and Hensman, Angelita M. and Van Meurs, Krisa P. and Chalak, Lina F. and Hamrick, Shannon E. G. and Sokol, Gregory M. and Walsh, Michele C. and Poindexter, Brenda B. and Faix, Roger G. and Watterberg, Kristi L. and Frantz, Ivan D. and Guillet, Ronnie and Devaskar, Uday and Truog, William E. and Chock, Valerie Y. and Wyckoff, Myra H. and McGowan, Elisabeth C. and Carlton, David P. and Harmon, Heidi M. and Brumbaugh, Jane E. and Cotten, C. Michael and Sánchez, Pablo J. and Hibbs, Anna M. and Higgins, Rosemary D.},
  date = {2017-10},
  journaltitle = {JAMA},
  volume = {318},
  number = {16},
  pages = {1550+},
  issn = {0098-7484},
  doi = {10.1001/jama.2017.14972},
  url = {http://dx.doi.org/10.1001/jama.2017.14972},
  citeulike-article-id = {14468904},
  citeulike-attachment-1 = {lap17eff.pdf; /pdf/user/harrelfe/article/14468904/1121693/lap17eff.pdf; 45c4faa44eaae4bdc24b392bc4934ead9e872b35},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.2017.14972},
  day = {24},
  posted-at = {2017-10-30 16:03:37},
  priority = {0},
  keywords = {bayesian-inference,rct}
}

@article{lar04mul,
  title = {Multivariate Regression Trees for Analysis of Abundance Data},
  author = {Larsen, David R. and Speckman, Paul L.},
  date = {2004},
  journaltitle = {Biometrics},
  volume = {60},
  pages = {543--549},
  citeulike-article-id = {13265418},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {cluster-analysis,multivariate,multivariate-regression,recursive-partitioning-for-covariance-matrices,regression-trees}
}

@article{lar05app,
  title = {Appropriate Assessment of Neighborhood Effects on Individual Health: Integrating Random and Fixed Effects in Multilevel Logistic Regression.},
  author = {Larsen, Klaus and Merlo, Juan},
  date = {2005-01},
  journaltitle = {Am J Epi},
  volume = {161},
  number = {1},
  eprint = {15615918},
  eprinttype = {pmid},
  pages = {81--88},
  issn = {0002-9262},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/15615918},
  abstract = {The logistic regression model is frequently used in epidemiologic studies, yielding odds ratio or relative risk interpretations. Inspired by the theory of linear normal models, the logistic regression model has been extended to allow for correlated responses by introducing random effects. However, the model does not inherit the interpretational features of the normal model. In this paper, the authors argue that the existing measures are unsatisfactory (and some of them are even improper) when quantifying results from multilevel logistic regression analyses. The authors suggest a measure of heterogeneity, the median odds ratio, that quantifies cluster heterogeneity and facilitates a direct comparison between covariate effects and the magnitude of heterogeneity in terms of well-known odds ratios. Quantifying cluster-level covariates in a meaningful way is a challenge in multilevel logistic regression. For this purpose, the authors propose an odds ratio measure, the interval odds ratio, that takes these difficulties into account. The authors demonstrate the two measures by investigating heterogeneity between neighborhoods and effects of neighborhood-level covariates in two examples--public physician visits and ischemic heart disease hospitalizations--using 1999 data on 11,312 men aged 45-85 years in Malmo, Sweden.},
  citeulike-article-id = {13558229},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/15615918},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=15615918},
  day = {1},
  posted-at = {2015-03-22 21:28:08},
  priority = {2},
  keywords = {accuracy,predictive-accuracy},
  note = {Proposes something similar to the g-index (gr)}
}

@article{lar05six,
  title = {Six Online Statistics Courses: {{Examination}} and Review},
  author = {Larreamendy-Joerns, Jorge and Leinhardt, Gaea and Corredor, Javier},
  date = {2005},
  journaltitle = {Am Statistician},
  volume = {59},
  pages = {240--251},
  citeulike-article-id = {13265426},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {distance-learning,evaluation,excellent-review,great-description-of-goals-and-criteria,scholarly-approach,web-based-instruction}
}

@article{lar16pro,
  title = {A Proportional Odds Transition Model for Ordinal Responses with an Application to Pig Behaviour},
  author = {Lara, I. and Hinde, John and Castro, Ariane and Silva, Iran},
  date = {2016-06-02},
  journaltitle = {Journal of Applied Statistics},
  pages = {1--16},
  doi = {10.1080/02664763.2016.1191623},
  abstract = {Categorical data are quite common in many fields of science including in behaviour studies in animal science. In this article, the data concern the degree of lesions in pigs, related to the behaviour of these animals. The experimental design corresponded to two levels of environmental enrichment and four levels of genetic lineages in a completely randomized factorial with data collected longitudinally over four time occasions. The transition models used for the data analysis are based on stochastic processes and Generalized Linear Models. In general, these are not used for analysis of longitudinal data but they are useful in many situations as in this study. We present some aspects of this class of models for the stationary case. The proportional odds transition model is used to construct the matrix of transition probabilities and a function was developed in the R system to fit this model. The likelihood ratio test was used to verify the assumption of odds ratio proportionality and to select the structure of the linear predictor. The methodology used allowed for the choice of a model that can be used to explain the relationship between the severity of lesions in pigs and the use of the environmental enrichment.},
  keywords = {multistate-model,ordinal,serial}
}

@article{lar78pea,
  title = {Small-Sample {{Comparisons}} of {{Exact Levels}} for {{Chi-squared Goodness-of-fit Statistics}}},
  author = {Larntz, Kinley},
  date = {1978},
  journaltitle = {JASA},
  volume = {73},
  pages = {253--263},
  citeulike-article-id = {13264461},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {binomial,categorical-data,freeman-tukey-statistic,likelihood-ratio-test,pearson-chi-squared-test}
}

@article{lar85mix,
  title = {A Mixture Model for the Regression Analysis of Competing Risks Data},
  author = {Larson, Martin G. and Dinse, Gregg E.},
  date = {1985},
  journaltitle = {Appl Stat},
  volume = {34},
  pages = {201--211},
  citeulike-article-id = {13264462},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {competing-risks,logistic-model-extensions}
}

@article{lar97gro,
  title = {Grouped Random Effects Models for {{Bayesian}} Meta-Analysis},
  author = {Larose, Daniel T. and Dey, Dipak K.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1817--1829},
  citeulike-article-id = {13264463},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {bayesian-inference,grouping-random-effects-by-study-type,meta-analysis,random-effects-model}
}

@book{latex,
  title = {{{LᴬT}}{{{\textsubscript{E}}}}{{X}}: {{A Document Preparation System}}},
  author = {Lamport, Leslie},
  date = {1994},
  edition = {Second},
  publisher = {{Addison-Wesley}},
  location = {{Reading, MA}},
  citeulike-article-id = {13264464},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@article{lau95pre,
  title = {Predictive Model Selection},
  author = {Laud, Purushottam W. and Ibrahim, Joseph G.},
  date = {1995},
  journaltitle = {J Roy Stat Soc B},
  volume = {57},
  pages = {247--262},
  citeulike-article-id = {13264465},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {aic,bayes-factor,bayesian-inference,bic,maximum-likelihood,model-selection,transformation-selection,variable-selection}
}

@article{lau96eva,
  title = {Evaluating the Effect of Optimized Cutoff Values in the Assessment of Prognostic Factors},
  author = {Lausen, B. and Schumacher, M.},
  date = {1996},
  journaltitle = {Comp Stat Data Analysis},
  volume = {21},
  number = {3},
  pages = {307--326},
  doi = {10.1016/0167-9473(95)00016-X},
  url = {http://dx.doi.org/10.1016/0167-9473(95)00016-X},
  citeulike-article-id = {13264466},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0167-9473(95)00016-X},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {cutpoints,dichotomizing-continuous-variables,teaching-mds}
}

@article{lau97cli,
  title = {Clinical Prediction Rules: {{A}} Review and Suggested Modifications of Methodological Standards},
  author = {Laupacis, Andreas and Sekar, Nandita and Stiell, Ian G.},
  date = {1997},
  journaltitle = {JAMA},
  volume = {277},
  pages = {488--494},
  doi = {10.1001/jama.277.6.488},
  url = {http://dx.doi.org/10.1001/jama.277.6.488},
  citeulike-article-id = {13264467},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.277.6.488},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {clinical-prediction,multivariable-modeling,teaching-mds},
  note = {ROC curves are not of interest to clinicians;debate about choosing a rule with sensitivity of 1.0;use of probabilities instead of classifications;reporting of statistical results}
}

@article{lav07sta,
  title = {A Statistical Overview on Univariate Calibration, Inverse Regression, and Detection Limits: {{Application}} to Gas Chromatography/Mass Spectrometry Technique},
  author = {Lavagnini, Irma and Magno, Franco},
  date = {2007},
  journaltitle = {Mass Spect Rev},
  volume = {26},
  pages = {1--18},
  citeulike-article-id = {13265818},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {calibration,detection-limit,inverse-regression,quantification-limit,weighted-regression},
  note = {linear and quadratic inverse regression and calibration}
}

@article{lav88imp,
  title = {Improving the Aggregate Performance of Psychiatric Diagnostic Methods When Not All Subjects Receive the Standard Test},
  author = {Lavori, Philip W. and Keller, Martin B.},
  date = {1988},
  journaltitle = {Stat Med},
  volume = {7},
  pages = {727--737},
  citeulike-article-id = {13264468},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {adjustment,diagnosis,horvitz-thompson-estimator,missing-data,multiple-imputation,propensity-score,testing,verification-bias}
}

@article{lav94cau,
  title = {Causal Estimation of Time-Varying Treatment Effects in Observational Studies: {{Application}} to Depressive Disorder},
  author = {Lavori, Philip W. and Dawson, Ree and Mueller, Timothy B.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1089--1100},
  citeulike-article-id = {13264469},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {discrete-survival-model,dynamic-treatment,propensity-score,repeated-logistic-model,tdc}
}

@article{lav95mul,
  title = {A Multiple Imputation Strategy for Clinical Trials with Truncation of Patient Data},
  author = {Lavori, Philip W. and Dawson, Ree and Shera, David},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1913--1925},
  citeulike-article-id = {13264470},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {completers-analysis,dropouts,informative-censoring,last-value-analysis,longitudinal-data,multiple-imputation,propensity-score,study-design}
}

@article{law10est,
  title = {Estimation of Prediction Error for Survival Models},
  author = {Lawless, Jerald F. and Yuan, Yan},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {262--274},
  citeulike-article-id = {13265797},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {absolute-error,brier-score,confidence-intevals,expected-loss,inverse-probability-of-censoring-weights,misspecified-models,survival-time-predictors},
  note = {focus on errors in predicted mean or median, allowing for distribution to be truncated;also has an example of assessing accuracy using the Brier score}
}

@article{law78,
  title = {Efficient Screening of Nonnormal Regression Models},
  author = {Lawless, J. F. and Singhal, K.},
  date = {1978},
  journaltitle = {Biometrics},
  volume = {34},
  pages = {318--327},
  citeulike-article-id = {13264471},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@book{law82,
  title = {Statistical {{Models}} and {{Methods}} for {{Lifetime Data}}},
  author = {Lawless, J. F.},
  date = {1982},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264472},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@article{law95ana,
  title = {The Analysis of Recurrent Events for Multiple Subjects},
  author = {Lawless, J. F.},
  date = {1995},
  journaltitle = {Appl Stat},
  volume = {44},
  pages = {487--498},
  citeulike-article-id = {13264473},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {counting-process,cumulative-mean-function,recurrent-events,repeated-events,robust-methods}
}

@article{law95som,
  title = {Some Simple Robust Methods for the Analysis of Recurrent Events},
  author = {Lawless, J. F. and Nadeau, C.},
  date = {1995},
  journaltitle = {Technometrics},
  volume = {37},
  pages = {158--168},
  citeulike-article-id = {13264474},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {assessing-informative-censoring,cumulative-mean-function,recurrent-events,repeated-events}
}

@article{law96sur,
  title = {Survival Analyses of Randomized Clinical Trials Adjusted for Patients Who Switch Treatments},
  author = {Law, Matthew G. and Kaldor, John M.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2069--2076},
  citeulike-article-id = {13264475},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {crossovers,drop-in,dropouts,non-compliance,tdc}
}

@article{le08fac,
  title = {{{FactoMineR}}: {{An R Package}} for {{Multivariate Analysis}}},
  shorttitle = {{{FactoMineR}}},
  author = {Lê, Sébastien and Josse, Julie and Husson, François},
  date = {2008-03-18},
  journaltitle = {Journal of Statistical Software},
  volume = {25},
  number = {1},
  pages = {1--18},
  issn = {1548-7660},
  doi = {10.18637/jss.v025.i01},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v025i01},
  urldate = {2021-05-19},
  issue = {1},
  langid = {english},
  keywords = {correspondence-analysis,data-reduction,multivariate,pca,unsupervised-learning}
}

@article{leb93sur,
  title = {Survival Trees by Goodness of Fit},
  author = {LeBlanc, Michael and Crowley, John},
  date = {1993},
  journaltitle = {J Am Stat Assoc},
  volume = {88},
  pages = {457--467},
  citeulike-article-id = {13264476},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {bootstrap,cart,survival-analysis}
}

@article{leb94ada,
  title = {Adaptive Principal Surfaces},
  author = {LeBlanc, Michael and Tibshirani, Robert},
  date = {1994},
  journaltitle = {J Am Stat Assoc},
  volume = {89},
  pages = {53--64},
  citeulike-article-id = {13264477},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {data-reduction,mars,multivariate-analysis,principal-components,splines}
}

@article{lec88cor,
  title = {Correspondence Analysis and Logistic Modelling: {{Complementary}} Use in the Analysis of a Health Survey among Nurses},
  author = {Leclerc, A. and Luce, D. and Lert, F. and Chastang, J. F. and Logeay, P.},
  date = {1988},
  journaltitle = {Stat Med},
  volume = {7},
  pages = {983--995},
  citeulike-article-id = {13264478},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {data-reduction,general,multivariate-analysis,predictive-methods,scaling}
}

@article{led87eff,
  title = {Effects of Different Paced Heart Rates on Canine Coronary Occlusion and Reperfusion Arrhythmias},
  author = {Lederman, S. N. and Wenger, T. L. and Harrell, F. E. and Strauss, H. C.},
  date = {1987},
  journaltitle = {Am Heart J},
  volume = {113},
  pages = {1365--1369},
  citeulike-article-id = {13265363},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{lee00cli,
  title = {Clinical Trials and Sample Size Considerations: {{Another}} Perspective},
  author = {Zelen, Marvin and Lee, Sandra J.},
  date = {2000-05},
  journaltitle = {Stat Sci},
  volume = {15},
  number = {2},
  pages = {95--110},
  issn = {0883-4237},
  doi = {10.1214/ss/1009212752},
  url = {http://dx.doi.org/10.1214/ss/1009212752},
  citeulike-article-id = {14225799},
  citeulike-attachment-1 = {lee00cli.pdf; /pdf/user/harrelfe/article/14225799/1094362/lee00cli.pdf; a9751d588730de4dab642dfd81cf0f58d1e20c21},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/ss/1009212752},
  posted-at = {2016-12-10 15:43:50},
  priority = {0},
  keywords = {bayes,bayesian-inference,rct,sample-size},
  note = {uses an unrealistic prior with a point mass at zero effect, discussed in excellent commentaries (e.g., by Rich Simon) which question a few other things}
}

@article{lee00ext,
  title = {Extensions and Applications of Event Charts},
  author = {Lee, Jack J. and Hess, Kenneth R. and Dubin, Joel A.},
  date = {2000},
  journaltitle = {Am Statistician},
  volume = {54},
  pages = {63--70},
  citeulike-article-id = {13265117},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {graphical-methods-for-survival-data}
}

@article{lee04con,
  title = {Conditional and {{Marginal Models}}: {{Another View}}},
  shorttitle = {Conditional and {{Marginal Models}}},
  author = {Lee, Youngjo and Nelder, John A.},
  date = {2004-05},
  journaltitle = {Statistical Science},
  volume = {19},
  number = {2},
  pages = {219--238},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/088342304000000305},
  url = {https://projecteuclid.org/journals/statistical-science/volume-19/issue-2/Conditional-and-Marginal-Models-Another-View/10.1214/088342304000000305.full},
  urldate = {2021-12-03},
  abstract = {There has existed controversy about the use of marginal and conditional models, particularly in the analysis of data from longitudinal studies. We show that alleged differences in the behavior of parameters in so-called marginal and conditional models are based on a failure to compare like with like. In particular, these seemingly apparent differences are meaningless because they are mainly caused by preimposed unidentifiable constraints on the random effects in models. We discuss the advantages of conditional models over marginal models. We regard the conditional model as fundamental, from which marginal predictions can be made.},
  keywords = {conditional-analysis,longitudinal,marginal-model,serial}
}

@article{lee10spa,
  title = {Sparse Logistic Principal Components Analysis for Binary Data},
  author = {Lee, Seokho and Huang, Jianhua Z. and Hu, Jianhua},
  date = {2010},
  journaltitle = {Ann Appl Stat},
  volume = {4},
  number = {3},
  pages = {1579--1601},
  citeulike-article-id = {13265860},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {bootstrap,data-reduction,dimension-reduction,lasso,model-based-pc,pc-for-binary-data,penalized-mle,shrinkage,sparse-pc}
}

@article{lee11bou,
  title = {Bounding the Bias of Unmeasured Factors with Confounding and Effect-Modifying Potentials},
  author = {Lee, Wen-Chung},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  pages = {1007--1017},
  citeulike-article-id = {13265873},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {confounding,sensitivity-analysis,unmeasured-confounders}
}

@article{lee12bay,
  title = {Bayesian Clinical Trials in Action},
  author = {Lee, Jack J. and Chu, Caleb T.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {25},
  pages = {2955--2972},
  doi = {10.1002/sim.5404},
  url = {http://dx.doi.org/10.1002/sim.5404},
  abstract = {Although the frequentist paradigm has been the predominant approach to clinical trial design since the 1940s, it has several notable limitations. Advancements in computational algorithms and computer hardware have greatly enhanced the alternative Bayesian paradigm. Compared with its frequentist counterpart, the Bayesian framework has several unique advantages, and its incorporation into clinical trial design is occurring more frequently. Using an extensive literature review to assess how Bayesian methods are used in clinical trials, we find them most commonly used for dose finding, efficacy monitoring, toxicity monitoring, diagnosis/decision making, and studying pharmacokinetics/pharmacodynamics. The additional infrastructure required for implementing Bayesian methods in clinical trials may include specialized software programs to run the study design, simulation and analysis, and web-based applications, all of which are particularly useful for timely data entry and analysis. Trial success requires not only the development of proper tools but also timely and accurate execution of data entry, quality control, adaptive randomization, and Bayesian computation. The relative merit of the Bayesian and frequentist approaches continues to be the subject of debate in statistics. However, more evidence can be found showing the convergence of the two camps, at least at the practical level. Ultimately, better clinical trial methods lead to more efficient designs, lower sample sizes, more accurate conclusions, and better outcomes for patients enrolled in the trials. Bayesian methods offer attractive alternatives for better trials. More Bayesian trials should be designed and conducted to refine the approach and demonstrate their real benefit in action.},
  citeulike-article-id = {13265978},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5404},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {adaptive-trial-design,bayes,bayesian-paradigm,clinical-trial-conduct,frequentist-paradigm,rct,trial-efficiency,trial-ethics}
}

@article{lee12rec,
  title = {Recovery of Information from Multiple Imputation: A Simulation Study},
  author = {Lee, Katherine J. and Carlin, John B.},
  date = {2012-06},
  journaltitle = {Emerg Themes Epi},
  volume = {9},
  number = {1},
  eprint = {22695083},
  eprinttype = {pmid},
  pages = {3+},
  issn = {1742-7622},
  doi = {10.1186/1742-7622-9-3},
  url = {http://dx.doi.org/10.1186/1742-7622-9-3},
  abstract = {BACKGROUND:Multiple imputation is becoming increasingly popular for handling missing data. However, it is often implemented without adequate consideration of whether it offers any advantage over complete case analysis for the research question of interest, or whether potential gains may be offset by bias from a poorly fitting imputation model, particularly as the amount of missing data increases.METHODS:Simulated datasets (n=1000) drawn from a synthetic population were used to explore information recovery from multiple imputation in estimating the coefficient of a binary exposure variable when various proportions of data (10-90\%) were set missing at random in a highly-skewed continuous covariate or in the binary exposure. Imputation was performed using multivariate normal imputation (MVNI), with a simple or zero-skewness log transformation to manage non-normality. Bias, precision, mean-squared error and coverage for a set of regression parameter estimates were compared between multiple imputation and complete case analyses.RESULTS:For missingness in the continuous covariate, multiple imputation produced less bias and greater precision for the effect of the binary exposure variable, compared with complete case analysis, with larger gains in precision with more missing data. However, even with only moderate missingness, large bias and substantial under-coverage were apparent in estimating the continuous covariate's effect when skewness was not adequately addressed. For missingness in the binary covariate, all estimates had negligible bias but gains in precision from multiple imputation were minimal, particularly for the coefficient of the binary exposure.CONCLUSIONS:Although multiple imputation can be useful if covariates required for confounding adjustment are missing, benefits are likely to be minimal when data are missing in the exposure variable of interest. Furthermore, when there are large amounts of missingness, multiple imputation can become unreliable and introduce bias not present in a complete case analysis if the imputation model is not appropriate. Epidemiologists dealing with missing data should keep in mind the potential limitations as well as the potential benefits of multiple imputation. Further work is needed to provide clearer guidelines on effective application of this method.},
  citeulike-article-id = {10786725},
  citeulike-attachment-1 = {lee12rec.pdf; /pdf/user/harrelfe/article/10786725/1061514/lee12rec.pdf; a5dbfe46b54e30ff6e2f5f7bee6f08cd389470cb},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/1742-7622-9-3},
  citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3544721/},
  citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/22695083},
  citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=22695083},
  day = {13},
  pmcid = {PMC3544721},
  posted-at = {2016-04-01 14:30:42},
  priority = {2},
  keywords = {imputation,missing,missing-data},
  note = {Not sure that the authors satisfactorily dealt with nonlinear predictor effects
\par
in the absence of strong auxiliary information, there is little to gain from multiple imputation with missing data in the exposure-of-interest. In fact, the authors went further to say that multiple imputation can introduce bias not present in a complete case analysis if a poorly fitting imputation model is used [from Yong Hao Pua]}
}

@article{lee15wha,
  title = {What Is the Question?},
  author = {Leek, Jeffery T. and Peng, Roger D.},
  date = {2015-03-20},
  journaltitle = {Science},
  volume = {347},
  number = {6228},
  eprint = {25721505},
  eprinttype = {pmid},
  pages = {1314--1315},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaa6146},
  url = {https://science.sciencemag.org/content/347/6228/1314},
  urldate = {2019-09-27},
  abstract = {Mistaking the type of question being considered is the most common error in data analysis Mistaking the type of question being considered is the most common error in data analysis},
  langid = {english},
  keywords = {design,inference,scientific-approach,study-design,study-interpretation}
}

@article{lee17alt,
  title = {Semiparametric Regression Analysis for Alternating Recurrent Event Data},
  author = {Lee, Chi H. and Huang, Chiung-Yu and Xu, Gongjun and Luo, Xianghua},
  journaltitle = {Stat Med},
  pages = {n/a},
  doi = {10.1002/sim.7563},
  url = {http://dx.doi.org/10.1002/sim.7563},
  abstract = {Alternating recurrent event data arise frequently in clinical and epidemiologic studies, where 2 types of events such as hospital admission and discharge occur alternately over time. The 2 alternating states defined by these recurrent events could each carry important and distinct information about a patient's underlying health condition and/or the quality of care. In this paper, we propose a semiparametric method for evaluating covariate effects on the 2 alternating states jointly. The proposed methodology accounts for the dependence among the alternating states as well as the heterogeneity across patients via a frailty with unspecified distribution. Moreover, the estimation procedure, which is based on smooth estimating equations, not only properly addresses challenges such as induced dependent censoring and intercept sampling bias commonly confronted in serial event gap time data but also is more computationally tractable than the existing rank-based methods. The proposed methods are evaluated by simulation studies and illustrated by analyzing psychiatric contacts from the South Verona Psychiatric Case Register.},
  citeulike-article-id = {14482705},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7563},
  posted-at = {2017-11-24 13:42:23},
  priority = {2},
  keywords = {recurrent-events,survival-analysis}
}

@article{lee19dep,
  title = {Dependence Modeling for Multi-Type Recurrent Events via Copulas},
  author = {Lee, Jooyoung and Cook, Richard J.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {21},
  pages = {4066--4082},
  issn = {1097-0258},
  doi = {10.1002/sim.8283},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8283},
  urldate = {2019-08-10},
  abstract = {When several types of recurrent events may arise, interest often lies in marginal modeling and studying the nature of the dependence structure. In this paper, we propose a multivariate mixed-Poisson model with the dependence between events accommodated by type-specific random effects which are associated through use of a Gaussian copula. Such models retain marginal features with a simple interpretation, reflect the heterogeneity in risk for each type of event, and provide insight into the dependence between the different types of events. Semiparametric inference is proposed based on composite likelihood to avoid high dimensional integration. An application to a study of nutritional supplements in malnourished children is given in which the goal is to evaluate the reduction in the rate of several different kinds of infection.},
  langid = {english},
  keywords = {copula,recurrent-events}
}

@article{lee19joi,
  title = {Joint Modelling of Competing Risks and Current Status Data: An Application to a Spontaneous Labour Study},
  shorttitle = {Joint Modelling of Competing Risks and Current Status Data},
  author = {Lee, Youjin and Wang, Mei-Cheng and Grantz, Katherine L. and Sundaram, Rajeshwari},
  date = {2019},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume = {0},
  number = {0},
  issn = {1467-9876},
  doi = {10.1111/rssc.12351},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12351},
  urldate = {2019-04-11},
  abstract = {The second stage of labour begins when the cervix is fully dilated and pushing begins until the fetus is delivered. A Caesarean delivery (CD) or operative vaginal delivery (OVD) is typically encouraged after the recommended time set by ‘expert consensus’. This recommended time has been set out of concern for an increased chance of maternal and neonatal morbidities due to a prolonged second stage of labour, but without thorough consideration of heterogeneous risks for spontaneous vaginal delivery (SVD) and morbidities among women. To provide quantitative evidence for the recommendation, the first step is to compare the risks for SVD, CD or OVD, and the risks of maternal or neonatal morbidities simultaneously across the duration of the second stage of labour. To address such risk comparisons statistically, one needs to study the joint distribution for the time to delivery due to each mode and time to maternal or neonatal morbidity given information provided for each individual. We introduce a joint model which combines the competing risks data for delivery time and current status data for any type of maternal or neonatal morbidity given each woman's baseline characteristics. These two processes are assumed dependent through individual-specific frailty under the joint model. Our numerical studies include a simulation that reflects the structure of observed real data and a detailed real data analysis based on nearly 12000 spontaneous labours. Our finding indicates the necessity to incorporate maternal characteristic such as age or body mass index in assessing the probability for delivery due to SVD, CD or OVD and the onset of morbidities across the second stage of labour.},
  langid = {english},
  keywords = {competing-risk,current-status-data,survival}
}

@article{lee19med,
  title = {Mediation {{Analysis}}},
  author = {Lee, Hopin and Herbert, Robert D. and McAuley, James H.},
  date = {2019-02-19},
  journaltitle = {JAMA},
  volume = {321},
  number = {7},
  pages = {697--698},
  issn = {0098-7484},
  doi = {10.1001/jama.2018.21973},
  url = {https://jamanetwork.com/journals/jama/fullarticle/2723293},
  urldate = {2019-02-23},
  abstract = {This JAMA Guide to Statistics and Methods reviews the use of mediation analysis to evaluate possible mechanisms that the effects of interventions are presumed to work through.},
  langid = {english},
  keywords = {mediation-effect}
}

@article{lee83,
  title = {A Comparison of Test Statistics for Assessing the Effects of Concomitant Variables in Survival Analysis},
  author = {Lee, K. L. and Harrell, F. E. and Tolley, H. D. and Rosati, R. A.},
  date = {1983},
  journaltitle = {Biometrics},
  volume = {39},
  pages = {341--350},
  citeulike-article-id = {13264479},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@incollection{lee83sec,
  title = {Secondary Prevention Trials in Post-Myocardial Infarction Patients: {{Methodologic}} Issues},
  booktitle = {The {{First Year}} after a {{Myocardial Infarction}}},
  author = {Lee, K. L. and Harrell, F. E. and Califf, R. M. and Pryor, D. B. and Hlatky, M. A. and Rosati, R. A.},
  editor = {Kulbertus, H. E. and Wellens, H. J. J.},
  date = {1983},
  publisher = {{Futura Publishing Co.}},
  location = {{Mount Kisco NY}},
  citeulike-article-id = {13264480},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@article{lee86,
  title = {Predicting Outcome in Coronary Disease: {{Statistical}} Models versus Expert Clinicians},
  author = {Lee, K. L. and Pryor, D. B. and Harrell, F. E. and Califf, R. M. and Behar, V. S. and Floyd, W. L. and Morris, J. J. and Waugh, R. A. and Whalen, R. E. and Rosati, R. A.},
  date = {1986},
  journaltitle = {Am J Med},
  volume = {80},
  pages = {553--560},
  citeulike-article-id = {13264481},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@article{lee88,
  title = {Assessing Partial Influence in Generalized Linear Models},
  author = {Ah, Lee},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  citeulike-article-id = {13264482},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,graphical-methods,logistic-model}
}

@article{lee90pro,
  title = {Prognostic Value of Radionuclide Angiography in Medically Treated Patients with Coronary Artery Disease: {{A}} Comparison with Clinical and Catheterization Variables},
  author = {Lee, K. L. and Pryor, D. B. and Pieper, K. S. and Harrell, F. E. and Califf, R. M. and Mark, D. B. and Hlatky, M. A. and Coleman, R. E. and Cobb, F. R. and Jones, R. H.},
  date = {1990},
  journaltitle = {Circ},
  volume = {82},
  pages = {1705--1717},
  citeulike-article-id = {13264483},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@book{lee92,
  title = {Statistical {{Methods}} for {{Survival Data Analysis}}},
  author = {Lee, E. T.},
  date = {1980},
  edition = {Second},
  publisher = {{Lifetime Learning Publications}},
  location = {{Belmont, CA}},
  citeulike-article-id = {13264484},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@incollection{lee92cox,
  title = {Cox-Type Regression Analysis for Large Numbers of Small Groups of Correlated Failure Time Observations},
  booktitle = {Survival {{Analysis}}: {{State}} of the {{Art}}},
  author = {Lee, Eric W. and Wei, L. J. and Amato, David A.},
  editor = {Klein, John P. and Goel, Prem K.},
  date = {1992},
  series = {{{NATO ASI}}},
  pages = {237--247},
  publisher = {{Kluwer Academic}},
  location = {{Boston}},
  citeulike-article-id = {13264485},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {cluster-sampling,correlated-observations,cox-model,dependent-observations}
}

@article{lee92seq,
  title = {Sequential Rank Tests with Repeated Measurements in Clinical Trials},
  author = {Lee, J. W. and DeMets, D. L.},
  date = {1992},
  journaltitle = {J Am Stat Assoc},
  volume = {87},
  pages = {136--142},
  citeulike-article-id = {13264486},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {nonparametrics,sequential-tests}
}

@article{lee94hol,
  title = {Holding {{GUSTO}} up to the Light},
  author = {Lee, Kerry L. and Califf, Robert M. and Simes, John and Van de Werf, Frans and Topol, Eric J. and {the GUSTO Investigators}},
  date = {1994},
  journaltitle = {Ann Int Med},
  volume = {120},
  pages = {876--881},
  citeulike-article-id = {13264487},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {blinding-poolability,gusto,interpretation-of-rcts,mega-trials,subgroup-analysis,t-pa}
}

@article{lee96two,
  title = {Two Sample Comparison for Large Groups of Correlated Binary Responses},
  author = {Lee, Eric W.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1187--1197},
  citeulike-article-id = {13264488},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {cluster-randomization,large-clusters}
}

@article{lee98ass,
  title = {Assessment of Covariate Effects in {{Aalen}}'s Additive Hazard Model},
  author = {Lee, Eunyoung and Weissfeld, Lisa A.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {983--998},
  citeulike-article-id = {13264489},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {additive-hazard-model}
}

@article{lee98dis,
  title = {A Discordancy Test Approach to Identify Outliers of Length of Hospital Stay},
  author = {Lee, Andy H. and Xiao, Jiangui and Vemuri, Siva R. and Zhao, Yuejen},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {2199--2206},
  citeulike-article-id = {13264490},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {length-of-stay,outlier,trimming}
}

@article{lef93glo,
  title = {Global Tests for Multiple Binary Outcomes},
  author = {Lefkopoulou, Myrto and Ryan, Louise},
  date = {1993},
  journaltitle = {Biometrics},
  volume = {49},
  pages = {975--988},
  doi = {10.2307/2532240},
  url = {http://dx.doi.org/10.2307/2532240},
  citeulike-article-id = {13264491},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2532240},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {clinical-trials,multiple-endpoints,rct}
}

@article{leg95eff,
  title = {Efficiency and Power of Tests for Multiple Binary Outcomes},
  author = {Legler, Julie M. and Lefkopoulou, Myrto and Ryan, Louise M.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {680--693},
  citeulike-article-id = {13264492},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {multiple-endpoints,multiple-outcomes,study-design}
}

@article{leg97lat,
  title = {Latent Variable Models for Teratogenesis Using Multiple Binary Outcomes},
  author = {Legler, Julie M. and Ryan, Louise M.},
  date = {1997},
  journaltitle = {J Am Stat Assoc},
  volume = {92},
  pages = {13--20},
  citeulike-article-id = {13264493},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {binary-endpoints,item-response-theory,latent-variables,multiple-endpoints,random-effects}
}

@article{leh07par,
  title = {Parsimonious Analysis of Time-Dependent Effects in the {{Cox}} Model},
  author = {Lehr, Stephan and Schemper, Michael},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {2686--2698},
  citeulike-article-id = {13265596},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {overfitting,parsimony,tdc,various-approaches},
  note = {using 4 d.f. for fractional polynomial selection}
}

@article{leh90,
  title = {Model Specification: {{The}} Views of {{Fisher}} and {{Neyman}} and Later Developments},
  author = {Lehmann, E. L.},
  date = {1990},
  journaltitle = {Stat Sci},
  volume = {5},
  pages = {160--168},
  citeulike-article-id = {13264494},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {general,miscellaneous,predictive-methods}
}

@article{leh94com,
  title = {Comment on: {{On}} the Design and Analysis of Randomized Clinical Trials with Multiple Endpoints},
  author = {Lehmacher, Walter and Wassmer, Gernot and Reitmeir, Peter},
  date = {1994},
  journaltitle = {Biometrics},
  volume = {50},
  pages = {581--583},
  citeulike-article-id = {13264495},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {multiple-endpoints,obrien-multiple-endpoint-test,study-design}
}

@article{leh95mod,
  title = {Modernizing Statistics {{Ph}}.{{D}}. Programs},
  author = {Lehoczky, John},
  date = {1995},
  journaltitle = {Am Statistician},
  volume = {49},
  pages = {12--17},
  citeulike-article-id = {13264496},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {teaching-statisticians}
}

@article{leh96imp,
  title = {Implementing the {{Bayesian}} Paradigm: Reporting Research Results over the {{World-Wide Web}}.},
  author = {Lehmann, H. P. and Wachter, M. R.},
  date = {1996},
  journaltitle = {Proceedings : a conference of the American Medical Informatics Association / ... AMIA Annual Fall Symposium. AMIA Fall Symposium},
  eprint = {8947703},
  eprinttype = {pmid},
  pages = {433--437},
  issn = {1091-8280},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2232964/},
  abstract = {For decades, statisticians, philosophers, medical investigators and others interested in data analysis have argued that the Bayesian paradigm is the proper approach for reporting the results of scientific analyses for use by clients and readers. To date, the methods have been too complicated for non-statisticians to use. In this paper we argue that the World-Wide Web provides the perfect environment to put the Bayesian paradigm into practice: the likelihood function of the data is parsimoniously represented on the server side, the reader uses the client to represent her prior belief, and a downloaded program (a Java applet) performs the combination. In our approach, a different applet can be used for each likelihood function, prior belief can be assessed graphically, and calculation results can be reported in a variety of ways. We present a prototype implementation, BayesApplet, for two-arm clinical trials with normally-distributed outcomes, a prominent model for clinical trials. The primary implication of this work is that publishing medical research results on the Web can take a form beyond or different from that currently used on paper, and can have a profound impact on the publication and use of research results.},
  citeulike-article-id = {13346740},
  citeulike-attachment-1 = {leh96imp.pdf; /pdf/user/harrelfe/article/13346740/983544/leh96imp.pdf; b5a59f8e18230cb4ddc17759b426db8f88cb2e69},
  citeulike-linkout-0 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2232964/},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/8947703},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=8947703},
  pmcid = {PMC2232964},
  posted-at = {2014-09-04 12:57:17},
  priority = {0},
  keywords = {bayes,rct,teaching-mds}
}

@article{leh97bay,
  title = {Bayesian Communication of Research Results over the {{World Wide Web}}},
  author = {Lehmann, Harold P. and Nguyen, Bach},
  date = {1997},
  journaltitle = {M.D. Computing},
  volume = {14},
  number = {5},
  eprint = {9308343},
  eprinttype = {pubmed},
  pages = {353--359},
  citeulike-article-id = {13264497},
  citeulike-linkout-0 = {http://www.ncbi.nlm.nih.gov/pubmed/9308343},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {bayesian-methods,varying-prior-using-www,web-based-teaching}
}

@article{lei97mar,
  title = {A Marginal Regression Modelling Framework for Evaluating Medical Diagnostic Tests},
  author = {Leisenring, Wendy and Pepe, Margaret S. and Longton, Gary},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1263--1281},
  citeulike-article-id = {13264498},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {diagnosis,score-test-derivation-of-mcnemars-test}
}

@article{lei98reg,
  title = {Regression Modelling of Diagnostic Likelihood Ratios for the Evaluation of Medical Diagnostic Tests},
  author = {Leisenring, Wendy and Pepe, Margaret S.},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {444--452},
  citeulike-article-id = {13264499},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {audiology,bayes-factor,clustered-data,diagnosis-and-testing,gee,likelihood-ratios,predictive-value,sensitivity,specificity}
}

@article{lem88,
  title = {Predicting the Outcome of Intensive Care Unit Patients},
  author = {Lemeshow, S. and Teres, D. and Avrunin, J. S. and Pastides, H.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {348--356},
  citeulike-article-id = {13264500},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {predictive-accuracy,prognosis}
}

@article{len01som,
  title = {Some Practical Guidelines for Effective Sample Size Determination},
  author = {Lenth, Russell V.},
  date = {2001},
  journaltitle = {Am Statistician},
  volume = {55},
  pages = {187--193},
  doi = {10.1198/000313001317098149},
  url = {http://dx.doi.org/10.1198/000313001317098149},
  citeulike-article-id = {13265218},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/000313001317098149},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {guidelines,sample-size,teaching-mds},
  note = {problems with Cohen's method}
}

@article{len09gen,
  title = {On General Adaptive Sparse Principal Component Analysis},
  author = {Leng, Chenlei and Wang, Hansheng},
  date = {2009},
  journaltitle = {J Comp Graph Stat},
  volume = {18},
  number = {1},
  pages = {201--215},
  citeulike-article-id = {13265737},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {adaptive-lasso,bic,data-reduction,generalized-adaptive-sparse-principal-component-analysis-gas-pca,lars,sparse-principal-components}
}

@article{len13hea,
  title = {Heart Transplant Survival Outcomes for Adriamycin-Dilated Cardiomyopathy},
  author = {Lenneman, A. J. and Wang, L. and Wigger, M. and Frangoul, H. and Harrell, F. E. and Silverstein, C. and Sawyer, D. B. and Lenneman, C. G.},
  date = {2013-02},
  journaltitle = {Am J Card},
  volume = {111},
  number = {4},
  pages = {609--612},
  doi = {10.1016/j.amjcard.2012.10.048},
  url = {http://dx.doi.org/10.1016/j.amjcard.2012.10.048},
  citeulike-article-id = {13265961},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.amjcard.2012.10.048},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{leo04fun,
  title = {Functional Form Diagnostics for {{Cox}}'s Proportional Hazards Model},
  author = {León, Larry F. and Tsai, Chih-Ling},
  date = {2004},
  journaltitle = {Biometrics},
  volume = {60},
  pages = {75--84},
  citeulike-article-id = {13265365},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {and-fleming-for-use-of-scatterplot-smooth-of-martingale-residuals,bootstrap,box-tidwell-transformation,cox-model,criticize-therneau,functional-form,goodness-of-fit,grambsch,kolmogorov-smirnov,residual-plot,survival-analysis,truncated-mean-survival,without-explanation}
}

@article{leo05mix,
  title = {A Mixed-Effects Quintile-Stratified Propensity Adjustment for Effectiveness Analyses of Ordered Categorical Doses},
  author = {Leon, Andrew C. and Hedeker, Donald},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {647--658},
  citeulike-article-id = {13265408},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {causal-inference,mixed-effects-model,observational-study,propensity-analysis,propensity-for-treatment-intensity,propensity-score,treatment-effectiveness}
}

@article{les95bio,
  title = {The Biostatistician in Medical Research: {{Allocating}} Time and Effort},
  author = {Lesser, Martin L. and Parker, Robert A.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1683--1692},
  citeulike-article-id = {13264501},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {consulting,management,time}
}

@article{les96eff,
  title = {Effect of Dropouts in a Longitudinal Study: {{An}} Application of a Repeated Ordinal Model},
  author = {Lesaffre, Emmanuel and Molenberghs, Geert and Dewulf, Lode},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1123--1141},
  citeulike-article-id = {13264502},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {dropouts,longitudinal,ordinal-response,repeated-measures}
}

@article{les96gui,
  title = {Guidelines for Budgeting Biostatistics Involvement in Research Projects},
  author = {Lesser, Martin L.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2127--2133},
  citeulike-article-id = {13264503},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {biostatistics-budgeting,consulting}
}

@article{lev10rel,
  title = {Relative Risk and Odds Ratio Data Are Still Portrayed with Inappropriate Scales in the Medical Literature},
  author = {Levine, Mitchell A. H. and El-Nahas, Ahmad I. and Asa, Benjamin},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {1045--1047},
  citeulike-article-id = {13265842},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {hazard-ratio,logarithmic-scale,odds-ratio,relative-risk,statistical-graphics}
}

@article{lev98ant,
  title = {Antilymphocyte Antibodies, Renal Transplantation, and Meta-Analysis},
  author = {Levey, Andrew S. and Schmid, Christopher H. and Lau, Joseph},
  date = {1998},
  journaltitle = {Ann Int Med},
  volume = {128},
  pages = {863--865},
  doi = {10.7326/0003-4819-128-10-199805150-00011},
  url = {http://dx.doi.org/10.7326/0003-4819-128-10-199805150-00011},
  citeulike-article-id = {13264504},
  citeulike-linkout-0 = {http://dx.doi.org/10.7326/0003-4819-128-10-199805150-00011},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {interaction,meta-analysis,non-ph,publication-bias,subgroup-analysis,teaching-mds},
  note = {nice example of benefits of individual vs. aggregate data due to having individual event times and being able to study waning treatment effects;subgroup analysis vs. interaction test}
}

@article{lew95sta,
  title = {Statistical Issues in the Regulation of Medicines},
  author = {Lewis, John A.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {127--136},
  citeulike-article-id = {13264505},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {pharmaceutical,statistical-sop}
}

@article{li03dia,
  title = {A Diamond-Shaped Equiponderant Graphical Display of the Effects of Two Categorical Predictors on Continuous Outcomes},
  author = {Li, Xiuhong and Buechner, Jennifer M. and Tarwater, Patrick M. and Muñoz, Alvaro},
  date = {2003},
  journaltitle = {Am Statistician},
  volume = {57},
  pages = {193--199},
  citeulike-article-id = {13265348},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {diamond-plot,graphics,three-dimensional-bar-graphs,two-dimensional-projections},
  note = {trellis multi-panel displays are dependent on ordering of stratification variables;S language;problems with block charts (3D bar graphs); incredibly, the authors have elected to file a patent application for diamond graphs}
}

@article{li04qt,
  title = {{{QT}} Analysis: A Complex Answer to a `simple' Problem},
  author = {Li, Lang and Desai, Mehul and Desta, Zeruesenay and Flockhart, David},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  pages = {2625--2643},
  citeulike-article-id = {13265384},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {clinical-safety,linear-mixed-model,pharmaceutical,qt,restricted-maximum-likelihood-estimate,subject-specific-qt-correction}
}

@article{li07est,
  title = {Estimation of the Mediation Effect with a Binary Mediator},
  author = {Li, Yan and Schneider, Julie A. and Bennett, David A.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3398--3414},
  citeulike-article-id = {13265610},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {direct-effect,logist-model,mediation-effect,probit}
}

@article{li08smo,
  title = {Smooth Bootstrap Methods for Analysis of Longitudinal Data},
  author = {Li, Yue and Wang, You-Gan},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {937--953},
  citeulike-article-id = {13265660},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {cluster-bootstrap,estimating-functions,graphics,longitudinal-data,repeated-measures,resampling,sandwich-estimator,serial-data,smooth-bootstrap}
}

@article{li12new,
  title = {A New Residual for Ordinal Outcomes},
  author = {Li, Chun and Shepherd, Bryan E.},
  date = {2012},
  journaltitle = {Biometrika},
  volume = {99},
  number = {2},
  eprint = {http://biomet.oxfordjournals.org/content/99/2/473.full.pdf+html},
  pages = {473--480},
  doi = {10.1093/biomet/asr073},
  url = {http://biomet.oxfordjournals.org/content/99/2/473.abstract},
  abstract = {We propose a new residual for regression models of ordinal outcomes, defined as Esign(y,Y), where y is the observed outcome and Y is a random variable from the fitted distribution. This new residual is a single value per subject irrespective of the number of categories of the ordinal outcome, contains directional information between the observed value and the fitted distribution, and does not require the assignment of arbitrary numbers to categories. We study its properties, describe its connections with other residuals, ranks and ridits, and demonstrate its use in model diagnostics.},
  citeulike-article-id = {13265929},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/asr073},
  citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/99/2/473.abstract},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {model-diagnostics,ordinal-output,ordinal-regression,ordinal-response,residuals}
}

@article{li18pre,
  title = {Prediction {{Accuracy Measures}} for a {{Nonlinear Model}} and for {{Right-Censored Time-to-Event Data}}},
  author = {Li, Gang and Wang, Xiaoyan},
  date = {2018-09-13},
  journaltitle = {Journal of the American Statistical Association},
  volume = {0},
  number = {0},
  pages = {1--17},
  issn = {0162-1459},
  doi = {10.1080/01621459.2018.1515079},
  url = {https://doi.org/10.1080/01621459.2018.1515079},
  urldate = {2019-03-16},
  abstract = {This article develops a pair of new prediction summary measures for a nonlinear prediction function with right-censored time-to-event data. The first measure, defined as the proportion of explained variance by a linearly corrected prediction function, quantifies the potential predictive power of the nonlinear prediction function. The second measure, defined as the proportion of explained prediction error by its corrected prediction function, gauges the closeness of the prediction function to its corrected version and serves as a supplementary measure to indicate (by a value less than 1) whether the correction is needed to fulfill its potential predictive power and quantify how much prediction error reduction can be realized with the correction. The two measures together provide a complete summary of the predictive accuracy of the nonlinear prediction function. We motivate these measures by first establishing a variance decomposition and a prediction error decomposition at the population level and then deriving uncensored and censored sample versions of these decompositions. We note that for the least square prediction function under the linear model with no censoring, the first measure reduces to the classical coefficient of determination and the second measure degenerates to 1. We show that the sample measures are consistent estimators of their population counterparts and conduct extensive simulations to investigate their finite sample properties. A real data illustration is provided using the PBC data. Supplementary materials for this article are available online. An R package PAmeasures has been developed and made available via the CRAN R library. Supplementary materials for this article are available online.},
  keywords = {calibration,calibration-accuracy,censored-data,explained-variation,predictive-accuracy,survival}
}

@article{li18sam,
  title = {Sample Size Determination for {{GEE}} Analyses of Stepped Wedge Cluster Randomized Trials},
  author = {Li, Fan and Turner, Elizabeth L. and Preisser, John S.},
  date = {2018-06},
  journaltitle = {Biometrics},
  issn = {0006341X},
  doi = {10.1111/biom.12918},
  url = {http://dx.doi.org/10.1111/biom.12918},
  abstract = {In stepped wedge cluster randomized trials, intact clusters of individuals switch from control to intervention from a randomly assigned period onwards. Such trials are becoming increasingly popular in health services research. When a closed cohort is recruited from each cluster for longitudinal follow‐up, proper sample size calculation should account for three distinct types of intraclass correlations: the within‐period, the inter‐period, and the within‐individual correlations. Setting the latter two correlation parameters to be equal accommodates cross‐sectional designs. We propose sample size procedures for continuous and binary responses within the framework of generalized estimating equations that employ a block exchangeable within‐cluster correlation structure defined from the distinct correlation types. For continuous responses, we show that the intraclass correlations affect power only through two eigenvalues of the correlation matrix. We demonstrate that analytical power agrees well with simulated power for as few as eight clusters, when data are analyzed using bias‐corrected estimating equations for the correlation parameters concurrently with a bias‐corrected sandwich variance estimator.},
  citeulike-article-id = {14606018},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/biom.12918},
  day = {19},
  posted-at = {2018-06-21 12:20:04},
  priority = {2},
  keywords = {cluster-randomization,cluster-randomized-trial,gee,sample-size,stepped-wedge}
}

@article{li19bay,
  title = {A {{Bayesian}} Approach for Individual-Level Drug Benefit-Risk Assessment},
  author = {Li, Kan and Luo, Sheng and Yuan, Sammy and Mt‐Isa, Shahrul},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8166},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8166},
  urldate = {2019-04-16},
  abstract = {In existing benefit-risk assessment (BRA) methods, benefit and risk criteria are usually identified and defined separately based on aggregated clinical data and therefore ignore the individual-level differences as well as the association among the criteria. We proposed a Bayesian multicriteria decision-making method for BRA of drugs using individual-level data. We used a multidimensional latent trait model to account for the heterogeneity of treatment effects with latent variables introducing the dependencies among outcomes. We then applied the stochastic multicriteria acceptability analysis approach for BRA incorporating imprecise and heterogeneous patient preference information. We adopted an efficient Markov chain Monte Carlo algorithm when implementing the proposed method. We applied our method to a case study to illustrate how individual-level benefit-risk profiles could inform decision-making.},
  langid = {english},
  keywords = {bayes,decision-theory,drug-development,latent-variable,multicriteria-decision,multiple-endpoints,rct,risk-benefit-ratio}
}

@article{li19tim,
  title = {A Time-Varying {{Bayesian}} Joint Hierarchical Copula Model for Analysing Recurrent Events and a Terminal Event: An Application to the {{Cardiovascular Health Study}}},
  shorttitle = {A Time-Varying {{Bayesian}} Joint Hierarchical Copula Model for Analysing Recurrent Events and a Terminal Event},
  author = {Li, Zheng and Chinchilli, Vernon M. and Wang, Ming},
  date = {2019},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume = {0},
  number = {0},
  issn = {1467-9876},
  doi = {10.1111/rssc.12382},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12382},
  urldate = {2019-10-10},
  abstract = {Recurrent events could be stopped by a terminal event, which commonly occurs in biomedical and clinical studies. Taking the Cardiovascular Health Study as a motivating example, patients can experience recurrent events of myocardial infarction (MI) or stroke during follow-up, which, however, can be truncated by death. Since death could be a devastating complication of MI or stroke recurrences, ignoring dependent censoring when analysing recurrent events may lead to invalid inference. The joint shared frailty model is widely used but with several limitations: two event processes are conditionally independent given the subject level frailty, which could be violated because the dependence may rely on unknown covariates varying across recurrences; the correlation between recurrent events and death is constant over time because of the same frailty within subject, but MI or stroke recurrences could have a time-varying influence on death due to higher risk of another event of MI or stroke after the first. We propose a time-varying joint hierarchical copula model under the Bayesian framework to accommodate correlation between recurrent events and dependence between two event processes which may change over time. The performance of our method is extensively evaluated by simulation studies, and lastly by the Cardiovascular Health Study for illustration.},
  langid = {english},
  keywords = {competing-risk,copula,multiple-endpoints,recurrent-events}
}

@article{li20pow,
  title = {Power Analysis for Cluster Randomized Trials with Multiple Binary Co-Primary Endpoints},
  author = {Li, Dateng and Cao, Jing and Zhang, Song},
  date = {2020},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13212},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13212},
  urldate = {2019-12-24},
  abstract = {Cluster randomized trials (CRTs) are widely used in different areas of medicine and public health. Recently, with increasing complexity of medical therapies and technological advances in monitoring multiple outcomes, many clinical trials attempt to evaluate multiple co-primary endpoints. In this study we present a power analysis method for CRTs with K ≥ 2 binary co-primary endpoints. It is developed based on the GEE (generalized estimating equation) approach, and three types of correlations are considered: inter-subject correlation within each endpoint, intra-subject correlation across endpoints, and inter-subject correlation across endpoints. A closed-form joint distribution of the K test statistics is derived, which facilitates the evaluation of power and type I error for arbitrarily constructed hypotheses. We further present a theorem that characterizes the relationship between various correlations and testing power. We assess the performance of the proposed power analysis method based on extensive simulation studies. An application example to a real clinical trial is presented. This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {cluster-randomization,cluster-randomized-trial,power,rct,sample-size}
}

@article{li21eva,
  title = {Evaluation of Predictive Model Performance of an Existing Model in the Presence of Missing Data},
  author = {Li, Pin and Taylor, Jeremy M. G. and Spratt, Daniel E. and Karnes, R. Jeffery and Schipper, Matthew J.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8978},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8978},
  urldate = {2021-04-12},
  abstract = {In medical research, the Brier score (BS) and the area under the receiver operating characteristic (ROC) curves (AUC) are two common metrics used to evaluate prediction models of a binary outcome, such as using biomarkers to predict the risk of developing a disease in the future. The assessment of an existing prediction models using data with missing covariate values is challenging. In this article, we propose inverse probability weighted (IPW) and augmented inverse probability weighted (AIPW) estimates of AUC and BS to handle the missing data. An alternative approach uses multiple imputation (MI), which requires a model for the distribution of the missing variable. We evaluated the performance of IPW and AIPW in comparison with MI in simulation studies under missing completely at random, missing at random, and missing not at random scenarios. When there are missing observations in the data, MI and IPW can be used to obtain unbiased estimates of BS and AUC if the imputation model for the missing variable or the model for the missingness is correctly specified. MI is more efficient than IPW. Our simulation results suggest that AIPW can be more efficient than IPW, and also achieves double robustness from miss-specification of either the missingness model or the imputation model. The outcome variable should be included in the model for the missing variable under all scenarios, while it only needs to be included in missingness model if the missingness depends on the outcome. We illustrate these methods using an example from prostate cancer.},
  langid = {english},
  keywords = {accuracy,brier-score,clinical-prediction,mi,missing,prediction},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8978}
}

@article{li91,
  title = {Sliced Inverse Regression for Dimension Reduction},
  author = {Li, K. C.},
  date = {1991},
  journaltitle = {J Am Stat Assoc},
  volume = {86},
  pages = {316--327},
  citeulike-article-id = {13264506},
  posted-at = {2014-07-14 14:09:36},
  priority = {0}
}

@article{li91cho,
  title = {On the Choice of Times for Data Analysis in Group Sequential Clinical Trials},
  author = {Li, Z. and Geller, N. L.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {745--750},
  doi = {10.2307/2532161},
  url = {http://dx.doi.org/10.2307/2532161},
  citeulike-article-id = {13264507},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2532161},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {clinical-trials,rct,sequential-methods}
}

@article{li91lar,
  title = {Large-{{Sample Significance Levels}} from {{Multiply Imputed Data Using Moment-Based Statistics}} and an {{F Reference Distribution}}},
  author = {Li, K. H. and Raghunathan, T. E. and Rubin, D. B.},
  date = {1991-12},
  journaltitle = {JASA},
  volume = {86},
  number = {416},
  pages = {1065--1073},
  publisher = {Taylor & Francis},
  doi = {10.1080/01621459.1991.10475152},
  url = {http://dx.doi.org/10.1080/01621459.1991.10475152},
  abstract = {Abstract We present a procedure for computing significance levels from data sets whose missing values have been multiply imputed data. This procedure uses moment-based statistics, m ≤ 3 repeated imputations, and an F reference distribution. When m = ∞, we show first that our procedure is essentially the same as the ideal procedure in cases of practical importance and, second, that its deviations from the ideal are basically a function of the coefficient of variation of the canonical ratios of complete to observed information. For small m our procedure's performance is largely governed by this coefficient of variation and the mean of these ratios. Using simulation techniques with small m, we compare our procedure's actual and nominal large-sample significance levels and conclude that it is essentially calibrated and thus represents a definite improvement over previously available procedures. Furthermore, we compare the large-sample power of the procedure as a function of m and other factors, such as the dimensionality of the estimand and fraction of missing information, to provide guidance on the choice of the number of imputations; generally, we find the loss of power due to small m to be quite modest in cases likely to occur in practice.},
  citeulike-article-id = {14363947},
  citeulike-attachment-1 = {li91lar.pdf; /pdf/user/harrelfe/article/14363947/1110550/li91lar.pdf; 570c83cc1324c89a61cb8e280354e500cf9bf2d8},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1991.10475152},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1991.10475152},
  day = {1},
  posted-at = {2017-05-28 14:18:43},
  priority = {4},
  keywords = {missing-data,multiple-imputation}
}

@article{li98cal,
  title = {The Calculation of a Confidence Interval on the Absolute Estimated Benefit for an Individual Patient},
  author = {Li, Wei and Girard, Pascal and Boissel, Jean-Pierre and Gueyffier, Franc},
  date = {1998},
  journaltitle = {Comp Biomed Res},
  volume = {31},
  pages = {244--256},
  citeulike-article-id = {13264508},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {absolute-benefit,clinical-benefit,relative-benefit,survival-model}
}

@article{li99app,
  title = {An Application of Lifetime Models in Estimation of Expected Length of Stay of Patients in Hospital with Complexity and Age Adjustment},
  author = {Li, Jianli},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {3337--3344},
  citeulike-article-id = {13264509},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {estimation-of-mean-los-by-area-under-the-survival,los,survival-analysis-for-length-of-stay}
}

@article{li99dim,
  title = {Dimension Reduction for Censored Regression Data},
  author = {Li, Ker-Chau and Wang, Jane-Ling and Chen, Chun-Houh},
  date = {1999},
  journaltitle = {Ann Stat},
  volume = {27},
  pages = {1--23},
  citeulike-article-id = {13264510},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {data-reduction,dimensionality-reduction}
}

@article{lia00lon,
  title = {Longitudinal Data Analysis of Continuous and Discrete Responses for Pre-Post Designs},
  author = {Liang, Kung-Yee and Zeger, Scott L.},
  date = {2000},
  journaltitle = {Sankhyā},
  volume = {62},
  pages = {134--148},
  citeulike-article-id = {13265666},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {ancova,change,change-score,clinical-trials,longitudinal-data,pre-post-design,random-effects-model,rct,repeated-measures,serial-data},
  note = {makes an error in assuming the baseline variable will have the same univariate distribution as the response except for a shift;baseline may have for example a truncated distribution based on a trial's inclusion criteria;if correlation between baseline and response is zero, ANCOVA will be twice as efficient as simple analysis of change scores;if correlation is one they may be equally efficient}
}

@article{lia03adj,
  title = {Adjusted Coefficients of Determination for Logistic Regression},
  author = {Liao, J. G. and McGee, Dan},
  date = {2003},
  journaltitle = {Am Statistician},
  volume = {57},
  pages = {161--165},
  citeulike-article-id = {13265346},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {association,bias-correction,binary-response,overfitting,predictive-accuracy,r2},
  note = {motivation for adjusted R-squared;uses simulation to adjust for bias due to overfitting}
}

@article{lia87,
  title = {Extended {{Mantel-Haenszel}} Estimating Procedure for Multivariate Logistic Regression Models},
  author = {Liang, K. Y.},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {289--299},
  citeulike-article-id = {13264511},
  posted-at = {2014-07-14 14:09:36},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{lia89cla,
  title = {A Class of Logistic Regression Models for Multivariate Binary Time Series},
  author = {Liang, K. Y. and Zeger, S. L.},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {447--451},
  citeulike-article-id = {13264512},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{lia89use,
  title = {One the Use of Concordant Pairs in Matched Case-Control Studies},
  author = {Liang, K. Y. and Zeger, S. L.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {1145--1156},
  citeulike-article-id = {13264513},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {case-control-studies,logistic-model-extensions,matching}
}

@article{lia90,
  title = {The {{Cox}} Proportional Hazards Model with Change Point: {{An}} Epidemiologic Application},
  author = {Liang, K. Y. and Self, S. G. and Liu, X.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {783--793},
  citeulike-article-id = {13264514},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model,testing-proportional-hazards}
}

@article{lid18ana,
  title = {Analyzing Ordinal Data with Metric Models: {{What}} Could Possibly Go Wrong?},
  shorttitle = {Analyzing Ordinal Data with Metric Models},
  author = {Liddell, Torrin M. and Kruschke, John K.},
  date = {2018-11-01},
  journaltitle = {Journal of Experimental Social Psychology},
  volume = {79},
  pages = {328--348},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2018.08.009},
  url = {http://www.sciencedirect.com/science/article/pii/S0022103117307746},
  urldate = {2019-01-07},
  abstract = {We surveyed all articles in the Journal of Personality and Social Psychology (JPSP), Psychological Science (PS), and the Journal of Experimental Psychology: General (JEP:G) that mentioned the term “Likert,” and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an effect where none exists, Type I errors) and failures to detect effects (i.e., loss of power, Type II errors). We demonstrate systematic inversions of effects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems — false alarms, misses, and inversions — for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-fire way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their flexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
  keywords = {bayes,ordinal,robustness}
}

@article{lil96sta,
  title = {The Statistical Basis of Public Policy: {{A}} Paradigm Shift Is Overdue},
  author = {Lilford, R. J. and Braunholtz, D.},
  date = {1996},
  journaltitle = {BMJ},
  volume = {313},
  pages = {603--607},
  citeulike-article-id = {13264515},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {adjusting-for-study-bias-or-quality,bayesian-inference,excellent-for-teaching-bayesian-methods-and-explaining-the-advantages,teaching-mds}
}

@article{lin00fit,
  title = {On Fitting {{Cox}}'s Proportional Hazards Models to Survey Data},
  author = {Lin, D. Y.},
  date = {2000},
  journaltitle = {Biometrika},
  volume = {87},
  pages = {37--47},
  citeulike-article-id = {13265132},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {sample-survey,sampling-weights,see-bin92fit}
}

@article{lin00pro,
  title = {Proportional Means Regression for Censored Medical Costs},
  author = {Lin, D. Y.},
  date = {2000},
  journaltitle = {Biometrics},
  volume = {56},
  pages = {775--778},
  citeulike-article-id = {13265173},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {analysis-of-cost,censored-cost,censoring,counting-process,health-economics,survival-analysis}
}

@article{lin01,
  title = {Semiparametric Transformation Models for Point Processes},
  author = {Lin, D. Y. and Wei, L. J. and Ying, Z.},
  date = {2001},
  journaltitle = {J Am Stat Assoc},
  volume = {96},
  pages = {620--628},
  citeulike-article-id = {13265317},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {counting-process,intensity-model,marginal-means,proportional-hazards,proportional-means,recurrent-events,simulation-setup,survival},
  note = {simulation setup for recurrent events using the marginal means E[N(t)] setup;counting process}
}

@article{lin03reg,
  title = {Regression Analysis of Incomplete Medical Cost Data},
  author = {Lin, D. Y.},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {1181--1200},
  citeulike-article-id = {13265316},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {analysis-of-cost-data,censoring,economic-evaluation,estimating-equations,good-definitions,informative-censoring,inverse-probability-of-censoring-weighting,pattern-mixture-models,regression-model}
}

@article{lin03sem,
  title = {Semiparametric Regression Analysis of Longitudinal Data with Informative Drop-Outs},
  author = {Lin, D. Y. and Ying, Zhiliang},
  date = {2003},
  journaltitle = {Biostatistics},
  volume = {4},
  pages = {385--398},
  citeulike-article-id = {13265444},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {artificial-censoring,counting-process,dependent-censoring,informative-dropout,linear-regression,missing-data,nonrandom-dropout,repeated-measures},
  note = {does not parameterize dependence structures or distributions;assumes the same correlation between latent time to informative dropout and the response variable in both treatment groups;RCT;may be most promising method for comparing treatments in the presence of nonrandom dropout}
}

@article{lin17bay,
  title = {Bayesian Nonparametric Analysis of Longitudinal Studies in the Presence of Informative Missingness},
  author = {Linero, A. R.},
  date = {2017-06},
  journaltitle = {Biometrika},
  volume = {104},
  number = {2},
  pages = {327--341},
  issn = {0006-3444},
  doi = {10.1093/biomet/asx015},
  url = {http://dx.doi.org/10.1093/biomet/asx015},
  citeulike-article-id = {14360238},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/asx015},
  posted-at = {2017-05-19 22:09:38},
  priority = {2},
  keywords = {bayesian-inference,bayesian-modeling,informative-dropout,longitudinal-data,missing-data,serial-data}
}

@article{lin21ens,
  title = {Ensuring Exchangeability in Data-Based Priors for a {{Bayesian}} Analysis of Clinical Trials},
  author = {Lin, Junjing and Gamalo-Siebers, Margaret and Tiwari, Ram},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2172},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2172},
  urldate = {2021-09-30},
  abstract = {In many orphan diseases and pediatric indications, the randomized controlled trials may be infeasible because of their size, duration, and cost. Leveraging information on the control through a prior can potentially reduce sample size. However, unless an objective prior is used to impose complete ignorance for the parameter being estimated, it results in biased estimates and inflated type-I error. Hence, it is essential to assess both the confirmatory and supplementary knowledge available during the construction of the prior to avoid “cherry-picking” advantageous information. For this purpose, propensity score methods are employed to minimize selection bias by weighting supplemental control subjects according to their similarity in terms of pretreatment characteristics to the subjects in the current trial. The latter can be operationalized through a proposed measure of overlap in propensity-score distributions. In this paper, we consider single experimental arm in the current trial and the control arm is completely borrowed from the supplemental data. The simulation experiments show that the proposed method reduces prior and data conflict and improves the precision of the of the average treatment effect.},
  langid = {english},
  keywords = {bayes,exchangeability,prior},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2172}
}

@article{lin21not,
  title = {A Note on Point Estimation and Interval Estimation of the Relative Treatment Effect under a Simple Crossover Design},
  author = {Lin, Chii-Dean and Lui, Kung-Jong},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2176},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2176},
  urldate = {2021-11-20},
  abstract = {To increase power or reduce the number of patients needed for a parallel groups design, the crossover design has been often used to study treatments for noncurable chronic diseases. However, in the presence of carry-over effect caused by treatments, the commonly-used estimator which ignores the carry-over effect leads to a biased estimator for estimating the treatment effect difference. A two-stage test approach aimed to address carry-over effect proposed was found to be potentially misleading. In this paper, we propose a weighted average of the commonly-used estimator and an unbiased estimator that uses only the first period of the data. We derive an optimal weight that minimizes the mean squared error (MSE) and its modified estimator. We apply Monte Carlo simulation to evaluate the performance of the proposed estimators in a variety of situations. In the simulations, we examine the estimated MSE (EMSE), percentile interval length, and coverage probability calculated from the percentile intervals among considered estimators. Simulation results show that our proposed weighted average estimator and its modified estimator lead to smaller EMSEs on average comparing to the two commonly used estimators. The coverage probabilities using our proposed estimators are reasonably close to the nominal confidence level and the interval lengths are shorter comparing to the use of the unbiased estimator that uses only the first period of the data. We apply an example that was to evaluate the efficacy of two type of bronchodilators for asthma treatment to demonstrate the use of the proposed estimators.},
  langid = {english},
  keywords = {cross-over-trials,design,design-of-rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2176}
}

@article{lin89ass,
  title = {Assessing Diagnostic Tests by a Strictly Proper Scoring Rule},
  author = {Linnet, K.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {609--618},
  citeulike-article-id = {13264516},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {bootstrap,diagnosis,predictive-accuracy,proper-scoring-rule,testing}
}

@article{lin89rob,
  title = {The Robust Inference for the {{Cox}} Proportional Hazards Model},
  author = {Lin, D. Y. and Wei, L. J.},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {1074--1078},
  citeulike-article-id = {13264517},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {survival-analysis-proportional-hazards-model}
}

@article{lin91exa,
  title = {Exact Statistical Inference for Group Sequential Trials},
  author = {Lin, D. Y. and Wei, L. J. and DeMets, D. L.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {1399--1408},
  citeulike-article-id = {13264518},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {exact-tests,sequential-methods}
}

@article{lin91pre,
  title = {Predicting the Outcomes of Electrophysiologic Studies of Patients with Unexplained Syncope: {{Preliminary}} Validation of a Derived Model},
  author = {Linzer, M. and Prystowsky, E. N. and Divine, G. W. and Matchar, D. B. and Samsa, G. and Harrell, F. E.},
  date = {1991},
  journaltitle = {J Gen Int Med},
  volume = {6},
  pages = {113--120},
  citeulike-article-id = {13264519},
  posted-at = {2014-07-14 14:09:37},
  priority = {0}
}

@article{lin93ana,
  title = {The {{Analysis}} of {{Experimental Data}}: {{The Appreciation}} of {{Tea}} and {{Wine}}},
  author = {Lindley, Dennis V.},
  date = {1993-03},
  journaltitle = {Teaching Statistics},
  volume = {15},
  number = {1},
  pages = {22--25},
  publisher = {Blackwell Publishing Ltd},
  doi = {10.1111/j.1467-9639.1993.tb00252.x},
  url = {http://dx.doi.org/10.1111/j.1467-9639.1993.tb00252.x},
  abstract = {A classical experiment on the tasting of tea is used to show that many standard methods of analysis of the resulting data are unsatisfactory. A similar experiment with wine is used to show how a more sensible method may be developed.},
  citeulike-article-id = {10418027},
  citeulike-attachment-1 = {lin93ana.pdf; /pdf/user/harrelfe/article/10418027/1121742/lin93ana.pdf; 243d4fbea879999e1f76b707d0e2502d5aca542f},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.1467-9639.1993.tb00252.x},
  day = {1},
  posted-at = {2017-10-31 12:04:19},
  priority = {0},
  keywords = {bayes,teaching-mds,teaching-statisticians}
}

@article{lin93che,
  title = {Checking the {{Cox}} Model with Cumulative Sums of Martingale-Based Residuals},
  author = {Lin, D. Y. and Wei, L. J. and Ying, Z.},
  date = {1993},
  journaltitle = {Biometrika},
  volume = {80},
  pages = {557--572},
  citeulike-article-id = {13264520},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {covariable-transformations,cox-model,examples-to-compare-with-splines,goodness-of-fit,ph,residuals}
}

@article{lin94con,
  title = {Confidence Bands for Survival Curves under the Proportional Hazards Model},
  author = {Lin, D. Y. and Fleming, T. R. and Wei, L. J.},
  date = {1994},
  journaltitle = {Biometrika},
  volume = {81},
  pages = {73--81},
  citeulike-article-id = {13264521},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {confidence-bands,confidence-limits,counting-process,cox-ph-model,simultaneous-confidence-bands}
}

@article{lin94cox,
  title = {Cox Regression Analysis of Multivariate Failure Time Data: {{The}} Marginal Approach},
  author = {Lin, D. Y.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {2233--2247},
  citeulike-article-id = {13264522},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {cluster-sampling,competing-risks,examples,extensions-of-cox-model,multiple-events,multivariate-failure-time,robust-covariance-matrix,sandwich-estimator}
}

@article{lin95fit,
  title = {Fitting Parametric Counting Processes by Using Log-Linear Models},
  author = {Lindsey, J. K.},
  date = {1995},
  journaltitle = {Appl Stat},
  volume = {44},
  pages = {201--212},
  citeulike-article-id = {13264523},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {counting-processes,cox-ph-model,poisson-regression,recurrent-events,repeated-events}
}

@article{lin96com,
  title = {Comparing Two Failure Time Distributions in the Presence of Dependent Censoring},
  author = {Lin, D. Y. and Robins, J. M. and Wei, L. J.},
  date = {1996},
  journaltitle = {Biometrika},
  volume = {83},
  pages = {381--393},
  citeulike-article-id = {13264524},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {dependent-censoring,informative-censoring,multiple-events,nonfatal-endpoints-in-presence-of-fatal-endpoints}
}

@article{lin97est,
  title = {Estimating Medical Costs from Incomplete Follow-up Data},
  author = {Lin, D. Y. and Feuer, E. J. and Etzioni, R. and Wax, Y.},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {419--434},
  citeulike-article-id = {13264525},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {analysis-of-costs,cost-distribution,economic-evaluation,informative-censoring}
}

@article{lin97est2,
  title = {Estimating the Proportion of Treatment Effect Explained by a Surrogate Marker},
  author = {Lin, D. Y. and Fleming, T. R. and De Gruttola, V.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1515--1527},
  citeulike-article-id = {13264526},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {study-design,surrogate-endpoint}
}

@book{lin97mod,
  title = {Models for {{Repeated Measurements}}},
  author = {Lindsey, James K.},
  date = {1997},
  publisher = {{Clarendon Press}},
  citeulike-article-id = {13265326},
  posted-at = {2014-07-14 14:09:54},
  priority = {0}
}

@article{lin97non,
  title = {Non-Parametric Inference for Cumulative Incidence Functions in Competing Risks Studies},
  author = {Lin, D. Y.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {901--910},
  citeulike-article-id = {13264527},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {competing-risks,cumulative-incidence-function,multiple-events}
}

@article{lin97sim,
  title = {Simple Models for Repeated Ordinal Responses with an Application to a Seasonal Rhinitis Clinical Trial},
  author = {Lindsey, J. K. and Jones, B. and Ebbutt, A. F.},
  date = {1997},
  journaltitle = {Statistics in Medicine},
  volume = {16},
  number = {24},
  pages = {2873--2882},
  issn = {1097-0258},
  doi = {10.1002/(SICI)1097-0258(19971230)16:24<2873::AID-SIM675>3.0.CO;2-D},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0258%2819971230%2916%3A24%3C2873%3A%3AAID-SIM675%3E3.0.CO%3B2-D},
  urldate = {2021-01-03},
  abstract = {In contrast to other models for ordinal data, the continuation ratio model can be fitted with standard statistical software. This makes it particularly appropriate for large clinical trials with ordinal response variables. In addition, when the trials are longitudinal, this model can be applied to individual responses instead of frequencies in contingency tables. Dependence can be incorporated by conditioning on the previous response, yielding a form of Markov chain. This approach is applied to the analysis of a large seasonal rhinitis trial, where patients were observed over 28 days and six symptoms recorded as ordinal responses. © 1997 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {markov-model,ordinal,serial,transition-model},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-0258\%2819971230\%2916\%3A24\%3C2873\%3A\%3AAID-SIM675\%3E3.0.CO\%3B2-D},
  note = {Uses continuation ratio model, which requires stringing ot the data doubly (over categories and over time) but is flexible.~ Does not cover irregular times.~ States that if an observation is missing in the middle it will require ignoring the next non-missing observation.}
}

@article{lin98app,
  title = {On the Appropriateness of Marginal Models for Repeated Measurements in Clinical Trials},
  author = {Lindsey, J. K. and Lambert, P.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {447--469},
  citeulike-article-id = {13264528},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {marginal-models,problems-with-gee}
}

@article{lin98ass,
  title = {Assessing the Sensitivity of Regression Results to Unmeasured Confounders in Observational Studies},
  author = {Lin, D. Y. and Psaty, B. M. and Kronmal, R. A.},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {948--963},
  citeulike-article-id = {13264529},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {confounding,propensity-score,sensitivity-analysis,unmeasured-covariable},
  annotation = {See important letter to the editor by Tyler VanderWeele BCS 64:645-649; 2008}
}

@article{lin98cho,
  title = {Choosing among Generalized Linear Models Applied to Medical Data},
  author = {Lindsey, J. K. and Jones, B.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {59--68},
  citeulike-article-id = {13264530},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {aic,model-uncertainty,non-nested-models}
}

@article{lin98tut,
  title = {Tutorial in {{Biostatistics}}: {{Methods}} for Interval-Censored Data},
  author = {Lindsey, Jane C. and Ryan, Louise M.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {219--238},
  citeulike-article-id = {13264531},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {interval-censoring}
}

@article{lip02deg,
  title = {A {{Degrees-Of-Freedom}} Approximation in {{Multiple}} Imputation},
  author = {Lipsitz, Stuart and Parzen, Michael and Zhao, Lue P.},
  date = {2002-01},
  journaltitle = {J Stat Comp Sim},
  volume = {72},
  number = {4},
  pages = {309--318},
  publisher = {Taylor & Francis},
  doi = {10.1080/00949650212848},
  url = {http://dx.doi.org/10.1080/00949650212848},
  abstract = {When using multiple imputation to form confidence intervals with missing data, Rubin and Schenker (1986) proposed using a t -distribution with approximate degrees-of-freedom which is a function of the number of multiple imputations and the within and between imputation variance. In this t -approximation, Rubin and Schenker assume there are a finite number of multiple imputations, but an infinite number of observations in the sample. We propose a further degrees-of-freedom approximation which is a function of the within and between imputation variance, the number of multiple imputations, and the number of observations in the sample. When the number of observations in the sample is small, our approximate degrees-of-freedom may be more appropriate, as seen in our simulations.},
  citeulike-article-id = {14252164},
  citeulike-attachment-1 = {lip02deg.pdf; /pdf/user/harrelfe/article/14252164/1097934/lip02deg.pdf; 1db4dfb795c958d5d7eebf1bc6e800820c856fc2},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00949650212848},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/00949650212848},
  day = {1},
  posted-at = {2017-01-14 20:32:16},
  priority = {0},
  keywords = {missing-data,multiple-imputation}
}

@article{lip17one,
  title = {One-{{Step Generalized Estimating Equations With Large Cluster Sizes}}},
  author = {Lipsitz, Stuart and Fitzmaurice, Garrett and Sinha, Debajyoti and Hevelone, Nathanael and Hu, Jim and Nguyen, Louis L.},
  date = {2017-04},
  journaltitle = {J Comp Graph Stat},
  pages = {1--4},
  publisher = {Taylor & Francis},
  doi = {10.1080/10618600.2017.1321552},
  url = {http://dx.doi.org/10.1080/10618600.2017.1321552},
  abstract = {Medical studies increasingly involve a large sample of independent clusters, where the cluster sizes are also large. Our motivating example from the 2010 Nationwide Inpatient Sample (NIS) has 8,001,068 patients and 1049 clusters, with average cluster size of 7627. Consistent parameter estimates can be obtained naively assuming independence, which are inefficient when the intra-cluster correlation (ICC) is high. Efficient generalized estimating equations (GEE) incorporate the ICC and sum all pairs of observations within a cluster when estimating the ICC. For the 2010 NIS, there are 92.6 billion pairs of observations, making summation of pairs computationally prohibitive. We propose a one-step GEE estimator that (1) matches the asymptotic efficiency of the fully iterated GEE; (2) uses a simpler formula to estimate the ICC that avoids summing over all pairs; and (3) completely avoids matrix multiplications and inversions. These three features make the proposed estimator much less computationally intensive, especially with large cluster sizes. A unique contribution of this article is that it expresses the GEE estimating equations incorporating the ICC as a simple sum of vectors and scalars.},
  citeulike-article-id = {14401935},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/10618600.2017.1321552},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2017.1321552},
  day = {24},
  posted-at = {2017-07-29 13:18:51},
  priority = {2},
  keywords = {clustered-data,gee,improving-sandwich-estimator-when-number-of-clusters-is-small,large-clusters}
}

@article{lip22cau,
  title = {Causal {{Directed Acyclic Graphs}}},
  author = {Lipsky, Ari M. and Greenland, Sander},
  date = {2022-02-28},
  journaltitle = {JAMA},
  issn = {0098-7484},
  doi = {10.1001/jama.2022.1816},
  url = {https://doi.org/10.1001/jama.2022.1816},
  urldate = {2022-03-01},
  abstract = {The design and interpretation of clinical studies requires consideration of variables beyond the exposure or treatment of interest and patient outcomes, including decisions about which variables to capture and, of those, which to control for in statistical analyses to minimize bias in estimating treatment effects. Causal directed acyclic graphs (DAGs) are a useful tool for communicating researchers’ understanding of the potential interplay among variables and are commonly used for mediation analysis. Assumptions are presented visually in a causal DAG and, based on this visual representation, researchers can deduce which variables require control to minimize bias and which variables could introduce bias if controlled in the analysis.},
  keywords = {causal-analysis,causal-effects,causality,dag,directed-graph,teaching-mds}
}

@article{lip96jac,
  title = {A Jackknife Estimator of Variance for {{Cox}} Regression for Correlated Survival Data},
  author = {Lipsitz, Stuart R. and Parzen, Michael},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {291--298},
  citeulike-article-id = {13264532},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {cluster-sampling,jackknife,robust-covariance-estimator}
}

@article{lip98inf,
  title = {Inference Using Conditional Logistic Regression with Missing Covariates},
  author = {Lipsitz, Stuart R. and Parzen, Michael and Ewell, Marian},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {295--303},
  citeulike-article-id = {13264533},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {casewise-deletion,conditional-logistic-model,missing-covariables,missing-data},
  note = {applies methods of vac93log;model propensity for missing}
}

@article{lip98sem,
  title = {A Semiparametric Method of Multiple Imputation},
  author = {Lipsitz, Stuart R. and Zhao, Lue P. and Molenberghs, Geert},
  date = {1998},
  journaltitle = {J Roy Stat Soc B},
  volume = {60},
  pages = {127--144},
  citeulike-article-id = {13264534},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {bayesian-bootstrap,missing-data,multiple-imputation}
}

@article{lit04rob,
  title = {Robust Likelihood-Based Analysis of Multivariate Data with Missing Values},
  author = {Little, Roderick and An, Hyonggin},
  date = {2004},
  journaltitle = {Statistica Sinica},
  volume = {14},
  pages = {949--968},
  citeulike-article-id = {13265396},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {double-robustness,incomplete-data,penalized-splines,regression-imputation,weighting},
  note = {intuitive approximations for efficiency of regression single imputation; excellent overview of missing data analysis; expression for bias under NMAR; regression imputation is more effective than propensity score imputation, especially if the regression model is flexible; Horvitz-Thompson estimator; flexible additive model; inclusion of propensity score as a covariate; 1983 reference for this; new estimator that is consistent if either the model for imputed values or for missingness is correctly specified; simulation setup for missingness and response variable; "Despite the large literature devoted to nonignorable missing data adjustments, we believe that the key to successful treatment of missing data is to measure covariates that are predictive of the missing values, and to model carefully the relationships between the missing values and these covariates. Likelihood-based methods based on multivariate models for the data are useful tools for making efficient use of the available data, but standard models such as the multivariate normal imply linear additive relationships between the variables that may be too simplistic. We propose easily-fitted spline models that yield regression predictions that are more robust to nonlinearity in the relationship between the missing variables and the covariates, under MAR assumptions. A key idea is to single out the propensity score for this robust form of modeling."}
}

@article{lit06cal,
  title = {Calibrated {{Bayes}}: {{A Bayes}}/Frequentist Roadmap},
  author = {Little, Roderick J.},
  date = {2006},
  journaltitle = {Appl Stat},
  volume = {60},
  pages = {213--223},
  citeulike-article-id = {13265479},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  note = {excellent background of the Bayesian approach}
}

@article{lit15int,
  title = {Intention-to-Treat Analysis with Treatment Discontinuation and Missing Data in Clinical Trials},
  author = {Little, Roderick and Kang, Shan},
  date = {2015-07},
  journaltitle = {Stat Med},
  volume = {34},
  number = {16},
  pages = {2381--2390},
  issn = {02776715},
  doi = {10.1002/sim.6352},
  url = {http://dx.doi.org/10.1002/sim.6352},
  citeulike-article-id = {14214857},
  citeulike-attachment-1 = {lit15int.pdf; /pdf/user/harrelfe/article/14214857/1092993/lit15int.pdf; 1cb75652bb6486c89a5c6bd01a886c9c1f6f1471},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6352},
  day = {20},
  posted-at = {2016-11-25 19:00:41},
  priority = {0},
  keywords = {dropouts,estimand,intention-to-treat,missing-data,rct}
}

@article{lit88mis,
  title = {Missing-Data Adjustments in Large Surveys},
  author = {Little, Roderick J. A.},
  date = {1988},
  journaltitle = {J Bus Econ Stat},
  volume = {6},
  pages = {287--296},
  citeulike-article-id = {13264536},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  note = {coined the term "predictive mean matching" to refer to imputation of a missing value by another observation's observed value when the predicted value for that variable is the closest one to the predicted variable value for the missing observation}
}

@article{lit89,
  title = {Testing the Equality of Two Independent Binomial Proportions},
  author = {Little, R. J. A.},
  date = {1989},
  journaltitle = {Am Statistician},
  volume = {43},
  pages = {283--288},
  citeulike-article-id = {13264537},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,miscellaneous}
}

@article{lit92reg,
  title = {Regression with Missing {{X}}'s: {{A}} Review},
  author = {Little, Roderick J. A.},
  date = {1992},
  journaltitle = {J Am Stat Assoc},
  volume = {87},
  pages = {1227--1237},
  citeulike-article-id = {13264538},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {missing-data}
}

@article{lit95mod,
  title = {Modeling the Drop-out Mechanism in Repeated-Measures Studies},
  author = {Little, Roderick J. A.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {1112--1121},
  citeulike-article-id = {13264539},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {dropouts,informative-censoring,missing-data,study-design}
}

@article{lit96int,
  title = {Intent-to-Treat Analysis for Longitudinal Studies with Drop-Outs},
  author = {Little, Roderick and Yau, Linda},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {1324--1333},
  doi = {10.2307/2532847},
  url = {http://dx.doi.org/10.2307/2532847},
  citeulike-article-id = {13264540},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2532847},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {clinical-trials,dropouts,intention-to-treat,last-value-carried-forward,locf,longitudinal-data-analysis,missing-data,multiple-imputation,rct,repeated-measures}
}

@incollection{lit98mis,
  title = {Missing {{Data}}},
  booktitle = {Ency of {{Biostatistics}}},
  author = {Little, Roderick J.},
  date = {1998},
  pages = {2622--2635},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264541},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {missing-data}
}

@book{littlerubin,
  title = {Statistical {{Analysis}} with {{Missing Data}}},
  author = {Little, Roderick J. A. and Rubin, Donald B.},
  date = {2002},
  edition = {second},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264535},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {missing-data}
}

@article{liu01sam,
  title = {On Sample Size and Inference for Two-Stage Adaptive Designs},
  author = {Liu, Q. and Chi, G. Y. H.},
  date = {2001},
  journaltitle = {Biometrics},
  volume = {57},
  pages = {172--177},
  citeulike-article-id = {13265509},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{liu07sha,
  title = {A Shared Random Effects Model for Censored Medical Costs and Mortality},
  author = {Liu, Lei and Wolfe, Robert A. and Kalbfleisch, John D.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {139--155},
  citeulike-article-id = {13265547},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {change-point,cost-analysis,informative-censoring,mixed-model,ph-model,re-censoring,survival-analysis}
}

@article{liu09sho,
  title = {Should Baseline Be a Covariate or Dependent Variable in Analyses of Change from Baseline in Clinical Trials?},
  author = {Liu, Guanghan F. and Lu, Kaifeng and Mogg, Robin and Mallick, Madhuja and Mehrotra, Devan V.},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {2509--2530},
  citeulike-article-id = {13265792},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {ancova,baseline,constrained-lda,longitudinal-data-analysis,rct,repeated-measures,serial-data},
  note = {seems to miss several important points, such as the fact that the baseline variable is often part of the inclusion/exclusion criteria and so has a truncated distribution that is different from that of the follow-up measurements;sharp rebuke in ken10sho}
}

@article{liu10ran,
  title = {A Rank-Based Test for Comparison of Multidimensional Outcomes},
  author = {Liu, Aiyi and Li, Qizhai and Yu, Kai and Yu, Kai F.},
  date = {2010},
  journaltitle = {J Am Stat Assoc},
  volume = {105},
  number = {490},
  pages = {578--587},
  citeulike-article-id = {13265834},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {autism,behrens-fisher-problem,cardioprotective-solution,case-control-study,grown-hormones,multiple-endpoints,multiple-outcomes,rank-sum-statistics},
  note = {see obr84pro}
}

@article{liu13phy,
  title = {Physician Performance Assessment Using a Composite Quality Index},
  author = {Liu, Kaibo and Jain, Shabnam and Shi, Jianjun},
  date = {2013},
  journaltitle = {Stat Med},
  volume = {32},
  number = {15},
  pages = {2661--2680},
  doi = {10.1002/sim.5710},
  url = {http://dx.doi.org/10.1002/sim.5710},
  abstract = {Assessing physician performance is important for the purposes of measuring and improving quality of service and reducing healthcare delivery costs. In recent years, physician performance scorecards have been used to provide feedback on individual measures; however, one key challenge is how to develop a composite quality index that combines multiple measures for overall physician performance evaluation. A controversy arises over establishing appropriate weights to combine indicators in multiple dimensions, and cannot be easily resolved. In this study, we proposed a generic unsupervised learning approach to develop a single composite index for physician performance assessment by using non-negative principal component analysis. We developed a new algorithm named iterative quadratic programming to solve the numerical issue in the non-negative principal component analysis approach. We conducted real case studies to demonstrate the performance of the proposed method. We provided interpretations from both statistical and clinical perspectives to evaluate the developed composite ranking score in practice. In addition, we implemented the root cause assessment techniques to explain physician performance for improvement purposes.},
  citeulike-article-id = {13265972},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5710},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {composite-quality-index,iterative-quadratic-programming-iqp-algorithm-for-npca,non-negative-principal-component-analysis-npca,physician-performance-assessment}
}

@article{liu14est,
  title = {Estimating {{Risk}} with {{Time-to-Event Data}}: {{An Application}} to the {{Women}}'s {{Health Initiative}}.},
  author = {Liu, Dandan and Zheng, Yingye and Prentice, Ross L. and Hsu, Li},
  date = {2014-06},
  journaltitle = {JASA},
  volume = {109},
  number = {506},
  eprint = {25018574},
  eprinttype = {pmid},
  pages = {514--524},
  issn = {0162-1459},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25018574},
  abstract = {Accurate and individualized risk prediction is critical for population control of chronic diseases such as cancer and cardiovascular disease. Large cohort studies provide valuable resources for building risk prediction models, as the risk factors are collected at the baseline and subjects are followed over time until disease occurrence or termination of the study. However, for rare diseases the baseline risk may not be estimated reliably based on cohort data only, due to sparse events. In this paper, we propose to make use of external information to improve efficiency for estimating time-dependent absolute risk. We derive the relationship between external disease incidence rates and the baseline risk, and incorporate the external disease incidence information into estimation of absolute risks, while allowing for potential difference of disease incidence rates between cohort and external sources. The asymptotic properties, namely, uniform consistency and weak convergence, of the proposed estimators are established. Simulation results show that the proposed estimator for absolute risk is more efficient than that based on the Breslow estimator, which does not utilize external disease incidence rates. A large cohort study, the Women's Health Initiative Observational Study, is used to illustrate the proposed method.},
  citeulike-article-id = {14033267},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25018574},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25018574},
  day = {1},
  posted-at = {2016-05-11 14:28:08},
  priority = {2},
  keywords = {ctsafac}
}

@article{liu14met,
  title = {Methods for {{Estimating Center Effects}} on {{Recurrent Events}}.},
  author = {Liu, Dandan and Kalbfleisch, John D. and Schaubel, Douglas E.},
  date = {2014-05},
  journaltitle = {Stat Biosci},
  volume = {6},
  number = {1},
  eprint = {24976871},
  eprinttype = {pmid},
  pages = {19--37},
  issn = {1867-1764},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/24976871},
  abstract = {In this article, we develop methods for quantifying center effects with respect to recurrent event data. In the models of interest, center effects are assumed to act multiplicatively on the recurrent event rate function. When the number of centers is large, traditional estimation methods that treat centers as categorical variables have many parameters and are sometimes not feasible to implement, especially with large numbers of distinct recurrent event times. We propose a new estimation method for center effects which avoids including indicator variables for centers. We then show that center effects can be consistently estimated by the center-specific ratio of observed to expected cumulative numbers of events. We also consider the case where the recurrent event sequence can be stopped permanently by a terminating event. Large sample results are developed for the proposed estimators. We assess the finite-sample properties of the proposed estimators through simulation studies. The method is then applied to national hospital admissions data for end stage renal disease patients.},
  citeulike-article-id = {14033266},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/24976871},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=24976871},
  day = {1},
  posted-at = {2016-05-11 14:27:16},
  priority = {2},
  keywords = {ctsafac}
}

@article{liu17mod,
  title = {Modeling Continuous Response Variables Using Ordinal Regression},
  author = {Liu, Qi and Shepherd, Bryan E. and Li, Chun and Harrell, Frank E.},
  date = {2017},
  journaltitle = {Statistics in Medicine},
  volume = {36},
  number = {27},
  pages = {4316--4335},
  issn = {1097-0258},
  doi = {10.1002/sim.7433},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7433},
  urldate = {2020-07-15},
  abstract = {We study the application of a widely used ordinal regression model, the cumulative probability model (CPM), for continuous outcomes. Such models are attractive for the analysis of continuous response variables because they are invariant to any monotonic transformation of the outcome and because they directly model the cumulative distribution function from which summaries such as expectations and quantiles can easily be derived. Such models can also readily handle mixed type distributions. We describe the motivation, estimation, inference, model assumptions, and diagnostics. We demonstrate that CPMs applied to continuous outcomes are semiparametric transformation models. Extensive simulations are performed to investigate the finite sample performance of these models. We find that properly specified CPMs generally have good finite sample performance with moderate sample sizes, but that bias may occur when the sample size is small. Cumulative probability models are fairly robust to minor or moderate link function misspecification in our simulations. For certain purposes, the CPMs are more efficient than other models. We illustrate their application, with model diagnostics, in a study of the treatment of HIV. CD4 cell count and viral load 6 months after the initiation of antiretroviral therapy are modeled using CPMs; both variables typically require transformations, and viral load has a large proportion of measurements below a detection limit.},
  langid = {english},
  keywords = {continuous-variables,ordinal,po,proportional-odds},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7433}
}

@article{liu17moda,
  title = {Modeling Continuous Response Variables Using Ordinal Regression},
  author = {Liu, Qi and Shepherd, Bryan E. and Li, Chun and Harrell, Frank E.},
  date = {2017-11-30},
  journaltitle = {Stat Med},
  volume = {36},
  number = {27},
  eprint = {28872693},
  eprinttype = {pmid},
  pages = {4316--4335},
  issn = {1097-0258},
  doi = {10.1002/sim.7433},
  abstract = {We study the application of a widely used ordinal regression model, the cumulative probability model (CPM), for continuous outcomes. Such models are attractive for the analysis of continuous response variables because they are invariant to any monotonic transformation of the outcome and because they directly model the cumulative distribution function from which summaries such as expectations and quantiles can easily be derived. Such models can also readily handle mixed type distributions. We describe the motivation, estimation, inference, model assumptions, and diagnostics. We demonstrate that CPMs applied to continuous outcomes are semiparametric transformation models. Extensive simulations are performed to investigate the finite sample performance of these models. We find that properly specified CPMs generally have good finite sample performance with moderate sample sizes, but that bias may occur when the sample size is small. Cumulative probability models are fairly robust to minor or moderate link function misspecification in our simulations. For certain purposes, the CPMs are more efficient than other models. We illustrate their application, with model diagnostics, in a study of the treatment of HIV. CD4 cell count and viral load 6~months after the initiation of antiretroviral therapy are modeled using CPMs; both variables typically require transformations, and viral load has a large proportion of measurements below a detection limit.},
  langid = {english},
  pmcid = {PMC5675816},
  keywords = {methodology,ordinal}
}

@article{liu19bay,
  title = {A {{Bayesian Time-Varying Coefficient Model}} for {{Multitype Recurrent Events}}},
  author = {Liu, Yi and Guo, Feng},
  date = {2019-10-31},
  journaltitle = {Journal of Computational and Graphical Statistics},
  pages = {1--12},
  issn = {1061-8600},
  doi = {10.1080/10618600.2019.1686988},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/10618600.2019.1686988},
  urldate = {2019-12-16},
  abstract = {This article proposes a Bayesian time-varying coefficient model to evaluate the temporal profile of intensity for multitype recurrent events. The model obtains smooth estimates for both time-varying coefficients and the baseline intensity using Bayesian penalized splines. One major challenge in Bayesian penalized splines is that the smoothness of a spline fit is sensitive to the subjective choice of hyperparameters. We establish a procedure to objectively determine the hyperparameters through robust prior specification. To effectively update the high-dimensional spline parameters, we develop a Markov chain Monte Carlo procedure based on the Metropolis-adjusted Langevin algorithms. A joint sampling scheme is used to achieve better convergence and mixing properties. A simulation study confirms satisfactory model performance in estimating time-varying coefficients under different curvature and event rate scenarios. Application to a commercial truck driver naturalistic driving data reveals that drivers with 7-hours-or-less sleep time have a significantly higher safety-critical event intensity after 8\,hr of driving and the intensity remains high after taking a break. The findings provide crucial information for the truck driver hours-of-service regulation and fatigue management. The proposed model provides a flexible and robust tool to evaluate the temporal profile of intensity for multitype recurrent events. Supplemental materials for this article are available online.},
  keywords = {bayes,recurrent-events,time-varying-coefficients}
}

@article{liu21cor,
  title = {Correct and Logical Causal Inference for Binary and Time-to-Event Outcomes in Randomized Controlled Trials},
  author = {Liu, Yi and Wang, Bushi and Yang, Miao and Hui, Jianan and Xu, Heng and Kil, Siyoen and Hsu, Jason C.},
  date = {2021},
  journaltitle = {Biometrical Journal},
  volume = {n/a},
  number = {n/a},
  issn = {1521-4036},
  doi = {10.1002/bimj.202000202},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000202},
  urldate = {2021-07-24},
  abstract = {Targeted therapies tend to have biomarker defined subgroups that derive differential efficacy from treatments. This article corrects three prevailing oversights in stratified analyses comparing treatments in randomized controlled trials (RCTs) with binary and time-to-event outcomes: 1.Using efficacy measures such as odds ratio (OR) and hazard ratio (HR) can make a prognostic biomarker appear predictive, targeting wrong patients, because the inference is affected by a confounding/covert factor even with ignorable treatment assignment in an RCT. As shown analytically and with real immunotherapy patient level data, OR and HR cannot meet the causal Estimand requirement of ICH E9R1. 2.Mixing efficacy in subgroups by prevalence, the prevailing practice, can give misleading results also, for any efficacy measured as a ratio. However, mixing relative response (RR) and ratio of median (RoM) survival times by the prognostic effect, the confounding/covert factor hiding in plain sight, will give causal inference in an RCT. 3.Effects in subgroups should not be mixed on the logarithmic scale, because it creates an artificial Estimand for the whole population which changes depending on how the population is divided into subgroups. Current computer package implementations contain all these oversights. Probabilities, including survival curve probabilities, naturally average within each treatment arm by prevalence. The subgroup mixable estimation (SME) principle fixes the oversights by first averaging probabilities (not their logarithms) within each treatment arm, then computing simultaneous confidence intervals for ratio efficacy in subgroups and their mixtures based on rigorous mathematical derivation, to finally provide causal inference in the form of apps.},
  langid = {english},
  keywords = {causal-inference,effect-measure,estimand,or},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000202},
  note = {The authors used loaded terms "correct" and "logical" in a cavalier fashion.~ They defined an efficacy measure as "logic-respecting" if the unstratified estimate is between the stratified estimates.~ There is no logic here, and this only points out that the authors think of the linear estimand space as magical.~ The authors seem to be believe that "population level efficacy" (Section 4.2, first paragraph) is of interest, and they do not acknowledge either that (1) this is not how clinical decisions are made, (2) populations may change, (3) population mixtures of patients who are candidates for therapy change over time, (4) RCTs do not need to have samples that are representative of populations, (5) neither sponsors nor regulators should be required to know covariate distributions in the ultimate target population, and (6) if proportional hazards holds in subgroups, it is impossible to hold in the combined sample, so envisioning a proportional hazards model for the whole sample is nonsensical.~ In the last two paragraphs of Section 4.2 the authors state that "Random assignments of treatments to patients in RCT designs needs to avoid bias not only in assessing" ... efficacy in the usual way but also when comparing patients in one stratum on treatment A with patients in another stratum on treatment B.~~ That may be the case but this kind of comparison, though implicitly involved in population-level contrasts, is of no interest to anyone.~ The authors go along to say at the end of this section "We feel that (the definition of)~ Estimand for efficacy in the whole population and in subgroups should be one and the same ... Makes no sense to define efficacy for the whole population that changes according to the subgroups it might get divided into." There is no logic to that. Just before Section 5 the authors mention the need for the strata distributions to be specified.~ These population distributions will not be known.~
\par
In Section 7.1.1 the authors engage in dichotomania and present a bogus analysis for effect modification due to a continuous biomarker.
\par
Section 8.1: This analysis is misleading.~ The authors do not realize that incomplete conditioning on the biomarker causes hidden heterogeneity within biomarker intervals.
\par
Commentary by Gene Pennelo and Dandan Xu: Section 5: "One lesson that can be learned from this analysis is that variables should not be dichotomized before they are analyzed... Indeed, when interaction between continuous bTMB and treatment is included in the Cox model, the p value is 0.9681, indicating no evidence that bTMB is predictive."~ Section 7: "nonlogic respecting of rankings of causal effect measures ... cannot arise provided that the causal effect measure mu is redefined in terms of the potential outcomes within a subject."~ Section 7.1 when focusing on ORs addresses the same point.~ Section 8: "In response to their provocative findings, we found that the odds and hazard ratios are logic respecting when the subgroups are purely predictive, that is, the distribution of potential outcome for the control treatment is homogeneous across subgroups.~ We also found that when we redefined the odds and hazard ratio causal estimands in terms of the joint distribution of the potential outcomes, the discrepancies are resolved under specific models in which the potential outcomes are conditionally independent."
\par
Commentary by Dong Xi and Frank Bretz: "This distinction [between conditional and marginal estimands] has been largely neglected in pharmaceutical drug development.~ For example, a marginal estimand for a binary outcome could be defined as a marginal odds ratio, which is a contrast of response probabilities obtained by averaging over the covariate space.~ On the other hand, a conditional estimand could be the treatment effect parameter in a standard logistic regression with covariates, which should be interpreted as an odds ratio conditioning on certain values of the covariates... It is neither right nor wrong to favour one estimand over another, much like one cannot favour apples over oranges... Both estimands allow for a causal interpretation in the sense of ICH (2019), and the choice between them should be guided by clinical meaningfulness of the resulting treatment effects."~ "... confounding and non-collapsibility are two separate issues".~ "... we believe that the collapsiblity of a measure of association defined by Huitfeldt et al (2019) and the logic-respecting definition are equivalent..."~ "It is useful to link SME with standardization (Hernan \& Robins, 2020, Section 2.3)..."~ "Based on the above steps, we can see that standardization uses the conditional regression model for a marginal estimand (Daniel et al 2021).~ It is closely related to the target maximum likelihood estimation and has a certain level of robustness to model misspecification in the conditional regression model under randomization (Moore \& van der Laan, 2009; Rosenblum \& van der Laan, 2010)."~ "Liu et al (2021) also considered the use of hazard ratios for time-to-event analysis.~ As argued by Sjolander et al (2016), the reason for non-collapsibility of hazard ratios is different than for odds ratios, because hazards are based on conditional probabilities on survival, and these cannot be averaged over covariates (Daniel et al, 2021).~ Moreover, for hazard ratios the estimand depends on the proportional hazard assumption; If it holds for both subgroups, it is almost always wrong for the overall.~ Without the proportional hazard assumption, however, the estimand of Cox model is a weighted average of hazard ratios over time, which is difficult to describe.~ This could be seen as a drawback on the primary analysis before looking at subgroups."
\par
Authors' rejoinder to commentaries:~ The authors did not address most of the criticisms contained in the two commentaries.~ The authors' rejoinder is not very logical as they emphasize caring what happens to patients but their methods are inconsistent with patient decision making.~ Their statement "We think in terms of clinical consequences, what benefits patients, what harms patients" is at odds with their statement "following nature to mix within each treatment arm first before calculating any efficacy measure between treatments resolves issues".}
}

@article{liu79ran,
  title = {A Rank Statistic for Assessing the Amount of Variation Explained by Risk Factors in Epidemiologic Studies},
  author = {Liu, Kiang and Dyer, Alan R.},
  date = {1979},
  journaltitle = {Am J Epi},
  volume = {109},
  pages = {597--606},
  citeulike-article-id = {13264542},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {rank-correlation,roc-area}
}

@article{loa19var,
  title = {Variational {{Bayes Estimation}} of {{Discrete-Margined Copula Models With Application}} to {{Time Series}}},
  author = {Loaiza-Maya, Rubén and Smith, Michael Stanley},
  date = {2019-01-14},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {0},
  number = {0},
  pages = {1--17},
  issn = {1061-8600},
  doi = {10.1080/10618600.2018.1562936},
  url = {https://doi.org/10.1080/10618600.2018.1562936},
  urldate = {2019-04-10},
  abstract = {We propose a new variational Bayes (VB) estimator for high-dimensional copulas with discrete, or a combination of discrete and continuous, margins. The method is based on a variational approximation to a tractable augmented posterior and is faster than previous likelihood-based approaches. We use it to estimate drawable vine copulas for univariate and multivariate Markov ordinal and mixed time series. These have dimension rT, where T is the number of observations and r is the number of series, and are difficult to estimate using previous methods. The vine pair-copulas are carefully selected to allow for heteroscedasticity, which is a feature of most ordinal time series data. When combined with flexible margins, the resulting time series models also allow for other common features of ordinal data, such as zero inflation, multiple modes, and under or overdispersion. Using six example series, we illustrate both the flexibility of the time series copula models and the efficacy of the VB estimator for copulas of up to 792 dimensions and 60 parameters. This far exceeds the size and complexity of copula models for discrete data that can be estimated using previous methods. An online appendix and MATLAB code implementing the method are available as supplementary materials.},
  keywords = {bayes,copula}
}

@report{loc13sig,
  title = {A Significance Test for the Lasso},
  author = {Lockhart, Richard and Taylor, Jonathan and Tibshirani, Ryan J. and Tibshirani, Robert},
  date = {2013},
  eprint = {1301.7161},
  eprinttype = {arxiv},
  institution = {{arXiv}},
  url = {http://arxiv.org/abs/1301.7161},
  archiveprefix = {arXiv},
  citeulike-article-id = {13265956},
  citeulike-linkout-0 = {http://arxiv.org/abs/1301.7161},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{loc19imp,
  title = {The {{Impact}} of {{Results Blind Science Publishing}} on {{Statistical Consultation}} and {{Collaboration}}},
  author = {Locascio, Joseph J.},
  date = {2019-03-29},
  journaltitle = {The American Statistician},
  volume = {73},
  pages = {346--351},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1505658},
  url = {https://doi.org/10.1080/00031305.2018.1505658},
  urldate = {2019-08-12},
  abstract = {The author has previously proposed results blind manuscript evaluation (RBME) as a method of ameliorating often cited problems of statistical inference and scientific publication, notably publication bias, overuse/misuse of null hypothesis significance testing (NHST), and irreproducibility of reported scientific results. In RBME, manuscripts submitted to scientific journals are assessed for suitability for publication without regard to their reported results. Criteria for publication are based exclusively on the substantive importance of the research question addressed in the study, conveyed in the Introduction section of the manuscript, and the quality of the methodology, as reported in the Methods section. Practically, this policy is implemented by a two stage process whereby the editor initially distributes only the Introduction and Methods sections of a submitted manuscript to reviewers and a provisional decision regarding acceptance is made, followed by a second stage in which the complete manuscript is distributed for review but only if the decision of the first stage is for acceptance. The present paper expands upon this recommendation by addressing implications of this proposed policy with respect to statistical consultation and collaboration in research. It is suggested that under RBME, statisticians will become more integrated into research endeavors and called upon sooner for their input.},
  issue = {sup1},
  keywords = {collaboration,consulting,writing}
}

@article{loh88,
  title = {Tree-Structured Classification via Generalized Discriminant Analysis (with Discussion)},
  author = {Loh, W-Y and Vanichsetakul, N.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {715--728},
  citeulike-article-id = {13264543},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,general,logistic-model,predictive-methods}
}

@article{lon00usi,
  title = {Using Heteroscedasticity Consistent Standard Errors in the Linear Regression Model},
  author = {Long, J. Scott and Ervin, Laurie H.},
  date = {2000},
  journaltitle = {Am Statistician},
  volume = {54},
  pages = {217--224},
  citeulike-article-id = {13265152},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {huber-white-sandwich-estimator,robust-covariance-matrix}
}

@article{lon13han,
  title = {Handling the Limit of Detection by Extrapolation},
  author = {Longford, Nicholas T.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {26},
  pages = {3133--3146},
  doi = {10.1002/sim.5373},
  url = {http://dx.doi.org/10.1002/sim.5373},
  abstract = {A general method of estimation with a variable observed subject to a limit of detection is introduced. It is based on extrapolation of the estimates obtained by increasing the limit of detection. Theoretical arguments support the method in some special cases, and it is explored by simulations. Several examples are presented and adaptations for other kinds of censoring explored.},
  citeulike-article-id = {13265975},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5373},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {censoring,extrapolation,ideal-data,imputation,limit-of-detection,simex}
}

@article{lov97rec,
  title = {Recruitment for Controlled Clinical Trials: {{Literature}} Summary and Annotated Bibliography},
  author = {Lovato, Laura C. and Hill, Kristin and Hertert, Stephanie and Hunninghame, Donald B. and Probstfield, Jeffrey L.},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {328--357},
  citeulike-article-id = {13264544},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {cct,recruitment,study-design}
}

@article{lu20ana,
  title = {Analysis of {{Longitudinal-Ordered Categorical Data}} for {{Muscle Spasm Adverse Event}} of {{Vismodegib}}: {{Comparison Between Different Pharmacometric Models}}},
  shorttitle = {Analysis of {{Longitudinal-Ordered Categorical Data}} for {{Muscle Spasm Adverse Event}} of {{Vismodegib}}},
  author = {Lu, Tong and Yang, Yujie and Jin, Jin Y. and Kågedal, Matts},
  date = {2020},
  journaltitle = {CPT: Pharmacometrics \& Systems Pharmacology},
  volume = {9},
  number = {2},
  pages = {96--105},
  issn = {2163-8306},
  doi = {10.1002/psp4.12487},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/psp4.12487},
  urldate = {2022-04-12},
  abstract = {Longitudinal-ordered categorical data, common in clinical trials, can be effectively analyzed with nonlinear mixed effect models. In this article, we systematically evaluated the performance of three different models in longitudinal muscle spasm adverse event (AE) data obtained from a clinical trial for vismodegib: a proportional odds (PO) model, a discrete-time Markov model, and a continuous-time Markov model. All models developed based on weekly spaced data can reasonably capture the proportion of AE grade over time; however, the PO model overpredicted the transition frequency between grades and the cumulative probability of AEs. The influence of data frequency (daily, weekly, or unevenly spaced) was also investigated. The PO model performance reduced with increased data frequency, and the discrete-time Markov model failed to describe unevenly spaced data, but the continuous-time Markov model performed consistently well. Clinical trial simulations were conducted to illustrate the muscle spasm resolution time profile during the 8-week dose interruption period after 12 weeks of continuous treatment.},
  langid = {english},
  keywords = {markov,ordinal,po,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/psp4.12487}
}

@article{lu21bay,
  title = {Bayesian Approaches to Variable Selection: A Comparative Study from Practical Perspectives},
  shorttitle = {Bayesian Approaches to Variable Selection},
  author = {Lu, Zihang and Lou, Wendy},
  date = {2021-03-24},
  journaltitle = {The International Journal of Biostatistics},
  publisher = {{De Gruyter}},
  issn = {1557-4679},
  doi = {10.1515/ijb-2020-0130},
  url = {https://www.degruyter.com/document/doi/10.1515/ijb-2020-0130/html?_llca=transfer%3A6c4e2be67680df8697a36347096dc061&_llch=4a014e430be2a0321edc05c36ca125ee393e28b730c6fd6acf796c4547770148},
  urldate = {2022-01-26},
  abstract = {In many clinical studies, researchers are interested in parsimonious models that simultaneously achieve consistent variable selection and optimal prediction. The resulting parsimonious models will facilitate meaningful biological interpretation and scientific findings. Variable selection via Bayesian inference has been receiving significant advancement in recent years. Despite its increasing popularity, there is limited practical guidance for implementing these Bayesian approaches and evaluating their comparative performance in clinical datasets. In this paper, we review several commonly used Bayesian approaches to variable selection, with emphasis on application and implementation through R software. These approaches can be roughly categorized into four classes: namely the Bayesian model selection, spike-and-slab priors, shrinkage priors, and the hybrid of both. To evaluate their variable selection performance under various scenarios, we compare these four classes of approaches using real and simulated datasets. These results provide practical guidance to researchers who are interested in applying Bayesian approaches for the purpose of variable selection.},
  langid = {english},
  keywords = {bayes,variable-selection}
}

@article{lub02com,
  title = {Combined Enpoints: Can We Use Them?},
  author = {Lubsen, Jacobus and Kirwan, Bridget-Anne},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {2959--2970},
  citeulike-article-id = {13265295},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {combined-endpoints,composite-endpoints,event-free-survival,handling-deaths-when-studying-nonfatal-endpoints,intention-to-treat,meta-analysis,multiple-endpoints,multiple-outcomes,rct,study-design,survival-analysis,worst-rank-scores}
}

@article{lub78pra,
  title = {A Practical Device for the Application of a Diagnostic or Prognostic Function},
  author = {Lubsen, Jacobus and Pool, Jan and van der Does, Emiel},
  options = {useprefix=true},
  date = {1978},
  journaltitle = {Meth Info Med},
  volume = {17},
  pages = {127--129},
  citeulike-article-id = {13264545},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {nomogram}
}

@article{lud98why,
  title = {Why Permutation Tests Are Superior to t and {{F}} Tests in Biomedical Research},
  author = {Ludbrook, John and Dudley, Hugh},
  date = {1998},
  journaltitle = {Am Statistician},
  volume = {52},
  pages = {127--132},
  citeulike-article-id = {13264546},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  note = {population inference vs. inference only for subjects in study;permutation test; randomization test;if study is randomized but subjects are not chosen at random from a population, randomization tests are more appropriate}
}

@article{luf93cal,
  title = {Calculating the Probability of Rare Events: {{Why}} Settle for an Approximation?},
  author = {Luft, H. S. and Brown, B. W.},
  date = {1993},
  journaltitle = {Hlth Serv Res},
  volume = {28},
  pages = {419--439},
  citeulike-article-id = {13264547},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  note = {comparing observed and predicted from a logistic model (?)}
}

@article{lum09ove,
  title = {Overinterpretation of Clinical Applicability in Molecular Diagnostic Research},
  author = {Lumbreras, B. and Parker, L. A. and Porta, M. and Pollan, M. and Ioannidis, J. P. and Hernandez-Aguado, I.},
  date = {2009},
  journaltitle = {Clin Chem},
  volume = {55},
  pages = {786--94},
  citeulike-article-id = {13265847},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  note = {authors of 108 studies who were laboratory scientists were 19-fold more likely to overinterpret the clinical utility of molecular diagnostic tests compared with clinic-based authors}
}

@article{lun01cum,
  title = {Cumulative Logit Models for Ordinal Data: A Case Study Involving Allergic Rhinitis Severity Scores},
  author = {Lunn, David J. and Wakefield, Jon and Racine-Poon, Amy},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2261--2285},
  citeulike-article-id = {13265215},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {bugs-code,generalized-ordinal-regression-models-using-latent-variables,mixed-effects-models,random-effects,repeated-measurements,serial-data}
}

@article{lun01cuma,
  title = {Cumulative Logit Models for Ordinal Data: A Case Study Involving Allergic Rhinitis Severity Scores},
  shorttitle = {Cumulative Logit Models for Ordinal Data},
  author = {Lunn, David J. and Wakefield, Jon and Racine-Poon, Amy},
  date = {2001},
  journaltitle = {Statistics in Medicine},
  volume = {20},
  number = {15},
  pages = {2261--2285},
  issn = {1097-0258},
  doi = {10.1002/sim.922},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.922},
  urldate = {2021-10-21},
  abstract = {Ordered categorical data arise in numerous settings, a common example being pain scores in analgesic trials. The modelling of such data is intrinsically more difficult than the modelling of continuous data due to the constraints on the underlying probabilities and the reduced amount of information that discrete outcomes contain. In this paper we discuss the class of cumulative logit models, which provide a natural framework for ordinal data analysis. We show how viewing the categorical outcome as the discretization of an underlying continuous response allows a natural interpretation of model parameters. We also show how covariates are incorporated into the model and how various types of correlation among repeated measures on the same individual may be accounted for. The models are illustrated using longitudinal allergy data consisting of sneezing scores measured on a four-point scale. Our approach throughout is Bayesian and we present a range of simple diagnostics to aid model building. Copyright © 2001 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {bayes,markov,ordinal,random-effects,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.922},
  note = {Has an example where variance of random effects is greatly reduced when modeling serial dependence using a Markov model vs. using the ordinary random effects model, stating that within-subject variation is mostly explained by serial correlation.}
}

@article{lun04str,
  title = {Stratification and Weighting via the Propensity Score in Estimation of Causal Treatment Effects: A Comparative Study},
  author = {Lunceford, Jared K. and Davidian, Marie},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  pages = {2937--2960},
  citeulike-article-id = {13265389},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {covariate-balance,double-robustness,horvitz-thompson-estimator,observational-data,propensity},
  note = {"Theoretical and empirical results indicate that the popular version of stratification via estimated propensity scores based on within-stratum sample mean differences and a fixed number of strata can lead to biased inference due to residual confounding, and the effect of this bias becomes more serious with increasing sample size. Using more strata can increase the sample size at which the trade-off of bias and variability involved in efficiency takes place, but stratifying on quintiles seems to be the most popular approach in practice, even for substantial sample sizes. Thus, as the trade-off point will be unknown for any specific problem, this approach should be used with caution. An interesting avenue for future research would be to establish guidelines for choosing the number of strata based on theoretical analysis of the rate at which the number of strata should increase with sample size to eliminate bias. A modification of stratification based instead on within-stratum regression estimates of treatment effect can eliminate this bias and achieve dramatic improvements in efficiency, but correct specification of the regression model is essential; otherwise, bias and degradation of performance can result. In this regard, this approach is similar to estimating causal effects via direct regression modelling but is less sensitive to mismodelling. Methods based on weighting are consistent and offer approximately unbiased inference for practical sample sizes. The semiparametric efficient estimator identified by the theory of Robins et al. [13], which incorporates regression modelling as a way to gain efficiency, also yields high precision. Although stratification based on regression and direct modelling can outperform this approach under some conditions, this estimator enjoys the unique 'double robustness' property in that it continues to lead to unbiased estimation of the average causal effect even if the regression models involved do not coincide with the true relationship, affording the analyst broad protection against misspecification not available with these other approaches. The results presented here support routine use of this estimator in practice."; nice derivations of inner workings of propensity score}
}

@article{lun09bug,
  title = {The {{BUGS}} Project: {{Evolution}}, Critique and Future Directions (with Discussion)},
  author = {Lunn, David and Spiegelhalter, David and Thomas, Andrew and Best, Nicky},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {3049--3082},
  citeulike-article-id = {13265785},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {bayesian-modeling,bugs,openbugs}
}

@article{lun95app,
  title = {Applying {{Cox}} Regression to Competing Risks},
  author = {Lunn, Mary and McNeil, Don},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {524--532},
  citeulike-article-id = {13264548},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {byar-prostate-cancer-dataset,competing-risks,extensions-of-cox-model,multiple-events},
  note = {ordinary variance OK when subjects have only one event}
}

@article{lun98not,
  title = {A Note on Generating Correlated Binary Variables},
  author = {Lunn, A. D. and Davies, S. J.},
  date = {1998},
  journaltitle = {Biometrika},
  volume = {85},
  pages = {487--490},
  citeulike-article-id = {13264549},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {autoregressive-correlation-structure,bootstrap,correlated-binary-variates,exchangeable-correlation-structure,generating-random-variables,multivariate,simulation}
}

@article{luo06tun,
  title = {Tuning Variable Selection Procedures by Adding Noise},
  author = {Luo, Xiaohui and Stfanski, Leonard A. and Boos, Dennis D.},
  date = {2006},
  journaltitle = {Technometrics},
  volume = {48},
  pages = {165--175},
  citeulike-article-id = {13265470},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {aic,bic,cp,forward-selection,model-selection,simex,variable-selection},
  note = {adding a known amount of noise to the response and studying σ² to tune the stopping rule to avoid overfitting or underfitting;simulation setup}
}

@article{luo16can,
  title = {Canonical Variate Regression},
  author = {Luo, Chongliang and Liu, Jin and Dey, Dipak K. and Chen, Kun},
  date = {2016-07},
  journaltitle = {Biostatistics},
  volume = {17},
  number = {3},
  eprint = {26861909},
  eprinttype = {pmid},
  pages = {468--483},
  publisher = {Oxford University Press},
  issn = {1468-4357},
  doi = {10.1093/biostatistics/kxw001},
  url = {http://dx.doi.org/10.1093/biostatistics/kxw001},
  abstract = {In many fields, multi-view datasets, measuring multiple distinct but interrelated sets of characteristics on the same set of subjects, together with data on certain outcomes or phenotypes, are routinely collected. The objective in such a problem is often two-fold: both to explore the association structures of multiple sets of measurements and to develop a parsimonious model for predicting the future outcomes. We study a unified canonical variate regression framework to tackle the two problems simultaneously. The proposed criterion integrates multiple canonical correlation analysis with predictive modeling, balancing between the association strength of the canonical variates and their joint predictive power on the outcomes. Moreover, the proposed criterion seeks multiple sets of canonical variates simultaneously to enable the examination of their joint effects on the outcomes, and is able to handle multivariate and non-Gaussian outcomes. An efficient algorithm based on variable splitting and Lagrangian multipliers is proposed. Simulation studies show the superior performance of the proposed approach. We demonstrate the effectiveness of the proposed approach in an F\_2 intercross mice study and an alcohol dependence study.},
  citeulike-article-id = {14070617},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biostatistics/kxw001},
  citeulike-linkout-1 = {http://biostatistics.oxfordjournals.org/content/17/3/468.abstract},
  citeulike-linkout-2 = {http://biostatistics.oxfordjournals.org/content/17/3/468.full.pdf},
  citeulike-linkout-3 = {http://biostatistics.oxfordjournals.org/cgi/content/abstract/17/3/468},
  citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/26861909},
  citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=26861909},
  day = {1},
  posted-at = {2016-06-16 23:46:45},
  priority = {2},
  keywords = {canonical-correlation,canonical-variates,multivariate-analysis}
}

@article{luo21bay,
  title = {Bayesian Latent Multi-State Modeling for Nonequidistant Longitudinal Electronic Health Records},
  author = {Luo, Yu and Stephens, David A. and Verma, Aman and Buckeridge, David L.},
  date = {2021},
  journaltitle = {Biometrics},
  volume = {77},
  number = {1},
  pages = {78--90},
  issn = {1541-0420},
  doi = {10.1111/biom.13261},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13261},
  urldate = {2021-03-10},
  abstract = {Large amounts of longitudinal health records are now available for dynamic monitoring of the underlying processes governing the observations. However, the health status progression across time is not typically observed directly: records are observed only when a subject interacts with the system, yielding irregular and often sparse observations. This suggests that the observed trajectories should be modeled via a latent continuous-time process potentially as a function of time-varying covariates. We develop a continuous-time hidden Markov model to analyze longitudinal data accounting for irregular visits and different types of observations. By employing a specific missing data likelihood formulation, we can construct an efficient computational algorithm. We focus on Bayesian inference for the model: this is facilitated by an expectation-maximization algorithm and Markov chain Monte Carlo methods. Simulation studies demonstrate that these approaches can be implemented efficiently for large data sets in a fully Bayesian setting. We apply this model to a real cohort where patients suffer from chronic obstructive pulmonary disease with the outcome being the number of drugs taken, using health care utilization indicators and patient characteristics as covariates.},
  langid = {english},
  keywords = {continuous-time-markov-chain,ehr,latent-variable,markov,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13261}
}

@article{lur02sea,
  title = {Seamlessly Expanding a Randomized Phase {{II}} Trial to Phase {{III}}},
  author = {Lurdes, Y. T. and Thall, P. F. and Berry, D. A.},
  date = {2002},
  journaltitle = {Biometrics},
  volume = {58},
  number = {4},
  pages = {823--831},
  doi = {10.1111/j.0006-341X.2002.00823.x},
  url = {http://dx.doi.org/10.1111/j.0006-341X.2002.00823.x},
  citeulike-article-id = {13265653},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/j.0006-341X.2002.00823.x},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {bayesian-methods,drug-development,rct,seamless-phase-ii-iii}
}

@article{lus07app,
  title = {Appropriateness of Some Resampling-Based Inference Procedures for Assessing Performance of Prognostic Classifiers Derived from Microarray Data},
  author = {Lusa, Lara and McShane, Lisa M. and Radmacher, Michael D. and Shih, Joanna H. and Wright, George W. and Simon, Richard},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {1102--1113},
  citeulike-article-id = {13265562},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {classification,cross-validation,gene-expression,microarray,molecular-profiling,resampling},
  note = {demonstrates how unbelievably naive it is to test the correlation between predictions from "THE cross-validated classifier" and the observed outcome}
}

@article{lyd09rec,
  title = {Recommended Tests for Association in 2 2 Tables},
  author = {Lydersen, Stian and Fagerland, Morten W. and Laake, Petter},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {1159--1175},
  citeulike-article-id = {13265736},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {2times-2-tables,fishers-exact-test},
  note = {Fisher's test should never be used unless the mid-P correction is applied;value of unconditional tests;see letter to the editor 30:890-891;2011}
}

@article{lyl07pra,
  title = {A Practical Approach to Computing Power for Generalized Linear Models with Nominal, Count, or Ordinal Responses},
  author = {Lyles, Robert H. and Lin, Hung-Mo and Williamson, John M.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {1632--1648},
  citeulike-article-id = {13265564},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {likelihood-ratio,noncentral-chi-square-distribution,ordinal-response,power,regression,sample-size,wald-statistics}
}

@article{lyn95acc,
  title = {Accurate Prognostications of Death: {{Opportunities}} and Challenges for Clinicians},
  author = {Lynn, J. and Teno, J. M. and {Jr}},
  date = {1995},
  journaltitle = {W J Med},
  volume = {163},
  pages = {250--257},
  citeulike-article-id = {13264550},
  posted-at = {2014-07-14 14:09:37},
  priority = {0}
}

@article{lyn96def,
  title = {Defining `terminally Ill': {{Insights}} from {{SUPPORT}}},
  author = {Lynn, J. and Harrell, F. E. and Cohn, F. and Hamel, M. B. and Dawson, N. and Wu, A. W.},
  date = {1996},
  journaltitle = {Duquesne Law J},
  volume = {35},
  pages = {311--336},
  citeulike-article-id = {13264551},
  posted-at = {2014-07-14 14:09:37},
  priority = {0}
}

@article{lyn96sta,
  title = {Statistical Issues in Biologics Submissions to the {{FDA}}},
  author = {Lynch, Cornelius J. and Lachenbruch, Peter A.},
  date = {1996},
  journaltitle = {Drug Info J},
  volume = {30},
  pages = {921--932},
  doi = {10.1177/009286159603000408},
  url = {http://dx.doi.org/10.1177/009286159603000408},
  citeulike-article-id = {13264552},
  citeulike-linkout-0 = {http://dx.doi.org/10.1177/009286159603000408},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {checklist,clinical-trials,rct,reporting,study-design,teaching-mds},
  note = {checklist for design and reporting of pharmaceutical studies}
}

@article{lyn97pro,
  title = {Prognoses of Seriously Ill Hospitalized Patients on the Days before Death: {{Implications}} for Patient Care and Public Policy},
  author = {Lynn, J. and Harrell, F. E. and Cohn, F. and Wagner, D. and Connors, A. F.},
  date = {1997},
  journaltitle = {New Horizons},
  volume = {5},
  pages = {56--61},
  citeulike-article-id = {13264553},
  posted-at = {2014-07-14 14:09:37},
  priority = {0}
}

@article{mac00sci,
  title = {Scientific {{Method}}, {{Statistical Method}} and the {{Speed}} of {{Light}}},
  author = {MacKay, R. J. and Oldford, R. W.},
  date = {2000-08-01},
  journaltitle = {Statist. Sci.},
  volume = {15},
  number = {3},
  pages = {254--278},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1009212817},
  url = {https://projecteuclid.org/euclid.ss/1009212817},
  urldate = {2019-09-16},
  abstract = {What is “statistical method”? Is it the same as “scientific method”? This paper answers the first question by specifying the elements and procedures common to all statistical investigations and organizing these into a single structure. This structure is illustrated by careful examination of the first scientific study on the speed of light carried out by A. A. Michelson in 1879. Our answer to the second question is negative. To understand this a history on the speed of light up to the time of Michelson’s study is presented. The larger history and the details of a single study allow us to place the method of statistics within the larger context of science.},
  langid = {english},
  mrnumber = {MR1847825},
  zmnumber = {1059.62507},
  keywords = {experimental-design,scientific-approach,scientific-thinking}
}

@article{mac01gen,
  title = {Gene Expression Analysis of Medulloblastoma: Prognosis Prediction and Identification of Therapeutic Targets},
  author = {MacDonald, T. J. and Brown, K. M. and LaFleur, B. J. and Peterson, K. and Lawlor, C. and Packer, R. and Cogen, P. and Chen, Y. and {Stephan}},
  date = {2001},
  journaltitle = {Nat Gen},
  volume = {29},
  pages = {143--152},
  citeulike-article-id = {13265499},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{mac09goo,
  title = {Good {{Laboratory Practice}}: {{Preventing Introduction}} of {{Bias}} at the {{Bench}}},
  author = {Macleod, Malcolm R. and Fisher, Marc and O'Collins, Victoria and Sena, Emily S. and Dirnagl, Ulrich and Bath, Philip M. W. and Buchan, Alistair and van der Worp, H. Bart and Traystman, Richard and Minematsu, Kazuo and Donnan, Geoffrey A. and Howells, David W.},
  options = {useprefix=true},
  date = {2009-03},
  journaltitle = {Stroke},
  volume = {40},
  number = {3},
  eprint = {18703798},
  eprinttype = {pmid},
  pages = {e50-e52},
  publisher = {Lippincott Williams & Wilkins},
  issn = {1524-4628},
  doi = {10.1161/strokeaha.108.525386},
  url = {http://dx.doi.org/10.1161/strokeaha.108.525386},
  abstract = {Background and Purpose— As a research community, we have failed to demonstrate that drugs which show substantial efficacy in animal models of cerebral ischemia can also improve outcome in human stroke.Summary of Review— Accumulating evidence suggests this may be due, at least in part, to problems in the design, conduct and reporting of animal experiments which create a systematic bias resulting in the overstatement of neuroprotective efficacy.Conclusions— Here, we set out a series of measures to reduce bias in the design, conduct and reporting of animal experiments modeling human stroke.},
  citeulike-article-id = {10877479},
  citeulike-linkout-0 = {http://dx.doi.org/10.1161/strokeaha.108.525386},
  citeulike-linkout-1 = {http://stroke.ahajournals.org/content/40/3/e50.abstract},
  citeulike-linkout-2 = {http://stroke.ahajournals.org/content/40/3/e50.full.pdf},
  citeulike-linkout-3 = {http://stroke.ahajournals.org/cgi/content/abstract/40/3/e50},
  citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/18703798},
  citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=18703798},
  day = {1},
  posted-at = {2015-02-08 19:01:59},
  priority = {2},
  keywords = {animal,experimental-design,laboratory-data}
}

@article{mac21pre,
  title = {Predicting Study Duration in Clinical Trials with a Time-to-Event Endpoint},
  author = {Machida, Ryunosuke and Fujii, Yosuke and Sozu, Takashi},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8911},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8911},
  urldate = {2021-02-14},
  abstract = {In event-driven clinical trials comparing the survival functions of two groups, the number of events required to achieve the desired power is usually calculated using the Freedman formula or the Schoenfeld formula. Then, the sample size and the study duration derived from the required number of events are considered; however, their combination is not uniquely determined. In practice, various combinations are examined considering the enrollment speed, study duration, and the cost of enrollment. However, effective methods for visually representing their relationships and evaluating the uncertainty in study duration are insufficient. We developed a graphical approach for examining the relationship between sample size and study duration. To evaluate the uncertainty in study duration under a given sample size, we also derived the probability density function of the study duration and a method for updating the probability density function according to the observed number of events (ie, information time). The proposed methods are expected to improve the operation and management of clinical trials with a time-to-event endpoint.},
  langid = {english},
  keywords = {enrollment,logistics,prediction,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8911}
}

@article{mac97com,
  title = {A Comparison of Quantitative Computerized and Human Panel Coronary Endpoint Measures: {{Implications}} for the Design of Angiographic Trials},
  author = {Mack, Wendy J. and Azen, Stanley P. and Dunn, Meleana and Hodis, Howard N.},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {168--179},
  citeulike-article-id = {13264554},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {arteriosclerosis,cad,coronary-artery-disease,digital-angiography}
}

@article{mac98bia,
  title = {Bias in the Interpretation and Use of Research Results},
  author = {MacCoun, Robert J.},
  date = {1998},
  journaltitle = {Ann Rev Psychol},
  volume = {49},
  pages = {259--287},
  citeulike-article-id = {13265878},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  note = {quotes Robert Merton (1973) four norms of science: universalism, communism (public sharing of scientific information), disinterestedness, organized skepticism (scientific community must hold new findings to strict levels of scrutiny, through peer review, replication, and the testing of rival hypotheses}
}

@article{mac98whi,
  title = {Which Sums of Squares Are Best in Unbalanced Analysis of Variance?},
  author = {Macnaughton, D. B.},
  date = {1998},
  url = {http://www.matstat.com/ss},
  citeulike-article-id = {13264555},
  posted-at = {2014-07-14 14:09:37},
  priority = {0}
}

@article{mad13lar,
  title = {Large-Scale Parametric Survival Analysis},
  author = {Mittal, Sushil and Madigan, David and Cheng, Jerry Q. and Burd, Randall S.},
  date = {2013-10},
  journaltitle = {Stat Med},
  volume = {32},
  number = {23},
  pages = {3955--3971},
  doi = {10.1002/sim.5817},
  url = {http://dx.doi.org/10.1002/sim.5817},
  abstract = {Survival analysis has been a topic of active statistical research in the past few decades with applications spread across several areas. Traditional applications usually consider data with only a small numbers of predictors with a few hundreds or thousands of observations. Recent advances in data acquisition techniques and computation power have led to considerable interest in analyzing very-high-dimensional data where the number of predictor variables and the number of observations range between 10 4 and 10 6. In this paper, we present a tool for performing large-scale regularized parametric survival analysis using a variant of the cyclic coordinate descent method. Through our experiments on two real data sets, we show that application of regularized models to high-dimensional data avoids overfitting and can provide improved predictive performance and calibration over corresponding low-dimensional models.},
  citeulike-article-id = {13448172},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5817},
  day = {15},
  posted-at = {2014-11-29 16:58:07},
  priority = {2},
  keywords = {high-dimensional-data,multivariable-modeling,parametric-survival-model,survival-analysis}
}

@article{mad19pro,
  title = {The Proportion of Missing Data Should Not Be Used to Guide Decisions on Multiple Imputation},
  author = {Madley-Dowd, Paul and Hughes, Rachael and Tilling, Kate and Heron, Jon},
  date = {2019-06-01},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {110},
  pages = {63--73},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2019.02.016},
  url = {http://www.sciencedirect.com/science/article/pii/S0895435618308710},
  urldate = {2019-09-14},
  abstract = {Objectives Researchers are concerned whether multiple imputation (MI) or complete case analysis should be used when a large proportion of data are missing. We aimed to provide guidance for drawing conclusions from data with a large proportion of missingness. Study Design and Setting Via simulations, we investigated how the proportion of missing data, the fraction of missing information (FMI), and availability of auxiliary variables affected MI performance. Outcome data were missing completely at random or missing at random (MAR). Results Provided sufficient auxiliary information was available; MI was beneficial in terms of bias and never detrimental in terms of efficiency. Models with similar FMI values, but differing proportions of missing data, also had similar precision for effect estimates. In the absence of bias, the FMI was a better guide to the efficiency gains using MI than the proportion of missing data. Conclusion We provide evidence that for MAR data, valid MI reduces bias even when the proportion of missingness is large. We advise researchers to use FMI to guide choice of auxiliary variables for efficiency gain in imputation analyses, and that sensitivity analyses including different imputation models may be needed if the number of complete cases is small.},
  keywords = {missing}
}

@book{mad83lim,
  title = {Limited-{{Dependent}} and {{Qualitative Variables}} in {{Econometrics}}},
  author = {Maddala, G. S.},
  date = {1983},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge, UK}},
  citeulike-article-id = {13264556},
  posted-at = {2014-07-14 14:09:37},
  priority = {0}
}

@article{mag90r2,
  title = {{{R}}² Measures Based on {{Wald}} and Likelihood Ratio Joint Significance Tests},
  author = {Magee, Lonnie},
  date = {1990},
  journaltitle = {Am Statistician},
  volume = {44},
  pages = {250--253},
  citeulike-article-id = {13264557},
  posted-at = {2014-07-14 14:09:37},
  priority = {0}
}

@article{mag91com,
  title = {Computing Kernal-Smoothed Conditional Quantiles from Many Observations},
  author = {{Magee} and Burbidge, J. B. and Robb, A. L.},
  date = {1991},
  journaltitle = {J Am Stat Assoc},
  volume = {86},
  pages = {673--677},
  citeulike-article-id = {13264558},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {quantile}
}

@article{mag98non,
  title = {Nonlocal Behavior in Polynomial Regressions},
  author = {Magee, Lonnie},
  date = {1998},
  journaltitle = {Am Statistician},
  volume = {52},
  pages = {20--22},
  citeulike-article-id = {13264559},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {polynomial,robustness}
}

@article{mai21com,
  title = {A Comparison of Multiple Imputation Strategies for Handling Missing Data in Multi-Item Scales: {{Guidance}} for Longitudinal Studies},
  shorttitle = {A Comparison of Multiple Imputation Strategies for Handling Missing Data in Multi-Item Scales},
  author = {Mainzer, Rheanna and Apajee, Jemishabye and Nguyen, Cattram D. and Carlin, John B. and Lee, Katherine J.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9088},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9088},
  urldate = {2021-06-09},
  abstract = {Medical research often involves using multi-item scales to assess individual characteristics, disease severity, and other health-related outcomes. It is common to observe missing data in the scale scores, due to missing data in one or more items that make up that score. Multiple imputation (MI) is a popular method for handling missing data. However, it is not clear how best to use MI in the context of scale scores, particularly when they are assessed at multiple waves of data collection resulting in large numbers of items. The aim of this article is to provide practical advice on how to impute missing values in a repeatedly measured multi-item scale using MI when inference on the scale score is of interest. We evaluated the performance of five MI strategies for imputing missing data at either the item or scale level using simulated data and a case study based on four waves of the Longitudinal Study of Australian Children (LSAC). MI was implemented using both multivariate normal imputation and fully conditional specification, with two rules for calculating the scale score. A complete case analysis was also performed for comparison. Based on our results, we caution against the use of a MI strategy that does not include the scale score in the imputation model(s) when the scale score is required for analysis.},
  langid = {english},
  keywords = {longitudinal,mi,missing,scales,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9088}
}

@article{mak17pol,
  title = {Polygenic Scores via Penalized Regression on Summary Statistics.},
  author = {Heng, Timothy Shin and Milan, Robert and Wan, Shing and Zhou, Xueya and Chung, Pak},
  date = {2017-09},
  journaltitle = {Gen Epi},
  volume = {41},
  number = {6},
  eprint = {28480976},
  eprinttype = {pmid},
  pages = {469--480},
  issn = {1098-2272},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/28480976},
  abstract = {Polygenic scores (PGS) summarize the genetic contribution of a person's genotype to a disease or phenotype. They can be used to group participants into different risk categories for diseases, and are also used as covariates in epidemiological analyses. A number of possible ways of calculating PGS have been proposed, and recently there is much interest in methods that incorporate information available in published summary statistics. As there is no inherent information on linkage disequilibrium (LD) in summary statistics, a pertinent question is how we can use LD information available elsewhere to supplement such analyses. To answer this question, we propose a method for constructing PGS using summary statistics and a reference panel in a penalized regression framework, which we call lassosum. We also propose a general method for choosing the value of the tuning parameter in the absence of validation data. In our simulations, we showed that pseudovalidation often resulted in prediction accuracy that is comparable to using a dataset with validation phenotype and was clearly superior to the conservative option of setting the tuning parameter of lassosum to its lowest value. We also showed that lassosum achieved better prediction accuracy than simple clumping and P-value thresholding in almost all scenarios. It was also substantially faster and more accurate than the recently proposed LDpred.},
  citeulike-article-id = {14595150},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/28480976},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=28480976},
  posted-at = {2018-05-27 20:09:41},
  priority = {2},
  keywords = {genetic,genetic-association-studies,genetics,idiot-bayes,lasso,penalization,penalized-mle},
  note = {discusses naive Bayes (idiot Bayes). Decomposes the penalized lasso likelihood and shows how pieces of it can be estimated from other sources. Discusses loss of accuracy of naive Bayes if predictors are correlated.}
}

@article{mak89,
  title = {Issues in Planning and Interpreting Active Control Equivalence Studies},
  author = {Makuch, R. and Johnson, M.},
  date = {1989},
  journaltitle = {J Clin Epi},
  volume = {42},
  pages = {503--511},
  citeulike-article-id = {13264560},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {pharmaceutical,study-design-and-stopping-rules}
}

@article{mal01con,
  title = {Contrasting {{Bayesian}} Analysis of Survey Data and Clinical Trials},
  author = {Malec, Donald J.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1363--1371},
  citeulike-article-id = {13265192},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {bayesian-methods,choice-of-prior,contrast-with-frequentist,model-checking,nonparametric-evaluation-of-models,selection-bias,sensitivity-analysis}
}

@article{mal08rec,
  title = {Recommendations for the Primary Analysis of Continuous Endpoints in Longitudinal Clinical Trials},
  author = {Mallinckrodt, Craig H. and Lane, Peter W. and Schnell, Dan and Peng, Yahong and Mancuso, James P.},
  date = {2008},
  journaltitle = {Drug Info J},
  volume = {42},
  pages = {303--319},
  citeulike-article-id = {13265682},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {clinical-trials,last-observation-carried-forward,locf,longitudinal-data,missing-data,primary-analysis,rct,serial-data},
  note = {excellent comprehensive review of deficiencies of LOCF and a push for model-based analysis;problems of full models such as mixed models when missing is not at random are actually worse with LOCF;explaination of biases of LOCF and its use of non-design-based endpoint or improper imputation;paper falsely assumed change scores are appropriate;emphasized saturated correlation and time model;LOCF's conservatism in one setting may be seen as anti-conservative in another, e.g., non-inferiority trial;did not address time zero response issue or ANCOVA}
}

@article{mal16cho,
  title = {Choosing Estimands in Clinical Trials with Missing Data},
  author = {Mallinckrodt, Craig and Molenberghs, Geert and Rathmann, Suchitrita},
  date = {2016},
  journaltitle = {Pharm Stat},
  issn = {15391604},
  doi = {10.1002/pst.1765},
  url = {http://dx.doi.org/10.1002/pst.1765},
  citeulike-article-id = {14112178},
  citeulike-attachment-1 = {mal16cho.pdf; /pdf/user/harrelfe/article/14112178/1080331/mal16cho.pdf; 5197eb9c00bebc23d40985e3f85533758b7ca9a9},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1765},
  posted-at = {2016-08-12 12:39:08},
  priority = {3},
  keywords = {estimand,missing-data,rct,serial-data}
}

@article{mal98zer,
  title = {The Zeroth Problem},
  author = {Mallows, Colin},
  date = {1998},
  journaltitle = {Am Statistician},
  volume = {52},
  pages = {1--9},
  citeulike-article-id = {13264561},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {model-choice,model-specification},
  note = {HG Wells 1903 quote:"Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write"}
}

@article{mal99bay,
  title = {Bayes Offers a `{{New}}' Way to Make Sense of Numbers},
  author = {Malakoff, David},
  date = {1999},
  journaltitle = {Science},
  volume = {286},
  pages = {1460--1464},
  doi = {10.1126/science.286.5444.1460},
  url = {http://dx.doi.org/10.1126/science.286.5444.1460},
  citeulike-article-id = {13265096},
  citeulike-linkout-0 = {http://dx.doi.org/10.1126/science.286.5444.1460},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {bayes,clinical-trials,rct,teaching}
}

@article{man05eva,
  title = {Evaluating Survival Model Performance: A Graphical Approach},
  author = {Mandel, M. and Galae, N. and Simchen, E.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {1933--1945},
  citeulike-article-id = {13265430},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {bootstrap,discrimination,explained-variation,predictive-accuracy,roc-curve,time-varying-c-index,time-varying-effect}
}

@article{man05sta,
  title = {Statistical Modeling of the Differences between Successive {{R-R}} Intervals},
  author = {Mandrekar, Sumithra J. and Nagaraja, Haikady N. and Berntson, Gary G.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {437--451},
  citeulike-article-id = {13265401},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {ecg,heart-rate-variability,r-r-interval,successive-difference,weibull-distribution}
}

@article{man07cen,
  title = {Censoring and Truncation---{{Highlighting}} the Differences},
  author = {Mandel, Micha},
  date = {2007},
  journaltitle = {Am Statistician},
  volume = {61},
  number = {4},
  pages = {321--324},
  citeulike-article-id = {13265641},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  note = {good exposition of censoring vs. truncation}
}

@article{man08est,
  title = {Estimating Time-to-Event from Longitudinal Ordinal Data Using Random-Effects {{Markov}} Models: Application to Multiple Sclerosis Progression.},
  shorttitle = {Estimating Time-to-Event from Longitudinal Ordinal Data Using Random-Effects {{Markov}} Models},
  author = {Mandel, M. and Betensky, R.},
  date = {2008},
  journaltitle = {Biostatistics},
  doi = {10.1093/biostatistics/kxn008},
  abstract = {Longitudinal ordinal data are common in many scientific studies, including those of multiple sclerosis (MS), and are frequently modeled using Markov dependency. Several authors have proposed random-effects Markov models to account for heterogeneity in the population. In this paper, we go one step further and study prediction based on random-effects Markov models. In particular, we show how to calculate the probabilities of future events and confidence intervals for those probabilities, given observed data on the ordinal outcome and a set of covariates, and how to update them over time. We discuss the usefulness of depicting these probabilities for visualization and interpretation of model results and illustrate our method using data from a phase III clinical trial that evaluated the utility of interferon beta-1a (trademark Avonex) to MS patients of type relapsing-remitting.},
  keywords = {derived-outcome,markov-model,ordinal,random-effects,serial}
}

@article{man10ord,
  title = {Ordinal {{Regression Models}} for {{Continuous Scales}}},
  author = {Manuguerra, Maurizio and Heller, Gillian Z.},
  date = {2010-01},
  journaltitle = {Int J Biostat},
  volume = {6},
  number = {1},
  issn = {1557-4679},
  doi = {10.2202/1557-4679.1230},
  url = {http://dx.doi.org/10.2202/1557-4679.1230},
  citeulike-article-id = {14232080},
  citeulike-attachment-1 = {man10ord.pdf; /pdf/user/harrelfe/article/14232080/1095623/man10ord.pdf; f785bd1ab161455888b01617df621ddd57f8daa0},
  citeulike-linkout-0 = {http://dx.doi.org/10.2202/1557-4679.1230},
  day = {6},
  posted-at = {2016-12-22 15:03:30},
  priority = {0},
  keywords = {ordinal-regression,ordinal-response},
  note = {mislabeled a flexible parametric model as semi-parametric; does not cover semi-parametric approach with lots of intercepts}
}

@article{man17han,
  title = {Handling Time Varying Confounding in Observational Research},
  author = {Mansournia, Mohammad Ali and Etminan, Mahyar and Danaei, Goodarz and Kaufman, Jay S. and Collins, Gary},
  date = {2017-10-16},
  journaltitle = {BMJ},
  volume = {359},
  eprint = {29038130},
  eprinttype = {pmid},
  pages = {j4587},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1756-1833},
  doi = {10.1136/bmj.j4587},
  url = {https://www.bmj.com/content/359/bmj.j4587},
  urldate = {2021-09-15},
  abstract = {{$<$}p{$>$}Many exposures of epidemiological interest are time varying, and the values of potential confounders may change over time leading to time varying confounding. The aim of many longitudinal studies is to estimate the causal effect of a time varying exposure on an outcome that requires adjusting for time varying confounding. Time varying confounding affected by previous exposure often occurs in practice, but it is usually adjusted for by using conventional analytical methods such as time dependent Cox regression, random effects models, or generalised estimating equations, which are known to provide biased effect estimates in this setting. This article explains time varying confounding affected by previous exposure and outlines three causal methods proposed to appropriately adjust for this potential bias: inverse-probability-of-treatment weighting, the parametric G formula, and G estimation\emph{.}{$<$}/p{$>$}},
  langid = {english},
  keywords = {confounding,g-estimation,teaching-mds,time-dependent-confounding}
}

@article{man70why,
  title = {Why Stepdown Procedures in Variable Selection},
  author = {Mantel, Nathan},
  date = {1970},
  journaltitle = {Technometrics},
  volume = {12},
  pages = {621--625},
  citeulike-article-id = {13264562},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {collinearity,variable-selection}
}

@article{man74,
  title = {Evaluation of Response-Time Data Involving Transient States: {{An}} Illustration Using Heart-Transplant Data},
  author = {Mantel, N. and Byar, D. P.},
  date = {1974},
  journaltitle = {J Am Stat Assoc},
  volume = {69},
  pages = {81--86},
  citeulike-article-id = {13264563},
  posted-at = {2014-07-14 14:09:37},
  priority = {0}
}

@book{man84sta,
  title = {The {{Statistical Analysis}} of {{Experimental Data}}},
  author = {Mandel, J.},
  date = {1984},
  publisher = {{Dover Publications}},
  citeulike-article-id = {13265521},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{man96com,
  title = {A Comparative Study of Four Methods for Analysing Repeated Measures Data},
  author = {Manor, Orly and Kark, Jeremy D.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1143--1159},
  citeulike-article-id = {13264564},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {comparative-study,longitudinal,repeated-measures}
}

@article{man96eff,
  title = {Efficiency of Regression Estimates for Clustered Data},
  author = {Mancl, Lloyd A. and Leroux, Brian G.},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {500--511},
  citeulike-article-id = {13264565},
  posted-at = {2014-07-14 14:09:37},
  priority = {0},
  keywords = {cluster-randomization,clustered-data,gee,logistic-model,working-independence-model}
}

@article{man98hea,
  title = {Health Services Research Clinical Trials: {{Issues}} in the Evaluation of Economic Costs and Benefits},
  author = {Manheim, Larry M.},
  date = {1998},
  journaltitle = {Controlled Clin Trials},
  volume = {19},
  pages = {149--158},
  citeulike-article-id = {13264566},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {cost,health-economics,health-services-research,study-design}
}

@article{mao20cla,
  title = {A Class of Proportional Win-Fractions Regression Models for Composite Outcomes},
  author = {Mao, Lu and Wang, Tuo},
  date = {2020},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13382},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13382},
  urldate = {2020-09-25},
  abstract = {The win ratio is gaining traction as a simple and intuitive approach to analysis of prioritized composite endpoints in clinical trials. To extend it from two-sample comparison to regression, we propose a novel class of semiparametric models that includes as special cases both the two-sample win ratio and the traditional Cox proportional hazards model on time to the first event. Under the assumption that the covariate-specific win and loss fractions are proportional over time, the regression coefficient is unrelated to the censoring distribution and can be interpreted as the log win ratio resulting from one-unit increase in the covariate. U-statistic estimating functions, in the form of an arbitrary covariate-specific weight process integrated by a pairwise residual process, are constructed to obtain consistent estimators for the regression parameter. The asymptotic properties of the estimators are derived using uniform weak convergence theory for U-processes. Visual inspection of a “score” process provides useful clues as to the plausibility of the proportionality assumption. Extensive numerical studies using both simulated and real data from a major cardiovascular trial show that the regression methods provide valid inference on covariate effects and outperform the two-sample win ratio in both efficiency and robustness. The proposed methodology is implemented in the R-package WR, publicly available from the Comprehensive R Archive Network (CRAN). This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {composit-endpoint,multiple-endpoints,RCT,win-ratio},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13382}
}

@article{mao21cla,
  title = {A Class of Proportional Win-Fractions Regression Models for Composite Outcomes},
  author = {Mao, Lu and Wang, Tuo},
  date = {2021},
  journaltitle = {Biometrics},
  volume = {77},
  number = {4},
  pages = {1265--1275},
  issn = {1541-0420},
  doi = {10.1111/biom.13382},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13382},
  urldate = {2022-01-01},
  abstract = {The win ratio is gaining traction as a simple and intuitive approach to analysis of prioritized composite endpoints in clinical trials. To extend it from two-sample comparison to regression, we propose a novel class of semiparametric models that includes as special cases both the two-sample win ratio and the traditional Cox proportional hazards model on time to the first event. Under the assumption that the covariate-specific win and loss fractions are proportional over time, the regression coefficient is unrelated to the censoring distribution and can be interpreted as the log win ratio resulting from one-unit increase in the covariate. U-statistic estimating functions, in the form of an arbitrary covariate-specific weight process integrated by a pairwise residual process, are constructed to obtain consistent estimators for the regression parameter. The asymptotic properties of the estimators are derived using uniform weak convergence theory for U-processes. Visual inspection of a “score” process provides useful clues as to the plausibility of the proportionality assumption. Extensive numerical studies using both simulated and real data from a major cardiovascular trial show that the regression methods provide valid inference on covariate effects and outperform the two-sample win ratio in both efficiency and robustness. The proposed methodology is implemented in the R-package WR, publicly available from the Comprehensive R Archive Network (CRAN).},
  langid = {english},
  keywords = {composit-endpoint,multiple-endpoints,rct,win-ratio},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13382}
}

@article{mao21res,
  title = {On Restricted Mean Time in Favor of Treatment},
  author = {Mao, Lu},
  date = {2021},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13570},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13570},
  urldate = {2021-09-27},
  abstract = {The restricted mean time in favor (RMT-IF) of treatment is a nonparametric effect size for complex life history data. It is defined as the net average time the treated spend in a more favorable state than the untreated over a pre-specified time window. It generalizes the familiar restricted mean survival time from the two-state life-death model to account for intermediate stages in disease progression. The overall estimand can be additively decomposed into stage-wise effects, with the standard restricted mean survival time as a component. Alternate expressions of the overall and stage-wise estimands as integrals of the marginal survival functions for a sequence of landmark transitioning events allow them to be easily estimated by plug-in Kaplan–Meier estimators. The dynamic profile of the estimated treatment effects as a function of follow-up time can be visualized using a multilayer, cone-shaped “bouquet plot”. Simulation studies under realistic settings show that the RMT-IF meaningfully and accurately quantifies the treatment effect and outperforms traditional tests on time to the first event in statistical efficiency thanks to its fuller utilization of patient data. The new methods are illustrated on a colon cancer trial with relapse and death as outcomes and a cardiovascular trial with recurrent hospitalizations and death as outcomes. The R-package rmt implements the proposed methodology and is publicly available from the Comprehensive R Archive Network (CRAN). This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {multiple-endpoints,multistate-model,restricted-mean-life},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13570},
  note = {The author's notation is gorgeous.
\par
"According to ICH-E9(R1) Addendum, such intercurrent events should be accounted for as part of the outcome rather than censoring'~ (mentions "discontinuation of treatment due to side effect, that terminates the follow-up and prevents subsequent events from being observed."
\par
Bouquet plot
\par
"Overall, patients undergoing exercise training gain an average of 5.1 months in a more favorable state compared with those under usual care only.~ This gain comprises an additional 2.9 months of survival time ... and an additional 2.2 months with fewer hospitalizations among the living"}
}

@article{map93mar,
  title = {Markers as Time-Dependent Covariates in Relative Risk Regression},
  author = {Workshop, Map},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2087--2098},
  citeulike-article-id = {13264567},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {intervening-events,markers,nonfatal-events,surrogate-endpoints,tdc}
}

@article{mar00use,
  title = {Use of a Secure Internet {{Web}} Site for Collaborative Medical Research},
  author = {Marshall, Wesley W. and Haley, Robert W.},
  date = {2000},
  journaltitle = {JAMA},
  volume = {284},
  pages = {1843--1849},
  citeulike-article-id = {13265235},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {database-management,reseach-data,security,web}
}

@article{mar01par,
  title = {Paradigm Shifts in Clinical Trials Enabled by Information Technology},
  author = {Marks, Ron and Conlon, Michael and Ruberg, Stephen J.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2683--2696},
  citeulike-article-id = {13265237},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {all-electronic-clinical-trial,data-management,multi-center-trial,web}
}

@article{mar01use,
  title = {The Use of Classification and Regression Trees in Clinical Epidemiology},
  author = {Marshall, Roger J.},
  date = {2001},
  journaltitle = {J Clin Epi},
  volume = {54},
  pages = {603--609},
  citeulike-article-id = {13265204},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {cart,recursive-partitioning},
  note = {many significant problems with the method identified;newer variations are unlikely to be helpful since they retain the hierarchical nature of trees;common errors in unioning nodes;false interactions}
}

@article{mar02pro,
  title = {Prospective Prediction in the Presence of Missing Data},
  author = {Marshall, Guillermo and Warner, Bradley and MaWhinney, Samantha and Hammermeister, Karl},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {561--570},
  citeulike-article-id = {13265311},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {missing-data,prediction},
  note = {predict for each new observation using a customized model refit for available predictors only, using the fast backward stepdown method; only requires saving beta hats and covariance matrix from original model fit, not the original dataset}
}

@article{mar04sta,
  title = {Statistical Issues in the Prospective Monitoring of Health Outcomes across Multiple Units},
  author = {Marshall, Clare and Best, Nicky and Bottle, Alex and Aylin, Paul},
  date = {2004},
  journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  volume = {167},
  number = {3},
  pages = {541--559},
  issn = {1467-985X},
  doi = {10.1111/j.1467-985X.2004.apm10.x},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-985X.2004.apm10.x},
  urldate = {2020-07-08},
  abstract = {Summary. Following several recent inquiries in the UK into medical malpractice and failures to deliver appropriate standards of health care, there is pressure to introduce formal monitoring of performance outcomes routinely throughout the National Health Service. Statistical process control (SPC) charts have been widely used to monitor medical outcomes in a variety of contexts and have been specifically advocated for use in clinical governance. However, previous applications of SPC charts in medical monitoring have focused on surveillance of a single process over time. We consider some of the methodological and practical aspects that surround the routine surveillance of health outcomes and, in particular, we focus on two important methodological issues that arise when attempting to extend SPC charts to monitor outcomes at more than one unit simultaneously (where a unit could be, for example, a surgeon, general practitioner or hospital): the need to acknowledge the inevitable between-unit variation in ‘acceptable’ performance outcomes due to the net effect of many small unmeasured sources of variation (e.g. unmeasured case mix and data errors) and the problem of multiple testing over units as well as time. We address the former by using quasi-likelihood estimates of overdispersion, and the latter by using recently developed methods based on estimation of false discovery rates. We present an application of our approach to annual monitoring ‘all-cause’ mortality data between 1995 and 2000 from 169 National Health Service hospital trusts in England and Wales.},
  langid = {english},
  keywords = {bayes,outcomes-research,provider-profiling,quality-assurance,scorecard,scorecarding},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-985X.2004.apm10.x}
}

@article{mar11car,
  title = {Is Cardiac Catheterization Necessary before Initial Management of Patients with Stable Ischemic Heart Disease? {{Results}} from a {{Web-based}} Survey of Cardiologists},
  author = {Maron, D. J. and Stone, G. W. and Berman, D. S. and Mancini, G. B. and Scott, T. A. and Byrne, D. W. and Harrell, F. E. and Shaw, L. J. and Hachamovitch, R. and Boden, W. E. and Weintraub, W. S. and Spertus, J. A.},
  date = {2011-12},
  journaltitle = {Am Heart J},
  volume = {162},
  pages = {1034--1043},
  citeulike-article-id = {13265912},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@article{mar11emp,
  title = {Empirical {{Performance}} of {{Cross-Validation With Oracle Methods}} in a {{Genomics Context}}},
  author = {Martinez, Josue G. and Carroll, Raymond J. and Müller, Samuel and Sampson, Joshua N. and Chatterjee, Nilanjan},
  date = {2011},
  journaltitle = {Am Statistician},
  volume = {65},
  number = {4},
  eprint = {http://pubs.amstat.org/doi/pdf/10.1198/tas.2011.11052},
  pages = {223--228},
  doi = {10.1198/tas.2011.11052},
  url = {http://pubs.amstat.org/doi/abs/10.1198/tas.2011.11052},
  abstract = {When employing model selection methods with oracle properties such as the smoothly clipped absolute deviation (SCAD) and the Adaptive Lasso, it is typical to estimate the smoothing parameter by m-fold cross-validation, for example, m = 10. In problems where the true regression function is sparse and the signals large, such cross-validation typically works well. However, in regression modeling of genomic studies involving Single Nucleotide Polymorphisms (SNP), the true regression functions, while thought to be sparse, do not have large signals. We demonstrate empirically that in such problems, the number of selected variables using SCAD and the Adaptive Lasso, with 10-fold cross-validation, is a random variable that has considerable and surprising variation. Similar remarks apply to non-oracle methods such as the Lasso. Our study strongly questions the suitability of performing only a single run of m-fold cross-validation with any oracle method, and not just the SCAD and Adaptive Lasso.},
  citeulike-article-id = {13265920},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/tas.2011.11052},
  citeulike-linkout-1 = {http://pubs.amstat.org/doi/abs/10.1198/tas.2011.11052},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@article{mar16und,
  title = {Understanding the {{Role}} of {{P Values}} and {{Hypothesis Tests}} in {{Clinical Research}}},
  author = {Mark, Daniel B. and Lee, Kerry L. and Harrell, Frank E.},
  date = {2016-12},
  journaltitle = {JAMA Card},
  volume = {1},
  number = {9},
  pages = {1048--1054},
  issn = {2380-6583},
  doi = {10.1001/jamacardio.2016.3312},
  url = {http://dx.doi.org/10.1001/jamacardio.2016.3312},
  citeulike-article-id = {14172377},
  citeulike-attachment-1 = {mar16und.pdf; /pdf/user/harrelfe/article/14172377/1088981/mar16und.pdf; fd408c8d0219f686a715f3c4fddfe17d79f27977},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jamacardio.2016.3312},
  day = {01},
  posted-at = {2016-10-27 00:05:11},
  priority = {0},
  keywords = {hypothesis-testing,p-values,teaching-mds}
}

@article{mar20ini,
  title = {Initial {{Invasive}} or {{Conservative Strategy}} for {{Stable Coronary Disease}}},
  author = {Maron, David J. and Hochman, Judith S. and Reynolds, Harmony R. and Bangalore, Sripal and O'Brien, Sean M. and Boden, William E. and Chaitman, Bernard R. and Senior, Roxy and López-Sendón, Jose and Alexander, Karen P. and Lopes, Renato D. and Shaw, Leslee J. and Berger, Jeffrey S. and Newman, Jonathan D. and Sidhu, Mandeep S. and Goodman, Shaun G. and Ruzyllo, Witold and Gosselin, Gilbert and Maggioni, Aldo P. and White, Harvey D. and Bhargava, Balram and Min, James K. and Mancini, G. B. John and Berman, Daniel S. and Picard, Michael H. and Kwong, Raymond Y. and Ali, Ziad A. and Mark, Daniel B. and Spertus, John A. and Krishnan, Mangalath N. and Elghamaz, Ahmed and Moorthy, Nagaraja and Hueb, Whady A. and Demkow, Marcin and Mavromatis, Kreton and Bockeria, Olga and Peteiro, Jesus and Miller, Todd D. and Szwed, Hanna and Doerr, Rolf and Keltai, Matyas and Selvanayagam, Joseph B. and Steg, P. Gabriel and Held, Claes and Kohsaka, Shun and Mavromichalis, Stavroula and Kirby, Ruth and Jeffries, Neal O. and Harrell, Frank E. and Rockhold, Frank W. and Broderick, Samuel and Ferguson, T. Bruce and Williams, David O. and Harrington, Robert A. and Stone, Gregg W. and Rosenberg, Yves and {ISCHEMIA Research Group}},
  date = {2020-04-09},
  journaltitle = {N Engl J Med},
  volume = {382},
  number = {15},
  eprint = {32227755},
  eprinttype = {pmid},
  pages = {1395--1407},
  issn = {1533-4406},
  doi = {10.1056/NEJMoa1915922},
  abstract = {BACKGROUND: Among patients with stable coronary disease and moderate or severe ischemia, whether clinical outcomes are better in those who receive an invasive intervention plus medical therapy than in those who receive medical therapy alone is uncertain. METHODS: We randomly assigned 5179 patients with moderate or severe ischemia to an initial invasive strategy (angiography and revascularization when feasible) and medical therapy or to an initial conservative strategy of medical therapy alone and angiography if medical therapy failed. The primary outcome was a composite of death from cardiovascular causes, myocardial infarction, or hospitalization for unstable angina, heart failure, or resuscitated cardiac arrest. A key secondary outcome was death from cardiovascular causes or myocardial infarction. RESULTS: Over a median of 3.2 years, 318 primary outcome events occurred in the invasive-strategy group and 352 occurred in the conservative-strategy group. At 6 months, the cumulative event rate was 5.3\% in the invasive-strategy group and 3.4\% in the conservative-strategy group (difference, 1.9 percentage points; 95\% confidence interval [CI], 0.8 to 3.0); at 5 years, the cumulative event rate was 16.4\% and 18.2\%, respectively (difference, -1.8 percentage points; 95\% CI, -4.7 to 1.0). Results were similar with respect to the key secondary outcome. The incidence of the primary outcome was sensitive to the definition of myocardial infarction; a secondary analysis yielded more procedural myocardial infarctions of uncertain clinical importance. There were 145 deaths in the invasive-strategy group and 144 deaths in the conservative-strategy group (hazard ratio, 1.05; 95\% CI, 0.83 to 1.32). CONCLUSIONS: Among patients with stable coronary disease and moderate or severe ischemia, we did not find evidence that an initial invasive strategy, as compared with an initial conservative strategy, reduced the risk of ischemic cardiovascular events or death from any cause over a median of 3.2 years. The trial findings were sensitive to the definition of myocardial infarction that was used. (Funded by the National Heart, Lung, and Blood Institute and others; ISCHEMIA ClinicalTrials.gov number, NCT01471522.).},
  langid = {english},
  pmcid = {PMC7263833},
  keywords = {collaboration,cv}
}

@article{mar20uni,
  title = {A Unified Approach to Sample Size and Power Determination for Testing Parameters in Generalized Linear and Time-to-Event Regression Models},
  author = {Martens, Michael J. and Logan, Brent R.},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8823},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8823},
  urldate = {2020-11-22},
  abstract = {To ensure that a study can properly address its research aims, the sample size and power must be determined appropriately. Covariate adjustment via regression modeling permits more precise estimation of the effect of a primary variable of interest at the expense of increased complexity in sample size/power calculation. The presence of correlation between the main variable and other covariates, commonly seen in observational studies and non-randomized clinical trials, further complicates this process. Though sample size and power specification methods have been obtained to accommodate specific covariate distributions and models, most existing approaches rely on either simple approximations lacking theoretical support or complex procedures that are difficult to apply at the design stage. The current literature lacks a general, coherent theory applicable to a broader class of regression models and covariate distributions. We introduce succinct formulas for sample size and power determination with the generalized linear, Cox, and Fine-Gray models that account for correlation between a main effect and other covariates. Extensive simulations demonstrate that this method produces studies that are appropriately sized to meet their type I error rate and power specifications, particularly offering accurate sample size/power estimation in the presence of correlated covariates.},
  langid = {english},
  keywords = {covariate-adjustment,power,sample-size},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8823}
}

@article{mar84cli,
  title = {Clinical Characteristics and Long-Term Survival of Patients with Variant Angina},
  author = {Mark, D. B. and Califf, R. M. and Morris, K. G. and Harrell, F. E. and Pryor, D. B. and Hlatky, M. A. and Lee, K. L. and Rosati, R. A.},
  date = {1984},
  journaltitle = {Circ},
  volume = {59},
  pages = {880--888},
  citeulike-article-id = {13264568},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{mar85mod,
  title = {Models and the Use of Signed Rank Tests},
  author = {Maritz, J. S.},
  date = {1985},
  journaltitle = {Stat Med},
  volume = {4},
  pages = {145--153},
  doi = {10.1002/sim.4780040205},
  url = {http://dx.doi.org/10.1002/sim.4780040205},
  citeulike-article-id = {13264569},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780040205},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {change,measuring-change,one-sample-problem,percent-change,signed-rank-test,teaching-mds}
}

@article{mar87,
  title = {Exercise Treadmill Score for Predicting Prognosis in Coronary Artery Disease},
  author = {Mark, D. B. and Hlatky, M. A. and Harrell, F. E. and Lee, K. L. and Califf, R. M. and Pryor, D. B.},
  date = {1987},
  journaltitle = {Ann Int Med},
  volume = {106},
  pages = {793--800},
  citeulike-article-id = {13264570},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{mar87loc,
  title = {Localizing Coronary Artery Obstructions with the Exercise Treadmill Test},
  author = {Mark, D. B. and Hlatky, M. A. and Lee, K. L. and Harrell, F. E. and Califf, R. M. and Pryor, D. B.},
  date = {1987},
  journaltitle = {Ann Int Med},
  volume = {106},
  pages = {53--55},
  citeulike-article-id = {13264571},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{mar89pai,
  title = {Painless Exercise {{ST}} Deviation on the Treadmill: Long-Term Prognosis},
  author = {Mark, D. B. and Hlatky, M. A. and Califf, R. M. and Morris JJ, S. and McCants, C. B. and Lee, K. L. and Harrell, F. E. and Pryor, D. B.},
  date = {1989},
  journaltitle = {J Am Coll Cardiol},
  volume = {14},
  pages = {885--892},
  citeulike-article-id = {13264572},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{mar90,
  title = {Principal Component Estimation for Generalized Linear Regression},
  author = {Marx BD, Smith E. P.},
  date = {1990},
  journaltitle = {Biometrika},
  volume = {77},
  pages = {23--31},
  citeulike-article-id = {13264573},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {general,multivariate-analysis,predictive-methods}
}

@article{mar91pro,
  title = {Prospective Validation of a Prognostic Exercise Treadmill Exercise Score in Outpatients},
  author = {Mark, D. B. and Shaw, L. and Harrell, F. E. and Hlatky, M. A. and Lee, K. L. and Bengston, J. R. and McCants, C. B. and Califf, R. M. and Pryor, D. B.},
  date = {1991},
  journaltitle = {NEJM},
  volume = {325},
  pages = {849--853},
  citeulike-article-id = {13264574},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{mar94acc,
  title = {Accuracy of the Clinical Examination in Detecting Hypoxemia in Infants with Respiratory Illness},
  author = {Margolis, P. A. and Ferkol, T. W. and Marsocci, S. and Super, D. M. and Keyes, L. L. and McNutt, R. and Harrell, F. E.},
  date = {1994},
  journaltitle = {J Pediatr},
  volume = {124},
  pages = {552--560},
  citeulike-article-id = {13264575},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{mar94ass,
  title = {Assessment of Predictive Models for Binary Outcomes: {{An}} Empirical Approach Using Operative Death from Cardiac Surgery},
  author = {Marshall, Guillermo and Grover, Frederick L. and Henderson, William G. and Hammermeister, Karl E.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1501--1511},
  citeulike-article-id = {13264576},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {cart,principal-components,variable-clustering}
}

@article{mar94con,
  title = {The Continuing Evolution of Therapy for Coronary Artery Disease: {{Initial}} Results from the Era of Coronary Angioplasty},
  author = {Mark, D. B. and Nelson, C. L. and Califf, R. M. and Harrell, F. E. and Lee, K. L. and Jones, R. H. and Fortin, D. F. and Stack, R. S. and Glower, D. D. and Smith, L. R. and DeLong, E. R. and Smith, P. K. and Reves, J. G. and Jollis, J. G. and Tcheng, J. E. and Muhlbaier, L. H. and Lowe, J. E. and Phillips, H. R. and Pryor, D. B.},
  date = {1994},
  journaltitle = {Circ},
  volume = {89},
  pages = {2015--2025},
  citeulike-article-id = {13264577},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {adjusted-survival-curves,cabg,cox-model-applications,observational-study,propensity,ptca,two-propensity-scores-for-three-treatments}
}

@article{mar95,
  title = {Cost Effectiveness of Thrombolytic Therapy with Tissue Plasminogen Activator as Compared with Streptokinase for Acute Myocardial Infarction},
  author = {Mark, D. B. and Hlatky, M. A. and Califf, R. M. and Naylor, C. D. and Lee, K. L. and Armstrong, P. W. and Barbash, G. and White, H. and Simoons, M. L. and Nelson, C. L. and Clapp-Channing, N. and Knight, J. D. and {Harrell} and Topol, E. J.},
  date = {1995},
  journaltitle = {NEJM},
  volume = {332},
  pages = {1418--1424},
  citeulike-article-id = {13264578},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {cost-analysis,cost-effectiveness,extrapolation-of-survival-curves-to-get-life-expectancy}
}

@book{mar95ana,
  title = {Analyzing {{Survival Data}} from {{Clinical Trials}} and {{Observational Studies}}},
  author = {Marubini, Ettore and Valsecchi, Maria G.},
  date = {1995},
  publisher = {{Wiley}},
  location = {{Chichester}},
  citeulike-article-id = {13264579},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {adjusted-survival-curves,competing-risks,group-sequential-test,rct,relationships-between-test-statistics,sequential-monitoring,study-design,survival-analysis,tdc}
}

@article{mar95mul,
  title = {Multi-State Models and Diabetic Retinopathy},
  author = {Marshall, Guillermo and Jones, Richard H.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1975--1983},
  citeulike-article-id = {13264580},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {markov-model,multi-state-model,multiple-events,recurrent-events,repeated-events}
}

@article{mar95ran,
  title = {Rank Tests for Main and Interaction Effects in Analysis of Variance},
  author = {Marden, John I. and Muyot, Maria E.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {1388--1398},
  citeulike-article-id = {13264581},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {aligned-rank-test,nonparametric,problems-with-rank-transform-anova,rank-test}
}

@article{mar98rel,
  title = {Reliability of League Tables of in Vitro Fertilisation Clinics: Retrospective Analysis of Live Birth Rates.},
  author = {Marshall, E. C. and Spiegelhalter, D. J.},
  date = {1998},
  journaltitle = {BMJ},
  volume = {316},
  number = {7146},
  url = {http://www.biomedsearch.com/nih/Reliability-league-tables-in-vitro/9614016.html},
  citeulike-article-id = {13265939},
  citeulike-linkout-0 = {http://www.biomedsearch.com/nih/Reliability-league-tables-in-vitro/9614016.html},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {provider-profiling,ranking,ranks,shrinkage}
}

@article{marubini.review,
  title = {Review of: {{Analyzing Survival Data}} from {{Clinical Trials}} and {{Observational Studies}}},
  author = {Marubini, E. and Valsecchi, M.},
  date = {1996},
  journaltitle = {Technometrics},
  volume = {38},
  pages = {299},
  citeulike-article-id = {13264582},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  note = {points out absence of software examples}
}

@article{mas05bat,
  title = {Battery {{Reduction}}},
  booktitle = {Encyclopedia of Biostatistics},
  author = {Massaro, Joseph M.},
  date = {2005},
  publisher = {John Wiley & Sons, Ltd},
  doi = {10.1002/0470011815.b2a13004},
  url = {http://dx.doi.org/10.1002/0470011815.b2a13004},
  abstract = {Battery reduction is used to select a subset of m variables from an original set of n variables (m~{$<~$}n) that reproduce a large proportion of the variance in the original set of n variables. There are a number of procedures for performing battery reduction analysis. A popular method involves first performing a principal components analysis to select m components, which account for the salient variance in the original data. Gram–Schmidt orthogonal rotations are then performed to determine the m variables that account for the largest proportion of variance. The procedure is illustrated and reference made to a SAS macro for performing the analysis.},
  citeulike-article-id = {13452154},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/0470011815.b2a13004},
  posted-at = {2014-12-04 13:02:24},
  priority = {2},
  keywords = {data-reduction,pca}
}

@article{mat07app,
  title = {Application of the Principal Stratification Approach to the {{Faenza}} Randomized Experiment on Breast Self-Examination},
  author = {Mattei, A. and Mealli, F.},
  date = {2007},
  journaltitle = {Biometrics},
  volume = {63},
  pages = {437--446},
  citeulike-article-id = {13265600},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {causal-model,handles-simultaneous-complexities,missing-data,noncompliance,principal-stratification,truncation-by-death}
}

@article{mat15inc,
  title = {Inconsistent Treatment Estimates from Mis-Specified Logistic Regression Analyses of Randomized Trials},
  author = {Matthews, J. N. S. and Badi, N. H.},
  date = {2015-08},
  journaltitle = {Stat Med},
  volume = {34},
  number = {19},
  pages = {2681--2694},
  issn = {02776715},
  doi = {10.1002/sim.6508},
  url = {http://dx.doi.org/10.1002/sim.6508},
  citeulike-article-id = {14214856},
  citeulike-attachment-1 = {mat15inc.pdf; /pdf/user/harrelfe/article/14214856/1092992/mat15inc.pdf; 815a0c32912af30307fdf1ecb30b2e6e8301cfe7},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6508},
  day = {30},
  posted-at = {2016-11-25 18:55:05},
  priority = {0},
  keywords = {ancova,binary-logistic-model,covariable-adjustment,covariate-adjustment}
}

@article{mat17ste,
  title = {Stepped Wedge Designs: Insights from a Design of Experiments Perspective},
  author = {Matthews, J. N. S. and Forbes, A. B.},
  journaltitle = {Stat Med},
  doi = {10.1002/sim.7403},
  url = {http://dx.doi.org/10.1002/sim.7403},
  abstract = {Stepped wedge designs (SWDs) have received considerable attention recently, as they are potentially a useful way to assess new treatments in areas such as health services implementation. Because allocation is usually by cluster, SWDs are often viewed as a form of cluster-randomized trial. However, since the treatment within a cluster changes during the course of the study, they can also be viewed as a form of crossover design. This article explores SWDs from the perspective of crossover trials and designed experiments more generally. We show that the treatment effect estimator in a linear mixed effects model can be decomposed into a weighted mean of the estimators obtained from (1) regarding an SWD as a conventional row-column design and (2) a so-called vertical analysis, which is a row-column design with row effects omitted. This provides a precise representation of ” horizontal” and ” vertical” comparisons, respectively, which to date have appeared without formal description in the literature. This decomposition displays a sometimes surprising way the analysis corrects for the partial confounding between time and treatment effects. The approach also permits the quantification of the loss of efficiency caused by mis-specifying the correlation parameter in the mixed-effects model. Optimal extensions of the vertical analysis are obtained, and these are shown to be highly inefficient for values of the within-cluster dependence that are likely to be encountered in practice. Some recently described extensions to the classic SWD incorporating multiple treatments are also compared using the experimental design framework.},
  citeulike-article-id = {14410359},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7403},
  posted-at = {2017-08-08 12:50:42},
  priority = {2},
  keywords = {cluster-randomized-trial,crossover,stepped-wedge}
}

@article{mat90ana,
  title = {Analysis of Serial Measurements in Medical Research},
  author = {Matthews, J. N. S. and Altman, Douglas G. and Campbell, M. J. and Royston, Patrick},
  date = {1990},
  journaltitle = {BMJ},
  volume = {300},
  pages = {230--235},
  doi = {10.1136/bmj.300.6719.230},
  url = {http://dx.doi.org/10.1136/bmj.300.6719.230},
  citeulike-article-id = {13264583},
  citeulike-linkout-0 = {http://dx.doi.org/10.1136/bmj.300.6719.230},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {growth-curve,peak-vs-growth-relationships,relating-peak-to-time-to-peak,repeated-measurements,serial-data,summary-measures,teaching-mds},
  annotation = {Letter to editor by S. Senn in same issue}
}

@article{mat93ref,
  title = {A Refinement to the Analysis of Serial Data Using Summary Measures},
  author = {Matthews, J. N. S.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {27--37},
  doi = {10.1002/sim.4780120105},
  url = {http://dx.doi.org/10.1002/sim.4780120105},
  citeulike-article-id = {13264584},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780120105},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {area-under-the-curve,auc,longitudinal-data,serial-data,summary-measures,teaching-mds,weighting,weighting-each-subject-differently}
}

@article{mat98bay,
  title = {A {{Bayesian}} Hierarchical Survival Model for the Institutional Effects in a Multi-Centre Cancer Clinical Trial},
  author = {Matsuyama, Yutaka and Sakamoto, Junichi and Ohashi, Yasuo},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1893--1908},
  doi = {10.1002/(SICI)1097-0258(19980915)17:17\%3C1893::AID-SIM878\%3E3.3.CO;2-I},
  url = {http://dx.doi.org/10.1002/(SICI)1097-0258(19980915)17:17%3C1893::AID-SIM878%3E3.3.CO;2-I},
  citeulike-article-id = {13264585},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/(SICI)1097-0258(19980915)17:17%3C1893::AID-SIM878%3E3.3.CO;2-I},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {bayes,bayesian-inference,hierarchical-model,multi-center-trial,rct,site-by-treatment-interaction}
}

@book{max04dat,
  title = {Data {{Matters}}: {{Conceptual Statistics}} for a {{Random World}}},
  author = {Maxwell, N.},
  date = {2004},
  publisher = {{Key College Pub.}},
  url = {https://books.google.com/books?id=KH5GAAAAYAAJ}
}

@article{max93biv,
  title = {Bivariate Median Splits and Spurious Statistical Significance},
  author = {Maxwell, S. E. and Delaney, H. D.},
  date = {1993},
  journaltitle = {Psych Bull},
  volume = {113},
  pages = {181--190},
  doi = {10.1037//0033-2909.113.1.181},
  url = {http://dx.doi.org/10.1037//0033-2909.113.1.181},
  citeulike-article-id = {13265286},
  citeulike-linkout-0 = {http://dx.doi.org/10.1037//0033-2909.113.1.181},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {categorization-of-continuous-variables,cutpoints,dichotomization,teaching-mds}
}

@article{may04dev,
  title = {Development and Validation of a Prognostic Model for Survival Time Data: Application to Prognosis of {{HIV}} Positive Patients Treated with Antiretroviral Therapy},
  author = {May, Margaret and Royston, Patrick and Egger, Matthias and Justice, Amy C. and Sterne, Jonathan A. C.},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  pages = {2375--2398},
  citeulike-article-id = {13265380},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {c-index,cross-validation,deviance,hiv,model-validation,prognostic-model,survival-model,validation},
  note = {C-index and generalization of Brier score for right-censoring were not sensitive enough to allow choosing from among multiple models;deviance statistic was more sensitive;claims that AIC selects too complex a model}
}

@article{may06pee,
  title = {Peering at Peer Review Revealed High Degree of Chance Associated with Funding of Grant Applications},
  author = {Mayo, Nancy E. and Brophy, James and Goldberg, Mark S. and Klein, Marina B. and Miller, Sydney and Platt, Robert W. and Ritchie, Judith},
  date = {2006},
  journaltitle = {J Clin Epi},
  volume = {59},
  pages = {842--848},
  citeulike-article-id = {13265480},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  note = {compared structured scientific in-depth 2-reviewer critique with independent rankings of all 11 reviewers;poor agreement of two approaches (kappa=.36). 10 reviewers provided optimum consistency for the ranking method;too much chance in assigning two primary reviewers;all reviewer ranking method removes the impact of extreme reviews}
}

@article{mcc09bay,
  title = {Bayesian Propensity Score Analysis for Observational Data},
  author = {McCandless, Lawrence C. and Gustafson, Paul and Austin, Peter C.},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {94--112},
  citeulike-article-id = {13265723},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {bayesian-statistics,bias,causal-inference,confounding,observational-study,propensity-score},
  note = {using Bayesian credible intervals to adjust for uncertainty in estimation of propensity score;relied heavily on Rubin 5-category propensity adjustment}
}

@article{mcc80reg,
  title = {Regression Models for Ordinal Data},
  author = {McCullagh, Peter},
  date = {1980},
  journaltitle = {J Roy Stat Soc B},
  volume = {42},
  pages = {109--142},
  citeulike-article-id = {13264586},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {ordinal-logistic-model}
}

@article{mcc84pri,
  title = {Principal Variables},
  author = {McCabe, George P.},
  date = {1984},
  journaltitle = {Technometrics},
  volume = {26},
  pages = {137--144},
  citeulike-article-id = {13265574},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {data-reduction,multivariate-analysis,principal-components,principal-variables}
}

@book{mcc85,
  title = {Generalized {{Linear Models}}},
  author = {McCullagh, P. and Nelder, J. A.},
  date = {1985},
  publisher = {{Chapman and Hall}},
  location = {{New York}},
  citeulike-article-id = {13264587},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@book{mcc89gen,
  title = {Generalized {{Linear Models}}},
  author = {McCullagh, P. and Nelder, John A.},
  date = {1989-08},
  edition = {Second},
  publisher = {{Chapman and Hall/CRC}},
  url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0412317605},
  abstract = {The success of the first edition of Generalized Linear Models led to the updated Second Edition, which continues to provide a definitive unified, treatment of methods for the analysis of diverse types of data. Today, it remains popular for its clarity, richness of content and direct relevance to agricultural, biological, health, engineering, and other applications.The authors focus on examining the way a response variable depends on a combination of explanatory variables, treatment, and classification variables. They give particular emphasis to the important case where the dependence occurs through some unknown, linear combination of the explanatory variables.The Second Edition includes topics added to the core of the first edition, including conditional and marginal likelihood methods, estimating equations, and models for dispersion effects and components of dispersion. The discussion of other topics-log-linear and related models, log odds-ratio regression models, multinomial response models, inverse linear and related models, quasi-likelihood functions, and model checking-was expanded and incorporates significant revisions.Comprehension of the material requires simply a knowledge of matrix theory and the basic ideas of probability theory, but for the most part, the book is self-contained. Therefore, with its worked examples, plentiful exercises, and topics of direct use to researchers in many disciplines, Generalized Linear Models serves as ideal text, self-study guide, and reference.},
  citeulike-article-id = {155079},
  citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0412317605},
  citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0412317605},
  citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0412317605},
  citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0412317605},
  citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0412317605/citeulike00-21},
  citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0412317605},
  citeulike-linkout-6 = {http://www.worldcat.org/isbn/0412317605},
  citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0412317605},
  citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0412317605&index=books&linkCode=qs},
  citeulike-linkout-9 = {http://www.librarything.com/isbn/0412317605},
  day = {01},
  howpublished = {̃},
  isbn = {0-412-31760-5},
  posted-at = {2014-10-05 15:23:06},
  priority = {2},
  keywords = {glm}
}

@article{mcc92hig,
  title = {High and Low Strength Nonsynchronized Shocks given during Canine Ventricular Tachycardia},
  author = {McClelland, J. H. and Daubert, J. P. and Kavanaug, K. M. and Harrell, F. E. and Ideker, R. E.},
  date = {1992},
  journaltitle = {Pacing Clin Electrophys},
  volume = {15},
  pages = {986--992},
  citeulike-article-id = {13265361},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{mcc94,
  title = {Does More Intensive Treatment of Acute Myocardial Infarction in the Elderly Reduce Mortality? {{Analysis}} Using Instrumental Variables},
  author = {McClellan, Mark and McNeil, Barbara J. and Newhouse, Joseph P.},
  date = {1994},
  journaltitle = {JAMA},
  volume = {272},
  pages = {859--866},
  citeulike-article-id = {13264588},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {confounding,observational-study,propensity-score,structural-equations}
}

@book{mce16sta,
  title = {Statistical Rethinking : A {{Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  date = {2016},
  url = {http://www.worldcat.org/isbn/9781482253443},
  citeulike-article-id = {14255283},
  citeulike-linkout-0 = {http://www.worldcat.org/isbn/9781482253443},
  citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9781482253443},
  citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9781482253443&index=books&linkCode=qs},
  citeulike-linkout-3 = {http://www.librarything.com/isbn/9781482253443},
  citeulike-linkout-4 = {http://www.worldcat.org/oclc/920672225},
  isbn = {978-1-4822-5344-3},
  posted-at = {2017-01-15 19:24:57},
  priority = {4},
  keywords = {bayes,bayesian-inference,bayesian-methods,teaching-mds}
}

@article{mcg13nat,
  title = {The {{National Neurosurgery Quality}} and {{Outcomes Database}} ({{N}}(2){{QOD}}): General Overview and Pilot-Year Project Description},
  author = {McGirt, M. J. and Speroff, T. and Dittus, R. S. and Harrell, F. E. and Asher, A. L.},
  date = {2013-01},
  journaltitle = {Neurosurg Focus},
  volume = {34},
  number = {1},
  citeulike-article-id = {13265955},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{mcg17ana,
  title = {An Analysis from the {{Quality Outcomes Database}}, {{Part}} 1. {{Disability}}, Quality of Life, and Pain Outcomes Following Lumbar Spine Surgery: Predicting Likely Individual Patient Outcomes for Shared Decision-Making},
  shorttitle = {An Analysis from the {{Quality Outcomes Database}}, {{Part}} 1. {{Disability}}, Quality of Life, and Pain Outcomes Following Lumbar Spine Surgery},
  author = {McGirt, Matthew J. and Bydon, Mohamad and Archer, Kristin R. and Devin, Clinton J. and Chotai, Silky and Parker, Scott L. and Nian, Hui and Harrell, Frank E. and Speroff, Theodore and Dittus, Robert S. and Philips, Sharon E. and Shaffrey, Christopher I. and Foley, Kevin T. and Asher, Anthony L.},
  date = {2017-10},
  journaltitle = {J Neurosurg Spine},
  volume = {27},
  number = {4},
  eprint = {28498074},
  eprinttype = {pmid},
  pages = {357--369},
  issn = {1547-5646},
  doi = {10.3171/2016.11.SPINE16526},
  abstract = {OBJECTIVE Quality and outcomes registry platforms lie at the center of many emerging evidence-driven reform models. Specifically, clinical registry data are progressively informing health care decision-making. In this analysis, the authors used data from a national prospective outcomes registry (the Quality Outcomes Database) to develop a predictive model for 12-month postoperative pain, disability, and quality of life (QOL) in patients undergoing elective lumbar spine surgery. METHODS Included in this analysis were 7618 patients who had completed 12 months of follow-up. The authors prospectively assessed baseline and 12-month patient-reported outcomes (PROs) via telephone interviews. The PROs assessed were those ascertained using the Oswestry Disability Index (ODI), EQ-5D, and numeric rating scale (NRS) for back pain (BP) and leg pain (LP). Variables analyzed for the predictive model included age, gender, body mass index, race, education level, history of prior surgery, smoking status, comorbid conditions, American Society of Anesthesiologists (ASA) score, symptom duration, indication for surgery, number of levels surgically treated, history of fusion surgery, surgical approach, receipt of workers' compensation, liability insurance, insurance status, and ambulatory ability. To create a predictive model, each 12-month PRO was treated as an ordinal dependent variable and a separate proportional-odds ordinal logistic regression model was fitted for each PRO. RESULTS There was a significant improvement in all PROs (p {$<$} 0.0001) at 12 months following lumbar spine surgery. The most important predictors of overall disability, QOL, and pain outcomes following lumbar spine surgery were employment status, baseline NRS-BP scores, psychological distress, baseline ODI scores, level of education, workers' compensation status, symptom duration, race, baseline NRS-LP scores, ASA score, age, predominant symptom, smoking status, and insurance status. The prediction discrimination of the 4 separate novel predictive models was good, with a c-index of 0.69 for ODI, 0.69 for EQ-5D, 0.67 for NRS-BP, and 0.64 for NRS-LP (i.e., good concordance between predicted outcomes and observed outcomes). CONCLUSIONS This study found that preoperative patient-specific factors derived from a prospective national outcomes registry significantly influence PRO measures of treatment effectiveness at 12 months after lumbar surgery. Novel predictive models constructed with these data hold the potential to improve surgical effectiveness and the overall value of spine surgery by optimizing patient selection and identifying important modifiable factors before a surgery even takes place. Furthermore, these models can advance patient-focused care when used as shared decision-making tools during preoperative patient counseling.},
  langid = {english},
  keywords = {collaboration}
}

@article{mci96pop,
  title = {The Population Risk as an Explanatory Variable in Research Synthesis of Clinical Trials},
  author = {McIntosh, Martin W.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1713--1728},
  citeulike-article-id = {13264589},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {measurement-error,regression-to-the-mean,treatment-effect-vs-placebo-rate}
}

@article{mck15bay,
  title = {Bayesian {{Model Choice}} in {{Cumulative Link Ordinal Regression Models}}},
  author = {McKinley, Trevelyan J. and Morters, Michelle and Wood, James L. N.},
  date = {2015-03},
  journaltitle = {Bayesian Anal.},
  volume = {10},
  number = {1},
  pages = {1--30},
  issn = {1936-0975, 1931-6690},
  doi = {10.1214/14-BA884},
  url = {https://projecteuclid.org/euclid.ba/1422468421},
  urldate = {2019-01-19},
  abstract = {The use of the proportional odds (PO) model for ordinal regression is ubiquitous in the literature. If the assumption of parallel lines does not hold for the data, then an alternative is to specify a non-proportional odds (NPO) model, where the regression parameters are allowed to vary depending on the level of the response. However, it is often difficult to fit these models, and challenges regarding model choice and fitting are further compounded if there are a large number of explanatory variables. We make two contributions towards tackling these issues: firstly, we develop a Bayesian method for fitting these models, that ensures the stochastic ordering conditions hold for an arbitrary finite range of the explanatory variables, allowing NPO models to be fitted to any observed data set. Secondly, we use reversible-jump Markov chain Monte Carlo to allow the model to choose between PO and NPO structures for each explanatory variable, and show how variable selection can be incorporated. These methods can be adapted for any monotonic increasing link functions. We illustrate the utility of these approaches on novel data from a longitudinal study of individual-level risk factors affecting body condition score in a dog population in Zenzele, South Africa.},
  langid = {english},
  mrnumber = {MR3420895},
  zmnumber = {1334.62141},
  keywords = {bayes,ordinal,partial-proportional-odds,proportional-odds}
}

@article{mck75sta,
  title = {A Statistical Model for the Analysis of Ordinal Level Dependent Variables},
  author = {McKelvey, Richard D. and Zavoina, William},
  date = {1975},
  journaltitle = {J Math Soc},
  volume = {4},
  number = {1},
  eprint = {https://doi.org/10.1080/0022250X.1975.9989847},
  pages = {103--120},
  publisher = {Routledge},
  doi = {10.1080/0022250X.1975.9989847},
  url = {https://doi.org/10.1080/0022250X.1975.9989847},
  abstract = {This paper develops a model, with assumptions similar to those of the linear model, for use when the observed dependent variable is ordinal. This model is an extension of the dichotomous probit model, and assumes that the ordinal nature of the observed dependent variable is due to methodological limitations in collecting the data, which force the researcher to lump together and identify various portions of an (otherwise) interval level variable. The model assumes a linear eflect of each independent variable as well as a series of break points between categories for the dependent variable. Maximum likelihood estimators are found for these parameters, along with their asymptotic sampling distributions, and an analogue of R 2 (the coefficient of determination in regression analysis) is defined to measure goodness of fit. The use of the model is illustrated with an analysis of Congressional voting on the 1965 Medicare Bill.},
  citeulike-article-id = {14571852},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/0022250X.1975.9989847},
  citeulike-linkout-1 = {https://doi.org/10.1080/0022250X.1975.9989847},
  posted-at = {2018-04-19 19:21:18},
  priority = {2},
  keywords = {generalized-r2,predictive-accuracy,r2},
  note = {For binary logistic denominator has pi² / 3}
}

@article{mcm00pow,
  title = {Power Calculation for Clinical Trials When the Outcome Is a Composite Ranking of Survival and a Non-Fatal Outcome},
  author = {McMahon, Robert P. and Harrell, Frank E.},
  date = {2000},
  journaltitle = {Controlled Clin Trials},
  volume = {21},
  pages = {305--312},
  citeulike-article-id = {13265104},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{mcm01joi,
  title = {Joint Testing of Mortality and a Non-Fatal Outcome in Clinical Trials},
  author = {McMahon, Robert P. and Harrell, Frank E.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1165--1172},
  citeulike-article-id = {13265105},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{mcm02stu,
  title = {Study Control, Violators, Inclusion Criteria and Defining Explanatory and Pragmatic Trials},
  author = {McMahon, Alex D.},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {1365--1376},
  citeulike-article-id = {13265281},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {explanatory-trial,inclusion-criteria,intention-to-treat,pragmatic-trial,rct,representativeness,study-design},
  note = {"We should accept that most trials in humans are 'explanatory'. The division line should ve moved, so that pragmatic studies are in the domain of non-therapeutics and complex treatments"}
}

@article{mcn77spl,
  title = {Spline Interpolation of Demographic Data},
  author = {McNeil, D. R. and Trussell, J. and Turner, J. C.},
  date = {1977},
  journaltitle = {Demography},
  volume = {14},
  pages = {245--252},
  citeulike-article-id = {13264590},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {natural-spline,restricted-cubic-spline,splines}
}

@article{mcn92gra,
  title = {On Graphing Paired Data},
  author = {McNeil, Don},
  date = {1992},
  journaltitle = {Ann Math Stat},
  volume = {46},
  pages = {307--311},
  citeulike-article-id = {13264591},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {graphical-methods,one-sample-problem,paired-data}
}

@article{mcs05rep,
  title = {Reporting Recommendations for Tumor Marker Prognostic Studies ({{REMARK}})},
  author = {McShane, Lisa M. and Altman, Douglas G. and Sauerbrei, Willi and Taube, Sheila E. and Gion, Massimo and Clark, Gary M. and {The Statistics Subcommittee of the NCI-EORTC Working Group on Cancer Diagnostics}},
  date = {2005},
  journaltitle = {J Nat Cancer Inst},
  volume = {97},
  pages = {1180--1184},
  citeulike-article-id = {13265554},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {bad-biomarker-research,reporting-guidelines}
}

@article{mcs17sta,
  title = {Statistical {{Significance}} and the {{Dichotomization}} of {{Evidence}}},
  author = {McShane, Blakeley B. and Gal, David},
  date = {2017-10},
  journaltitle = {JASA},
  volume = {112},
  number = {519},
  pages = {885--895},
  publisher = {Taylor & Francis},
  issn = {0162-1459},
  doi = {10.1080/01621459.2017.1289846},
  url = {http://dx.doi.org/10.1080/01621459.2017.1289846},
  abstract = {In light of recent concerns about reproducibility and replicability, the ASA issued a Statement on Statistical Significance and p-values aimed at those who are not primarily statisticians. While the ASA Statement notes that statistical significance and p-values are ?commonly misused and misinterpreted,? it does not discuss and document broader implications of these errors for the interpretation of evidence. In this article, we review research on how applied researchers who are not primarily statisticians misuse and misinterpret p-values in practice and how this can lead to errors in the interpretation of evidence. We also present new data showing, perhaps surprisingly, that researchers who are primarily statisticians are also prone to misuse and misinterpret p-values thus resulting in similar errors. In particular, we show that statisticians tend to interpret evidence dichotomously based on whether or not a p-value crosses the conventional 0.05 threshold for statistical significance. We discuss implications and offer recommendations.},
  citeulike-article-id = {14469592},
  citeulike-attachment-1 = {mcshane₁7ₛtatistical₁121749.pdf; /pdf/user/harrelfe/article/14469592/1121749/mcshane₁7ₛtatistical₁121749.pdf; b057aeeefd4e90e067e607d5a79e257d3792c62c},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.2017.1289846},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1289846},
  day = {30},
  posted-at = {2017-10-31 12:31:40},
  priority = {3},
  keywords = {misinterpretation-of-p-values,p-values,teaching-mds,teaching-statisticians}
}

@article{mee95tea,
  title = {Teaching about Approximate Confidence Regions Based on Maximum Likelihood Estimation},
  author = {Meeker, William Q. and Escobar, Luis A.},
  date = {1995},
  journaltitle = {Am Statistician},
  volume = {49},
  pages = {48--53},
  citeulike-article-id = {13264592},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {confidence-intervals,maximum-likelihood,mle,profile-likelihood,wald-statistics}
}

@article{meh03awa,
  title = {Awakening the Dragon's Breath: {{Biostatistics}}, Competency and Competition in the Pharmaceutical Industry},
  author = {Mehta, Shreefal and Peters, Lois and Burke, Richard},
  date = {2003},
  journaltitle = {Trans IEEE},
  pages = {504--508},
  citeulike-article-id = {13265583},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  note = {CROs are getting an increasing amount of outsourcing of tasks of all types from pharma and are spreading and equalizing technology, making it more available to small pharma. If outsourcing of core competencies such as biostatistics to CROs continues to the point that CROs have too much power and being to compete with pharma, the result could destabilize drug product life cycles. "... firms gain competitive advantage from resources that are difficult to trade, transfer, imitate or replicate ... Statistical analysis of the clinical data is a key point of regulatory scruitiny, suggesting that biostatistics would have to be developed as a core competence for pharmaceutical companies to be successful."}
}

@article{meh09opt,
  title = {Optimizing {{Trial Design}}: {{Sequential}}, {{Adaptive}}, and {{Enrichment Strategies}}},
  author = {Mehta, Cyrus and Gao, Ping and Bhatt, Deepak L. and Harrington, Robert A. and Skerjanec, Simona and Ware, James H.},
  date = {2009-02},
  journaltitle = {Circ},
  volume = {119},
  number = {4},
  eprint = {19188520},
  eprinttype = {pmid},
  pages = {597--605},
  publisher = {Lippincott Williams & Wilkins},
  issn = {1524-4539},
  doi = {10.1161/circulationaha.108.809707},
  url = {http://dx.doi.org/10.1161/circulationaha.108.809707},
  citeulike-article-id = {12738549},
  citeulike-attachment-1 = {meh09opt.pdf; /pdf/user/harrelfe/article/12738549/983439/meh09opt.pdf; 83963a813c52b76099964831bb0b36af2fccb482},
  citeulike-linkout-0 = {http://dx.doi.org/10.1161/circulationaha.108.809707},
  citeulike-linkout-1 = {http://circ.ahajournals.org/content/119/4/597.full.abstract},
  citeulike-linkout-2 = {http://circ.ahajournals.org/content/119/4/597.full.full.pdf},
  citeulike-linkout-3 = {http://circ.ahajournals.org/cgi/content/abstract/119/4/597},
  citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/19188520},
  citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=19188520},
  day = {3},
  posted-at = {2014-09-04 00:06:01},
  priority = {0},
  keywords = {interim-monitoring,rct,sequential-monitoring,study-design-and-stopping-rules,teaching-mds}
}

@article{meh12eff,
  title = {An Efficient Alternative to the Stratified {{Cox}} Model Analysis},
  author = {Mehrotra, Devan V. and Su, Shu-Chih and Li, Xiaoming},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {17},
  pages = {1849--1856},
  doi = {10.1002/sim.5327},
  url = {http://dx.doi.org/10.1002/sim.5327},
  abstract = {Consider a typical two-treatment randomized clinical trial involving a time-to-event endpoint, with randomization stratified by a categorical prognostic factor (for example gender). At the design stage, it is often assumed that the treatment hazard ratio (HR) is constant across the strata, and the data are commonly analyzed using the stratified Cox proportional hazards model. We caution that this ubiquitous approach is needlessly risky because departures from the assumption of the HR being the same for all the strata can result in a notably biased and/or less powerful analysis. An alternative approach is proposed in which first the [log] HR is estimated separately for each stratum using an unstratified Cox model, and then the stratum-specific estimates are combined for overall inference using either sample size or 'minimum risk' stratum weights. The advantages of the proposed two-step analysis versus the common one-step stratified Cox model analysis are illustrated using simulations that were conducted to support the design of a vaccine clinical trial.},
  citeulike-article-id = {13265933},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5327},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {inverse-variance-weights,minimum-risk-weights,ph,sample-size-weights,stratification,stratified-cox,stratified-logrank,treatment-by-stratum-interaction}
}

@article{mei08hie,
  title = {Hierarchical Testing of Variable Importance},
  author = {Meinshausen, Nicolai},
  date = {2008},
  journaltitle = {Biometrika},
  volume = {95},
  number = {2},
  pages = {265--278},
  citeulike-article-id = {13265680},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {hierarchical-clustering,high-dimensional-data,higher-criticism-alternative,multiple-linear-regression,multiple-testing},
  note = {a solution to collinearity;controls familywise error at a prespecified level, simultaneously over all resolution levels;adaptive selection of best resolution level (amount of clustering);variable clustering;variable importance is first testing at the coarsest level (global null), then smaller clusters or even individual variables are examined}
}

@article{mei94ass,
  title = {Assessing the Effect of Time-Varying Covariates in Cross-Sectional Studies},
  author = {Meinert, R. and Frischer, T. and Kuehr, J.},
  date = {1994},
  journaltitle = {J Clin Epi},
  volume = {47},
  pages = {983--991},
  citeulike-article-id = {13264593},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {change-in-exposure,tdc},
  annotation = {See letter to the editor 1995 p. 989}
}

@article{men00coe,
  title = {Coefficients of Determination for Multiple Logistic Regression Analysis},
  author = {Menard, Scott},
  date = {2000},
  journaltitle = {Am Statistician},
  volume = {54},
  pages = {17--24},
  citeulike-article-id = {13265114},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {generalized-r2,predictive-accuracy},
  note = {proportion of log likelihood explained not as dependent on base rate as Nagelkerke R²}
}

@article{men94mul,
  title = {Multiple-Imputation Inferences with Uncongenial Sources of Input},
  author = {Meng, Xiao-Li},
  date = {1994},
  journaltitle = {Stat Sci},
  volume = {9},
  pages = {538--558},
  citeulike-article-id = {13264594},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {multiple-imputation}
}

@article{mes94com,
  title = {Comparison of Chemotherapy and Bone Marrow Transplants Using Two Independent Clnical Databases},
  author = {Messerer, Dorle and Neiss, Albrecht and Horowitz, Mary M. and Hoelzer, Dieter and Gale, Robert P.},
  date = {1994},
  journaltitle = {J Clin Epi},
  volume = {47},
  pages = {1119--1126},
  citeulike-article-id = {13264595},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {waiting-time-bias}
}

@article{mey14det,
  title = {Determinants of Health after Hospital Discharge: Rationale and Design of the {{Vanderbilt Inpatient Cohort Study}} ({{VICS}})},
  author = {Meyers, Abby G. and Salanitro, Amanda and Wallston, Kenneth A. and Cawthon, Courtney and Vasilevskis, Eduard E. and Goggins, Kathryn M. and Davis, Corinne M. and Rothman, Russell L. and Castel, Liana D. and Donato, Katarine M. and Schnelle, John F. and Bell, Susan P. and Schildcrout, Jonathan S. and Osborn, Chandra Y. and Harrell, Frank E. and Kripalani, Sunil},
  date = {2014},
  journaltitle = {BMC Hlth Serv Res},
  volume = {14},
  pages = {10},
  doi = {10.1186/1472-6963-14-10},
  url = {http://www.biomedcentral.com/1472-6963/14/10},
  citeulike-article-id = {13265986},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/1472-6963-14-10},
  citeulike-linkout-1 = {http://www.biomedcentral.com/1472-6963/14/10},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {ctsafac,design}
}

@article{mey19obj,
  title = {Objecting to Experiments That Compare Two Unobjectionable Policies or Treatments},
  author = {Meyer, Michelle N. and Heck, Patrick R. and Holtzman, Geoffrey S. and Anderson, Stephen M. and Cai, William and Watts, Duncan J. and Chabris, Christopher F.},
  date = {2019-05-09},
  journaltitle = {PNAS},
  eprint = {31072934},
  eprinttype = {pmid},
  pages = {201820701},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1820701116},
  url = {https://www.pnas.org/content/early/2019/05/08/1820701116},
  urldate = {2019-05-10},
  abstract = {Randomized experiments have enormous potential to improve human welfare in many domains, including healthcare, education, finance, and public policy. However, such “A/B tests” are often criticized on ethical grounds even as similar, untested interventions are implemented without objection. We find robust evidence across 16 studies of 5,873 participants from three diverse populations spanning nine domains—from healthcare to autonomous vehicle design to poverty reduction—that people frequently rate A/B tests designed to establish the comparative effectiveness of two policies or treatments as inappropriate even when universally implementing either A or B, untested, is seen as appropriate. This “A/B effect” is as strong among those with higher educational attainment and science literacy and among relevant professionals. It persists even when there is no reason to prefer A to B and even when recipients are treated unequally and randomly in all conditions (A, B, and A/B). Several remaining explanations for the effect—a belief that consent is required to impose a policy on half of a population but not on the entire population; an aversion to controlled but not to uncontrolled experiments; and a proxy form of the illusion of knowledge (according to which randomized evaluations are unnecessary because experts already do or should know “what works”)—appear to contribute to the effect, but none dominates or fully accounts for it. We conclude that rigorously evaluating policies or treatments via pragmatic randomized trials may provoke greater objection than simply implementing those same policies or treatments untested.},
  langid = {english},
  keywords = {randomization,study-design}
}

@article{mia18eff,
  title = {Effects of Endogenous Serum Neuregulin-1β on Morbidity and Mortality in Patients with Heart Failure and Left Ventricular Systolic Dysfunction},
  author = {Miao, Jennifer and Huang, Shi and Su, Yan Ru and Lenneman, Carrie A. and Wright, Meera and Harrell, Frank E. and Sawyer, Douglas B. and Lenihan, Daniel J.},
  date = {2018-11},
  journaltitle = {Biomarkers},
  volume = {23},
  number = {7},
  eprint = {29871526},
  eprinttype = {pmid},
  pages = {704--708},
  issn = {1366-5804},
  doi = {10.1080/1354750X.2018.1485054},
  abstract = {CONTEXT: Improved left ventricular ejection fraction (LVEF) following administration of recombinant human Neuregulin-1β (NRG), epidermal growth factor (EGF) involved in cardiomyocyte repair/survival, has been observed in patients with systolic heart failure (HF). METHODS: Serum NRG was measured by ELISA in 248 patients with NYHA class I-IV HF. RESULTS: NRG exhibited a marginally significant effect on LVEF trajectory over 11\,months (p\,=\,0.07). There is no apparent level of NRG that predicts improved survival. CONCLUSIONS: There is a potential relationship between serum NRG and improved LVEF, indicating the need to investigate the utility of NRG in predicting HF outcomes, including LVEF maintenance.},
  langid = {english},
  pmcid = {PMC6291851},
  keywords = {collaboration,cv}
}

@article{mic05pre,
  title = {Prediction of Cancer Outcome with Microarrays: A Multiple Random Validation Strategy},
  author = {Michiels, Stefan and Koscielny, Serge and Hill, Catherine},
  date = {2005},
  journaltitle = {Lancet},
  volume = {365},
  pages = {488--492},
  citeulike-article-id = {13265447},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  note = {comment on p. 454;validation;microarray;bioinformatics;machine learning;nearest centroid;severe problems with data splitting;high variability of list of genes;problems with published studies;nice results for effect of training sample size on misclassification error;nice use of confidence intervals on accuracy estimates;unstable molecular signatures;high instability due to dependence on selection of training sample}
}

@article{mic98gif,
  title = {The {{Gifi}} System of Descriptive Multivariate Analysis},
  author = {Michailidis, George and de Leeuw, Jan},
  options = {useprefix=true},
  date = {1998},
  journaltitle = {Stat Sci},
  volume = {13},
  pages = {307--336},
  citeulike-article-id = {13264596},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {correspondence-analysis,nonlinear-principal-components}
}

@article{mil01gro,
  title = {Group Comparisons Involving Missing Data in Clinical Trials: A Comparison of Estimates and Power (Size) for Some Simple Approaches},
  author = {Miller, Michael E. and Morgan, Timothy M. and Espeland, Mark A. and Emerson, Scott S.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2383--2397},
  citeulike-article-id = {13265221},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  note = {conditional mean imputation;not correcting variance for imputation can sometimes result in variances that are too large;formalizes fixed-value fillin with model}
}

@article{mil05var,
  title = {Variance Estimation in Clinical Studies with Interim Sample Size Reestimation},
  author = {Miller, F.},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  pages = {355--361},
  citeulike-article-id = {13265514},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{mil07ran,
  title = {A Randomized Trial of {{Pegaptanib}} Sodium for Age-Related Macular Degeneration Used an Innovative Design to Explore Disease-Modifying Effects},
  author = {Mills, Edward and Heels-Ansdell, Diane and Kelly, Steven and Guyatt, Gordon},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {456--460},
  citeulike-article-id = {13265576},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {age-related-macular-degeneration,disease-modifying,randomized-clinical-trial,rct,research-methodology},
  note = {re-randomization;randomizing at the end of an RCT into another RCT}
}

@article{mil83wha,
  title = {What Price {{Kaplan--Meier}}?},
  author = {Miller, Rupert G.},
  date = {1983},
  journaltitle = {Biometrics},
  volume = {39},
  pages = {1077--1081},
  citeulike-article-id = {13264597},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {censored-data,kaplan-meier}
}

@article{mil91val,
  title = {Validation Techniques for Logistic Regression Models},
  author = {Miller, Michael E. and Hui, Siu L. and Tierney, William M.},
  date = {1991},
  journaltitle = {Stat Med},
  volume = {10},
  pages = {1213--1226},
  note = {see sta09sim .~ Some of the methods in the paper are based on logistCal.pdf by Harrell \& Lee - see http://hbiostat.org/papers/feh/logistCal.pdf}
}

@article{min01not,
  title = {A Note on Optimal Matching with Variable Controls Using the Assignment Algorithm},
  author = {Ming, Kewei and Rosenbaum, Paul R.},
  date = {2001},
  journaltitle = {J Comp Graph Stat},
  volume = {10},
  pages = {455--463},
  citeulike-article-id = {13265229},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {assignment-algorithm,full-matching,matched-sampling,minimum-cost-flow,network-optimization,observational-studies,variable-controls}
}

@article{min90pro,
  title = {Profile-Likelihood-Based Confidence Intervals},
  author = {Minkin, Salomon},
  date = {1990},
  journaltitle = {Appl Stat},
  volume = {39},
  pages = {125--126},
  citeulike-article-id = {13264599},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {confidence-intervals,maximum-likelihood},
  note = {See also Minkin's letter to the Editor, Stat in Med 12:989, 1993.}
}

@article{mit88bay,
  title = {Bayesian Variable Selection in Linear Regression},
  author = {Mitchell, T. J. and Beauchamp, J. J.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {1023--1036},
  citeulike-article-id = {13264600},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {bayesian-methods,model-selection,variable-selection}
}

@article{mit96exp,
  title = {Explained Variation for Logistic Regression},
  author = {Mittlböck, Martina and Schemper, Michael},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1987--1997},
  doi = {10.1002/(SICI)1097-0258(19961015)15:19\%3C1987::AID-SIM318\%3E3.3.CO;2-0},
  url = {http://dx.doi.org/10.1002/(SICI)1097-0258(19961015)15:19%3C1987::AID-SIM318%3E3.3.CO;2-0},
  citeulike-article-id = {13264601},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/(SICI)1097-0258(19961015)15:19%3C1987::AID-SIM318%3E3.3.CO;2-0},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  note = {ease of interpretation of indexes of explained variation;use of R² in logistic regression;examples of values of many indexes; penalizing for number of predictors}
}

@article{moh21sim,
  title = {Simultaneous Confidence Intervals for Ranks with Application to Ranking Institutions},
  author = {Mohamad, Diaa Al and Goeman, Jelle J. and van Zwet, Erik W.},
  date = {2021},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13419},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13419},
  urldate = {2020-12-25},
  abstract = {When a ranking of institutions such as medical centers or universities is based on a numerical measure of performance provided with a standard error, confidence intervals (CIs) should be calculated to assess the uncertainty of these ranks. We present a novel method based on Tukey's honest significant difference (HSD) test to construct simultaneous CIs for the true ranks. When all the true performances are equal, the probability of coverage of our method attains the nominal level. In case the true performance measures have no exact ties, our method is conservative. For this situation, we propose a rescaling method to the nominal level which results in shorter CIs while keeping control of the simultaneous coverage. We also show that a similar rescaling can be applied to correct a recently proposed Monte-Carlo based method which is anticonservative. After rescaling, the two methods perform very similarly. However, the rescaling of the Monte-Carlo based method is computationally much more demanding and becomes infeasible when the number of institutions is larger than 30 to 50. We discuss another recently proposed method similar to ours based on simultaneous CIs for the true performance. We show that our method provides uniformly shorter CIs for the same confidence level. We illustrate the superiority of our new methods with a data analysis for travel time to work in the U.S. and on rankings of 64 hospitals in the Netherlands.},
  langid = {english},
  keywords = {provider-profiling,ranking,ranking-outcomes-and-institutions,simultaneous-confidence-intervals},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13419}
}

@article{mol09inc,
  title = {Incomplete Data in Clinical Studies: {{Analysis}}, Sensitivity, and Sensitivity Analysis (with Discussion)},
  author = {Molenberghs, Geert},
  date = {2009},
  journaltitle = {Drug Info J},
  volume = {43},
  pages = {403--492},
  citeulike-article-id = {13265781},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {longitudinal-data,missing-data,nonrandom-dropouts,rct,sensitivity-analysis}
}

@article{mol97ana,
  title = {The Analysis of Longitudinal Ordinal Data with Nonrandom Drop-Out},
  author = {Molenberghs, G. and Kenward, M. G. and Lesaffre, E.},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {33--44},
  citeulike-article-id = {13264602},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {dale-model,em,informative-censoring,missing-values,nonrandom-drop-out,ordinal-response,repeated-measurements,serial-measurements}
}

@article{mon16aut,
  title = {Automated Detection of Atrial Fibrillation from the Electrocardiogram Channel of Polysomnograms.},
  author = {Monahan, Ken and Song, Yanna and Loparo, Ken and Mehra, Reena and Harrell, Frank E. and Redline, Susan},
  date = {2016-05},
  journaltitle = {Sleep and Breathing},
  volume = {20},
  number = {2},
  eprint = {26092280},
  eprinttype = {pmid},
  pages = {515--522},
  issn = {1522-1709},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/26092280},
  abstract = {Accurate identification of atrial fibrillation episodes from polysomnograms is important for research purposes but requires manual review of a large number of long electrocardiographic tracings. As automated assessment of these tracings for atrial fibrillation may improve efficiency, this study aimed to evaluate this approach in polysomnogram-derived electrocardiographic data. A previously described algorithm to detect atrial fibrillation from single-lead electrocardiograms was applied to polysomnograms from a large epidemiologic study of obstructive sleep apnea in older men (Osteoporotic Fractures in Men [MrOS] Sleep Study). Atrial fibrillation status during each participant's PSG was determined by independent manual review. Models to predict atrial fibrillation status from a combination of algorithm output and clinical/polysomnographic characteristics were developed, and their accuracy was evaluated using standard statistical techniques. Derivation and validation cohorts each consisted of 1395 individuals; 5~\% of each group had atrial fibrillation. Model parameters were optimized for the derivation cohort using the Akaike information criterion. Application to the validation cohort of these optimized models revealed high sensitivity (85-90~\%) and specificity (90-95~\%) as well as good predictive ability, as assessed by the C statistic ({$>$}0.9) and generalized R (2) values (∼0.6). Addition of cardiovascular or polysomnogram data to the models did not improve their performance. In a research setting, automated detection of atrial fibrillation from polysomnogram-derived electrocardiographic signals appears feasible and agrees well with manual identification. Future studies can evaluate the utility of this technique as applied to clinical polysomnograms and ambulatory electrocardiographic monitoring.},
  citeulike-article-id = {14102488},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/26092280},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=26092280},
  posted-at = {2016-07-26 21:11:47},
  priority = {2},
  keywords = {collaboration}
}

@book{moo01reb,
  title = {Rebel {{Code}}: {{The Inside Story}} of {{Linux}} and the {{Open Source Revolution}}},
  author = {Moody, Glyn},
  date = {2001},
  publisher = {{Perseus Publishing}},
  location = {{Cambridge MA}},
  citeulike-article-id = {13265196},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {computer,linux,open-source-software}
}

@article{moo02sho,
  title = {Should Scoring Rules Be Based on Odds Ratios or Regression Coefficients?},
  author = {Moons, Karel G. M. and Harrell, F. E. and Steyerberg, Ewout W.},
  date = {2002},
  journaltitle = {J Clin Epi},
  volume = {55},
  pages = {1054--1055},
  doi = {10.1016/S0895-4356(02)00453-5},
  url = {http://dx.doi.org/10.1016/S0895-4356(02)00453-5},
  citeulike-article-id = {13265301},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0895-4356(02)00453-5},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-prediction-rules,improper-summing-of-odds-ratios,point-scores,scoring-rules},
  annotation = {refereed letter to the editor}
}

@article{moo03sen,
  title = {Sensitivity and Specificity Should Be De-Emphasized in Diagnostic Accuracy Studies},
  author = {Moons, Karel G. M. and Harrell, Frank E.},
  date = {2003},
  journaltitle = {Acad Rad},
  volume = {10},
  pages = {670--672},
  citeulike-article-id = {13265330},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {accuracy,diagnosis,reasons-for-avoiding-sensitivity-and-specificity},
  annotation = {Editorial}
}

@article{moo04pen,
  title = {Penalized Maximum Likelihood Estimation to Directly Adjust Diagnostic and Prognostic Prediction Models for Overoptimism: A Clinical Example},
  author = {Moons, K. G. M. and {Donders} and Steyerberg, E. W. and Harrell, F. E.},
  date = {2004},
  journaltitle = {J Clin Epi},
  volume = {57},
  pages = {1262--1270},
  citeulike-article-id = {13265394},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {bootstrapping,overfitting,overoptimism,penalization,prediction-research,shrinkage}
}

@article{moo06usi,
  title = {Using the Outcome for Imputation of Missing Predictor Values Was Preferred},
  author = {Moons, Karel G. M. and Donders, Rogier A. R. T. and Stijnen, Theo and Harrell, Frank E.},
  date = {2006},
  journaltitle = {J Clin Epi},
  volume = {59},
  pages = {1092--1101},
  doi = {10.1016/j.jclinepi.2006.01.009},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2006.01.009},
  citeulike-article-id = {13265492},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2006.01.009},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {aregimpute,graphics,imputation,mice,missing-data,response,teaching-mds},
  note = {use of outcome variable; excellent graphical summaries of simulations}
}

@book{moo95dea,
  title = {Deadly {{Medicine}}: {{Why Tens}} of {{Thousands}} of {{Patients Died}} in {{America}}'s {{Worst Drug Disaster}}},
  author = {Moore, Thomas J.},
  date = {1995},
  publisher = {{Simon \& Shuster}},
  location = {{New York}},
  citeulike-article-id = {13264603},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  annotation = {review in Stat in Med 16:2507-2510, 1997}
}

@article{moo97lim,
  title = {Limitations of Sensitivity, Specificity, Likelihood Ratio, and {{Bayes}}' Theorem in Assessing Diagnostic Probabilities: {{A}} Clinical Example},
  author = {Moons, Karel G. M. and van Es, Gerrit-Anne and Deckers, Jaap W. and Habbema, J. D. F. and Grobbee, Diederick E.},
  options = {useprefix=true},
  date = {1997},
  journaltitle = {Epi},
  volume = {8},
  number = {1},
  pages = {12--17},
  citeulike-article-id = {13265697},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {coronary-artery-disease,diagnosis,diagnostic-accuracy,sensitivity,specificity},
  note = {non-constancy of sensitivity, specificity, likelihood ratio in a real example}
}

@article{mor05sta,
  title = {Statistical Collaboration to Impact Policy Decisions},
  author = {Morton, Sally C.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {493--501},
  citeulike-article-id = {13265407},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {case-study,collaboration,consulting,health-policy,health-services-research,impact},
  note = {excellent definition of collaborating vs. consulting;two excellent case studies where statisticians made a major difference}
}

@article{mor06red,
  title = {Reduced Heart Rate Variability: An Indicator of Cardiac Uncoupling and Diminished Physiologic Reserve in 1,425 Trauma Patients.},
  author = {Morris, John A. and Norris, Patrick A. and Ozdas, A. and Waitman, L. R. and Harrell, Frank E. and Willians, A. E. and Cao, H. and Jenkins, J. M.},
  date = {2006},
  journaltitle = {J Trauma},
  volume = {60},
  pages = {1165--1173},
  citeulike-article-id = {13265550},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {mortality-model,physiology,signal-analysis,signal-processing}
}

@article{mor07neg,
  title = {Negative Score Test Statistic (with Discussion)},
  author = {Morgan, B. J. T. and Palmer, K. J. and Ridout, M. S.},
  date = {2007},
  journaltitle = {Am Statistician},
  volume = {61},
  number = {4},
  pages = {285--295},
  citeulike-article-id = {13265640},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  note = {zero-inflated Poisson;score test;can be negative if expected information is not used}
}

@article{mor13lim,
  title = {Limitations of Medical Research and Evidence at the Patient-Clinician Encounter Scale},
  author = {Morris, Alan H. and Ioannidis, John P. A.},
  date = {2013},
  journaltitle = {Chest},
  volume = {143},
  number = {4},
  pages = {1127--1135},
  doi = {10.1378/chest.12-1908},
  url = {http://dx.doi.org/10.1378/chest.12-1908},
  citeulike-article-id = {13265971},
  citeulike-linkout-0 = {http://dx.doi.org/10.1378/chest.12-1908},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {bad-science,personalized-medicine,practice-guidelines,problems-with-non-randomized-studies}
}

@article{mor17cho,
  title = {Choosing Appropriate Analysis Methods for Cluster Randomised Cross-over Trials with a Binary Outcome},
  author = {Morgan, Katy E. and Forbes, Andrew B. and Keogh, Ruth H. and Jairath, Vipul and Kahan, Brennan C.},
  date = {2017-01},
  journaltitle = {Stat Med},
  volume = {36},
  number = {2},
  pages = {318--333},
  issn = {02776715},
  doi = {10.1002/sim.7137},
  url = {http://dx.doi.org/10.1002/sim.7137},
  citeulike-article-id = {14333063},
  citeulike-attachment-1 = {mor17cho.pdf; /pdf/user/harrelfe/article/14333063/1106843/mor17cho.pdf; 1069d42e3abfbe70af8d9d03b54ad5b4ec4e54b8},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7137},
  day = {30},
  posted-at = {2017-04-06 22:07:06},
  priority = {2},
  keywords = {cluster-randomization,cluster-randomized-trial,cluster-randomized-trials,crossover,crossover-study,pragmatic-trial}
}

@unpublished{mor17usi,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  date = {2017-12},
  eprint = {1712.03198},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1712.03198},
  abstract = {Simulation studies are computer experiments which involve creating data by pseudorandom sampling. The key strength of simulation studies is the ability to understand the behaviour of statistical methods because some `truth' is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analysed and reported. This article outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting and presentation. In particular, we provide: a structured approach for planning and reporting simulation studies; coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their computation; ideas on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing current practice and identifying areas for improvement, we review 100 articles taken from Volume 34 of Statistics in Medicine which included at least one simulation study.},
  archiveprefix = {arXiv},
  citeulike-article-id = {14501640},
  citeulike-linkout-0 = {http://arxiv.org/abs/1712.03198},
  citeulike-linkout-1 = {http://arxiv.org/pdf/1712.03198},
  day = {8},
  posted-at = {2017-12-12 12:53:45},
  priority = {4},
  keywords = {simulation,simulation-setup}
}

@article{mor19usi,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {11},
  pages = {2074--2102},
  issn = {1097-0258},
  doi = {10.1002/sim.8086},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8086},
  urldate = {2019-04-06},
  abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some “truth” (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (“ADEMP”); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
  langid = {english},
  keywords = {simulation,simulation-setup}
}

@article{mor19usia,
  title = {Using Simulation Studies to Evaluate Statistical Methods},
  author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8086},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8086},
  urldate = {2019-01-19},
  abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some “truth” (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (“ADEMP”); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
  langid = {english},
  keywords = {simulation,simulation-setup}
}

@article{mor86omi,
  title = {Omitting Covariates from the Proportional Hazards Model},
  author = {Morgan, Timothy M.},
  date = {1986},
  journaltitle = {Biometrics},
  volume = {42},
  pages = {993--995},
  citeulike-article-id = {13264604},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {covariable-adjustment,loss-of-power-when-covariables-omitted}
}

@article{mos04odd,
  title = {Odds Ratios for a Continuous Outcome Variable without Dichotomizing},
  author = {Moser, Barry K. and Coombs, Laura P.},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  pages = {1843--1860},
  citeulike-article-id = {13265376},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {categorization,cutpoint,cutpoints,dichotomizing-continuous-response-variable,response,teaching-mds},
  note = {large loss of efficiency and power;embeds in a logistic distribution, similar to proportional odds model;categorization;dichotomization of a continuous response in order to obtain odds ratios often results in an inflation of the needed sample size by a factor greater than 1.5}
}

@article{moy92ana,
  title = {Analysis of a Clinical Trial Involving a Combined Mortality and Adherence Dependent Interval Censored Endpoint},
  author = {Moyé, Lemuel A. and Davis, Barry R. and Hawkins, C. Morton},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1705--1717},
  doi = {10.1002/sim.4780111305},
  url = {http://dx.doi.org/10.1002/sim.4780111305},
  citeulike-article-id = {13264605},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780111305},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {composite-endpoints,compound-endpoints,interval-censoring,quality-of-life,rct}
}

@article{moy97siz,
  title = {Sizing Clinical Trials with Variable Endpoint Event Rates},
  author = {Moyé, Lemuel A.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2267--2282},
  citeulike-article-id = {13264606},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {power,sample-size},
  note = {simple formula for sample size for 2-sample binomial as a function of the percent risk reduction}
}

@article{moz17dir,
  title = {Direct Likelihood Inference on the Cause-Specific Cumulative Incidence Function: {{A}} Flexible Parametric Regression Modelling Approach},
  author = {Mozumder, Sarwar I. and Rutherford, Mark and Lambert, Paul},
  date = {2017-10},
  journaltitle = {Stat Med},
  issn = {02776715},
  doi = {10.1002/sim.7498},
  url = {http://dx.doi.org/10.1002/sim.7498},
  citeulike-article-id = {14445300},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7498},
  day = {02},
  posted-at = {2017-10-04 12:49:46},
  priority = {2},
  keywords = {competing-risks,cumulative-incidence-function,parametric-survival-model,survival-analysis}
}

@article{msa21mak,
  title = {Making {{Patient-Specific Treatment Decisions Using Prognostic Variables}} and {{Utilities}} of {{Clinical Outcomes}}},
  author = {Msaouel, Pavlos and Lee, Juhee and Thall, Peter F.},
  date = {2021-01},
  journaltitle = {Cancers},
  volume = {13},
  number = {11},
  pages = {2741},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/cancers13112741},
  url = {https://www.mdpi.com/2072-6694/13/11/2741},
  urldate = {2021-06-01},
  abstract = {We argue that well-informed patient-specific decision-making may be carried out as three consecutive tasks: (1) estimating key parameters of a statistical model, (2) using prognostic information to convert these parameters into clinically interpretable values, and (3) specifying joint utility functions to quantify risk–benefit trade-offs between clinical outcomes. Using the management of metastatic clear cell renal cell carcinoma as our motivating example, we explain the role of prognostic covariates that characterize between-patient heterogeneity in clinical outcomes. We show that explicitly specifying the joint utility of clinical outcomes provides a coherent basis for patient-specific decision-making.},
  issue = {11},
  langid = {english},
  keywords = {clinical-prediction,decision-support-techniques,decision-theory,prognosis,utilities,utility-function}
}

@article{mud96gen,
  title = {A Generalization of the {{Weibull}} Distribution with Application to the Analysis of Survival Data},
  author = {Mudholkar, Govind S. and Srivastava, Deo K. and Kollia, Georgia D.},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {1575--1583},
  citeulike-article-id = {13264607},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {assessing-ph,bathtub-hazard-function,generalized-weibull-distribution,non-ph,parametric-survival-model}
}

@article{mue83com,
  title = {Comparing Survival Distributions: {{A}} Review for Nonstatisticians. {{II}}},
  author = {Muenz, L. R.},
  date = {1983},
  journaltitle = {Ca Invest},
  volume = {1},
  pages = {537--545},
  citeulike-article-id = {13264608},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {assessing-ph,cumulative-hazard-ratio-plots,graphics-methods}
}

@article{mue85mar,
  title = {Markov {{Models}} for {{Covariate Dependence}} of {{Binary Sequences}}},
  author = {Muenz, Larry R. and Rubinstein, Lawrence V.},
  date = {1985},
  journaltitle = {Biometrics},
  volume = {41},
  number = {1},
  eprint = {2530646},
  eprinttype = {jstor},
  pages = {91--101},
  publisher = {{[Wiley, International Biometric Society]}},
  issn = {0006-341X},
  doi = {10.2307/2530646},
  abstract = {Suppose that a heterogeneous group of individuals is followed over time and that each individual can be in state 0 or state 1 at each time point. The sequence of states is assumed to follow a binary Markov chain. In this paper we model the transition probabilities for the 0 to 0 and 1 to 0 transitions by two logistic regressions, thus showing how the covariates relate to changes in state. With p covariates, there are 2(p + 1) parameters including intercepts, which we estimate by maximum likelihood. We show how to use transition probability estimates to test hypotheses about the probability of occupying state 0 at time i (i = 2, ..., T) and the equilibrium probability of state 0. These probabilities depend on the covariates. A recursive algorithm is suggested to estimate regression coefficients when some responses are missing. Extensions of the basic model which allow time-dependent covariates and nonstationary or second-order Markov chains are presented. An example shows the model applied to a study of the psychological impact of breast cancer in which women did or did not manifest distress at four time points in the year following surgery.},
  keywords = {binary-data,markov,markov-model,serial},
  note = {Not clear on why dual models are need.~ I think I'm content with P(0 -{$>$} 1) = expit(alpha + beta*x) and P(1 -{$>$} 0) = expit(-alpha -beta*x - gamma) where gamma is the coefficient of Y(t-1) in the logistic model.
\par
Covers median time until entering a state.
\par
Table 4 states that b'x = d'x is equivalent to independence of binary sequences for a specific clear.~ Not clear on this.
\par
Covers missing responses.
\par
Has matrix exponent form of occupation probabilities.}
}

@book{mueR,
  title = {R for {{SAS}} and {{SPSS Users}}},
  author = {Muenchen, Robert A.},
  date = {2008},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265718},
  posted-at = {2014-07-14 14:10:02},
  priority = {0}
}

@article{mug10fle,
  title = {A Flexible Approach to the Crossing Hazards Problem},
  author = {Muggeo, Vito M. R. and Tagliavia, Miriam},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {1947--1957},
  citeulike-article-id = {13265840},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {crossing-hazards,crossing-point,non-ph,non-proportional-hazards,p-splines,penalized-splines,restricted-estimation,time-varying-effect},
  note = {failed to reference per06red or per07app}
}

@inproceedings{muh84kap,
  title = {\%{{Macro KAPLAN}} for {{Kaplan--Meier}} Survival Curve Estimation},
  booktitle = {Proceedings of the {{SAS User}}'s {{Group International}}},
  author = {Muhlbaier, L. H. and Helms, M. J. and {Jr}},
  date = {1984},
  volume = {9},
  pages = {673--681},
  citeulike-article-id = {13264609},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{muh92obs,
  title = {Observational Comparison of Event-Free Survival with Medical and Surgical Therapy in Patients with Coronary Artery Disease: 20 Years of Follow-Up},
  author = {Muhlbaier, L. H. and Pryor, D. B. and Rankin, J. S. and Smith, L. R. and Mark, D. B. and Jones, R. H. and Glower, D. D. and Harrell, F. E. and Lee, K. L. and Califf, R. M. and Sabiston, D. C.},
  date = {1992},
  journaltitle = {Circ},
  volume = {86(II)},
  pages = {198--204},
  citeulike-article-id = {13264610},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{mul83ris,
  title = {Risk Stratification and Survival after Myocardial Infarction},
  author = {{Multicenter Postinfarction Research Group}},
  date = {1983},
  journaltitle = {NEJM},
  volume = {309},
  pages = {331--336},
  abstract = {We assessed the role of physiologic measurements of heart function in predicting mortality after myocardial infarction. Most of the 866 patients enrolled in our multicenter study underwent 24-hour Holter monitoring and determination of the resting radionuclide ventricular ejection fraction before discharge. Univariate analyses showed a progressive increase in cardiac mortality during one year as the ejection fraction fell below 0.40 and as the number of ventricular ectopic depolarizations exceeded one per hour. Only four risk factors among eight prespecified variables were independent predictors of mortality: an ejection fraction below 0.40, ventricular ectopy of 10 or more depolarizations per hour, advanced New York Heart Association functional class before infarction, and rales heard in the upper two thirds of the lung fields while the patient was in the coronary-care unit. Various combinations of these four factors identified five risk subgroups with two-year mortality rates ranging from 3 per cent (no factors) to 60 per cent (all four factors).},
  citeulike-article-id = {13265603},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  note = {terrible example of dichotomizing continuous variables;figure ins Papers/modelingPredictors}
}

@article{mul98ext,
  title = {Extending the Family of {{Bayesian}} Bootstraps and Exchangeable Urn Schemes},
  author = {Muliere, Pietro and Walker, Stephen},
  date = {1998},
  journaltitle = {J Roy Stat Soc B},
  volume = {60},
  pages = {175--182},
  citeulike-article-id = {13264611},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {bayesian-bootstrap,bootstrapping-censored-data,finite-population,urn}
}

@article{mun17man,
  title = {A Manifesto for Reproducible Science},
  author = {Munafò, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and Percie du Sert, Nathalie and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
  date = {2017-01},
  journaltitle = {Nat Hum Behav},
  volume = {1},
  number = {1},
  pages = {0021+},
  issn = {2397-3374},
  doi = {10.1038/s41562-016-0021},
  url = {http://dx.doi.org/10.1038/s41562-016-0021},
  citeulike-article-id = {14250247},
  citeulike-attachment-1 = {mun17man.pdf; /pdf/user/harrelfe/article/14250247/1118453/mun17man.pdf; e6caf4697d1d925e364218a03f34111c4e4fefbc},
  citeulike-linkout-0 = {http://dx.doi.org/10.1038/s41562-016-0021},
  day = {10},
  posted-at = {2017-09-20 11:51:45},
  priority = {3},
  keywords = {reproducibility}
}

@article{mur03opt,
  title = {Optimal Dynamic Treatment Regimes (with Discussion)},
  author = {Murphy, S. A.},
  date = {2003},
  journaltitle = {J Roy Stat Soc B},
  volume = {65},
  pages = {331--366},
  citeulike-article-id = {13265516},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{mur03sma,
  title = {Small Samples and Ordered Logistic Regression: {{Does}} It Help to Collapse Categories of Outcome?},
  author = {Murad, Havi and Fleischman, Anat and Sadetzki, Siegal and Geyer, Orna and Freedman, Laurence S.},
  date = {2003},
  journaltitle = {Am Statistician},
  volume = {57},
  pages = {155--160},
  citeulike-article-id = {13265345},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {cumulative-logit,po-model,proportional-odds-model,wald-test},
  note = {collapsing categories makes Wald tests too conservative for small sample sizes;categorization}
}

@article{mur05exp,
  title = {An Experimental Design for the Development of Adaptive Treatment Strategies},
  author = {Murphy, S. A.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {1455--1481},
  citeulike-article-id = {13265517},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@incollection{mur05mod,
  title = {A Model for the Development of a “near-Miss” Reporting System for a {{General Clinical Research Center}}: {{Implications}} for Research Subject Safety},
  booktitle = {Advances in {{Patient Safety}}: {{From Research}} to {{Implementation}}},
  author = {Murff, H. J. and France, D. J. and Byrne, D. L. and Hedstrom, C. and Speroff, T. and Dittus, R. S.},
  editor = {Henriksen, K. and Battles, J. B. and Marks, E. S. and Lewin, D. I.},
  date = {2005-02},
  volume = {3},
  number = {05-0021-3},
  publisher = {{AHRQ}},
  location = {{Rockville MD}},
  citeulike-article-id = {13265526},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{mur06huma,
  title = {Human Subjects Protection in Clinical Research: {{Results}} of a National Survey of Research Nurses},
  author = {Murff, H. J. and Pichert, J. W. and Byrne, D. W. and Hedstrom, C. and Black, M. and Churchill, L. and Speroff, T.},
  date = {2006},
  journaltitle = {IRB: Eth Hum Res},
  volume = {in press},
  citeulike-article-id = {13265524},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{mur06humb,
  title = {Human Subjects Protection in Clinical Research: {{Research Participant}} Safety and Systems Factors in {{General Clinical Research Centers}}},
  author = {Murff, H. J. and Pichert, J. W. and Byrne, D. W. and Hedstrom, C. and Black, M. and Speroff, T.},
  date = {2006},
  journaltitle = {IRB: Eth Hum Res},
  volume = {in press},
  citeulike-article-id = {13265525},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{mur13inf,
  title = {{{InfoVis}} and Statistical Graphics: {{Comment}}},
  author = {Murrell, Paul},
  date = {2013},
  journaltitle = {J Comp Graph Stat},
  volume = {22},
  number = {1},
  eprint = {http://www.tandfonline.com/doi/pdf/10.1080/10618600.2012.751875},
  pages = {33--37},
  doi = {10.1080/10618600.2012.751875},
  url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2012.751875},
  citeulike-article-id = {13265968},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/10618600.2012.751875},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2012.751875},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  note = {Excellent brief how-to list; incorporated into graphscourse}
}

@article{mur18imp,
  title = {Improved Adherence Adjustment in the {{Coronary Drug Project}}},
  author = {Murray, Eleanor J. and Hernán, Miguel A.},
  date = {2018-03},
  journaltitle = {Trials},
  volume = {19},
  number = {1},
  pages = {158},
  doi = {10.1186/s13063-018-2519-5},
  url = {https://doi.org/10.1186/s13063-018-2519-5},
  abstract = {The survival difference between adherers and non-adherers to placebo in the Coronary Drug Project has been used to support the thesis that adherence adjustment in randomized trials is not generally possible and, therefore, that only intention-to-treat analyses should be trusted. We previously demonstrated that adherence adjustment can be validly conducted in the Coronary Drug Project using a simplistic approach. Here, we re-analyze the data using an approach that takes full advantage of recent methodological developments.},
  citeulike-article-id = {14545031},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/s13063-018-2519-5},
  citeulike-linkout-1 = {https://doi.org/10.1186/s13063-018-2519-5},
  day = {05},
  posted-at = {2018-03-06 15:02:45},
  priority = {2},
  keywords = {compliance,nonadherence,rct}
}

@article{mur96non,
  title = {Nonparametric Survival Estimation Using Prognostic Longitudinal Covariates},
  author = {Murray, Susan and Tsiatis, Anastasios A.},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {137--151},
  citeulike-article-id = {13264612},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {intervening-event,multiple-events,study-design,surrogate-endpoint}
}

@article{mus21pha,
  title = {A {{Phase}} 2 {{Randomized Placebo-Controlled Adjuvant Trial}} of {{GI-4000}}, a {{Recombinant Yeast Expressing Mutated RAS Proteins}} in {{Patients}} with {{Resected Pancreas Cancer}}},
  author = {Muscarella, Peter and Bekaii-Saab, Tanios and McIntyre, Kristi and Rosemurgy, Alexander and Ross, Sharona B. and Richards, Donald A. and Fisher, William E. and Flynn, Patrick J. and Mattson, Alicia and Coeshott, Claire and Roder, Heinrich and Roder, Joanna and Harrell, Frank E. and Cohn, Allen and Rodell, Timothy C. and Apelian, David},
  date = {2021-03-01},
  journaltitle = {Journal of Pancreatic Cancer},
  volume = {7},
  number = {1},
  pages = {8--19},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  doi = {10.1089/pancan.2020.0021},
  url = {https://www.liebertpub.com/doi/10.1089/pancan.2020.0021},
  urldate = {2021-03-30},
  abstract = {Purpose: GI-4000, a series of recombinant yeast expressing four different mutated RAS proteins, was evaluated in subjects with resected ras-mutated pancreas cancer.Methods: Subjects (n\,=\,176) received GI-4000 or placebo plus gemcitabine. Subjects' tumors were genotyped to identify which matched GI-4000 product to administer. Immune responses were measured by interferon-γ (IFNγ) ELISpot assay and by regulatory T cell (Treg) frequencies on treatment. Pretreatment plasma was retrospectively analyzed by matrix-assisted laser desorption/ionization-time-of-flight (MALDI-ToF) mass spectrometry for proteomic signatures predictive of GI-4000 responsiveness.Results: GI-4000 was well tolerated, with comparable safety findings between treatment groups. The GI-4000 group showed a similar pattern of median recurrence-free and overall survival (OS) compared with placebo. For the prospectively defined and stratified R1 resection subgroup, there was a trend in 1 year OS (72\% vs. 56\%), an improvement in OS (523.5 vs. 443.5 days [hazard ratio (HR)\,=\,1.06 [confidence interval (CI): 0.53–2.13], p\,=\,0.872), and increased frequency of immune responders (40\% vs. 8\%; p\,=\,0.062) for GI-4000 versus placebo and a 159-day improvement in OS for R1 GI-4000 immune responders versus placebo (p\,=\,0.810). For R0 resection subjects, no increases in IFNγ responses in GI-4000–treated subjects were observed. A higher frequency of R0/R1 subjects with a reduction in Tregs (CD4+/CD45RA+/Foxp3low) was observed in GI-4000–treated subjects versus placebo (p\,=\,0.033). A proteomic signature was identified that predicted response to GI-4000/gemcitabine regardless of resection status.Conclusion: These results justify continued investigation of GI-4000 in studies stratified for likely responders or in combination with immune check-point inhibitors or other immunomodulators, which may provide optimal reactivation of antitumor immunity.ClinicalTrials.gov Number: NCT00300950.},
  keywords = {bayes,not-recent,oncology-rct,rct,sequential}
}

@online{mut21win,
  title = {Win Odds: {{An}} Adaptation of the Win Ratio to Include Ties | {{EndNote Click}}},
  shorttitle = {Win Odds},
  author = {Mütze, E. Brunner {and} M. Vandemeulebroecke {and} T.},
  date = {2021},
  url = {https://click.endnote.com/viewer?doi=10.1002%2Fsim.8967&token=WzMwMjM5MywiMTAuMTAwMi9zaW0uODk2NyJd.f1BwjvTJs5-GWqW1p63V7zAU3AQ},
  urldate = {2021-04-18},
  abstract = {Download PDF of Win odds: An adaptation of the win ratio to include ties published in Statistics in Medicine},
  langid = {english},
  keywords = {multiple-endpoints,odds-ratio,rct,win-ratio}
}

@book{mye90,
  title = {Classical and {{Modern Regression}} with {{Applications}}},
  author = {Myers, Raymond H.},
  date = {1990},
  publisher = {{PWS-Kent}},
  location = {{Boston}},
  citeulike-article-id = {13264613},
  posted-at = {2014-07-14 14:09:38},
  priority = {0}
}

@article{nag11ana,
  title = {Analysis by Categorizing or Dichotomizing Continuous Variables Is Inadvisable: {{An}} Example from the Natural History of Unruptured Aneurysms},
  author = {Naggara, O. and Raymond, J. and Guilbert, F. and Roy, D. and Weill, A. and Altman, D. G.},
  date = {2011},
  journaltitle = {Am J Neuroradiol},
  volume = {32},
  number = {3},
  pages = {437--440},
  doi = {10.3174/ajnr.A2425},
  url = {http://www.ajnr.org/content/32/3/437.abstract},
  abstract = {In medical research analyses, continuous variables are often converted into categoric variables by grouping values into ≥2 categories. The simplicity achieved by creating ≥2 artificial groups has a cost: Grouping may create rather than avoid problems. In particular, dichotomization leads to a considerable loss of power and incomplete correction for confounding factors. The use of data-derived "optimal" cut-points can lead to serious bias and should at least be tested on independent observations to assess their validity. Both problems are illustrated by the way the results of a registry on unruptured intracranial aneurysms are commonly used. Extreme caution should restrict the application of such results to clinical decision-making. Categorization of continuous data, especially dichotomization, is unnecessary for statistical analysis. Continuous explanatory variables should be left alone in statistical models.},
  citeulike-article-id = {13265917},
  citeulike-linkout-0 = {http://dx.doi.org/10.3174/ajnr.A2425},
  citeulike-linkout-1 = {http://www.ajnr.org/content/32/3/437.abstract},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {cutpoints,teaching-mds}
}

@article{nag91not,
  title = {A Note on a General Definition of the Coefficient of Determination},
  author = {Nagelkerke, N. J. D.},
  date = {1991},
  journaltitle = {Biometrika},
  volume = {78},
  pages = {691--692},
  citeulike-article-id = {13264614},
  posted-at = {2014-07-14 14:09:38},
  priority = {0},
  keywords = {maximum-likelihood,predictive-accuracy}
}

@article{nak21dom,
  title = {Domperidone {{Increases Harmful Cardiac Events}} in {{Parkinson}}'s {{Disease}}: {{A Bayesian Re-Analysis}} of an {{Observational Study}}},
  shorttitle = {Domperidone {{Increases Harmful Cardiac Events}} in {{Parkinson}}'s {{Disease}}},
  author = {Nakhlé, Gisèle and Brophy, James M. and Renoux, Christel and Khairy, Paul and Bélisle, Patrick and LeLorier, Jacques},
  date = {2021-09-07},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.09.002},
  url = {https://www.jclinepi.com/article/S0895-4356(21)00282-1/abstract},
  urldate = {2021-09-08},
  abstract = {Over the last two decades, Bayesian methods have gained popularity and their implementations have widened in statistical sciences and applied fields. From a healthcare perspective, regulatory agencies are now accepting Bayesian approaches for earlier phases of drug development [1,2] and comparative effectiveness research [3,4]. At the drug development level, Bayesian adaptive analytical approaches have been particularly attractive for achieving greater efficiency in reducing sample size, time and cost of trials [5].},
  langid = {english},
  keywords = {bayes,observational-data,observational-study}
}

@article{nam87,
  title = {A Simple Approximation for Calculating Sample Sizes for Detecting Linear Trend in Proportions},
  author = {Nam, J.},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {701--705},
  citeulike-article-id = {13264615},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,sample-size-estimation}
}

@article{nan05com,
  title = {Computational {{Algorithms}} for {{Double Bootstrap Confidence Intervals}}},
  author = {Nankervis, John C.},
  date = {2005-04},
  journaltitle = {Comput. Stat. Data Anal.},
  volume = {49},
  number = {2},
  pages = {461--475},
  publisher = {Elsevier Science Publishers B. V.},
  location = {Amsterdam, The Netherlands, The Netherlands},
  doi = {10.1016/j.csda.2004.05.023},
  url = {http://dx.doi.org/10.1016/j.csda.2004.05.023},
  citeulike-article-id = {13893167},
  citeulike-attachment-1 = {nan05com.pdf; /pdf/user/harrelfe/article/13893167/1047640/nan05com.pdf; 238da0a36b4a7a27b862e36fbd321c59b366bfb7},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.csda.2004.05.023},
  posted-at = {2015-12-23 13:45:58},
  priority = {0},
  keywords = {bootstrap,confidence-intervals,double-bootstrap},
  note = {No software provided but excellent algorithm. Shows improved coverage for asymmetric equal-tail confidence intervals for the mean from a lognormal distribution. For the percentile method, single bootstrap gave overall coverage of 0.88 and double 0.93 when n=30.}
}

@article{nas08eff,
  title = {Effects of an Oral Ghrelin Mimetic on Body Composition and Clinical Outcomes in Health Older Adults. {{A}} Randomized Trial},
  author = {Nass, R. and Pezzoli, S. S. and Oliveri, M. C. and Patrie, J. T. and Harrell, F. E. and Clasey, J. L. and {Emphet Al}},
  date = {2008},
  journaltitle = {Ann Int Med},
  volume = {149},
  pages = {601--611},
  citeulike-article-id = {13265704},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {data-reduction,gh,rct}
}

@article{nas18ite,
  title = {Iterative {{Multiple Imputation}}: {{A Framework}} to {{Determine}} the {{Number}} of {{Imputed Datasets}}},
  shorttitle = {Iterative {{Multiple Imputation}}},
  author = {Nassiri, Vahid and Molenberghs, Geert and Verbeke, Geert and Barbosa-Breda, João},
  date = {2018-12-10},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--17},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1543615},
  url = {https://doi.org/10.1080/00031305.2018.1543615},
  urldate = {2019-05-17},
  abstract = {We consider multiple imputation as a procedure iterating over a set of imputed datasets. Based on an appropriate stopping rule the number of imputed datasets is determined. Simulations and real-data analyses indicate that the sufficient number of imputed datasets may in some cases be substantially larger than the very small numbers that are usually recommended. For an easier use in various applications, the proposed method is implemented in the R package imi.},
  keywords = {imputatation,missing}
}

@article{nat14cur,
  title = {The Current State of {{Bayesian}} Methods in Medical Product Development: Survey Results and Recommendations from the {{DIA Bayesian Scientific Working Group}}},
  author = {Natanegara, Fanni and Neuenschwander, Beat and Seaman, John W. and Kinnersley, Nelson and Heilmann, Cory R. and Ohlssen, David and Rochester, George},
  date = {2014-01},
  journaltitle = {Pharm Stat},
  volume = {13},
  number = {1},
  pages = {3--12},
  issn = {15391604},
  doi = {10.1002/pst.1595},
  url = {http://dx.doi.org/10.1002/pst.1595},
  citeulike-article-id = {14530069},
  citeulike-attachment-1 = {nat14cur.pdf; /pdf/user/harrelfe/article/14530069/1128781/nat14cur.pdf; 75e2b6ad8c3ad854b5fbf1dcb2371a50199da228},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1595},
  posted-at = {2018-02-06 03:05:05},
  priority = {0},
  keywords = {bayes,bayesian-inference,drug-development,regulatory-viewpoint}
}

@article{nau93des,
  title = {Design Effects for Binary Regression Models Fitted to Dependent Data},
  author = {Neuhaus, John M. and Segal, Mark R.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {1259--1268},
  citeulike-article-id = {13264616},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {binary-logistic-model,cluster-sampling,design-effect,multivariate}
}

@article{nav06dru,
  title = {Drug-Related Hepatotoxicity},
  author = {Navarro, Victor J. and Senior, John R.},
  date = {2006},
  journaltitle = {NEJM},
  volume = {354},
  pages = {731--739},
  citeulike-article-id = {13265459},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {clinical-safety,pharmaceutical-safety}
}

@article{nav18inf,
  title = {Influence of {{Cardiovascular Risk Communication Tools}} and {{Presentation Formats}} on {{Patient Perceptions}} and {{Preferences}}},
  author = {Navar, Ann Marie and Wang, Tracy Y. and Mi, Xiaojuan and Robinson, Jennifer G. and Virani, Salim S. and Roger, Veronique L. and Wilson, Peter W. F. and Goldberg, Anne C. and Peterson, Eric D.},
  date = {2018-12-01},
  journaltitle = {JAMA Cardiol},
  volume = {3},
  number = {12},
  pages = {1192--1199},
  issn = {2380-6583},
  doi = {10.1001/jamacardio.2018.3680},
  url = {https://jamanetwork.com/journals/jamacardiology/fullarticle/2711641},
  urldate = {2018-12-26},
  abstract = {{$<$}h3{$>$}Importance{$<$}/h3{$><$}p{$>$}Practice guidelines recommend that clinicians engage patients in treatment decisions and explain atherosclerotic cardiovascular disease (ASCVD) risk but do not describe how to communicate this risk most effectively.{$<$}/p{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To determine how the ASCVD risk time horizon, outcome, and presentation format influence risk perceptions and treatment preferences.{$<$}/p{$><$}h3{$>$}Design, Setting, and Participants{$<$}/h3{$><$}p{$>$}From May 27, 2015, through November 12, 2015, participants from the Patient and Provider Assessment of Lipid Management Registry at 140 US cardiology, primary care, and endocrinology practices were presented 3 independent scenarios (representing the same hypothetical patient) and asked to rate their perceived risk and willingness to take medication to lower risk in light of (1) a 15\% 10-year ASCVD event risk, (2) a 4\% 10-year cardiovascular disease (CVD) death risk, and (3) a 50\% lifetime ASCVD event risk.{$<$}/p{$><$}h3{$>$}Exposures{$<$}/h3{$><$}p{$>$}Participants were randomized to receive risk estimates using numbers only, a bar graph, or a face pictogram.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Of 3566 eligible participants, 2708 (76.9\%) responded (median age, 67 years [interquartile range, 61-76 years]; 280 [10.3\%] African American; 1491 men [55.1\%]). When shown the lifetime ASCVD risk, respondents were more likely to consider the risk “high to very high” than when presented the 10-year ASCVD risk or the CVD death risk (70.1\% vs 31.4\% vs 25.7\%, respectively; both\emph{P} \&lt; .001). Treatment willingness was also the highest for lifetime ASCVD risk (77.9\% very willing) followed by 10-year ASCVD risk (68.1\%) and 10-year CVD death risk (63.1\%; both\emph{P} \&lt; .001). Compared with participants who were shown a bar graph or no graphic, those who were shown the risk information with a pictogram had the lowest perception of disease severity and the lowest willingness to consider therapy. These findings were robust across demographic and socioeconomic subgroups.{$<$}/p{$><$}h3{$>$}Conclusions and Relevance{$<$}/h3{$><$}p{$>$}The format, time horizon, and outcome used for risk estimation influence patient perceptions and should be considered when designing risk communication tools. When shown lifetime risk estimates, patients had higher risk perception and willingness for therapy than when shown 10-year estimates. Pictogram risk displays may decrease risk perception and consideration for treatment.{$<$}/p{$>$}},
  langid = {english},
  keywords = {probability,risk-communication,teaching,teaching-mds}
}

@book{nci98int,
  title = {Integrating {{Economic Analyses}} into {{Cancer Clinical Trials}}: {{The National Cancer Institute}} -- {{American Society}} of {{Clinical Oncology Economics Workbook}}},
  author = {{National Cancer Institute}},
  date = {1998},
  publisher = {{National Cancer Institute}},
  location = {{Bethesda, MD}},
  citeulike-article-id = {13265109},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {analysis-of-cost}
}

@article{nea05key,
  title = {Key {{Issues}} in {{End Point Selection}} for {{Heart Failure Trials}}: {{Composite End Points}}},
  shorttitle = {Key {{Issues}} in {{End Point Selection}} for {{Heart Failure Trials}}},
  author = {Neaton, James D. and Gray, Gerry and Zuckerman, Bram D. and Konstam, Marvin A.},
  date = {2005-10-01},
  journaltitle = {Journal of Cardiac Failure},
  volume = {11},
  number = {8},
  eprint = {16230258},
  eprinttype = {pmid},
  pages = {567--575},
  publisher = {{Elsevier}},
  issn = {1071-9164, 1532-8414},
  doi = {10.1016/j.cardfail.2005.08.350},
  url = {https://www.onlinejcf.com/article/S1071-9164(05)01180-2/abstract},
  urldate = {2020-12-10},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Background{$<$}/h3{$><$}p{$>$}Composite outcomes are commonly used in heart failure trials. The aim of this article is to discuss the advantages and disadvantages of composite outcomes and recommend guidelines for reporting them. Examples are used to illustrate key points.{$<$}/p{$><$}h3{$>$}Methods and Results{$<$}/h3{$><$}p{$>$}A workshop jointly planned by the Heart Failure Society of America and the US Food and Drug Administration was convened in April 2004. One of the panel discussions concerned the use of composite outcomes in heart failure trials. With use of composite outcomes, event rates are higher and if it is reasonable to assume that the treatment effect is similar for each component of the composite outcome, sample size will be smaller than using one of the components as the primary end point. Composites end points are difficult to interpret if effects are not similar for all components or if the effect of treatment is primarily on a more common, less serious component of the composite. Composite outcomes typically only focus on the first occurring event. This can lead to a substantial loss of information in some trials. When composite end points are used, data collection for all components should continue until the end of the trial so that each component can be separately evaluated.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}Composite end points should be used with caution. Additional research is need on optimally weighting components of composite outcomes and to better using the entire event history of patients in heart failure trials. Further analyses of completed trials could be useful in this respect.{$<$}/p{$>$}},
  langid = {english},
  keywords = {chf,multiple-endpoints,rct}
}

@article{nel72the,
  title = {Theory and Applications of Hazard Plotting for Censored Failure Data},
  author = {Nelson, W. B.},
  date = {1972},
  journaltitle = {Technometrics},
  volume = {14},
  pages = {945--965},
  citeulike-article-id = {13264617},
  posted-at = {2014-07-14 14:09:39},
  priority = {0}
}

@article{nes96app,
  title = {An Applied Statistician's Creed},
  author = {Nester, Marks R.},
  date = {1996},
  journaltitle = {Appl Stat},
  volume = {45},
  pages = {401--410},
  citeulike-article-id = {13264618},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  note = {excellent arguments about the uselessness of hypothesis testing and about H\_0 always being false}
}

@article{neu20pre,
  title = {Predictively Consistent Prior Effective Sample Sizes},
  author = {Neuenschwander, Beat and Weber, Sebastian and Schmidli, Heinz and O'Hagan, Anthony},
  date = {2020},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13252},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13252},
  urldate = {2020-03-07},
  abstract = {Determining the sample size of an experiment can be challenging, even more so when incorporating external information via a prior distribution. Such information is increasingly used to reduce the size of the control group in randomized clinical trials. Knowing the amount of prior information, expressed as an equivalent prior effective sample size (ESS), clearly facilitates trial designs. Various methods to obtain a prior's ESS have been proposed recently. They have been justified by the fact that they give the standard ESS for one-parameter exponential families. However, despite being based on similar information-based metrics, they may lead to surprisingly different ESS for non-conjugate settings, which complicates many designs with prior information. We show that current methods fail a basic predictive consistency criterion, which requires the expected posterior–predictive ESS for a sample of size N to be the sum of the prior ESS and N. The expected local-information-ratio ESS is introduced and shown to be predictively consistent. It corrects the ESS of current methods, as shown for normally distributed data with a heavy-tailed Student-t prior and exponential data with a generalized Gamma prior. Finally, two applications are discussed: the prior ESS for the control group derived from historical data, and the posterior ESS for hierarchical subgroup analyses. This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {bayes,effective-sample-size,prior},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13252}
}

@article{neu90,
  title = {Reader Reaction: Some Comments on {{Rosner}}'s Multiple Logistic Model for Clustered Data},
  author = {Neuhaus, J. M. and Jewell, N. P.},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {523--534},
  citeulike-article-id = {13264619},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{neu98est,
  title = {Estimation Efficiency with Omitted Covariates in Generalized Linear Models},
  author = {Neuhaus, John M.},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {1124--1129},
  citeulike-article-id = {13264620},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {confounding,efficiency,model-misspecification,omitted-covariable,rct},
  note = {"to improve the efficiency of estimated covariate effects of interest, analysts of randomized clinical trial data should adjust for covariates that are strongly associated with the outcome, and ... analysts of observational data should not adjust for covariates that do not confound the association of interest"}
}

@article{neu99eva,
  title = {The Evaluation of Multiple Clinical Endpoints, with Application to Asthma},
  author = {Neuhauser, Markus and Steinijans, Volker W. and Bretz, Frank},
  date = {1999},
  journaltitle = {Drug Info J},
  volume = {33},
  pages = {471--477},
  citeulike-article-id = {13264621},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {alpha-adjustment,multiple-endpoints,rct},
  note = {evaluation of rules such as Capizzzi and Zhang: "one endpoint must be significant at the 0.05 level and the other endpoint has to trend in the right direction (0.2 level)"}
}

@article{nev19sem,
  title = {Semiparametric Linear Transformation Models: {{Effect}} Measures, Estimators, and Applications},
  shorttitle = {Semiparametric Linear Transformation Models},
  author = {Neve, Jan De and Thas, Olivier and Gerds, Thomas A.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8078},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8078},
  urldate = {2019-01-05},
  abstract = {Semiparametric linear transformation models form a versatile class of regression models with the Cox proportional hazards model being the most well-known member. These models are well studied for right censored outcomes and are typically used in survival analysis. We consider transformation models as a tool for situations with uncensored continuous outcomes where linear regression is not appropriate. We introduce the probabilistic index as a uniform effect measure for the class of transformation models. We discuss and compare three estimators using a working Cox regression model: the partial likelihood estimator, an estimator based on binary generalized linear models and one based on probabilistic index model estimating equations. The latter has a superior performance in terms of bias and variance when the working model is misspecified. For the purpose of illustration, we analyze data that were collected at an urban alcohol and drug detoxification unit.},
  langid = {english},
  keywords = {ordinal,semiparametric-model,transformation-model}
}

@article{new01log,
  title = {Logit Confidence Intervals and the Inverse Sinh Transformation},
  author = {Newcombe, Robert G.},
  date = {2001},
  journaltitle = {Am Statistician},
  volume = {55},
  pages = {200--202},
  citeulike-article-id = {13349291},
  posted-at = {2014-09-06 14:37:59},
  priority = {0},
  keywords = {confidence-intervals,wilson-interval},
  annotation = {modified interval that is not bothered by zero frequencies;logit Wald and Wilson score intervals for binomial proportions are symmetric on the logit scale},
  note = {modified interval that is not bothered by zero frequencies;logit Wald and Wilson score intervals for binomial proportions are symmetric on the logit scale}
}

@article{new02par,
  title = {Parameters behind “Nonparametric” Statistics: {{Kendall}}'s Tau, {{Somers}}' {{D}} and Median Differences},
  author = {Newson, R.},
  date = {2002},
  journaltitle = {Stata Journal},
  volume = {2},
  number = {1},
  publisher = {Stata Press},
  location = {College Station, TX},
  url = {http://www.stata-journal.com/article.html?article=st0007},
  abstract = {So-called nonparametric statistical methods are often in fact based on population parameters, which can be estimated (with confidence limits) using the corresponding sample statistics. This article reviews the uses of three such parameters, namely Kendalls Somers D, and the Hodges-Lehmann median difference. Confidence intervals for these are demonstrated using the somersd package. It is argued that confidence limits for these parameters, and their differences, are more informative than the traditional practice of reporting only p-values. These three parameters are also important in defining other tests and parameters, such as the Wilcoxon test, the area under the receiver operating characteristic (ROC) curve, Harrells C, and the Theil median slope.},
  citeulike-article-id = {13470131},
  citeulike-attachment-1 = {new02par.pdf; /pdf/user/harrelfe/article/13470131/999110/new02par.pdf; 4ec009e6c80a620a1788351fc6de8b081cd5e039},
  citeulike-linkout-0 = {http://www.stata-journal.com/article.html?article=st0007},
  posted-at = {2014-12-26 14:41:40},
  priority = {2},
  keywords = {c-index,somers-dxy},
  annotation = {http://www.stata-journal.com/article.html?article=st0007}
}

@article{new06con,
  title = {Confidence Intervals for Rank Statistics: {{Somers}}' {{D}} and Extensions},
  author = {Newson, Roger},
  date = {2006},
  journaltitle = {Stata J},
  volume = {6},
  number = {3},
  pages = {309--334},
  citeulike-article-id = {13265489},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {censored-data,generalization-of-c-index,jackknife-variances,paired-data,stratification}
}

@book{new09evi,
  title = {Evidence-{{Based Diagnosis}}},
  author = {Newman, Thomas B. and Kohn, Michael A.},
  date = {2009},
  publisher = {{Cambridge University Press}},
  abstract = {Evidence-Based Diagnosis is a textbook about diagnostic, screening, and prognostic tests in clinical medicine. The authors' approach is based on many years of experience teaching physicians in a clinical research training program. Although requiring only a minimum of mathematics knowledge, the quantitative discussions in this book are deeper and more rigorous than in most introductory texts. The book includes numerous worked examples and 60 problems (with answers) based on real clinical situations and journal articles. The book will be helpful and accessible to anyone seeking to select, develop, or market medical tests. Topics covered include: the diagnostic process, test reliability and accuracy, likelihood ratios, and ROC curves, testing and treatment thresholds, critical appraisal of studies of diagnostic, screening and prognostic tests, test independence and methods of combining tests, quantifying treatment benefits using randomized trials and observational studies, Bayesian interpretation of P values and confidence intervals and challenges for evidence-based diagnosis and evidence-based medicine.},
  isbn = {978-0-521-71402-0},
  pagetotal = {312}
}

@article{new94app,
  title = {Approximate {{Bayesian}} Inference with the Weighted Likelihood Bootstrap (with Discussion)},
  author = {Newton, Michael A. and Rafter, Adrian E.},
  date = {1994},
  journaltitle = {J Roy Stat Soc B},
  volume = {56},
  pages = {3--48},
  citeulike-article-id = {13264622},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {bayesian-inference,bootstrap,weighted-mle}
}

@article{new98int,
  title = {Interval Estimation for the Difference between Independent Proportions: {{Comparison}} of Eleven Methods},
  author = {Newcombe, Robert G.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {873--890},
  citeulike-article-id = {13264623},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {confidence-interval,simulation-setup,two-sample-binomial}
}

@article{new98two,
  title = {Two-Sided Confidence Intervals for the Single Proportion: {{Comparison}} of Seven Methods},
  author = {Newcombe, Robert G.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {857--872},
  citeulike-article-id = {13264624},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {confidence-interval,one-sample-binomial}
}

@article{nga97emp,
  title = {An Empirical Comparison of Statistical Tests for Assessing the Proportional Hazards Assumption of {{Cox}}'s Model},
  author = {Ng'andu, Nicholas H.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {611--626},
  citeulike-article-id = {13264625},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {assessing-ph,power-of-harrell-lee-test}
}

@article{ngu20est,
  title = {Estimating Individualized Treatment Regimes from Crossover Designs},
  author = {Nguyen, Crystal T. and Luckett, Daniel J. and Kahkoska, Anna R. and Shearrer, Grace E. and Spruijt‐Metz, Donna and Davis, Jaimie N. and Kosorok, Michael R.},
  date = {2020},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13186},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13186},
  urldate = {2019-11-25},
  abstract = {The field of precision medicine aims to tailor treatment based on patient-specific factors in a reproducible way. To this end, estimating an optimal individualized treatment regime (ITR) that recommends treatment decisions based on patient characteristics to maximize the mean of a pre-specified outcome is of particular interest. Several methods have been proposed for estimating an optimal ITR from clinical trial data in the parallel group setting where each subject is randomized to a single intervention. However, little work has been done in the area of estimating the optimal ITR from crossover study designs. Such designs naturally lend themselves to precision medicine, because they allow for observing the response to multiple treatments for each patient. In this paper, we introduce a method for estimating the optimal ITR using data from a 2 × 2 crossover study with or without carryover effects. The proposed method is similar to policy search methods such as outcome weighted learning (OWL); however, we take advantage of the crossover design by using the difference in responses under each treatment as the observed reward. We establish Fisher and global consistency, present numerical experiments, and analyze data from a feeding trial to demonstrate the improved performance of the proposed method compared to standard methods for a parallel study design. This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {crossover,personalized-medicine}
}

@article{nhanes2010,
  title = {National {{Health}} and {{Nutrition Examination Survey}}},
  author = {{Centers for Disease Control and Prevention CDC. National Center for Health Statistics NCHS}},
  date = {2010},
  publisher = {U.S. Department of Health and Human Services, Centers for Disease Control and Prevention},
  location = {Hyattsville, MD},
  url = {http://www.cdc.gov/nchs/nhanes/nhanes2009-2010/nhanes09_10.htm},
  citeulike-article-id = {13265923},
  citeulike-linkout-0 = {http://www.cdc.gov/nchs/nhanes/nhanes2009-2010/nhanes09_10.htm},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@article{nic13dyn,
  title = {Dynamic Prediction by Landmarking in Competing Risks},
  author = {Nicolaie, M. A. and van Houwelingen, Hans C. and de Witte, T. M. and Putter, H.},
  options = {useprefix=true},
  date = {2013},
  journaltitle = {Stat Med},
  volume = {32},
  number = {12},
  pages = {2031--2047},
  doi = {10.1002/sim.5665},
  url = {http://dx.doi.org/10.1002/sim.5665},
  abstract = {We propose an extension of the landmark model for ordinary survival data as a new approach to the problem of dynamic prediction in competing risks with time-dependent covariates. We fix a set of landmark time points tLM within the follow-up interval. For each of these landmark time points tLM, we create a landmark data set by selecting individuals at risk at tLM; we fix the value of the time-dependent covariate in each landmark data set at tLM. We assume Cox proportional hazard models for the cause-specific hazards and consider smoothing the (possibly) time-dependent effect of the covariate for the different landmark data sets. Fitting this model is possible within the standard statistical software. We illustrate the features of the landmark modelling on a real data set on bone marrow transplantation.},
  citeulike-article-id = {13265965},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5665},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {competing-risks,cox-proportional-hazards-model,dynamic-prediction,landmark,time-dependent-variables}
}

@article{nic99reg,
  title = {Regression Modeling Strategies: {{An}} Illustrative Case Study from Medical Rehabilitation Outcomes Research},
  author = {Nick, Todd G. and Hardin, J. Michael},
  date = {1999},
  journaltitle = {Am J Occ Ther},
  volume = {53},
  pages = {459--470},
  citeulike-article-id = {13265158},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {regression-modeling-strategies,teaching}
}

@article{nin20sem,
  title = {Semiparametric Modelling and Estimation of Covariate-Adjusted Dependence between Bivariate Recurrent Events},
  author = {Ning, Jing and Cai, Chunyan and Chen, Yong and Huang, Xuelin and Wang, Mei-Cheng},
  date = {2020},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13229},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13229},
  urldate = {2020-01-30},
  abstract = {A time-dependent measure, termed the rate ratio, was proposed to assess the local dependence between two types of recurrent event processes in one-sample settings. However, the one-sample work does not consider modelling the dependence by covariates such as subject characteristics and treatments received. The focus of this paper is to understand how and in what magnitude the covariates influence the dependence strength for bivariate recurrent events. We propose the covariate-adjusted rate ratio, a measure of covariate-adjusted dependence. We propose a semiparametric regression model for jointly modeling the frequency and dependence of bivariate recurrent events: the first level is a proportional rates model for the marginal rates and the second level is a proportional rate ratio model for the dependence structure. We develop a pseudo-partial likelihood to estimate the parameters in the proportional rate ratio model. We establish the asymptotic properties of the estimators and evaluate the finite sample performance via simulation studies. We illustrate the proposed models and methods using a soft tissue sarcoma study that examines the effects of initial treatments on the marginal frequencies of local/distant sarcoma recurrence and the dependence structure between the two types of cancer recurrence. This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {copula,dependent-responses,multiple-endpoints,recurrent-events}
}

@article{nis06non,
  title = {Non-Parametric Inference of Adverse Events under Informative Censoring},
  author = {Nishikawa, Masako and Tango, Toshiro and Ogawa, Makiko},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {3981--4003},
  citeulike-article-id = {13265539},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {adverse-events,clinical-safety,cumulative-incidence-function,cumulative-joint-incidence,drug-safety,pharmaceutical-safety,recurrent-event-with-competing-risk,terminating-event,time-to-event-data},
  note = {novel way to use different severities of events as competing risks;dropout;informative censoring;AEs masked by withdrawal from treatment}
}

@article{nix01ran,
  title = {Randomization at the Level of Primary Care Practice: Use of Pre-Intervention Data and Random Effects Models},
  author = {Nixon, R. M. and Duffy, S. W. and Fender, G. R. K. and Day, N. E. and Prevost, T. C.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1727--1738},
  citeulike-article-id = {13265206},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {cluster-randomization,medical-practice-studies,pre-intervention-data}
}

@article{noe87,
  title = {Sample Size Determination for Some Common Nonparametric Tests},
  author = {Noether, G.},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {645--647},
  citeulike-article-id = {13264626},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {distribution-free-methods,sample-size-estimation}
}

@article{nol10com,
  title = {Computing in the Statistics Curricula},
  author = {Nolan, Deborah and Temple Lang, Duncan},
  date = {2010},
  journaltitle = {Am Statistician},
  volume = {64},
  number = {2},
  pages = {97--107},
  citeulike-article-id = {13265833},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {computational-literacy,curriculum-reform,information-technology,statistical-computing,statistical-education,statistics-curriculum},
  note = {best paper available on ideas for statistical computing curriculum;Figure 1 is an excellent summary of the inter-related subject areas;quotes Friedman (2001): "Computing has been one of the most glaring omissions in the set of tools that have so far defined Statistics. Had we incorporated computing methodology from its inception as a fundamental statistical tool (as opposed to simply a convenient way to apply our existing tools) many of the other related fields would not have needed to exist. They would have been part of our field."}
}

@article{nom21con,
  title = {Confidence Intervals of Prediction Accuracy Measures for Multivariable Prediction Models Based on the Bootstrap-Based Optimism Correction Methods},
  author = {Noma, Hisashi and Shinozaki, Tomohiro and Iba, Katsuhiro and Teramukai, Satoshi and Furukawa, Toshi A.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9148},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9148},
  urldate = {2021-07-25},
  abstract = {In assessing prediction accuracy of multivariable prediction models, optimism corrections are essential for preventing biased results. However, in most published papers of clinical prediction models, the point estimates of the prediction accuracy measures are corrected by adequate bootstrap-based correction methods, but their confidence intervals are not corrected, for example, the DeLong's confidence interval is usually used for assessing the C-statistic. These naïve methods do not adjust for the optimism bias and do not account for statistical variability in the estimation of parameters in the prediction models. Therefore, their coverage probabilities of the true value of the prediction accuracy measure can be seriously below the nominal level (eg, 95\%). In this article, we provide two generic bootstrap methods, namely, (1) location-shifted bootstrap confidence intervals and (2) two-stage bootstrap confidence intervals, that can be generally applied to the bootstrap-based optimism correction methods, that is, the Harrell's bias correction, 0.632, and 0.632+ methods. In addition, they can be widely applied to various methods for prediction model development involving modern shrinkage methods such as the ridge and lasso regressions. Through numerical evaluations by simulations, the proposed confidence intervals showed favorable coverage performances. Besides, the current standard practices based on the optimism-uncorrected methods showed serious undercoverage properties. To avoid erroneous results, the optimism-uncorrected confidence intervals should not be used in practice, and the adjusted methods are recommended instead. We also developed the R package predboot for implementing these methods ( https://github.com/nomahi/predboot). The effectiveness of the proposed methods are illustrated via applications to the GUSTO-I clinical trial.},
  langid = {english},
  keywords = {bootstrap,confidence-interval,predictive-accuracy,validation},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9148}
}

@article{noncomp,
  title = {Noncompliance},
  author = {{Various}},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {247--388},
  citeulike-article-id = {13264627},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {paper-by-rubin,summary-by-dr-cox,whole-issue-on-non-compliance-in-rcts}
}

@article{noo12bay,
  title = {Bayesian {{Analysis}} of {{Transition Model}} for {{Longitudinal Ordinal Response Data}}: {{Application}} to {{Insomnia Data}}},
  shorttitle = {Bayesian {{Analysis}} of {{Transition Model}} for {{Longitudinal Ordinal Response Data}}},
  author = {Noorian, Sajad and Ganjali, Mojtaba},
  date = {2012},
  journaltitle = {International Journal of Statistics in Medical Research},
  volume = {1},
  number = {2},
  pages = {148--161},
  issn = {1929-6029},
  url = {https://www.academia.edu/30796618/Bayesian_Analysis_of_Transition_Model_for_Longitudinal_Ordinal_Response_Data_Application_to_Insomnia_Data},
  urldate = {2020-12-22},
  abstract = {Bayesian Analysis of Transition Model for Longitudinal Ordinal Response Data: Application to Insomnia Data},
  langid = {english},
  keywords = {bayes,markov,ordinal,serial},
  note = {Bayesian inference for Goodman-Kruskal gamma rank correlation using multinomial distribution and Dirichlet prior.~ Markov proportional odds model with priors for intercepts that are ordered t distribution variates.~ Also uses a sequential-conditioning Markov-like prior for the coefficients of previous states.~ Methods don't scale to high number of Y levels.~ Dataset used is not a very good one as it categorized an ordinal measurement into a very crude ordinal measurement.~ Transition model is categorical in previous Y level.}
}

@article{nor01val,
  title = {Validating Recommendations for Coronary Angiography Following Acute Myocardial Infarction in the Elderly: {{A}} Matched Analysis Using Propensity Scores},
  author = {Normand, Sharon-Lise T. and Landrum, Mary B. and Guadagnoli, Edward and Ayanian, John Z. and Ryan, Thomas J. and Cleary, Paul D. and McNeil, Barbara J.},
  date = {2001},
  journaltitle = {J Clin Epi},
  volume = {54},
  pages = {387--398},
  citeulike-article-id = {13265188},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {good-example-of-propensity-score-and-matching,logistic-model-for-propensity}
}

@article{nor06car,
  title = {Cardiac Uncoupling and Heart Rate Variability Stratify {{ICU}} Patients by Mortality: A Study of 2088 Trauma Patients},
  author = {Norris, Patrick R. and Ozdas, A. and Cao, H. and Williams, A. E. and Harrell, F. E. and Jenkins, J. M. and Morris, John A.},
  date = {2006},
  journaltitle = {Ann Surg},
  volume = {243},
  pages = {804--812},
  citeulike-article-id = {13265585},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {heart-rate-variability},
  note = {discussion 812-814}
}

@article{nor89,
  title = {Issues in the Use of Change Scores in Randomized Trials},
  author = {Norman, G. R.},
  date = {1989},
  journaltitle = {J Clin Epi},
  volume = {42},
  pages = {1097--1105},
  citeulike-article-id = {13264628},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {measurement,research-methods}
}

@article{nor97sta,
  title = {Statistical Methods for Profiling Providers of Medical Care: {{Issues}} and Applications},
  author = {Normand, Sharon-Lise T. and Glickman, Mark E. and Gatsonis, Constantine A.},
  date = {1997},
  journaltitle = {J Am Stat Assoc},
  volume = {92},
  pages = {803--814},
  doi = {10.1080/01621459.1997.10474036},
  url = {http://dx.doi.org/10.1080/01621459.1997.10474036},
  citeulike-article-id = {13264629},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/01621459.1997.10474036},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {hierarchical-model,provider-profiling,scorecard},
  note = {use of posterior probability that one hospital's mortality exceeds the median mortality by at least a factor of 1.5;problems with HCFA's approach;random intercept model;random slope model;interaction between provider and severity of disease;methods for judging convergence of Gibbs sampler}
}

@article{nor98ens,
  title = {Ensuring Good Statistical Practice in Clinical Research: {{Guidelines}} for Standard Operating Procedures (an Update)},
  author = {North, Philip M.},
  date = {1998},
  journaltitle = {Drug Info J},
  volume = {32},
  pages = {665--682},
  citeulike-article-id = {13264630},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {pharmaceutical,rct,statistical-sop}
}

@article{nor99met,
  title = {Tutorial in {{Biostatistics}}: {{Meta-analysis}}: {{Formulating}}, Evaluating, Combining, and Reporting},
  author = {Normand, Sharon-Lise T.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {321--359},
  citeulike-article-id = {13264631},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {bugs,meta-analysis,mixed-models,publication-bias,random-effects,teaching-mds}
}

@article{not10bay,
  title = {Bayesian Projection Approaches to Variable Selection in Generalized Linear Models},
  author = {Nott, David J. and Leng, Chenlei},
  date = {2010-12},
  journaltitle = {Computational Statistics \& Data Analysis},
  volume = {54},
  number = {12},
  pages = {3227--3241},
  issn = {01679473},
  doi = {10.1016/j.csda.2010.01.036},
  url = {http://dx.doi.org/10.1016/j.csda.2010.01.036},
  abstract = {A Bayesian approach to variable selection which is based on the expected Kullback–Leibler divergence between the full model and its projection onto a submodel has recently been suggested in the literature. For generalized linear models an extension of this idea is proposed by considering projections onto subspaces defined via some form of L1L1 constraint on the parameter in the full model. This leads to Bayesian model selection approaches related to the lasso. In the posterior distribution of the projection there is positive probability that some components are exactly zero and the posterior distribution on the model space induced by the projection allows exploration of model uncertainty. Use of the approach in structured variable selection problems such as ANOVA models is also considered, where it is desired to incorporate main effects in the presence of interactions. Projections related to the non-negative garotte are able to respect the hierarchical constraints. A consistency result is given concerning the posterior distribution on the model induced by the projection, showing that for some projections related to the adaptive lasso and non-negative garotte the posterior distribution concentrates on the true model asymptotically.},
  citeulike-article-id = {6660033},
  citeulike-attachment-1 = {not10bay.pdf; /pdf/user/harrelfe/article/6660033/1072316/not10bay.pdf; f8fd0acb578c766ba3479da9adb036de784ecbe2},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.csda.2010.01.036},
  day = {10},
  posted-at = {2016-06-14 01:01:11},
  priority = {2},
  keywords = {bayesian-inference,bayesian-methods,model-approximation,pre-conditioning,variable-selection}
}

@article{nou90,
  title = {Proportional Hazards Changepoint Models in Survival Analysis},
  author = {Noura AA, Read K. L. Q.},
  date = {1990},
  journaltitle = {Appl Stat},
  volume = {39},
  pages = {241--253},
  citeulike-article-id = {13264632},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {general,survival-analysis-regression}
}

@article{nou96ste,
  title = {A Step-by-Step Recommendation for Sample Size Adjustment in Clinical Trials},
  author = {Noursalehi, Mojtaba and Rogers, James L.},
  date = {1996},
  journaltitle = {Drug Info J},
  volume = {30},
  pages = {957--960},
  citeulike-article-id = {13264633},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {adaptive-study,blinding,pharmaceutical,rct,sample-size-adjustment}
}

@article{ntz03pre,
  title = {Predictive Ability of {{DNA}} Microarrays for Cancer Outcome and Correlates: An Empirical Assessment},
  author = {Ntzani, Evangelia and Ioannidis, John P. A.},
  date = {2003},
  journaltitle = {Lancet},
  volume = {362},
  pages = {1439--1444},
  citeulike-article-id = {13265449},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  note = {"Only 26\% of the studies attempted independent validation or cross-validation of their proposed findings. ... 18 studies used cross-validation (eight complete, eight incomplete, and two both). Of the nine studies that used cross-validation for major clinical outcomes, one used complete cross-validation, seven used incomplete forms of cross-validation, and one used both. ... several modelling approaches were also tested, with comparable or slightly worse error rates than the eventually preferred approach presented as the main analysis. Sotiriou and colleagues probably used the same genes in all cross-validation sets, although this point is unclear. van't Veer and colleagues did both complete and incomplete cross-validations, focusing primarily on the results of the incomplete cross-validation (for the same genes each time), but the error rate was higher ... in the complete cross-validation. Three other groups ... also selected among several gene models the ones with best performance in cross-validation. ... However the best performance was seen in four small datasets ... the odds of reaching a formally significant association increased 3.5 times ... per doubling of sample size and 9.7 times ... per ten-fold increase in the number of probes. ... A study on lung adenocarcinoma found that unsupervised DNA microarray analysis predicted death with a sensitivity of 38\% and a specificity of 81\%. Cross-validation of supervised modelling gave 71\% sensitivity and 66\% specificity. In two independent validations, the sensitivity was 64\% and 50\%, with specificity 63\% and 64\%, respectively. ... We assessed 84 DNA microarray studies addressing important clinical issues on cancer outcomes and correlates. The predictive performance of this new technique was variable, and in many cases molecular classifications were not subjected to appropriate validation. Validation in independent datasets has been rare. Furthermore, without full adjustment for previously known predictors of cancer outcomes, appraisal of the contribution of DNA microarray data towards individualising cancer management is difficult. ... incomplete cross-validation can lead to inflated estimates of accuracy. ... Reporting of only the best results spuriously inflates accuracy. ... Phase III studies have been rare in prognostic research in general. ... Complete, uncensored reporting, publicly available data, and standardisation within and between institutions are essential"}
}

@article{nuz14sci,
  title = {Scientific Method: {{Statistical}} Errors},
  shorttitle = {Scientific Method},
  author = {Nuzzo, Regina},
  date = {2014-02-13},
  journaltitle = {Nature News},
  volume = {506},
  number = {7487},
  pages = {150},
  doi = {10.1038/506150a},
  url = {http://www.nature.com/news/scientific-method-statistical-errors-1.14700},
  urldate = {2020-03-16},
  abstract = {P values, the 'gold standard' of statistical validity, are not as reliable as many scientists assume.},
  langid = {english}
}

@article{nuz15how,
  title = {How Scientists Fool Themselves --- and How They Can Stop},
  author = {Nuzzo, Regina},
  date = {2015-10},
  journaltitle = {Nature},
  volume = {526},
  number = {7572},
  pages = {182--185},
  citeulike-article-id = {13805060},
  citeulike-attachment-1 = {nuz15how.pdf; /pdf/user/harrelfe/article/13805060/1039020/nuz15how.pdf; dcb280611572b9dee5407c90f7155cbefcd75611},
  day = {8},
  posted-at = {2015-10-18 13:22:58},
  priority = {0},
  keywords = {bad-science,reproducibility}
}

@book{oak86sta,
  title = {Statistical {{Inference}}: {{A Commentary}} for the {{Social}} and {{Behavioral Sciences}}},
  author = {Oakes, M.},
  date = {1986},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264634},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  note = {"It is incomparably more useful to have a plausible range for the value of a parameter than to know, with whatever degree of certitude, what single value is untenable."}
}

@article{obe97iss,
  title = {Issues and Algorithms in Cost-Effectiveness Inference},
  author = {Obenchain, Robert L.},
  date = {1997},
  journaltitle = {Biopharm Rep ASA},
  volume = {5},
  number = {2},
  pages = {1--7},
  citeulike-article-id = {13264635},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {bootstrap,cost-effectiveness,economic-analysis,fiellers-theorem,icer-slope,interpretation-of-negative-ce-ratio}
}

@article{obe99mix,
  title = {Mixed-Model Imputation of Cost Data for Early Discontinuers from a Randomized Clinical Trial},
  author = {Obenchain, Robert L. and Johnstone, Bryan M.},
  date = {1999},
  journaltitle = {Drug Info J},
  volume = {33},
  pages = {191--209},
  citeulike-article-id = {13264636},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {analysis-of-cost,approximate-bayesian-bootstrap,bootstrap,censoring,cost-per-unit-time,mixed-model,multiple-imputation,shrinkage,smearing-estimator}
}

@article{obr05sem,
  title = {Semi-Parametric and Non-Parametric Methods for Clinical Trials with Incomplete Data},
  author = {O'Brien, Peter C. and Zhang, David and Bailey, Kent R.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {341--358},
  citeulike-article-id = {13265402},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {clinical-trials,locf,missing-data,non-parametric,rct,semi-parametric},
  note = {LOCF was observed to produce markedly biased estimates and markedly inflated type I error rates when censoring was unequal in the two treatment arms";last rank carried forward;LRCF;"mixed model repeated measures performed similarly to cumulative change and LRCF and makes somewhat less restrictive assumptions about missingness mechanisms";cumulative change model similar to Kaplan-Meier piecing together of intervals;cumulative change and LRCF assume that "censoring mechanism may differ between treatment groups, but with treatment group the distribution of the change in the endpoint from baseline to last scheduled visit is assumed to be the same for completers and non-completers";errata 24:3385}
}

@article{obr84pro,
  title = {Procedure for Comparing Samples with Multiple Endpoints},
  author = {O'Brien, Peter C.},
  date = {1984},
  journaltitle = {Biometrics},
  volume = {40},
  pages = {1079--1087},
  citeulike-article-id = {13264637},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {multiple-events,multivariate-response,study-design},
  annotation = {Errata Biometrics 51:1580-1581; 1995; see liu10ran}
}

@inproceedings{obr86usi,
  title = {Using the {{SAS}} System to Perform Power Analyses for Log-Linear Models},
  booktitle = {Proceedings of the {{Eleventh Annual Conference}} of the {{SAS Users Group International}}},
  author = {O'Brien, Ralph G.},
  date = {1986},
  pages = {778--784},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary, NC}},
  citeulike-article-id = {13264638},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {maximum-likelihood,sample-size}
}

@article{obr88com,
  title = {Comparing Two Samples: {{Extensions}} of the t, Rank-Sum, and Log-Rank Test},
  author = {O'Brien, Peter C.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {52--61},
  doi = {10.1080/01621459.1988.10478564},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478564#.U_sn0XVdU3E},
  abstract = {I consider the problem of testing that two populations are identical with respect to the distribution of a continuous variable against the alternative that values tend to be larger in one population. I observe that the t, rank-sum, and log-rank tests are insensitive for a large class of alternatives that may be expected to occur commonly in practice, propose a criterion for identifying this problem in a particular data set, and propose corresponding extensions of the conventional methods. The proposed methods should be useful for both identifying and interpreting group differences.},
  citeulike-article-id = {13264639},
  citeulike-attachment-1 = {obrien₈8<sub>c</sub>omparing₉82093.pdf; /pdf/user/harrelfe/article/13264639/982093/obrien₈8<sub>c</sub>omparing₉82093.pdf; babefef8b2dff97476181427bc99321531113604},
  citeulike-linkout-0 = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478564#.U_sn0XVdU3E},
  citeulike-linkout-1 = {http://dx.doi.org/10.1080/01621459.1988.10478564},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {hotelling,logistic,multivariate},
  note = {see Hauck WW, Hyslop T, Anderson S (2000) Stat in Med 19:887-899}
}

@article{obr97int,
  title = {Interpreting Tests for Efficacy in Clinical Trials with Multiple Endpoints},
  author = {O'Brien, Peter C. and Geller, Nancy L.},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {222--227},
  citeulike-article-id = {13264640},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {innapropriate-use-of-multiple-endpoint-statistical-methods,multiple-endpoints,study-design}
}

@article{oet07adj,
  title = {Adjuvant Chemotherapy with Gemcitabine vs Observation in Patients Undergoing Curative-Intent Resection of Pancreatic Cancer},
  author = {Oettle, Helmut and Post, Stefan and Neuhaus, Peter and {Others}},
  date = {2007},
  journaltitle = {JAMA},
  volume = {297},
  number = {3},
  pages = {267--277},
  doi = {10.1001/jama.297.3.267},
  url = {http://dx.doi.org/10.1001/jama.297.3.267},
  citeulike-article-id = {13265664},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.297.3.267},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {cancer,pancreas},
  note = {clinical trial report;provides control event estimates for new trials of pancreatic cancer treatments}
}

@article{oh04dic,
  title = {Dicing with the Unknown},
  author = {O'Hagan, Tony},
  date = {2004},
  journaltitle = {Significance},
  volume = {1},
  number = {3},
  pages = {132--133},
  issn = {1740-9713},
  doi = {10.1111/j.1740-9713.2004.00050.x},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1740-9713.2004.00050.x},
  urldate = {2020-11-22},
  abstract = {There are many things that I am uncertain about, says Tony O'Hagan. Some are merely unknown to me, while others are unknowable. This article is about different kinds of uncertainty, and how the distinction between them impinges on the foundations of Probability and Statistics.},
  langid = {english},
  keywords = {bayes,probability,teaching,teaching-mds},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740-9713.2004.00050.x}
}

@article{oh11fas,
  title = {Fast Nonparametric Quantile Regression with Arbitrary Smoothing Methods},
  author = {Oh, Hee-Seok and Lee, Thomas C. M. and Nychka, Douglas W.},
  date = {2011},
  journaltitle = {J Comp Graph Stat},
  volume = {20},
  number = {2},
  pages = {510--526},
  citeulike-article-id = {13265887},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {quantile-regression},
  annotation = {errata 20:787-8;2011},
  note = {excellent example of approximating a function having discontinuous first derivative with one having smooth first derivative without changing the estimator detectably}
}

@article{oha01bay,
  title = {Bayesian Cost-Effectiveness Analysis from Clinical Trial Data},
  author = {O'Hagan, Anthony and Stevens, John W. and Montmartin, Jacques},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {733--753},
  doi = {10.1002/sim.861},
  url = {http://dx.doi.org/10.1002/sim.861},
  citeulike-article-id = {13265187},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.861},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {bayesian-model,c-e,cost-effectiveness,rct,winbugs},
  note = {winbugs example for getting probability of dominance}
}

@article{ohl07fle,
  title = {Flexible Random-Effects Models Using {{Bayesian}} Semi-Parametric Models: {{Applications}} to Institutional Comparisons},
  author = {{Ohlssen} and Sharples, L. D. and Spiegelhalter, D. J.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {2088--2112},
  citeulike-article-id = {13265568},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {bayesian-nonparametrics,dirichlet-process,great-winbugs-code-examples,health-services-research,hsr,institutional-comparisons,league-tables,outcomes-research,scorecarding}
}

@article{ohm96car,
  title = {Cardiac Troponin {{T}} Levels for Risk Stratification in Acute Myocardial Ischemia},
  author = {Ohman, E. M. and Armstrong, P. W. and Christenson, R. H. and Granger, C. B. and Katus, H. A. and Hamm, C. W. and O'Hannesian, M. A. and Wagner, G. S. and Kleiman, N. S. and Harrell, F. E. and Califf, R. M. and Topol, E. J. and Lee, K. L. and Investigators, The G.},
  date = {1996},
  journaltitle = {NEJM},
  volume = {335},
  pages = {1333--1341},
  citeulike-article-id = {13264641},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {clinical-prediction,medical-paper-examples-of-nonparametric-regression-and-splines}
}

@article{old62not,
  title = {A Note on the Analysis of Repeated Measurements of the Same Subjects},
  author = {Oldham, P. D.},
  date = {1962},
  journaltitle = {J Chron Dis},
  volume = {15},
  pages = {969},
  citeulike-article-id = {13265387},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  note = {Probably the first to suggest what is now called the Bland-Altman plot; analysis of change; change scores}
}

@article{oli04com,
  title = {Comorbid Disease and the Effect of Race and Ethnicity on In-Hospital Mortality from Aspiration Pneumonia},
  author = {Oliver, M. Norman and Stukenborg, George J. and Wagner, Douglas P. and Harrell, Frank E. and Kilbridge, Kerry L. and Lyman, Jason A. and Einbinder, Jonathan and Connors, Alfred F.},
  date = {2004},
  journaltitle = {J Nat Med Assoc},
  volume = {96},
  pages = {1462--1469},
  citeulike-article-id = {13265428},
  posted-at = {2014-07-14 14:09:56},
  priority = {0}
}

@article{ols90sta,
  title = {Statistical Analysis of Quality of Life Data in Cancer Clinical Trials},
  author = {Olschewski, M. and Schumacher, M.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {749--763},
  citeulike-article-id = {13264642},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {growth-curve-analysis,markov-chain,qol,repeated-measurements}
}

@article{oma00ana,
  title = {Analysis of a Cluster Randomized Trial with Binary Outcome Data Using a Multi-Level Model},
  author = {Omar, Rumana A. and Thompson, Simon G.},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {2675--2688},
  citeulike-article-id = {13265147},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {cluster-randomized-trial,cluster-variance-adjustment,hierarchical-model,marginal-model,multi-level-model,random-effects-model},
  note = {possible problems with cluster-adjusted variance estimates when cluster sizes differ strongly}
}

@article{oma01mod,
  title = {Modelling and Generating Correlated Binary Variables},
  author = {Oman, Samuel D. and Zucker, David M.},
  date = {2001},
  journaltitle = {Biometrika},
  volume = {88},
  pages = {287--290},
  citeulike-article-id = {13265197},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {simulating-binary-variables,simulation-setup}
}

@article{oma99ana,
  title = {Analysing Repeated Measurements Data: {{A}} Practical Comparison of Methods},
  author = {Omar, Rumana Z. and Wright, Eileen M. and Turner, Rebecca M. and Thompson, Simon G.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1587--1603},
  citeulike-article-id = {13264643},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {comparison,repeated-measurements,serial-data,teaching}
}

@article{opi95nif,
  title = {Nifedipine and {{Mortality}}: {{Grave}} Defects in the Dossier},
  author = {Opie, Lionel H. and Messerli, Franz H.},
  date = {1995},
  journaltitle = {Circ},
  volume = {92},
  pages = {1068--1073},
  citeulike-article-id = {13264644},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {ccb,meta-analysis}
}

@article{oqu05exp,
  title = {Explained Randomness in Proportional Hazards Models},
  author = {O'Quigley, John and Xu, Ronghui and Stare, Janez},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  number = {3},
  pages = {479--489},
  doi = {10.1002/sim.1946},
  url = {http://dx.doi.org/10.1002/sim.1946},
  abstract = {A coefficient of explained randomness, analogous to explained variation but for non-linear models, was presented by Kent. The construct hinges upon the notion of Kullback–Leibler information gain. Kent and O'Quigley developed these ideas, obtaining simple, multiple and partial coefficients for the situation of proportional hazards regression. Their approach was based upon the idea of transforming a general proportional hazards model to a specific one of Weibull form. Xu and O'Quigley developed a more direct approach, more in harmony with the semi-parametric nature of the proportional hazards model thereby simplifying inference and allowing, for instance, the use of time dependent covariates. A potential drawback to the coefficient of Xu and O'Quigley is its interpretation as explained randomness in the covariate given time. An investigator might feel that the interpretation of the Kent and O'Quigley coefficient, as a proportion of explained randomness of time given the covariate, is preferable. One purpose of this note is to indicate that, under an independent censoring assumption, the two population coefficients coincide. Thus the simpler inferential setting for Xu and O'Quigley can also be applied to the coefficient of Kent and O'Quigley. Our second purpose is to point out that a sample-based coefficient in common use in the SAS statistical package can be interpreted as an estimate of explained randomness when there is no censoring. When there is censoring the SAS coefficient would not seem satisfactory in that its population counterpart depends on an independent censoring mechanism. However there is a quick fix and we argue in favour of its use.},
  citeulike-article-id = {13265973},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.1946},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {correlation,explained-randomness,information-gain,proportional-hazards}
}

@article{oqu89,
  title = {Score Tests for Homogeneity of Regression Effect in the Proportional Hazards Model},
  author = {O'Quigley, J. and Pessione, F.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {135--144},
  citeulike-article-id = {13264645},
  posted-at = {2014-07-14 14:09:39},
  priority = {0}
}

@article{ora09hie,
  title = {A {{Hierarchical Ornstein}}–{{Uhlenbeck Model}} for {{Continuous Repeated Measurement Data}}},
  author = {Oravecz, Zita and Tuerlinckx, Francis and Vandekerckhove, Joachim},
  date = {2009-09-01},
  journaltitle = {Psychometrika},
  volume = {74},
  pages = {395--418},
  doi = {10.1007/s11336-008-9106-8},
  abstract = {In this paper, we present a diffusion model for the analysis of continuous-time change in multivariate longitudinal data. The central idea is to model the data from a single person with an Ornstein–Uhlenbeck diffusion process. We extend it hierarchically by allowing the parameters of the diffusion process to vary randomly over different persons. With this approach, both intra and interindividual differences are analyzed simultaneously. Furthermore, the individual difference parameters can be regressed on covariates, thereby providing an explanation of between-person differences. Unstructured and unbalanced data pose no problem for the model to be applied. We demonstrate the method on data from an experience sampling study to investigate changes in the core affect. It can be concluded that different factors from the five factor model of personality are related to features of the trajectories in the core affect space, such as the cross-correlation and variability of the changes.},
  keywords = {ornstein-uhlenbeck,serial}
}

@article{ora11lin,
  title = {The Linear Mixed Model and the Hierarchical {{Ornstein}}–{{Uhlenbeck}} Model: {{Some}} Equivalences and Differences},
  shorttitle = {The Linear Mixed Model and the Hierarchical {{Ornstein}}–{{Uhlenbeck}} Model},
  author = {Oravecz, Zita and Tuerlinckx, Francis},
  date = {2011},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  volume = {64},
  number = {1},
  pages = {134--160},
  issn = {2044-8317},
  doi = {10.1348/000711010X498621},
  url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1348/000711010X498621},
  urldate = {2020-12-04},
  abstract = {We focus on comparing different modelling approaches for intensive longitudinal designs. Two methods are scrutinized, namely the widely used linear mixed model (LMM) and the relatively unexplored Ornstein–Uhlenbeck (OU) process based state-space model. On the one hand, we show that given certain conditions they result in equivalent outcomes. On the other hand, we consider it important to emphasize that their perspectives are different and that one framework might better address certain types of research questions than the other. We show that, compared to a LMM, an OU process based approach can cope with modelling inter-individual differences in aspects that are more substantively interesting. However, the estimation of the LMM is faster and the model is more straightforward to implement. The models are illustrated through an experience sampling study.},
  langid = {english},
  keywords = {ornstein-uhlenbeck,serial},
  annotation = {\_eprint: https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1348/000711010X498621}
}

@article{ori88,
  title = {Statistical Methods for the Analysis of Longitudinal Data with Binary Responses},
  author = {Origasa, H.},
  date = {1988},
  journaltitle = {Institute of Statistics Mimeo Series},
  volume = {0},
  citeulike-article-id = {13264646},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{oro96two,
  title = {Two Cheers for {{Bayes}} (Letter)},
  author = {O'Rourke, Keith},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {350--351},
  citeulike-article-id = {13264647},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {basis-for-inference,bayesian-inference}
}

@article{osu91dis,
  title = {Discretized {{Laplacian}} Smoothing by Fourier Methods},
  author = {O'Sullivan, F.},
  date = {1991},
  journaltitle = {J Am Stat Assoc},
  volume = {86},
  pages = {634--642},
  citeulike-article-id = {13264648},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {multi-dimensional-smoothing}
}

@article{ove98com,
  title = {Comparative Evaluation of Two Models for Estimating Sample Sizes for Tests on Trends across Repeated Measurements},
  author = {Overall, John E. and Shobaki, Ghassan and Anderson, Cheryl B.},
  date = {1998},
  journaltitle = {Controlled Clin Trials},
  volume = {19},
  pages = {188--197},
  citeulike-article-id = {13264649},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {power,questionable-power-from-having-more-measurements-per-patient,repeated-measurements,sample-size,serial-data,study-design}
}

@article{oxm92con,
  title = {A Consumer's Guide to Subgroup Analysis},
  author = {Oxman, A. D. and Guyatt, G. H.},
  date = {1992},
  journaltitle = {Ann Int Med},
  volume = {116},
  pages = {78--84},
  citeulike-article-id = {13264650},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {multiple-comparisons,subgroup-analysis,teaching-mds}
}

@article{pac08ind,
  title = {Independent Predictors from Stepwise Logistic Regression May Be Nothing More than Publishable {{P}} Values.},
  author = {Pace, Nathan L.},
  date = {2008-12},
  journaltitle = {Anest Analgesia},
  volume = {107},
  number = {6},
  eprint = {19020117},
  eprinttype = {pmid},
  pages = {1775--1778},
  issn = {1526-7598},
  doi = {10.1213/ane.0b013e31818c1297},
  url = {http://dx.doi.org/10.1213/ane.0b013e31818c1297},
  citeulike-article-id = {4076091},
  citeulike-attachment-1 = {pac08ind.pdf; /pdf/user/harrelfe/article/4076091/1013110/pac08ind.pdf; d05771af342065561082af6aa2982bac59e3d0fa},
  citeulike-linkout-0 = {http://dx.doi.org/10.1213/ane.0b013e31818c1297},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19020117},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19020117},
  posted-at = {2015-04-10 15:56:49},
  priority = {0},
  keywords = {rms,stepwise,variable-selection}
}

@article{pal02eth,
  title = {Ethics, Data-Dependent Designs, and the Strategy of Clinical Trials: Time to Start Learning as We Go?},
  author = {Palmer, Christoper R.},
  date = {2002},
  journaltitle = {Stat Meth Med Res},
  volume = {11},
  pages = {381--402},
  doi = {10.1191/0962280202sm298ra},
  url = {http://dx.doi.org/10.1191/0962280202sm298ra},
  citeulike-article-id = {13265634},
  citeulike-linkout-0 = {http://dx.doi.org/10.1191/0962280202sm298ra},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {ethics,individual-ethics,rct},
  note = {we are stuck thinking about RCTs the way early statistician thought about agricultural trials in which one had to wait for the harvest to do the analysis}
}

@article{pal07imp,
  title = {Implementing a Decision-Theoretic Design in Clinical Trials: {{Why}} and How?},
  author = {Palmer, Christoper R. and Shahumyan, Harutyun},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4939--4957},
  citeulike-article-id = {13265635},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {data-dependent-designs,decision-theoretic-approach,ethics,history,rct,software},
  note = {Benefits of a decision-theoretic approach to clinical trials;excellent summary of ethical issues;first known clinical trial}
}

@article{pal82qrs,
  title = {A {{QRS}} Scoring System for Assessing Left Ventricular Function after Myocardial Infarction},
  author = {Palmeri, S. T. and Harrison, D. G. and Cobb, F. R. and Morris, K. G. and Harrell, F. E. and Ideker, R. E. and Selvester, R. H. and Wagner, G. S.},
  date = {1982},
  journaltitle = {NEJM},
  volume = {306},
  pages = {4--9},
  citeulike-article-id = {13264651},
  posted-at = {2014-07-14 14:09:39},
  priority = {0}
}

@article{pan00two,
  title = {A Two-Sample Test with Interval Censored Data via Multiple Imputation},
  author = {Pan, Wei},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {1--11},
  citeulike-article-id = {13265092},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {approximate-bayesian-bootstrap,simulation-setup}
}

@article{pan07pro,
  title = {Properties of Analysis Methods That Account for Clustering in Volume-Outcome Studies When the Primary Predictor Is Cluster Size},
  author = {Panageas, Katherine S. and Schrag, Deborah and Localio, A. Russell and Venkatraman, E. S. and Begg, Colin B.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {2017--2035},
  citeulike-article-id = {13265567},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {cluster-weighted-gee,health-services-research,hsr,informative-clustering,non-ignorable-cluster-size,outcomes-research,volume-outcome-studies}
}

@article{pan20spl,
  title = {Spline-Based Accelerated Failure Time Model},
  author = {Pang, Menglan and Platt, Robert W. and Schuster, Tibor and Abrahamowicz, Michal},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8786},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8786},
  urldate = {2020-10-30},
  abstract = {The accelerated failure time (AFT) model has been suggested as an alternative to the Cox proportional hazards model. However, a parametric AFT model requires the specification of an appropriate distribution for the event time, which is often difficult to identify in real-life studies and may limit applications. A semiparametric AFT model was developed by Komárek et al based on smoothed error distribution that does not require such specification. In this article, we develop a spline-based AFT model that also does not require specification of the parametric family of event time distribution. The baseline hazard function is modeled by regression B-splines, allowing for the estimation of a variety of smooth and flexible shapes. In comprehensive simulations, we validate the performance of our approach and compare with the results from parametric AFT models and the approach of Komárek. Both the proposed spline-based AFT model and the approach of Komárek provided unbiased estimates of covariate effects and survival curves for a variety of scenarios in which the event time followed different distributions, including both simple and complex cases. Spline-based estimates of the baseline hazard showed also a satisfactory numerical stability. As expected, the baseline hazard and survival probabilities estimated by the misspecified parametric AFT models deviated from the truth. We illustrated the application of the proposed model in a study of colon cancer.},
  langid = {english},
  keywords = {accelerated-failure-time-model,flexible-parametric-distribution,flexible-survival-model,spline},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8786}
}

@article{pap86pro,
  title = {Prognostic Implications of Angiographically Normal and Insignificantly Narrowed Coronary Arteries},
  author = {Papanicolaou, M. N. and Califf, R. M. and Hlatky, M. A. and McKinnis, R. A. and Harrell, F. E. and Mark, D. B. and McCants, B. and Rosati, R. A. and Lee, K. L. and Pryor, D. B.},
  date = {1986},
  journaltitle = {Am J Card},
  volume = {58},
  pages = {1181--1187},
  citeulike-article-id = {13264652},
  posted-at = {2014-07-14 14:09:39},
  priority = {0}
}

@article{par00est,
  title = {Estimating the Value of an Internal Biostatistical Consulting Service},
  author = {Parker, Robert A.},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {2131--2145},
  citeulike-article-id = {13265139},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {charges,consulting,value},
  note = {estimated in 1998 that the return on investment for statistical services in medical research is 6:1 in terms of grant funding generated; many non-monetary benefits are also listed. Table 1 is excellent.}
}

@article{par01cha,
  title = {Characteristics of Adult Primary Care Patients as Predictors of Future Health Services Charges},
  author = {Parkerson, George R. and Harrell, Frank E. and Hammond, William E. and Wang, Xin-Qun},
  date = {2001},
  journaltitle = {Med Care},
  volume = {39},
  pages = {1170--1181},
  citeulike-article-id = {13265279},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {case-mix,cox-model-for-cost,diagnostic-groups,health-related-qol,health-services-utilization,risk-adjustment,risk-assessment,severity-of-illness}
}

@article{par03sam,
  title = {Sample Size: {{More}} than Calculations},
  author = {Parker, Robert A. and Berman, Nancy G.},
  date = {2003},
  journaltitle = {Am Statistician},
  volume = {57},
  pages = {166--170},
  citeulike-article-id = {13265347},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {accuracy,detectable-difference,feasibility,precision,scientific-thinking},
  note = {often better to compute the achievable precision for a study than pretending we are choosing the sample size scientifically and well}
}

@article{par05ren,
  title = {Renal Cell Carcinoma with Renal Vein and Inferior Vena Caval Involvement: Clinicopathological Features, Surgical Techniques and Outcomes},
  author = {Parekh, D. J. and Cookson, M. S. and Chapman, W. and Harrell, F. E. and Wells, N. and Chang, S. S. and Smith, J. A.},
  date = {2005},
  journaltitle = {J Urol},
  volume = {173},
  number = {6},
  pages = {1897--902},
  url = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks&dbfrom=pubmed&retmode=ref&id=15879771},
  citeulike-article-id = {13265465},
  citeulike-linkout-0 = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks&#38;dbfrom=pubmed&#38;retmode=ref&#38;id=15879771},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {collaboration}
}

@article{par06gen,
  title = {A {{Generalized Estimating Equation Method}} for {{Fitting Autocorrelated Ordinal Score Data}} with an {{Application}} in {{Horticultural Research}}},
  author = {Parsons, N. R. and Edmondson, R. N. and Gilmour, S. G.},
  date = {2006},
  journaltitle = {Appl Stat},
  volume = {55},
  number = {4},
  eprint = {3879106},
  eprinttype = {jstor},
  abstract = {Generalized estimating equations for correlated repeated ordinal score data are developed assuming a proportional odds model and a working correlation structure based on a first-order autoregressive process. Repeated ordinal scores on the same experimental units, not necessarily with equally spaced time intervals, are assumed and a new algorithm for the joint estimation of the model regression parameters and the correlation coefficient is developed. Approximate standard errors for the estimated correlation coefficient are developed and a simulation study is used to compare the new methodology with existing methodology. The work was part of a project on post-harvest quality of pot-plants and the generalized estimating equation model is used to analyse data on poinsettia and begonia pot-plant quality deterioration over time. The relationship between the key attributes of plant quality and the quality and longevity of ornamental pot-plants during shelf and after-sales life is explored.},
  citeulike-article-id = {13265993},
  citeulike-linkout-0 = {http://www.jstor.org/stable/3879106},
  posted-at = {2014-07-14 14:10:09},
  priority = {0},
  keywords = {longitudinal-data,ordinal-response,proportional-odds-model,serial-data}
}

@article{par06int,
  title = {Interpretation of Subgroup Results in Clinical Trial Publications: {{Insights}} from a Survey of Medical Specialists in {{Ontario}}, {{Canada}}},
  author = {Parker, Andrea B. and Naylor, C. David},
  date = {2006},
  journaltitle = {Am Heart J},
  volume = {151},
  pages = {580--588},
  doi = {10.1016/j.ahj.2005.05.002},
  url = {http://dx.doi.org/10.1016/j.ahj.2005.05.002},
  citeulike-article-id = {13265463},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.ahj.2005.05.002},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {rct,subgroup-analysis,teaching-mds},
  note = {Survey of 435 physicians;many would exclude subgroup if no treatment benefit was shown even though the overall trial was positive;with overall harm when a subgroup showed benefit many would still use the drug;with overall null effect and positive interaction, many would adopt the new treatment;huge effect of academic appointment, devoting more time to research, formal training in research methodology;for those, many more demanded a significant interaction}
}

@article{par08pen,
  title = {Penalized Logistic Regression for Detecting Gene Interactions},
  author = {Park, Mee Y. and Hastie, Trevor},
  date = {2008},
  journaltitle = {Biostat},
  volume = {9},
  number = {1},
  pages = {30--50},
  citeulike-article-id = {13265705},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  note = {MDR does not do the dimensionality reduction it claims (confirmed with analysis of deviance of null models);MDR only finds interactions, not main effects;quadratic penalty automatically sets coefficient estimates for empty cells to zero and forces sum of k coefficients in a k-level categorical predictor to zero;bioinformatics;machine learning;penalized logistic regression;PMLE;gene-gene interactions;L2 norm}
}

@article{par10eff,
  title = {Effects of {{CYP2C19}} Genotype on Outcomes of Clopidogrel Treatment},
  author = {Paré, Guillaume and Mehta, Shamir R. and Yusuf, Salim and {Others}},
  date = {2010},
  journaltitle = {NEJM},
  volume = {online},
  citeulike-article-id = {13265849},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  annotation = {August 29, 2010}
}

@article{par11gen,
  title = {Generalized Linear Mixed Model for Longitudinal Binary Data with a Marginal Logit Link Function},
  author = {Parzen, Michael and Ghosh, Souparno and Lipsitz, Stuart and Sinha, Debajyoti and Fitzmaurice, Garrett M. and Mallick, Bani K. and Ibrahim, Joseph G.},
  date = {2011},
  journaltitle = {Ann Appl Stat},
  volume = {5},
  number = {1},
  pages = {449--467},
  doi = {10.1214/10-AOAS390},
  url = {http://dx.doi.org/10.1214/10-AOAS390},
  citeulike-article-id = {13265893},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/10-AOAS390},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {correlated-binary-data,correlations-can-decline-with-increasing-time-separation,correlations-interpreted-in-terms-of-kendalls-tau,longitudinal-binary-data,missing-at-random,multivariate-normal-distribution,probability-integral-transformation,random-effects-model-with-a-bridge-random-effects-distribution,yields-logistic-conditional-and-marginal-link-functions}
}

@article{par20con,
  title = {A Constrained Single-Index Regression for Estimating Interactions between a Treatment and Covariates},
  author = {Park, Hyung and Petkova, Eva and Tarpey, Thaddeus and Ogden, R. Todd},
  date = {2020},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13320},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13320},
  urldate = {2020-06-29},
  abstract = {We consider a single-index regression model, uniquely constrained to estimate interactions between a set of pretreatment covariates and a treatment variable on their effects on a response variable, in the context of analyzing data from randomized clinical trials. We represent interaction effect terms of the model through a set of treatment-specific flexible link functions on a linear combination of the covariates (a single index), subject to the constraint that the expected value given the covariates equals zero, while leaving the main effects of the covariates unspecified. We show that the proposed semiparametric estimator is consistent for the interaction term of the model, and that the efficiency of the estimator can be improved with an augmentation procedure. The proposed single-index regression provides a flexible and interpretable modeling approach to optimizing individualized treatment rules based on patients' data measured at baseline, as illustrated by simulation examples and an application to data from a depression clinical trial. This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {differential-effects,hte,interaction},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13320}
}

@article{par21aut,
  title = {Automatic Sparse Principal Component Analysis},
  author = {Park, Heewon and Yamaguchi, Rui and Imoto, Seiya and Miyano, Satoru},
  date = {2021},
  journaltitle = {Canadian Journal of Statistics},
  volume = {49},
  number = {3},
  pages = {678--697},
  issn = {1708-945X},
  doi = {10.1002/cjs.11579},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cjs.11579},
  urldate = {2021-08-16},
  abstract = {The wide availability of computers enables us to accumulate a huge amount of data, thus effective tools to extract information from the huge volume of data have become critical. Principal component analysis (PCA) is a useful and traditional tool for dimensionality reduction of massive high-dimensional datasets. Recently, sparse principal component (PC) loading estimation based on L1-type regularization has drawn a large amount of attention. Although sparse PCA makes interpretation easily and performs dimension reduction without disturbance from noisy features, the existing studies on sparse PCA were based on an arbitrary number of PCs without any statistical justification. We propose a novel method, called as automatic sparse PCA, which can perform PC selection and sparse PC loading estimation, simultaneously. For PC selection, we first develop sparse singular value decomposition (sparse SVD), then incorporate sparsity into PC loading estimation. The proposed method enables us to perform dimension reduction and PC loading estimation, simultaneously. Furthermore, we can perform PCA without disturbance from noisy features. It can be seen through Monte Carlo experiments that the proposed automatic sparse PCA outperforms sparse structure identification and reconstructing data based on low-dimensional projection. The proposed method is also applied to a number of real datasets and it can be also seen that our method achieves effectiveness for estimation accuracy and interpreting PCA results.},
  langid = {english},
  keywords = {data-reduction,pc,pca,sparse-pc,sparse-principal-components,unsupervised-learning},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cjs.11579}
}

@article{par90,
  title = {Comparison of Quantile Estimators in Normal Sampling},
  author = {Rs, Parrish},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {247--257},
  citeulike-article-id = {13264653},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {order-statistics,quantiles}
}

@article{par95hea,
  title = {Health Status and Severity of Illness as Predictors of Outcomes in Primary Care},
  author = {Parkerson, George R. and Broadhead, W and Tse, Chiu-Kit J.},
  date = {1995},
  journaltitle = {Med Care},
  volume = {33},
  pages = {53--66},
  citeulike-article-id = {13264654},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {ambulatory,dusoi,example-data,severity-of-illness}
}

@book{par95sur,
  title = {Survival {{Analysis}}: {{A Practical Approach}}},
  author = {Parmar, M. K. B. and Machin, D.},
  date = {1995},
  publisher = {{Wiley}},
  location = {{Chichester}},
  citeulike-article-id = {13264655},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  note = {textbook on survival analysis; see review Stat in Med 16:714-5;1997 and JASA 91:1751-2;1996}
}

@article{par97duk,
  title = {Duke Case-Mix System ({{DUMIX}}) for Ambulatory Health Care},
  author = {Parkerson, George R. and Michener, J. Lloyd and Yarnall, Kimberly S. H. and Hannond, W. Edward},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {1385--1394},
  citeulike-article-id = {13264656},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {dumix,dusoi}
}

@article{par98cri,
  title = {Criteria for Authorship for Statisticians in Medical Papers},
  author = {Parker, Robert A. and Berman, Nancy G.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {2289--2299},
  citeulike-article-id = {13264657},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {authorship}
}

@article{pas12est,
  title = {Estimating {{Discrete Markov Models From Various Incomplete Data Schemes}}},
  author = {Pasanisi, Alberto and Fu, Shuai and Bousquet, Nicolas},
  date = {2012-09},
  journaltitle = {Computational Statistics \& Data Analysis},
  volume = {56},
  number = {9},
  eprint = {1009.1216},
  eprinttype = {arxiv},
  pages = {2609--2625},
  issn = {01679473},
  doi = {10.1016/j.csda.2012.02.027},
  url = {http://arxiv.org/abs/1009.1216},
  urldate = {2021-05-02},
  abstract = {The parameters of a discrete stationary Markov model are transition probabilities between states. Traditionally, data consist in sequences of observed states for a given number of individuals over the whole observation period. In such a case, the estimation of transition probabilities is straightforwardly made by counting one-step moves from a given state to another. In many real-life problems, however, the inference is much more difficult as state sequences are not fully observed, namely the state of each individual is known only for some given values of the time variable. A review of the problem is given, focusing on Monte Carlo Markov Chain (MCMC) algorithms to perform Bayesian inference and evaluate posterior distributions of the transition probabilities in this missing-data framework. Leaning on the dependence between the rows of the transition matrix, an adaptive MCMC mechanism accelerating the classical Metropolis-Hastings algorithm is then proposed and empirically studied.},
  archiveprefix = {arXiv},
  keywords = {markov,missing,serial},
  note = {Comment: 26 pages - preprint accepted in 20th February 2012 for publication in Computational Statistics and Data Analysis (please cite the journal's paper)}
}

@article{pat15pre,
  title = {Prescription Opioid Epidemic and Infant Outcomes.},
  author = {Patrick, Stephen W. and Dudley, Judith and Martin, Peter R. and Harrell, Frank E. and Warren, Michael D. and Hartmann, Katherine E. and Ely, E. Wesley and Grijalva, Carlos G. and Cooper, William O.},
  date = {2015-05},
  journaltitle = {Pediatrics},
  volume = {135},
  number = {5},
  eprint = {25869370},
  eprinttype = {pmid},
  pages = {842--850},
  issn = {1098-4275},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25869370},
  abstract = {Although opioid pain relievers are commonly prescribed in pregnancy, their association with neonatal outcomes is poorly described. Our objectives were to identify neonatal complications associated with antenatal opioid pain reliever exposure and to establish predictors of neonatal abstinence syndrome (NAS). We used prescription and administrative data linked to vital statistics for mothers and infants enrolled in the Tennessee Medicaid program between 2009 and 2011. A random sample of NAS cases was validated by medical record review. The association of antenatal exposures with NAS was evaluated by using multivariable logistic regression, controlling for maternal and infant characteristics. Of 112,029 pregnant women, 31,354 (28\%) filled ≥ 1 opioid prescription. Women prescribed opioid pain relievers were more likely than those not prescribed opioids (P {$<$} .001) to have depression (5.3\% vs 2.7\%), anxiety disorder (4.3\% vs 1.6\%) and to smoke tobacco (41.8\% vs 25.8\%). Infants with NAS and opioid-exposed infants were more likely than unexposed infants to be born at a low birth weight (21.2\% vs 11.8\% vs 9.9\%; P {$<$} .001). In a multivariable model, higher cumulative opioid exposure for short-acting preparations (P {$<$} .001), opioid type (P {$<$} .001), number of daily cigarettes smoked (P {$<$} .001), and selective serotonin reuptake inhibitor use (odds ratio: 2.08 [95\% confidence interval: 1.67-2.60]) were associated with greater risk of developing NAS. Prescription opioid use in pregnancy is common and strongly associated with neonatal complications. Antenatal cumulative prescription opioid exposure, opioid type, tobacco use, and selective serotonin reuptake inhibitor use increase the risk of NAS. Copyright  2015 by the American Academy of Pediatrics.},
  citeulike-article-id = {14102489},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25869370},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25869370},
  posted-at = {2016-07-26 21:15:29},
  priority = {2},
  keywords = {collaboration}
}

@article{pau08pre,
  title = {“{{Preconditioning}}” for Feature Selection and Regression in High-Dimensional Problems},
  author = {Paul, Debashis and Bair, Eric and Hastie, Trevor and Tibshirani, Robert},
  date = {2008},
  journaltitle = {Ann Stat},
  volume = {36},
  number = {4},
  pages = {1595--1619},
  doi = {10.1214/009053607000000578},
  url = {http://dx.doi.org/10.1214/009053607000000578},
  citeulike-article-id = {13265691},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/009053607000000578},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {lasso,model-approximation,model-selection,penalized-mle,pmle,pre-conditioning,prediction-error,shinkage},
  note = {develop consistent Y using a latent variable structure, using for example supervised principal components. Then run stepwise regression or lasso predicting Y (lasso worked better). Can run into problems when a predictor has importance in an adjusted sense but has no marginal correlation with Y;model approximation;model simplification}
}

@article{pau18joi,
  title = {Joint Modeling of Recurrent Events and Survival: A {{Bayesian}} Non-Parametric Approach},
  shorttitle = {Joint Modeling of Recurrent Events and Survival},
  author = {Paulon, Giorgio and De Iorio, Maria and Guglielmi, Alessandra and Ieva, Francesca},
  date = {2018},
  journaltitle = {Biostatistics},
  doi = {10.1093/biostatistics/kxy026},
  url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxy026/5050476},
  urldate = {2018-07-08},
  abstract = {Heart failure (HF) is one of the main causes of morbidity, hospitalization, and death in the western world, and the economic burden associated with HF management is relevant and expected to increase in the future. We consider hospitalization data for HF in the most populated Italian Region, Lombardia. Data were extracted from the administrative data warehouse of the regional healthcare system. The main clinical outcome of interest is time to death and research focus is on investigating how recurrent hospitalizations affect the time to event. The main contribution of the article is to develop a joint model for gap times between consecutive rehospitalizations and survival time. The probability models for the gap times and for the survival outcome share a common patient specific frailty term. Using a flexible Dirichlet process model for \%Bayesian nonparametric prior as the random-effects distribution accounts for patient heterogeneity in recurrent event trajectories. Moreover, the joint model allows for dependent censoring of gap times by death or administrative reasons and for the correlations between different gap times for the same individual. It is straightforward to include covariates in the survival and/or recurrence process through the specification of appropriate regression terms. The main advantages of the proposed methodology are wide applicability, ease of interpretation, and efficient computations. Posterior inference is implemented through Markov chain Monte Carlo methods.},
  langid = {english},
  keywords = {bayes,multiple-endpoints,rct,recurrent-event-with-competing-risk,recurrent-events}
}

@article{pau21win,
  title = {Window Mean Survival Time},
  author = {Paukner, Mitchell and Chappell, Richard},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9138},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9138},
  urldate = {2021-07-17},
  abstract = {We propose a class of alternative estimates and tests to restricted mean survival time (RMST) which improves power in numerous survival scenarios while maintaining a level of interpretability. The industry standards for interpretable hypothesis tests in survival analysis, RMST and logrank tests (LRTs), can suffer from low power in cases where the proportional hazards assumption fails. In particular, when late differences occur between survival curves, our proposed estimate and class of tests, window mean survival time (WMST), outperforms both RMST and LRT without sacrificing interpretability, unlike weighted rank tests (WRTs). WMST has the added advantage of maintaining high power when the proportional hazards assumption is met, while WRTs do not. With testing methods often being chosen in advance of data collection, WMST can ensure adequate power without distributional assumptions and is robust to the choice of its restriction parameters. Functions for performing WMST analysis are provided in the survWM2 package in R.},
  langid = {english},
  keywords = {non-ph,restricted-mean-life},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9138},
  note = {Requires pre-specification of start of time window and doesn't seem to have a power advantage unless this point is after a point of survival curve separation.}
}

@book{pcaPP,
  title = {{{pcaPP}}: {{Robust PCA}} by {{Projection Pursuit}}},
  author = {Filzmoser, Peter and Fritz, Heinrich and Kalcher, Klaudius},
  date = {2012},
  url = {http://CRAN.R-project.org/package=pcaPP},
  citeulike-article-id = {13265960},
  citeulike-linkout-0 = {http://CRAN.R-project.org/package=pcaPP},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  annotation = {R package version 1.9-48}
}

@report{pea09cau,
  title = {Causal Inference in Statistics: {{An}} Overview},
  author = {{Pearl, Judea}},
  date = {2009-09},
  pages = {96--146},
  url = {http://ftp.cs.ucla.edu/pub/stat_ser/r350.pdf},
  urldate = {2019-08-14},
  abstract = {This review presents empirical researcherswith recent advancesin causal inference, and stresses the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis ofmultivariate data. Special emphasis is placed on the assumptions that underly all causal inferences, the languages used in formulating those assump-tions, the conditional nature of all causal and counterfactual claims, andthe methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation basedon the Structural Causal Model (SCM) described  in Pearl(2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: (1) queries about the effects of potential interven-tions, (also called “causal effects” or “policy evaluation”) (2) queries about probabilities of counterfactuals, (including assessment of “regret,” “attri-bution” or “causes of effects”) and (3) queries about direct and indirecteffects (also known as “mediation”). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.},
  keywords = {causal-inference,causality,causation},
  note = {DOI:10.1214/09-SS057
\par
See Sections 2.1-2.3}
}

@article{pea14ext,
  title = {External {{Validity}}: {{From Do-Calculus}} to {{Transportability Across Populations}}},
  shorttitle = {External {{Validity}}},
  author = {Pearl, Judea and Bareinboim, Elias},
  date = {2014-11},
  journaltitle = {Statistical Science},
  volume = {29},
  number = {4},
  pages = {579--595},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/14-STS486},
  url = {https://projecteuclid.org/journals/statistical-science/volume-29/issue-4/External-Validity-From-Do-Calculus-to-Transportability-Across-Populations/10.1214/14-STS486.full},
  urldate = {2021-07-20},
  abstract = {The generalizability of empirical findings to new environments, settings or populations, often called “external validity,” is essential in most scientific explorations. This paper treats a particular problem of generalizability, called “transportability,” defined as a license to transfer causal effects learned in experimental studies to a new population, in which only observational studies can be conducted. We introduce a formal representation called “selection diagrams” for expressing knowledge about differences and commonalities between populations of interest and, using this representation, we reduce questions of transportability to symbolic derivations in the do-calculus. This reduction yields graph-based procedures for deciding, prior to observing any data, whether causal effects in the target population can be inferred from experimental findings in the study population. When the answer is affirmative, the procedures identify what experimental and observational findings need be obtained from the two populations, and how they can be combined to ensure bias-free transport.},
  keywords = {causal-effects,causal-inference,causality,conditional-analysis,covariable-adjustment}
}

@article{pea94mea,
  title = {Measuring Changes in Logarithmic Data, with Special Reference to Bronchial Responsiveness},
  author = {Peat, Jennifer K. and Unger, William R. and Combe, Diana},
  date = {1994},
  journaltitle = {J Clin Epi},
  volume = {47},
  pages = {1099--1108},
  citeulike-article-id = {13264658},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {logarithm,measuring-change}
}

@article{ped93ana,
  title = {Analysis As-Randomized and the Problem of Non-Adherence: {{An}} Example from the {{Veteran}}'s {{Affairs}} Randomized Trial of Coronary Bypass Surgery},
  author = {Peduzzi, Peter and Wittes, Janet and Detre, Katherine and Holford, Theodore},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {1185--1195},
  citeulike-article-id = {13264659},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {cabg,crossover,intent-to-treat,itt,non-adherence,rct}
}

@article{ped95imp,
  title = {Importance of Events per Independent Variable in Proportional Hazards Regression Analysis. {{II}}. {{Accuracy}} and Precision of Regression Estimates},
  author = {Peduzzi, Peter and Concato, John and Feinstein, Alvan R. and Holford, Theodore R.},
  date = {1995},
  journaltitle = {J Clin Epi},
  volume = {48},
  pages = {1503--1510},
  citeulike-article-id = {13264660},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {events-per-variable,general,prediction,prognostic-modeling}
}

@article{ped96sim,
  title = {A Simulation Study of the Number of Events per Variable in Logistic Regression Analysis},
  author = {Peduzzi, Peter and Concato, John and Kemper, Elizabeth and Holford, Theodore R. and Feinstein, Alvan R.},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {1373--1379},
  citeulike-article-id = {13264661},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {events-per-variable,overfitting,sample-size-for-modeling}
}

@article{pee07ext,
  title = {External Validation of Prognostic Models for Critically Ill Patients Required Substantial Sample Sizes},
  author = {Peek, N. and Arts, D. G. T. and Bosman, R. J. and van der Voort, P. H. J. and de Keizer, N. F.},
  options = {useprefix=true},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {491--501},
  citeulike-article-id = {13265575},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {apache-ii,mortality-models,mpm-ii,prognostic-models,sample-size,saps-ii,validation},
  note = {large sample sizes need to obtain reliable external validations;inadequate power of DeLong, DeLong, and Clarke-Pearson test for differences in correlated ROC areas (p. 498);problem with tests of calibration accuracy having too much power for large sample sizes}
}

@article{pek10app,
  title = {Approximate Models for Aggregate Data When Individual-Level Data Sets Are Very Large or Unavailable},
  author = {Peköz, Erol A. and Shwartz, Michael and Christiansen, Cindy L. and Berlowitz, Dan},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {2180--2193},
  citeulike-article-id = {13265845},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {approximate-bayesian-methods,approximating-derivatives-of-log-likelihood-function,confidential-data,poisson-binomial}
}

@article{pen04ove,
  title = {Overall {{C}} as a Measure of Discrimination in Survival Analysis: Model Specific Population Value and Confidence Interval Estimation},
  author = {Pencina, Michael J. and D'Agostino, Ralph B.},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  pages = {2109--2123},
  citeulike-article-id = {13265379},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {c-index,discrimination,kendalls-tau,rank-correlation-with-censored-data,roc},
  note = {relationship between C and τ;formal proof of equivalence of using either predicted survival time or probability;coverage probability investigated by simulation}
}

@article{pen08eva,
  title = {Evaluating the Added Predictive Ability of a New Marker: {{From}} Area under the {{ROC}} Curve to Reclassification and Beyond},
  author = {Pencina, Michael J. and D'Agostino Sr, Ralph B. and D'Agostino Jr, Ralph B. and Vasan, Ramachandran S.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {157--172},
  citeulike-article-id = {13265590},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {auc,biomarker,c-index,discrimination,model-performance,risk-prediction},
  note = {small differences in ROC area can still be very meaningful;example of insignificant test for difference in ROC areas with very significant results from new method;Yates' discrimination slope;reclassification table;limiting version of this based on whether and amount by which probabilities rise for events and lower for non-events when compare new model to old;comparing two models;see letter to the editor by Van Calster and Van Huffel, Stat in Med 29:318-319, 2010 and by Cook and Paynter, Stat in Med 31:93-97, 2012}
}

@article{pen09rep,
  title = {Reproducible Research and {{Biostatistics}}},
  author = {Peng, Roger D.},
  date = {2009},
  journaltitle = {Biostat},
  volume = {10},
  pages = {405--408},
  citeulike-article-id = {13265767},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  note = {provides rationale and format for authors to store code and data to reproduce results in their papers}
}

@article{pen11ext,
  title = {Extensions of Net Reclassification Improvement Calculations to Measure Usefulness of New Biomarkers},
  author = {Pencina, Michael J. and D'Agostino, Ralph B. and Steyerberg, Ewout W.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  pages = {11--21},
  doi = {10.1002/sim.4085},
  url = {http://dx.doi.org/10.1002/sim.4085},
  citeulike-article-id = {13265876},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4085},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {added-value,comparing-biomarkers,discrimination,extension-of-nri-to-survival-and-case-control-data,model-performance,predictive-accuracy,risk-prediction},
  note = {lack of need for NRI to be category-based;arbitrariness of categories;"category-less or continuous NRI is the most objective and versatile measure of improvement in risk prediction;authors misunderstood the inadequacy of three categories if categories are used;comparison of NRI to change in C index;example of continuous plot of risk for old model vs. risk for new model}
}

@article{pen12nov,
  title = {Novel Metrics for Evaluating Improvement in Discrimination: Net Reclassification and Integrated Discrimination Improvement for Normal Variables and Nested Models},
  author = {Pencina, Michael J. and D'Agostino, Ralph B. and Demler, Olga V.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {2},
  pages = {101--113},
  doi = {10.1002/sim.4348},
  url = {http://dx.doi.org/10.1002/sim.4348},
  abstract = {Net reclassification and integrated discrimination improvements have been proposed as alternatives to the increase in the area under the curve for evaluating improvement in the performance of risk assessment algorithms introduced by the addition of new phenotypic or genetic markers. In this paper, we demonstrate that in the setting of linear discriminant analysis, under the assumptions of multivariate normality, all three measures can be presented as functions of the squared Mahalanobis distance. This relationship affords an interpretation of the magnitude of these measures in the familiar language of effect size for uncorrelated variables. Furthermore, it allows us to conclude that net reclassification improvement can be viewed as a universal measure of effect size. Our theoretical developments are illustrated with an example based on the Framingham Heart Study risk assessment model for high-risk men in primary prevention of cardiovascular disease},
  citeulike-article-id = {13265922},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4348},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {auc,biomarker,c-statistic,model-performance,risk-prediction,roc}
}

@article{pen12qua,
  title = {Quantifying Discrimination of {{Framingham}} Risk Functions with Different Survival {{C}} Statistics},
  author = {Pencina, Michael J. and D'Agostino, Ralph B. and Song, Linye},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {15},
  pages = {1543--1553},
  doi = {10.1002/sim.4508},
  url = {http://dx.doi.org/10.1002/sim.4508},
  abstract = {Cardiovascular risk prediction functions offer an important diagnostic tool for clinicians and patients themselves. They are usually constructed with the use of parametric or semi-parametric survival regression models. It is essential to be able to evaluate the performance of these models, preferably with summaries that offer natural and intuitive interpretations. The concept of discrimination, popular in the logistic regression context, has been extended to survival analysis. However, the extension is not unique. In this paper, we define discrimination in survival analysis as the model's ability to separate those with longer event-free survival from those with shorter event-free survival within some time horizon of interest. This definition remains consistent with that used in logistic regression, in the sense that it assesses how well the model-based predictions match the observed data. Practical and conceptual examples and numerical simulations are employed to examine four C statistics proposed in the literature to evaluate the performance of survival models. We observe that they differ in the numerical values and aspects of discrimination that they capture. We conclude that the index proposed by Harrell is the most appropriate to capture discrimination described by the above definition. We suggest researchers report which C statistic they are using, provide a rationale for their selection, and be aware that comparing different indices across studies may not be meaningful.},
  citeulike-article-id = {13265937},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4508},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {auc,c-index,censoring,concordance,discrimination,risk-function}
}

@article{pen18pro,
  title = {Propensity {{Score Estimation Using Classification}} and {{Regression Trees}} in the {{Presence}} of {{Missing Covariate Data}}},
  author = {Penning, de Vries Bas B.L. and {van}, Smeden Maarten and Groenwold, Rolf H.H.},
  date = {2018},
  journaltitle = {Epidemiologic Methods},
  volume = {7},
  number = {1},
  doi = {10.1515/em-2017-0020},
  url = {https://www.degruyter.com/view/j/em.2018.7.issue-1/em-2017-0020/em-2017-0020.xml},
  urldate = {2019-09-02},
  abstract = {Data mining and machine learning techniques such as classification and regression trees (CART) represent a promising alternative to conventional logistic regression for propensity score estimation. Whereas incomplete data preclude the fitting of a logistic regression on all subjects, CART is appealing in part because some implementations allow for incomplete records to be incorporated in the tree fitting and provide propensity score estimates for all subjects. Based on theoretical considerations, we argue that the automatic handling of missing data by CART may however not be appropriate. Using a series of simulation experiments, we examined the performance of different approaches to handling missing covariate data; (i) applying the CART algorithm directly to the (partially) incomplete data, (ii) complete case analysis, and (iii) multiple imputation. Performance was assessed in terms of bias in estimating exposure-outcome effects among the exposed, standard error, mean squared error and coverage. Applying the CART algorithm directly to incomplete data resulted in bias, even in scenarios where data were missing completely at random. Overall, multiple imputation followed by CART resulted in the best performance. Our study showed that automatic handling of missing data in CART can cause serious bias and does not outperform multiple imputation as a means to account for missing data.},
  keywords = {cart,missing,recursive-partitioning}
}

@article{pen98smo,
  title = {Smooth Goodness-of-Fit Tests for the Baseline Hazard in {{Cox}}'s Proportional Hazards Model},
  author = {Peña, Edsel A.},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {673--692},
  citeulike-article-id = {13264662},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {generalized-residual,model-validation,score-test},
  note = {testing consistency of underlying hazard estimate with a hypothesized hazard function}
}

@article{pep01pha,
  title = {Phases of Biomarker Discovery},
  author = {Pepe, Margaret S. and Etzioni, Ruth and Feng, Ziding and Potter, John D. and Thompson, Mary L. and Winget, M. and Yasui, Yutaka},
  date = {2001},
  journaltitle = {J Nat Cancer Inst},
  volume = {93},
  pages = {1054--1061},
  citeulike-article-id = {13265497},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {biomarker,study-design}
}

@book{pep03sta,
  title = {The {{Statistical Evaluation}} of {{Medical Tests}} for {{Classification}} and {{Prediction}}},
  author = {Pepe, Margaret S.},
  date = {2003},
  publisher = {{Oxford University Press}},
  location = {{Oxford}},
  citeulike-article-id = {13265498},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{pep04lim,
  title = {Limitations of the Odds Ratio in Gauging the Performance of a Diagnostic, Prognostic, or Screening Marker},
  author = {Pepe, M. S. and Janes, H. and Longton, G. and Leisenring, W. and Newcomb, P.},
  date = {2004},
  journaltitle = {Am J Epi},
  volume = {159},
  number = {9},
  pages = {882--890},
  citeulike-article-id = {13265894},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {odds-ratio,predictive-accuracy,predictive-performance}
}

@article{pep05eva,
  title = {Evaluating Technologies for Classification and Prediction in Medicine},
  author = {Pepe, Margaret S.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {3687--3696},
  citeulike-article-id = {13265453},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {diagnostic-test,disease-screening,odds-ratio,prognosis,roc-curve},
  note = {overemphasis on classification;MLE can yield poor classifiers;alternative objective function for classification accuracy}
}

@article{pep13tes,
  title = {Testing for Improvement in Prediction Model Performance},
  author = {Pepe, Margaret Sullivan and Kerr, Kathleen F. and Longton, Gary and Wang, Zheyu},
  date = {2013-04-30},
  journaltitle = {Stat Med},
  volume = {32},
  number = {9},
  eprint = {23296397},
  eprinttype = {pmid},
  pages = {1467--1482},
  issn = {1097-0258},
  doi = {10.1002/sim.5727},
  abstract = {Authors have proposed new methodology in recent years for evaluating the improvement in prediction performance gained by adding a new predictor, Y, to a risk model containing a set of baseline predictors, X, for a binary outcome D. We prove theoretically that null hypotheses concerning no improvement in performance are equivalent to the simple null hypothesis that Y is not a risk factor when controlling for X, H0 : P(D\,=\,1\,|\,X,Y )\,=\,P(D\,=\,1\,|\,X). Therefore, testing for improvement in prediction performance is redundant if Y has already been shown to be a risk factor. We also investigate properties of tests through simulation studies, focusing on the change in the area under the ROC curve (AUC). An unexpected finding is that standard testing procedures that do not adjust for variability in estimated regression coefficients are extremely conservative. This may explain why the AUC is widely considered insensitive to improvements in prediction performance and suggests that the problem of insensitivity has to do with use of invalid procedures for inference rather than with the measure itself. To avoid redundant testing and use of potentially problematic methods for inference, we recommend that hypothesis testing for no improvement be limited to evaluation of Y as a risk factor, for which methods are well developed and widely available. Analyses of measures of prediction performance should focus on estimation rather than on testing for no improvement in performance.},
  langid = {english},
  pmcid = {PMC3625503},
  keywords = {c-index,c-statistic,lr-tests,predictive-accuracy}
}

@article{pep89,
  title = {Weighted {{Kaplan--Meier}} Statistics: {{A}} Class of Distance Tests for Censored Survival Data},
  author = {Pepe, M. S. and Fleming, T. R.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {497--507},
  citeulike-article-id = {13264663},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {censored-data,general,survival-analysis-non-regression}
}

@article{pep91,
  title = {A Nonparametric Method for Dealing with Mismeasured Covariate Data},
  author = {Pepe, M. S. and Fleming, T. R.},
  date = {1991},
  journaltitle = {J Am Stat Assoc},
  volume = {86},
  pages = {108--113},
  citeulike-article-id = {13264664},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {maximum-likelihood,missing-data}
}

@article{pep91inf,
  title = {Inference for Events with Dependent Risks in Multiple Endpoint Studies},
  author = {Pepe, Margaret S.},
  date = {1991},
  journaltitle = {J Am Stat Assoc},
  volume = {86},
  pages = {770--778},
  citeulike-article-id = {13264665},
  posted-at = {2014-07-14 14:09:39},
  priority = {0}
}

@article{pep91qua,
  title = {A Qualifier {{Q}} for the Survival Function to Describe the Prevalence of a Transient Condition},
  author = {Pepe, M. S. and Longton, G. and Thornquist, M.},
  date = {1991},
  journaltitle = {Stat Med},
  volume = {10},
  pages = {413--421},
  citeulike-article-id = {13264666},
  posted-at = {2014-07-14 14:09:39},
  priority = {0}
}

@article{pep92inf,
  title = {Inference Using Surrogate Outcome Data and a Validation Sample},
  author = {Pepe, Margaret S.},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {355--365},
  citeulike-article-id = {13264667},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {study-design,surrogate-endpoint}
}

@article{pep93kap,
  title = {Kaplan--{{Meier}}, Marginal or Conditional Probability Curves in Summarizing Competing Risks Failure Time Data?},
  author = {Pepe, Margaret S. and Mori, Motomi},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {737--751},
  citeulike-article-id = {13264668},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {competing-risks,dependent-events,multiple-outcomes}
}

@article{pep93som,
  title = {Some Graphical Displays and Marginal Regression Analyses for Recurrent Failure Times and Time Dependent Covariates},
  author = {Pepe, Margaret S. and Cai, Jianwen},
  date = {1993},
  journaltitle = {J Am Stat Assoc},
  volume = {88},
  pages = {811--820},
  citeulike-article-id = {13264669},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {marginal-approach,recurrent-events,repeated-events}
}

@article{pep97reg,
  title = {A Regression Modelling Framework for Receiver Operating Characteristic Curves in Medical Diagnostic Testing},
  author = {Pepe, Margaret S.},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {595--608},
  citeulike-article-id = {13264670},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {diagnosis,ordinal-logistic-model,roc-analysis,testing}
}

@article{pep98thr,
  title = {Three Approaches to Regression Analysis of Receiver Operating Characteristic Curves for Continuous Test Results},
  author = {Pepe, Margaret S.},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {124--135},
  citeulike-article-id = {13264671},
  posted-at = {2014-07-14 14:09:39},
  priority = {0},
  keywords = {diagnosis,roc-curve,testing}
}

@article{per06fas,
  title = {A Fast Routine for Fitting {{Cox}} Models with Time Varying Effects of the Covariates},
  author = {Perperoglou, Aris and Le Cessie, S. and van Houwelingen, Hans C.},
  options = {useprefix=true},
  date = {2006},
  journaltitle = {Comp Prog Meth Biomed},
  volume = {81},
  pages = {154--161},
  citeulike-article-id = {13265598},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {computing,r,tdc},
  note = {nice computational trick;major time savings over Therneau approach;time-dependent covariates}
}

@article{per06red,
  title = {Reduced-Rank Hazard Regression for Modelling Non-Proportional Hazards},
  author = {Perperoglou, Aris and le Cessie, Saskia and van Houwelingen, Hans C.},
  options = {useprefix=true},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {2831--2845},
  citeulike-article-id = {13265483},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {cox-model,non-ph,ph},
  note = {natural structural way to allow for varying degrees of freedom in modeling non-PH}
}

@article{per07app,
  title = {Approaches in Modelling Long-Term Survival: {{An}} Application to Breast Cancer},
  author = {Perperoglou, Aris and Keramopoullos, Antonis and van Houwelingen, Hans C.},
  options = {useprefix=true},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {2666--2685},
  citeulike-article-id = {13265597},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {brier-scores,pseudo-observations,reduced-rank-models,relaxed-burr-model,tdc,time-dependent-effects}
}

@article{per10stu,
  title = {Studywise Minimization: {{A}} Treatment Allocation Method That Improves Balance among Treat Groups and Makes Allocation Unpredictable},
  author = {Perry, Marieke and Faes, Miriam and Reelick, Miriam F. and Rikkert, Marcel G. and Borm, George F.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {1118--1122},
  citeulike-article-id = {13265858},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {imbalance,minimization,rct,selection-bias,treatment-allocation}
}

@article{per16spe,
  title = {A Special Case of Reduced Rank Models for Identification and Modelling of Time Varying Effects in Survival Analysis},
  author = {Perperoglou, Aris},
  date = {2016-12},
  journaltitle = {Stat Med},
  volume = {35},
  number = {28},
  pages = {5135--5148},
  issn = {02776715},
  doi = {10.1002/sim.7088},
  url = {http://dx.doi.org/10.1002/sim.7088},
  citeulike-article-id = {14234113},
  citeulike-attachment-1 = {per16spe.pdf; /pdf/user/harrelfe/article/14234113/1095788/per16spe.pdf; e4077545e90f2b63a19db3cfac14f4ac4b0cf6c4},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7088},
  day = {10},
  posted-at = {2016-12-25 21:19:44},
  priority = {0},
  keywords = {reduced-rank,tdc},
  note = {The proposed strategy will overfit and fail to have correct confidence interval coverage. Even goes so far as to use univariable screening.}
}

@article{per18ran,
  title = {A {{Randomized Trial}} of {{Epinephrine}} in {{Out-of-Hospital Cardiac Arrest}}},
  author = {Perkins, Gavin D. and Ji, Chen and Deakin, Charles D. and Quinn, Tom and Nolan, Jerry P. and Scomparin, Charlotte and Regan, Scott and Long, John and Slowther, Anne and Pocock, Helen and Black, John J.M. and Moore, Fionna and Fothergill, Rachael T. and Rees, Nigel and O’Shea, Lyndsey and Docherty, Mark and Gunson, Imogen and Han, Kyee and Charlton, Karl and Finn, Judith and Petrou, Stavros and Stallard, Nigel and Gates, Simon and Lall, Ranjit},
  date = {2018-08-23},
  journaltitle = {New England Journal of Medicine},
  volume = {379},
  number = {8},
  eprint = {30021076},
  eprinttype = {pmid},
  pages = {711--721},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa1806842},
  url = {https://doi.org/10.1056/NEJMoa1806842},
  urldate = {2021-05-22},
  abstract = {Epinephrine in Cardiac Arrest In a randomized trial involving 8014 patients with out-of-hospital cardiac arrest, the use of epinephrine resulted in a significantly higher rate of 30-day survival than placebo but not a higher rate of survival with a favorable neurologic outcome.},
  keywords = {ordinal,ordinal-endpoints,rct},
  annotation = {\_eprint: https://doi.org/10.1056/NEJMoa1806842}
}

@article{per19rev,
  title = {A Review of Spline Function Procedures in {{R}}},
  author = {Perperoglou, Aris and Sauerbrei, Willi and Abrahamowicz, Michal and Schmid, Matthias},
  date = {2019-03-06},
  journaltitle = {BMC Medical Research Methodology},
  volume = {19},
  number = {1},
  pages = {46},
  issn = {1471-2288},
  doi = {10.1186/s12874-019-0666-3},
  url = {https://doi.org/10.1186/s12874-019-0666-3},
  urldate = {2021-09-30},
  abstract = {With progress on both the theoretical and the computational fronts the use of spline modelling has become an established tool in statistical regression analysis. An important issue in spline modelling is the availability of user friendly, well documented software packages. Following the idea of the STRengthening Analytical Thinking for Observational Studies initiative to provide users with guidance documents on the application of statistical methods in observational research, the aim of this article is to provide an overview of the most widely used spline-based techniques and their implementation in R.},
  keywords = {r,spline}
}

@article{per89,
  title = {Simultaneous-Equation Estimation in a Clinical Trial of the Effect of Smoking on Birth Weight},
  author = {{Permutt}},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {619--622},
  citeulike-article-id = {13264672},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {general,regression,study-design-and-stopping-rules}
}

@article{pes93new,
  title = {A New Confidence Interval Method Based on the Normal Approximation for the Difference of Two Binomial Probabilities},
  author = {Peskun, Peter H.},
  date = {1993},
  journaltitle = {J Am Stat Assoc},
  volume = {88},
  pages = {656--661},
  citeulike-article-id = {13264673},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {binomial,computational-methods,confidence-interval,proportions,two-sample}
}

@article{pet00exp,
  title = {Experimental {{Design}} and {{Methods}} for {{School-Based Randomized Trials}}},
  author = {Peterson, Arthur V. and Mann, Sue L. and Kealey, Kathleen A. and Marek, Patrick M.},
  date = {2000-04},
  journaltitle = {Cont Clin Trials},
  volume = {21},
  number = {2},
  pages = {144--165},
  issn = {01972456},
  doi = {10.1016/s0197-2456(99)00050-1},
  url = {http://dx.doi.org/10.1016/s0197-2456(99)00050-1},
  citeulike-article-id = {13349293},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0197-2456(99)00050-1},
  posted-at = {2014-09-06 14:43:24},
  priority = {2},
  keywords = {cluster-randomization,community-trials,design-effects},
  note = {examples of design effects (variance inflation factors) in cluster randomized trials}
}

@article{pet12mul,
  title = {Multiple Imputation of Missing Repeated Outcome Measurements Did Not Add to Linear Mixed-Effects Models.},
  author = {Peters, Sanne A. and Bots, Michiel L. and den Ruijter, Hester M. and Palmer, Mike K. and Grobbee, Diederick E. and Crouse, John R. and O'Leary, Daniel H. and Evans, Gregory W. and Raichlen, Joel S. and Moons, Karel G. and Koffijberg, Hendrik and {METEOR study group}},
  options = {useprefix=true},
  date = {2012},
  journaltitle = {J Clin Epi},
  volume = {65},
  number = {6},
  pages = {686--695},
  doi = {10.1016/j.jclinepi.2011.11.012},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2011.11.012},
  abstract = {To assess the added value of multiple imputation (MI) of missing repeated outcomes measures in longitudinal data sets analyzed with linear mixed-effects (LME) models. Data were used from a trial on the effects of Rosuvastatin on rate of change in carotid intima-media thickness (CIMT). The reference treatment effect was derived from a complete data set. Scenarios and proportions of missing values in CIMT measurements were applied and LME analyses were used before and after MI. The added value of MI, in terms of bias and precision, was assessed using the mean-squared error (MSE) of the treatment effects and coverage of the 95\% confidence interval. The reference treatment effect was -0.0177mm/y. The MSEs for LME analysis without and with MI were similar in scenarios with up to 40\% missing values. Coverage was large in all scenarios and was similar for LME with and without MI. Our study empirically shows that MI of missing end point data before LME analyses does not increase precision in the estimated rate of change in the end point. Hence, MI had no added value in this setting and standard LME modeling remains the method of choice.},
  citeulike-article-id = {13265934},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2011.11.012},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {imputation,longitudinal,missing,mixed-effects-model,repeated-measures,serial-data}
}

@article{pet76des,
  title = {Design and Analysis of Randomized Clinical Trials Requiring Prolonged Observation of Each Patient. {{I}}. {{Introduction}} and Design},
  author = {Peto, R. and Pike, M. C. and Armitage, P. and Breslow, N. E. and Cox, D. R. and Howard, S. V. and Mantel, N. and McPherson, K. and Peto, J. and Smith, P. G.},
  date = {1976},
  journaltitle = {Brit J Cancer},
  volume = {34},
  pages = {585--612},
  citeulike-article-id = {13264674},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {classic,study-design,survival-analysis,teaching-mds}
}

@article{pet77des,
  title = {Design and Analysis of Randomized Clinical Trials Requiring Prolonged Observation of Each Patient. {{II}}. {{Analysis}} and Examples},
  author = {Peto, R. and Pike, M. C. and Armitage, P. and Breslow, N. E. and Cox, D. R. and Howard, S. V. and Mantel, N. and McPherson, K. and Peto, J. and Smith, P. G.},
  date = {1977},
  journaltitle = {Brit J Cancer},
  volume = {35},
  pages = {1--39},
  citeulike-article-id = {13264675},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {classic,study-design,survival-analysis,teaching-mds}
}

@article{pet86fit,
  title = {Fitting Parametric Survival Models with Time-Dependent Covariates},
  author = {Petersen, Trond},
  date = {1986},
  journaltitle = {Appl Stat},
  volume = {35},
  pages = {281--288},
  citeulike-article-id = {13264676},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pet89ord,
  title = {Re: {{Ordinal}} Regression Models for Epidemiologic Data},
  author = {Peterson, Bercedis},
  date = {1989},
  journaltitle = {Am J Epi},
  volume = {129},
  pages = {745--748},
  citeulike-article-id = {13264677},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {partial-proportional-odds,proportional-odds-model}
}

@article{pet90inv,
  title = {Investigating Time Dependence in {{Cox}}'s Proportional Hazards Model},
  author = {Pettitt, A. N. and Bin Daud, I.},
  date = {1990},
  journaltitle = {Appl Stat},
  volume = {39},
  pages = {313--329},
  citeulike-article-id = {13264678},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {cox-model-graphical-methods,testing-proportional-hazards}
}

@article{pet90par,
  title = {Partial Proportional Odds Models for Ordinal Response Variables},
  author = {Peterson, Bercedis and Harrell, Frank E.},
  date = {1990},
  journaltitle = {Appl Stat},
  volume = {39},
  pages = {205--217},
  citeulike-article-id = {13264679},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pet93sam,
  title = {Sample Size Requirements and Length of Study for Testing Interaction in a 1 k Factorial Design When Time-to-Failure Is the Outcome},
  author = {Peterson, Bercedis and George, Stephen L.},
  date = {1993},
  journaltitle = {Controlled Clin Trials},
  volume = {14},
  pages = {511--522},
  citeulike-article-id = {13264680},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {cox-model,interaction-test,power,sample-size}
}

@article{pez02ful,
  title = {A Fully {{Bayesian}} Approach to Calculating Sample Sizes for Clinical Trials with Binary Reponses},
  author = {Pezeshk, Hamid and Gittins, John},
  date = {2002},
  journaltitle = {Drug Info J},
  volume = {36},
  pages = {143--150},
  citeulike-article-id = {13265273},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {bayesian-method,binomial,expected-net-benefit,regulator-as-a-third-decision-maker,sample-size}
}

@article{pha05inv,
  title = {Investigating Drug-Induced {{QT}} and {{QTc}} Prolongation in the Clinic: {{A}} Review of Statistical Design and Analysis Considerations: {{Report}} from the {{Pharmaceutical Research}} and {{Manufacturers}} of {{America QT Statistics Expert Team}}},
  author = {{Pharmaceutical Research and Manufacturers of America QT Statistics Expert Working Team}},
  date = {2005},
  journaltitle = {Drug Info J},
  volume = {39},
  pages = {243--266},
  citeulike-article-id = {13265431},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {clinical-safety,corrected-qt,drug-development-process,ecg,pharmaceutical-safety,qt-prolongation}
}

@article{pha21com,
  title = {A Comparison of Methods for Analyzing a Binary Composite Endpoint with Partially Observed Components in Randomized Controlled Trials},
  author = {Pham, Tra My and White, Ian R. and Kahan, Brennan C. and Morris, Tim P. and Stanworth, Simon J. and Forbes, Gordon},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9203},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9203},
  urldate = {2021-09-30},
  abstract = {Composite endpoints are commonly used to define primary outcomes in randomized controlled trials. A participant may be classified as meeting the endpoint if they experience an event in one or several components (eg, a favorable outcome based on a composite of being alive and attaining negative culture results in trials assessing tuberculosis treatments). Partially observed components that are not missing simultaneously complicate the analysis of the composite endpoint. An intuitive strategy frequently used in practice for handling missing values in the components is to derive the values of the composite endpoint from observed components when possible, and exclude from analysis participants whose composite endpoint cannot be derived. Alternatively, complete record analysis (CRA) (excluding participants with any missing components) or multiple imputation (MI) can be used. We compare a set of methods for analyzing a composite endpoint with partially observed components mathematically and by simulation, and apply these methods in a reanalysis of a published trial (TOPPS). We show that the derived composite endpoint can be missing not at random even when the components are missing completely at random. Consequently, the treatment effect estimated from the derived endpoint is biased while CRA results without the derived endpoint are valid. Missing at random mechanisms require MI of the components. We conclude that, although superficially attractive, deriving the composite endpoint from observed components should generally be avoided. Despite the potential risk of imputation model mis-specification, MI of missing components is the preferred approach in this study setting.},
  langid = {english},
  keywords = {composite-endpoint,missing,multiple-endpoints,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9203}
}

@article{pha21sam,
  title = {Sample Size Calculation for Two-Arm Trials with Time-to-Event Endpoint for Nonproportional Hazards Using the Concept of {{Relative Time}} When Inference Is Built on Comparing {{Weibull}} Distributions},
  author = {Phadnis, Milind A. and Mayo, Matthew S.},
  date = {2021},
  journaltitle = {Biometrical Journal},
  volume = {n/a},
  number = {n/a},
  issn = {1521-4036},
  doi = {10.1002/bimj.202000043},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000043},
  urldate = {2021-07-18},
  abstract = {Sample size calculations for two-arm clinical trials with a time-to-event endpoint have traditionally used the assumption of proportional hazards (PH) or the assumption of exponentially distributed survival times. Available software provides methods for sample size calculation using a nonparametric logrank test, Schoenfeld's formula for Cox PH model, or parametric calculations specific to the exponential distribution. In cases where the PH assumption is not valid, the first-choice method is to compute sample size assuming a piecewise linear survival curve (Lakatos approach) for both the control and treatment arms with judiciously chosen cut-points. Recent advances in literature have used the assumption of Weibull distributed times for single-arm trials, and, newer methods have emerged that allow sample size calculations for two-arm trials using the assumption of proportional time (PT) while considering non-PH. These methods, however, always assume an instantaneous effect of treatment relative to control requiring that the effect size be defined by a single number whose magnitude is preserved throughout the trial duration. Here, we consider the scenarios where the hypothesized benefit of treatment relative to control may not be constant giving rise to the notion of Relative Time (RT). By assuming that survival times for control and treatment arm come from two different Weibull distributions with different location and shape parameters, we develop the methodology for sample size calculation for specific cases of both non-PH and non-PT. Simulations are conducted to assess the operation characteristics of the proposed method and a practical example is discussed.},
  langid = {english},
  keywords = {cox-model,ph,power,sample-size,weibull-distribution,weibull-model},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000043}
}

@article{phi08com,
  title = {Comparative Review of Methods for Handling Drop-out in Longitudinal Studies},
  author = {Philipson, Peter M. and Ho, Weang K. and Henderson, Robin},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {6276--6298},
  doi = {10.1002/sim.3450},
  url = {http://dx.doi.org/10.1002/sim.3450},
  citeulike-article-id = {13265761},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3450},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {diagnostics,dropout,inverse-probability-weighting,longitudinal-data,missing-data,non-random-dropout,random-effects,rct,robustness-to-misspecification,selection-factorization,sensitivity-analysis,serial-data,taxonomy-of-missingness},
  note = {no clear winner emerged;impossible to construct a natural hierarchy of methods}
}

@article{phi18mea,
  title = {Measuring the {{Stability}} of {{Results From Supervised Statistical Learning}}},
  author = {Philipp, Michel and Rusch, Thomas and Hornik, Kurt and Strobl, Carolin},
  date = {2018-05-18},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {0},
  number = {0},
  pages = {1--16},
  issn = {1061-8600},
  doi = {10.1080/10618600.2018.1473779},
  url = {https://doi.org/10.1080/10618600.2018.1473779},
  urldate = {2018-08-29},
  abstract = {Stability is a major requirement to draw reliable conclusions when interpreting results from supervised statistical learning. In this article, we present a general framework for assessing and comparing the stability of results, which can be used in real-world statistical learning applications as well as in simulation and benchmark studies. We use the framework to show that stability is a property of both the algorithm and the data-generating process. In particular, we demonstrate that unstable algorithms (such as recursive partitioning) can produce stable results when the functional form of the relationship between the predictors and the response matches the algorithm. Typical uses of the framework in practical data analysis would be to compare the stability of results generated by different candidate algorithms for a dataset at hand or to assess the stability of algorithms in a benchmark study. Code to perform the stability analyses is provided in the form of an R package. Supplementary material for this article is available online.},
  keywords = {machine,reproducibility,stability,validation}
}

@article{phi20est,
  title = {Estimands in Practice: {{Bridging}} the Gap between Study Objectives and Statistical Analysis},
  shorttitle = {Estimands in Practice},
  author = {Phillips, Alan and Clark, Tim},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2056},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2056},
  urldate = {2020-09-13},
  abstract = {The International Council for Harmonisation (ICH) guideline E9 Statistical Principles for Clinical Trials (1) was issued in 1998. In October 2014, an addendum to ICH E9 was proposed on statistical principles relating to estimands and sensitivity analyses. The final version of the addendum to ICH E9 (R1) (2) was issued in November 2019. This virtual edition of Pharmaceutical Statistics takes a closer look at some of the progress that has been made since 2018 when implementing the estimand framework within clinical research. The articles discussed in this virtual issue are not new, but a compilation from previous issues. This specific article will act as a refresher for those not familiar with the topic and discuss the ABCs of estimands and their proposed deployment for improving the quality of clinical research. An overview of the more recent Pharmaceutical Statistics articles on estimands will be provided, signifying areas where progress have been made. The articles should be considered as contributions to the ongoing discussions rather than the final word. Finally, a personal perspective on the estimand success story and remaining challenges with proposed solutions will be discussed.},
  langid = {english},
  keywords = {drug-development,endpoints,estimand,outcomes,RCT},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2056}
}

@article{phi89,
  title = {Sample Size Requirements for Prospective Studies, with Examples for Coronary Heart Disease},
  author = {Phillips, A. N. and Pocock, S. J.},
  date = {1989},
  journaltitle = {J Clin Epi},
  volume = {42},
  pages = {639--648},
  citeulike-article-id = {13264681},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,sample-size-estimation}
}

@article{phi90pro,
  title = {Prognostic Scores for Detecting a High Risk Group: {{Estimating}} the Sensitivity When Applied to New Data},
  author = {Phillips, Andrew N. and Thompson, Simon G. and Pocock, Stuart J.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {1189--1198},
  citeulike-article-id = {13264682},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {calibration,logistic-model,overfitting,shrinkage,validation}
}

@article{phi99gui,
  title = {Guidelines for Assessing the Performance of Statisticians Involved in Clinical Research in the Pharmaceutical Industry},
  author = {Phillips, Alan},
  date = {1999},
  journaltitle = {Drug Info J},
  volume = {33},
  pages = {427--433},
  citeulike-article-id = {13264683},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {clinical-development-plans,clinical-reports,competency,evaluation-of-statisticians,protocols}
}

@report{phreg,
  type = {Technical Report},
  title = {{{SAS}}/{{STAT Software}}: {{The PHREG Procedure}}},
  author = {So, Y.},
  date = {1991},
  number = {P-217},
  institution = {{SAS Institute}},
  url = {http://support.sas.com/documentation/onlinedoc/stat},
  citeulike-article-id = {13264684},
  citeulike-linkout-0 = {http://support.sas.com/documentation/onlinedoc/stat},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pic20dir,
  title = {Directed Acyclic Graphs and Causal Thinking in Clinical Risk Prediction Modeling},
  author = {Piccininni, Marco and Konigorski, Stefan and Rohmann, Jessica L. and Kurth, Tobias},
  date = {2020-07-02},
  journaltitle = {BMC Medical Research Methodology},
  volume = {20},
  number = {1},
  pages = {179},
  issn = {1471-2288},
  doi = {10.1186/s12874-020-01058-z},
  url = {https://doi.org/10.1186/s12874-020-01058-z},
  urldate = {2020-07-08},
  abstract = {In epidemiology, causal inference and prediction modeling methodologies have been historically distinct. Directed Acyclic Graphs (DAGs) are used to model a priori causal assumptions and inform variable selection strategies for causal questions. Although tools originally designed for prediction are finding applications in causal inference, the counterpart has remained largely unexplored. The aim of this theoretical and simulation-based study is to assess the potential benefit of using DAGs in clinical risk prediction modeling.},
  keywords = {causal-inference,directed-graph,prediction,prediction-research}
}

@article{pic84cro,
  title = {Cross-Validation of Regression Models},
  author = {Picard, Richard R. and Cook, R. Dennis},
  date = {1984},
  journaltitle = {J Am Stat Assoc},
  volume = {79},
  pages = {575--583},
  citeulike-article-id = {13264685},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {cross-validation,regression-general}
}

@article{pic90,
  title = {Data Splitting},
  author = {Picard, R. R. and Berk, K. N.},
  date = {1990},
  journaltitle = {Am Statistician},
  volume = {44},
  pages = {140--147},
  citeulike-article-id = {13264686},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pic91,
  title = {Maximum Likelihood Estimation in the New Computing Environment},
  author = {Pickle, Linda W.},
  date = {1991-11},
  journaltitle = {Stat Comp Graphics News ASA},
  volume = {2},
  number = {2},
  pages = {6--15},
  citeulike-article-id = {13264687},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  note = {volume and number are printed incorrectly on the cover as vol 3 no 1}
}

@article{pie88,
  title = {Confidence Bands for Logistic Regression with Restricted Predictor Variables},
  author = {Piegorsch, W. W. and Casella, G.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {739--750},
  citeulike-article-id = {13264688},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,maximum-likelihood}
}

@article{pig99imp,
  title = {An Improved Goodness of Fit Statistic for Probability Prediction Models},
  author = {Pigeon, Joseph G. and Heyse, Joseph F.},
  date = {1999},
  journaltitle = {Biometrical J},
  volume = {41},
  pages = {71--82},
  citeulike-article-id = {13265209},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {general,goodness-of-fit,logistic-regression,polytomous-logistic-model,prediction},
  note = {adjustment to basic chi-square test to account for heterogeneity of P;does not reference hos97com;calibration in the large}
}

@article{pik00aut,
  title = {Automated Analysis Software for Screening Using {{{\textsc{S-Plus}}}} {{StatServer}}},
  author = {Pikounis, Bill and Gunter, Bert and Liaw, Andy and Pajni, Neeraj},
  date = {2000-10},
  citeulike-article-id = {13265164},
  posted-at = {2014-07-14 14:09:50},
  priority = {0}
}

@article{pik66,
  title = {A Method of Analysis of Certain Class of Experiments in Carcinogenesis},
  author = {Pike, M. C.},
  date = {1966},
  journaltitle = {Biometrics},
  volume = {22},
  pages = {142--161},
  citeulike-article-id = {13264689},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pin11eff,
  title = {The Effect of Obesity on Outcome of Unrelated Cord Blood Transplant in Children with Malignant Diseases},
  author = {Pine, M. and Wang, L. and Harrell, F. E. and Calder, C. and Manes, B. and Evans, M. and Domm, J. and Frangoul, H.},
  date = {2011-10},
  journaltitle = {Bone Mar Transpl},
  volume = {46},
  pages = {1309--1313},
  citeulike-article-id = {13265914},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@book{pinheiro-bates,
  title = {Mixed-{{Effects Models}} in {{S}} and {{S-PLUS}}},
  author = {Pinheiro, José C. and Bates, Douglas M.},
  date = {2000},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265320},
  posted-at = {2014-07-14 14:09:54},
  priority = {0}
}

@article{pit05use,
  title = {Use of Principal Component Analysis and the {{GE-biplot}} for the Graphical Exploration of Gene Expression Data},
  author = {Pittelkow, Yvonne and Wilson, Susan R.},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  pages = {630--634},
  citeulike-article-id = {13265421},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {bioinformatics,biplot,data-reduction,data-visualization,exploratory-data-analysis,ge-biplot,gene-expression-data,genomics,graphics,microarray,pca,pca-for-gene-expression-array,svd}
}

@article{pla00boo,
  title = {Bootstrap Confidence Intervals for the Sensitivity of a Quantitative Diagnostic Test},
  author = {Platt, Robert W. and Hanley, James A. and Yang, Hong},
  date = {2000-02},
  journaltitle = {Stat Med},
  volume = {19},
  number = {3},
  pages = {313--322},
  publisher = {John Wiley & Sons, Ltd.},
  doi = {10.1002/(sici)1097-0258(20000215)19:3\%3C313::aid-sim370\%3E3.0.co;2-k},
  url = {http://dx.doi.org/10.1002/(sici)1097-0258(20000215)19:3%3C313::aid-sim370%3E3.0.co;2-k},
  abstract = {We examine bootstrap approaches to the analysis of the sensitivity of quantitative diagnostic test data. Methods exist for inference concerning the sensitivity of one or more tests for fixed levels of specificity, taking into account the variability in the sensitivity due to variability in the test values for normal subjects. However, parametric methods do not adequately account for error, particularly when the data are non-normally distributed, and non-parametric methods have low power. We implement bootstrap methods for confidence limits for the sensitivity of a test for a fixed specificity and demonstrate that under certain circumstances the bootstrap method gives more accurate confidence intervals than do other methods, while it performs at least as well as other methods in many standard situations. Copyright  2000 John Wiley \& Sons, Ltd.},
  citeulike-article-id = {13349295},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/(sici)1097-0258(20000215)19:3%3C313::aid-sim370%3E3.0.co;2-k},
  day = {15},
  posted-at = {2014-09-06 14:46:22},
  priority = {2},
  keywords = {bootstrap,cutpoints,diagnosis,sensitivity},
  note = {bootstrap adjustment of sensitivity for having solved for cutpoint to achieve a certain specificity; diagnosis; testing; accuracy}
}

@article{pla64str,
  title = {Strong Inference},
  author = {Platt, John R.},
  date = {1964},
  journaltitle = {Science},
  volume = {146},
  number = {3642},
  pages = {347--353},
  citeulike-article-id = {13265852},
  posted-at = {2014-07-14 14:10:05},
  priority = {0}
}

@article{plo14mod,
  title = {Modern Modelling Techniques Are Data Hungry: A Simulation Study for Predicting Dichotomous Endpoints.},
  author = {van der Ploeg, Tjeerd and Austin, Peter C. and Steyerberg, Ewout W.},
  options = {useprefix=true},
  date = {2014-12},
  journaltitle = {BMC medical research methodology},
  volume = {14},
  number = {1},
  eprint = {25532820},
  eprinttype = {pmid},
  pages = {137+},
  publisher = {BioMed Central Ltd},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-14-137},
  url = {http://dx.doi.org/10.1186/1471-2288-14-137},
  abstract = {Modern modelling techniques may potentially provide more accurate predictions of binary outcomes than classical techniques. We aimed to study the predictive performance of different modelling techniques in relation to the effective sample size (“data hungriness”).},
  citeulike-article-id = {13467382},
  citeulike-attachment-1 = {plo14mod.pdf; /pdf/user/harrelfe/article/13467382/1001279/plo14mod.pdf; f52c6e42f5dad5a8e754553195722f31561d0acf},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2288-14-137},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/25532820},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=25532820},
  day = {22},
  posted-at = {2015-01-17 15:08:47},
  priority = {0},
  keywords = {events-per-variable,random-forest,recursive-partitioning,rms,study-design,svm,validation},
  note = {Would be better to use proper accuracy scores in the assessment. Too much emphasis on optimism as opposed to final discrimination measure. But much good practical information. Recursive partitioning fared poorly.}
}

@book{plo93psy,
  title = {The {{Psychology}} of {{Judgment}} and {{Decision Making}}},
  author = {Plous, Scott},
  date = {1993},
  publisher = {{McGraw Hill}},
  citeulike-article-id = {13265386},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  note = {p. 145:"In front of you is a wheel of fortune. The perimeter is lined with an array of numbers, and after the wheel is given a spin, the needle lands on 65. You are confronted with a question: Is the percentage of African countries in the United Nations greater or less than 65? Not a matter you have thought much about, but nonetheless, you are fairly sure that the percentage is less than 65. What, you are asked, is the {$<$}i{$>$}exact{$<$}/i{$>$} percentage of African countries in the United Nations? After some thought, you respond with an estimate of 45 percent. A research records your response, thanks you for your time, and off you go. Now you are another person, a person who has not yet answered questions about the United Nations, a person for whom the wheel of fortune will land on 10 rather than 65. After the wheel has stopped moving, the researcher asks: Is the percentage of African countries in the United Nations great or less than 10? More you say -- certainly it must be more. What is the {$<$}i{$>$}exact{$<$}/i{$>$} percentage of African countries in the United Nations? After some thought, you respond with an estimate of 25 percent. In fact, just a procedure, yielding identical results, was conducted by Amos Tversky and Daniel Kahneman (1974). Subjects who were randomly assigned to an experimental condition in which the needle landed on 65 subsequently gave a median estimate of 45 percent, and subjects for whom the needle landed on 10 gave a median estimate of 25 percent. Tversky and Kahneman explained this phenomenon in terms of 'anchoring and adjustment' -- that is, the insufficient adjustment up or down from an original starting value, or 'anchor'. ... Surprisingly, the effects of anchoring do not disappear with monetary incentives for accuracy (Tversky and Kahneman, 1974; Wright and Anderson, 1989) or with outrageously extreme anchors (Quattrone et al., 1984). In one experiment, Quattrone and his associates (1984) solicited exact numerical estimates after first asking whether the number of Beatles records that had made the top 10 fell above or below 100,025 albums, whether the average price of a college textbook was more or less than 7128.53, or whether the average temperature in San Francisco was greater or less than 558. Quattrone's research team found that absurdly high anchor values worked just as well as more plausible anchor values. From this result, they concluded that anchoring is a robust phenomenon in which the size of the effect grows with the discrepancy between the anchor and the 'preanchor estimate' ... until the effect reaches an asymptotic level. If true, these findings suggest that negotiators, advertisers, politicians, and other persuasion specialists will generally be most succesful by staking out extreme initial positions."}
}

@article{poc02sub,
  title = {Subgroup Analysis, Covariate Adjustment and Baseline Comparisons in Clinical Trial Reporting: Current Practice and Problems},
  author = {Pocock, Stuart J. and Assmann, Susan E. and Enos, Laura E. and Kasten, Linda E.},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {2917--2930},
  citeulike-article-id = {13265296},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {ancova,baseline,baseline-comparisons,covariable-adjustment,covariate-adjustment,rct,subgroup-analysis-overuse,underuse-of-interaction-tests}
}

@article{poc09tra,
  title = {Translating Statistical Findings into Plain {{English}}},
  author = {Pocock, Stuart J. and Ware, James H.},
  date = {2009},
  journaltitle = {Lancet},
  volume = {373},
  pages = {1926--1928},
  doi = {10.1016/S0140-6736(09)60499-2},
  url = {http://dx.doi.org/10.1016/S0140-6736(09)60499-2},
  citeulike-article-id = {13265760},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0140-6736(09)60499-2},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {confidence-intervals,confidence-limits,graphics,p-values,statistical-significance,teaching-mds},
  note = {nice summary of how to interpret P-values and confidence limits, including an excellent summary graph}
}

@article{poc12win,
  title = {The Win Ratio: A New Approach to the Analysis of Composite Endpoints in Clinical Trials Based on Clinical Priorities},
  shorttitle = {The Win Ratio},
  author = {Pocock, Stuart J. and Ariti, Cono A. and Collier, Timothy J. and Wang, Duolao},
  date = {2012-01},
  journaltitle = {Eur. Heart J.},
  volume = {33},
  number = {2},
  eprint = {21900289},
  eprinttype = {pmid},
  pages = {176--182},
  issn = {1522-9645},
  doi = {10.1093/eurheartj/ehr352},
  abstract = {The conventional reporting of composite endpoints in clinical trials has an inherent limitation in that it emphasizes each patient's first event, which is often the outcome of lesser clinical importance. To overcome this problem, we introduce the concept of the win ratio for reporting composite endpoints. Patients in the new treatment and control groups are formed into matched pairs based on their risk profiles. Consider a primary composite endpoint, e.g. cardiovascular (CV) death and heart failure hospitalization (HF hosp) in heart failure trials. For each matched pair, the new treatment patient is labelled a 'winner' or a 'loser' depending on who had a CV death first. If that is not known, only then they are labelled a 'winner' or 'loser' depending on who had a HF hosp first. Otherwise they are considered tied. The win ratio is the total number of winners divided by the total numbers of losers. A 95\% confidence interval and P-value for the win ratio are readily obtained. If formation of matched pairs is impractical then an alternative win ratio can be obtained by comparing all possible unmatched pairs. This method is illustrated by re-analyses of the EMPHASIS-HF, PARTNER B, and CHARM trials. The win ratio is a new method for reporting composite endpoints, which is easy to use and gives appropriate priority to the more clinically important event, e.g. mortality. We encourage its use in future trial reports.},
  langid = {english},
  keywords = {multiple-endpoints,multiple-events,rct}
}

@article{poc87,
  title = {The Analysis of Multiple Endpoints in Clinical Trials},
  author = {Pocock SJ, Tsiatis A. A.},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {487--498},
  citeulike-article-id = {13264690},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {multivariate-analysis,study-design-and-stopping-rules}
}

@article{pod96ass,
  title = {Associations of Types of Lens Opacities between and within Eyes of Individuals},
  author = {Podgor, Martin J. and Hiller, Rita and {The Framingham Eye Studies Group}},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {145--156},
  citeulike-article-id = {13264691},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {clustered-data,gee,logistic-model-extensions,multivariate-responses}
}

@article{pog01dat,
  title = {Data Management Procedures in the {{Asthma Clinical Research Network}}},
  author = {Pogash, Rosanne M. and Boehmer, Susan J. and Forand, Pamela E. and Dyer, Anne-Marie and Kunselman, Susan J.},
  date = {2001},
  journaltitle = {Controlled Clin Trials},
  volume = {22},
  pages = {168S-180S},
  citeulike-article-id = {13265248},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {data-management-procedures,data-quality,distributed-data-management,operations,phases}
}

@article{poh21cat,
  title = {Categories, Components, and Techniques in a Modular Construction of Basket Trials for Application and Further Research},
  author = {Pohl, Moritz and Krisam, Johannes and Kieser, Meinhard},
  date = {2021},
  journaltitle = {Biometrical Journal},
  volume = {n/a},
  number = {n/a},
  issn = {1521-4036},
  doi = {10.1002/bimj.202000314},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000314},
  urldate = {2021-05-05},
  abstract = {Basket trials have become a virulent topic in medical and statistical research during the last decade. The core idea of them is to treat patients, who express the same genetic predisposition—either personally or their disease—with the same treatment irrespective of the location of the disease. The location of the disease defines each basket and the pathway of the treatment uses the common genetic predisposition among the baskets. This opens the opportunity to share information among baskets, which can consequently increase the information of the basket-wise response with respect to the investigated treatment. This further allows dynamic decisions regarding futility and efficacy of individual baskets during the ongoing trial. Several statistical designs have been proposed on how a basket trial can be conducted and this has left an unclear situation with many options. The different designs propose different mathematical and statistical techniques, different decision rules, and also different trial purposes. This paper presents a broad overview of existing designs, categorizes them, and elaborates their similarities and differences. A uniform and consistent notation facilitates the first contact, introduction, and understanding of the statistical methodologies and techniques used in basket trials. Finally, this paper presents a modular approach for the construction of basket trials in applied medical science and forms a base for further research of basket trial designs and their techniques.},
  langid = {english},
  keywords = {adaptive,adaptive-clinical-trials,basket,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000314}
}

@article{por07omi,
  title = {“{{Omics}}” Research, Monetization of Intellectual Property and Fragmentation of Knowledge: Can Clinical Epidemiology Strengthen Integrative Research?},
  author = {Porta, Miguel and Hernández-Aguado, Ildefonso and Lumbreras, Blanca and Crous-Bou, Marta},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {1220--1225},
  citeulike-article-id = {13265646},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  note = {"monetization of intellectual property appears to be a powerful force favoring methodological limitations and an excessive reductionism and fragmentation of biologic knowledge";proteomics;genomics;clinical epidemiology;methods;relevance;validity;failure of omics business model}
}

@article{pos03iss,
  title = {Issues in Designing Flexible Trials},
  author = {Posch, M. and Bauer, P. and Brannath, W.},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {953--969},
  citeulike-article-id = {13265513},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{pos89,
  title = {An Effective Algorithm for the Noncentral Chi-Squared Distribution Function},
  author = {Ho, Posten},
  date = {1989},
  journaltitle = {Am Statistician},
  volume = {43},
  pages = {261--263},
  citeulike-article-id = {13264692},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {statistical-computation-algorithms}
}

@article{pot64gen,
  title = {A Generalized Multivariate Analysis of Variance Model Useful Especially for Growth Curve Problems},
  author = {Potthoff, Richard F. and Roy, S. N.},
  date = {1964},
  journaltitle = {Biometrika},
  volume = {51},
  pages = {313--326},
  citeulike-article-id = {13265957},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  note = {included an AR1 example}
}

@article{pow94gra,
  title = {Graphical Summary of Patient Status},
  author = {Powsner, Seth M. and Tufte, Edward R.},
  date = {1994},
  journaltitle = {Lancet},
  volume = {344},
  pages = {386--389},
  citeulike-article-id = {13264693},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {graphics,patient-displays,patient-monitoring}
}

@article{pra90cli,
  title = {Clinical and Regulatory Implications of the Cardiac Arrhythmia Suppression Trial ({{Editorial}})},
  author = {Pratt, C. M. and Brater, D. C. and Harrell, F. E. and Kowey, P. R. and Leier, C. V. and Lowenthal, D. T. and Messerli, F. and Packer, M. and {Pritchett} and Ruskin, J. N.},
  date = {1990},
  journaltitle = {Am J Card},
  volume = {65},
  pages = {103--105},
  citeulike-article-id = {13264694},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {arrhythmia,cast,fda,rct}
}

@article{pre78,
  title = {Choosing between Logistic Regression and Discriminant Analysis},
  author = {Press, S. J. and Wilson, S.},
  date = {1978},
  journaltitle = {J Am Stat Assoc},
  volume = {73},
  pages = {699--705},
  citeulike-article-id = {13264695},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pre78ana,
  title = {The Analysis of Failure Times in the Presence of Competing Risks},
  author = {Prentice, R. L. and Kalbfleisch, J. D. and Peterson, A. V. and Flournoy, N. and Farewell, V. T. and Breslow, N. E.},
  date = {1978},
  journaltitle = {Biometrics},
  volume = {34},
  pages = {541--554},
  citeulike-article-id = {13264696},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pre78reg,
  title = {Regression Analysis of Grouped Survival Data with Applications to Breast Cancer Data},
  author = {Prentice, R. L. and Gloeckler, L. A.},
  date = {1978},
  journaltitle = {Biometrics},
  volume = {34},
  pages = {57--67},
  citeulike-article-id = {13265163},
  posted-at = {2014-07-14 14:09:50},
  priority = {0}
}

@article{pre81,
  title = {Logistic Regression Diagnostics},
  author = {Pregibon, D.},
  date = {1981},
  journaltitle = {Ann Stat},
  volume = {9},
  pages = {705--724},
  citeulike-article-id = {13264697},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pre82res,
  title = {Resistant Fits for Some Commonly Used Logistic Models with Medical Applications},
  author = {Pregibon, Daryl},
  date = {1982},
  journaltitle = {Biometrics},
  volume = {38},
  pages = {485--498},
  citeulike-article-id = {13264698},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {influence,logistic-regression-model,resistant-fit,robust-methods}
}

@article{pre89,
  title = {Correlated Binary Regression with Covariates Specific to Each Binary Observation},
  author = {Prentice, R. L.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {1033--1048},
  citeulike-article-id = {13264699},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@incollection{prinqual,
  title = {The {{PRINQUAL Procedure}}},
  booktitle = {{{SAS}}/{{STAT}} 9.2 {{User}}'s {{Guide}}},
  author = {Kuhfeld, Warren F.},
  date = {2009},
  edition = {Second},
  publisher = {{SAS Publishing}},
  location = {{Cary, NC}},
  url = {http://support.sas.com/documentation/onlinedoc/stat},
  citeulike-article-id = {13264700},
  citeulike-linkout-0 = {http://support.sas.com/documentation/onlinedoc/stat},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pro12spe,
  title = {Spending Functions and Continuous-Monitoring Boundaries},
  author = {Proschan, Michael A. and Gordon Lan, K. K.},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {25},
  pages = {3024--3030},
  doi = {10.1002/sim.5481},
  url = {http://dx.doi.org/10.1002/sim.5481},
  abstract = {Clinical trials are monitored periodically for safety, efficacy, and futility. The spending function is a popular tool for efficacy monitoring because it does not require pre-specification of the number or timing of interim analyses. But there are infinitely many spending functions, so some guidance on how to choose one is helpful. We consider spending functions that are generated from different continuous-monitoring boundaries for Brownian motion. We use properties of the continuous-monitoring boundaries to derive properties of the associated spending function.},
  citeulike-article-id = {13265979},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5481},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {b-value,boundaries,brownian-motion,group-sequential-monitoring,information-fraction,interim-analyses,power,spending-functions}
}

@article{pro92eff,
  title = {Effects of Assumption Violations on Type {{I}} Error Rate in Group Sequential Monitoring},
  author = {Proschan, Michael A. and Follmann, Dean A. and Waclawiw, Myron A.},
  date = {1992},
  journaltitle = {Biometrics},
  volume = {48},
  pages = {1131--1143},
  doi = {10.2307/2532704},
  url = {http://dx.doi.org/10.2307/2532704},
  citeulike-article-id = {13264701},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2532704},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {clinical-trials,rct,sequential-methods,study-design}
}

@article{pro95des,
  title = {Designed Extensions of Studies Based on Conditional Power},
  author = {Proschan, Michael A. and Hunsberger, Sally A.},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {1315--1324},
  citeulike-article-id = {13264702},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {conditional-power,sequential-monitoring,study-design}
}

@article{pro97res,
  title = {A Restricted Test of Circadian Rhythm},
  author = {Proschan, Michael A. and Follman, Dean A.},
  date = {1997},
  journaltitle = {J Am Stat Assoc},
  volume = {92},
  pages = {717--724},
  citeulike-article-id = {13264703},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {circadian-rhythm,circular-distribution,test-of-randomness}
}

@article{pry83,
  title = {Estimating the Likelihood of Significant Coronary Artery Disease},
  author = {Pryor, David B. and Harrell, Frank E. and Lee, Kerry L. and Califf, Robert M. and Rosati, Robert A.},
  date = {1983},
  journaltitle = {Am J Med},
  volume = {75},
  pages = {771--780},
  citeulike-article-id = {13264704},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pry83imp,
  title = {An Improving Prognosis over Time in Medically Treated Patients with Coronary Artery Disease},
  author = {Pryor, D. B. and Harrell, F. E. and Lee, K. L. and Califf, R. M. and Rosati, R. A.},
  date = {1983},
  journaltitle = {Am J Card},
  volume = {52},
  pages = {444--448},
  citeulike-article-id = {13264705},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pry84eff,
  title = {The Effect of Crossovers on Estimates of Survival in Medically Treated Patients with Coronary Artery Disease},
  author = {Pryor, D. B. and Lee, K. L. and Harris, P. J. and Harrell, F. E. and Rosati, R. A.},
  date = {1984},
  journaltitle = {J Chron Dis},
  volume = {37},
  pages = {521--529},
  citeulike-article-id = {13264706},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pry84pro,
  title = {Prognostic Indicators from Radionuclide Angiography in Medically Treated Patients with Coronary Artery Disease},
  author = {Pryor, D. B. and Harrell, F. E. and Lee, K. L. and Rosati, R. A. and Coleman, R. E. and Cobb, F. R. and Califf, R. M. and Jones, R. H.},
  date = {1984},
  journaltitle = {Am J Card},
  volume = {53},
  pages = {18--22},
  citeulike-article-id = {13264707},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pry85cli,
  title = {Clinical Data Bases: {{Accomplishments}} and {{Unrealized Potential}}},
  author = {Pryor, D. B. and Califf, R. M. and Harrell, F. E. and Hlatky, M. A. and Lee, K. L. and Mark, D. B. and Rosati, R. A.},
  date = {1985},
  journaltitle = {Med Care},
  volume = {23},
  pages = {623--647},
  citeulike-article-id = {13264708},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pry87,
  title = {The Changing Survival Benefits of Coronary Revascularization over Time},
  author = {Pryor, D. B. and Harrell, F. E. and Rankin, J. S. and Lee, K. L. and Muhlbaier, L. H. and Oldham, H. N. and Hlatky, M. A. and Mark, D. B. and Reves, J. G. and Califf, R. M.},
  date = {1987},
  journaltitle = {Circ (Supplement V)},
  volume = {76},
  pages = {13--21},
  citeulike-article-id = {13264709},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@incollection{pry88tre,
  title = {Trends in the Presentation, Management and Survival of Patients with Coronary Artery Disease---{{The Duke Database}} for {{Cardiovascular Disease}}},
  booktitle = {Trends in {{Coronary Heart Disease Mortality}}: {{The}} Influence of {{Medical Care}}},
  author = {Pryor, D. B. and Harrell, F. E. and Rankin, J. S. and Lee, K. L. and Muhlbaier, L. H. and {Et Al}},
  date = {1988},
  pages = {76--87},
  publisher = {{Oxford University Press}},
  citeulike-article-id = {13264710},
  posted-at = {2014-07-14 14:09:40},
  priority = {0}
}

@article{pry91est,
  title = {Estimating the Likelihood of Severe Coronary Artery Disease},
  author = {Pryor, D. B. and Shaw, L. and Harrell, F. E. and Lee, K. L. and Hlatky, M. A. and Mark, D. B. and Muhlbaier, L. H. and Califf, R. M.},
  date = {1991},
  journaltitle = {Am J Med},
  volume = {90},
  pages = {553--562},
  citeulike-article-id = {13264711},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {clinical-prediction,medical-example-of-logistic-models}
}

@article{pry93val,
  title = {Value of the History and Physical Examination in Identifying Patients at Increased Risk for Coronary Artery Disease},
  author = {Pryor, D. B. and Shaw, L. and McCants, C. B. and Lee, K. L. and Mark, D. B. and Harrell, F. E. and Muhlbaier, L. H. and Califf, R. M.},
  date = {1993},
  journaltitle = {Ann Int Med},
  volume = {118},
  pages = {81--90},
  citeulike-article-id = {13264712},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {diagnosis,examples,incremental-information,logistic-model,teaching-mds}
}

@article{puh06mor,
  title = {More Medical Journals Should Inform Their Contributors about Three Key Principles of Graph Construction},
  author = {Puhan, Milo A. and ter Riet, Gerben and Eichler, Klaus and Steurer, Johann and Bachmann, Lucas M.},
  options = {useprefix=true},
  date = {2006},
  journaltitle = {J Clin Epi},
  volume = {59},
  pages = {1017--1022},
  doi = {10.1016/j.jclinepi.2005.12.016},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2005.12.016},
  citeulike-article-id = {13265490},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2005.12.016},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {graphics,principles-of-graphical-construction,teaching-mds}
}

@article{pul07sem,
  title = {Semi-Parametric Regression Models for Cost-Effectiveness Analysis: {{Improving}} the Efficiency of Estimation from Censored Data},
  author = {Pullenayegum, Eleanor M. and Willan, Andrew R.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3274--3299},
  citeulike-article-id = {13265607},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {analysis-of-cost,censored-cost-data,cost-effectiveness,covariate-adjustment,inverse-probability-weighting,semi-parametric-models}
}

@article{put05lon,
  title = {Long-Term Survival with Non-Proportional Hazards: Results from the {{Dutch Gastric Cancer Trial}}},
  author = {Putter, H. and Sasako, M. and Hartgrink, H. H. and van de Velde, C. J. H. and van Houwelingen, J. C.},
  options = {useprefix=true},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2807--2821},
  citeulike-article-id = {13265441},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {estimating-baseline-hazard-with-time-dependent-covariates,long-term-survival,non-ph,non-proportional-hazards,tdc,what-to-do-when-ph-fails}
}

@article{put07tut,
  title = {Tutorial in Biostatistics: {{Competing}} Risks and Multi-State Models},
  author = {Putter, H. and Fiocco, M. and Geskus, R. B.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {2389--2430},
  citeulike-article-id = {13265577},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {cmprsk-r-package,competing-risks,excellent-tutorial,multi-state-model,prediction,prognostic-factors,s-code,survival-analysis}
}

@article{put15var,
  title = {On the Variety of Methods for Calculating Confidence Intervals by Bootstrapping},
  author = {Puth, Marie-Therese and Neuhäuser, Markus and Ruxton, Graeme D.},
  date = {2015-06},
  journaltitle = {J Anim Ecol},
  pages = {n/a},
  doi = {10.1111/1365-2656.12382},
  url = {http://dx.doi.org/10.1111/1365-2656.12382},
  abstract = {* Researchers often want to place a confidence interval around estimated parameter values calculated from a sample. This is commonly implemented by bootstrapping. There are several different frequently used bootstrapping methods for this purpose. * Here we demonstrate that authors of recent papers frequently do not specify the method they have used and that different methods can produce markedly different confidence intervals for the same sample and parameter estimate. * We encourage authors to be more explicit about the method they use (and number of bootstrap resamples used). * We recommend the bias corrected and accelerated method as giving generally good performance; although researchers should be warned that coverage of bootstrap confidence intervals is characteristically less than the specified nominal level, and confidence interval evaluation by any method can be unreliable for small samples in some situations.},
  citeulike-article-id = {13652378},
  citeulike-attachment-1 = {put15var.pdf; /pdf/user/harrelfe/article/13652378/1022869/put15var.pdf; 8ae39fc05abc2948b1830ef71c73190ad342142d},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/1365-2656.12382},
  day = {1},
  posted-at = {2015-06-20 19:39:26},
  priority = {5},
  keywords = {bootstrap,confidence-intervals}
}

@article{put90,
  title = {Optimal Choice of Prognostic Variables with an Application to Cardiac Monitoring Using {{M-mode}} Echocardiography},
  author = {Puterman ML, Sandor G. G. S.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {273--286},
  citeulike-article-id = {13264713},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {general,predictive-methods}
}

@article{qia00ana,
  title = {Analysis of Messy Longitudinal Data from a Randomized Clinical Trial},
  author = {Qian, W. and Parmar, M. K. B. and Sambrook, R. J. and Fayers, P. M. and Girling, D. J. and Stephens, R. J.},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {2657--2674},
  citeulike-article-id = {13265146},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {analysis-of-summary-measures,categorical-data,multiple-symptoms,possibly-useful-for-analyzing-adverse-events,proportional-odds-model,random-effects-model,repeated-measures,serial-data}
}

@incollection{qia96wei,
  title = {A {{Weibull}} Model for Survival Data: {{Using}} Prediction to Decide When to Stop a Clinical Trial},
  author = {Qian, J. and Stangl, D. K. and George, S. L.},
  date = {1996},
  pages = {187--215},
  publisher = {{Marcel Dekker}},
  location = {{New York}},
  citeulike-article-id = {13264714},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {bayes,bayesian-inference,parametric-survival-model,posterior,rct,sequential,stopping,updating}
}

@article{qin94emp,
  title = {Empirical Likelihood and General Estimating Equations},
  author = {Qin, Jing and Lawless, Jerry},
  date = {1994},
  journaltitle = {Appl Stat},
  volume = {22},
  pages = {300--325},
  citeulike-article-id = {13264715},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {empirical-likelihood,gee,maximum-likelihood}
}

@article{qol97,
  title = {Quality of Life in Comparative Cancer Clinical Trials},
  author = {{Several}},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {275--317},
  citeulike-article-id = {13264716},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {qol,quality-of-life},
  note = {series of papers;see p. 281 for QTIME method which may not have the problem of informative censoring that Q-TWiST has}
}

@article{qol98,
  title = {{{QOL}}},
  author = {{Various}},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {511--796},
  citeulike-article-id = {13264717},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {informative-censoring,missing-data,qol,quality-of-life,serial-data,study-design}
}

@article{qu21def,
  title = {Defining Estimands Using a Mix of Strategies to Handle Intercurrent Events in Clinical Trials},
  author = {Qu, Yongming and Shurzinske, Linda and Sethuraman, Shanthi},
  date = {2021},
  journaltitle = {Pharmaceutical Statistics},
  volume = {20},
  number = {2},
  pages = {314--323},
  issn = {1539-1612},
  doi = {10.1002/pst.2078},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2078},
  urldate = {2021-03-07},
  abstract = {Randomized controlled trials (RCTs) are the gold standard for evaluation of the efficacy and safety of investigational interventions. If every patient in an RCT were to adhere to the randomized treatment, one could simply analyze the complete data to infer the treatment effect. However, intercurrent events (ICEs) including the use of concomitant medication for unsatisfactory efficacy, treatment discontinuation due to adverse events, or lack of efficacy may lead to interventions that deviate from the original treatment assignment. Therefore, defining the appropriate estimand (the appropriate parameter to be estimated) based on the primary objective of the study is critical prior to determining the statistical analysis method and analyzing the data. The International Council for Harmonisation (ICH) E9 (R1), adopted on November 20, 2019, provided five strategies to define the estimand: treatment policy, hypothetical, composite variable, while on treatment, and principal stratum. In this article, we propose an estimand using a mix of strategies in handling ICEs. This estimand is an average of the “null” treatment difference for those with ICEs potentially related to safety and the treatment difference for the other patients if they would complete the assigned treatments. Two examples from clinical trials evaluating antidiabetes treatments are provided to illustrate the estimation of this proposed estimand and to compare it with the estimates for estimands using hypothetical and treatment policy strategies in handling ICEs.},
  langid = {english},
  keywords = {estimand,intercurrent-event,multiple-endpoints,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2078}
}

@article{qu87,
  title = {A Generalized Model of Logistic Regression for Clustered Data},
  author = {Qu, Y. and Williams, G. W. and Beck, G. J. and Goormastic, M.},
  date = {1987},
  journaltitle = {Comm Stat A},
  volume = {16},
  pages = {3447--3476},
  citeulike-article-id = {13264718},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{qua08com,
  title = {Comparisons between {{ITT}} and Treatment Emergent Adverse Event Analysis},
  author = {Quan, Hui and Sun, Qiankun and Zhang, Ji and Shih, Weichung J.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {5356--5376},
  citeulike-article-id = {13265711},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {estimation-bias,fixed-stopping-time-design,fixed-study-duration-design,informative-censoring,off-drug-period,pharmaceutical-safety}
}

@article{qua18how,
  title = {How Well Do Discrete Choice Experiments Predict Health Choices? {{A}} Systematic Review and Meta-Analysis of External Validity},
  shorttitle = {How Well Do Discrete Choice Experiments Predict Health Choices?},
  author = {Quaife, Matthew and Terris-Prestholt, Fern and Di Tanna, Gian Luca and Vickerman, Peter},
  date = {2018-11-01},
  journaltitle = {Eur J Health Econ},
  volume = {19},
  number = {8},
  pages = {1053--1066},
  issn = {1618-7601},
  doi = {10.1007/s10198-018-0954-6},
  url = {https://doi.org/10.1007/s10198-018-0954-6},
  urldate = {2021-08-31},
  abstract = {Discrete choice experiments (DCEs) are economic tools that elicit the stated preferences of respondents. Because of their increasing importance in informing the design of health products and services, it is critical to understand the extent to which DCEs give reliable predictions outside of the experimental context. We systematically reviewed the literature of published DCE studies comparing predictions to choices made in reality; we extracted individual-level data to estimate a bivariate mixed-effects model of pooled sensitivity and specificity. Eight studies met the inclusion criteria, and six of these gave sufficient data for inclusion in a meta-analysis. Pooled sensitivity and specificity estimates were 88\% (95\% CI 81, 92\%) and 34\% (95\% CI 23, 46\%), respectively, and the area under the SROC curve (AUC) was 0.60 (95\% CI 0.55, 0.64). Results indicate that DCEs can produce reasonable predictions of health-related behaviors. There is a great need for future research on the external validity of DCEs, particularly empirical studies assessing predicted and revealed preferences of a representative sample of participants.},
  langid = {english},
  keywords = {discrete-choice-models,outcomes}
}

@article{qua96reg,
  title = {A Regression Survival Model for Testing the Proportional Hazards Assumption},
  author = {Quantin, Catherine and Moreau, Thierry and Asselain, Bernard and Maccaria, Jean and Lellouch, Joseph},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {874--885},
  citeulike-article-id = {13264719},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {harrell-lee-test-of-ph,power-of-tests-of-ph,testing-ph}
}

@book{quantreg,
  title = {Quantreg: {{Quantile Regression}}},
  author = {Koenker, Roger},
  date = {2009},
  url = {http://CRAN.R-project.org/package=quantreg},
  citeulike-article-id = {13265774},
  citeulike-linkout-0 = {http://CRAN.R-project.org/package=quantreg},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  annotation = {R package version 4.38}
}

@book{R,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {R Development Team,},
  date = {2020},
  location = {{Vienna, Austria}},
  url = {http://www.R-project.org},
  citeulike-article-id = {13265477},
  citeulike-linkout-0 = {http://www.R-project.org},
  howpublished = {www.r-project.org},
  isbn = {3-900051-07-0},
  organization = {R Foundation for Statistical Computing},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {group-rms}
}

@article{raa00how,
  title = {How to Select Covariates to Include in the Analysis of a Clinical Trial},
  author = {Raab, Gillian M. and Day, Simon and Sales, Jill},
  date = {2004},
  journaltitle = {Controlled Clin Trials},
  volume = {21},
  pages = {330--342},
  citeulike-article-id = {13265472},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {ancova,covariable-adjustment,rct},
  note = {how correlated with outcome must a variable before adding it helps more than hurts, as a function of sample size;planning;design;variable selection}
}

@article{raa93bay,
  title = {Bayesian Analysis of Binary Data from an Audit of Cervical Smears},
  author = {Raab, Gillian M. and Elton, Robert A.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2179--2189},
  citeulike-article-id = {13264720},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {bayesian,binary-data,shrinkage}
}

@book{rab00mea,
  title = {Measurement {{Errors}} and {{Uncertainties}}, 2nd Ed},
  author = {Rabinovich, S. G.},
  date = {2000},
  publisher = {{Springer-Verlag}},
  citeulike-article-id = {13265522},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{rad08var,
  title = {Variable Inclusion and Shrinkage Algorithms},
  author = {Radchenko, Peter and James, Gareth M.},
  date = {2008},
  journaltitle = {J Am Stat Assoc},
  volume = {103},
  number = {483},
  pages = {1304--1315},
  citeulike-article-id = {13265702},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {dantzig-selector,generalized-linear-model,lasso,variable-selectin},
  note = {solves problem caused by lasso using the same penalty parameter for variable selection and shrinkage which causes lasso to have to keep too many variables in the model to avoid overshrinking the remaining predictors;does not handle scaling issue well}
}

@article{rae16met,
  title = {Methods for Using Clinical Laboratory Test Results as Baseline Confounders in Multi-Site Observational Database Studies When Missing Data Are Expected.},
  author = {Raebel, Marsha A. and Shetterly, Susan and Lu, Christine Y. and Flory, James and Gagne, Joshua J. and Harrell, Frank E. and Haynes, Kevin and Herrinton, Lisa J. and Patorno, Elisabetta and Popovic, Jennifer and Selvan, Mano and Shoaibi, Azadeh and Wang, Xingmei and Roy, Jason},
  date = {2016-07},
  journaltitle = {Pharmacoepi drug safety},
  volume = {25},
  number = {7},
  eprint = {27146273},
  eprinttype = {pmid},
  pages = {798--814},
  issn = {1099-1557},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/27146273},
  abstract = {Our purpose was to quantify missing baseline laboratory results, assess predictors of missingness, and examine performance of missing data methods. Using the Mini-Sentinel Distributed Database from three sites, we selected three exposure-outcome scenarios with laboratory results as baseline confounders. We compared hazard ratios (HRs) or risk differences (RDs) and 95\% confidence intervals (CIs) from models that omitted laboratory results, included only available results (complete cases), and included results after applying missing data methods (multiple imputation [MI] regression, MI predictive mean matching [PMM] indicator). Scenario 1 considered glucose among second-generation antipsychotic users and diabetes. Across sites, glucose was available for 27.7-58.9\%. Results differed between complete case and missing data models (e.g., olanzapine: HR 0.92 [CI 0.73, 1.12] vs 1.02 [0.90, 1.16]). Across-site models employing different MI approaches provided similar HR and CI; site-specific models provided differing estimates. Scenario 2 evaluated creatinine among individuals starting high versus low dose lisinopril and hyperkalemia. Creatinine availability: 44.5-79.0\%. Results differed between complete case and missing data models (e.g., HR 0.84 [CI 0.77, 0.92] vs. 0.88 [0.83, 0.94]). HR and CI were identical across MI methods. Scenario 3 examined international normalized ratio (INR) among warfarin users starting interacting versus noninteracting antimicrobials and bleeding. INR availability: 20.0-92.9\%. Results differed between ignoring INR versus including INR using missing data methods (e.g., RD 0.05 [CI -0.03, 0.13] vs 0.09 [0.00, 0.18]). Indicator and PMM methods gave similar estimates. Multi-site studies must consider site variability in missing data. Different missing data methods performed similarly. Copyright  2016 John Wiley \& Sons, Ltd. Copyright  2016 John Wiley \& Sons, Ltd.},
  citeulike-article-id = {14102479},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/27146273},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=27146273},
  posted-at = {2016-07-26 20:58:10},
  priority = {2},
  keywords = {laboratory-data,missing-data}
}

@article{raf96app,
  title = {Approximate {{Bayes}} Factors and Accounting for Model Uncertainty in Generalised Linear Models},
  author = {Raftery, A. E.},
  date = {1996},
  journaltitle = {Biometrika},
  volume = {83},
  pages = {251--266},
  citeulike-article-id = {13264721},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {aic,bayes-factor,bic,model-selection,variable-selection}
}

@article{rag92dic,
  title = {Dichotomizing Continuous Outcome Variables: {{Dependence}} of the Magnitude of Association and Statistical Power on the Cutpoint},
  author = {Ragland, D. R.},
  date = {1992},
  journaltitle = {Epi},
  volume = {3},
  pages = {434--440},
  doi = {10.1097/00001648-199209000-00009},
  url = {http://dx.doi.org/10.1097/00001648-199209000-00009},
  citeulike-article-id = {13264722},
  citeulike-linkout-0 = {http://dx.doi.org/10.1097/00001648-199209000-00009},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {categorization-of-continuous-variables,cutpoints,teaching-mds},
  annotation = {See letters to editor May 1993 P. 274-, Vol 4 No. 3}
}

@article{rag96mul,
  title = {A Multiple-Imputation Analysis of a Case-Control Study of the Risk of Primary Cardiact Arrest among Pharmacologically Treated Hypertensives},
  author = {Raghunathan, Trivellore E. and Siscovick, David S.},
  date = {1996},
  journaltitle = {Appl Stat},
  volume = {45},
  pages = {335--352},
  citeulike-article-id = {13264723},
  posted-at = {2014-07-14 14:09:40},
  priority = {0},
  keywords = {bayesian-imputation,non-ignorable-missing-data-mechanism}
}

@article{rah19dev,
  title = {Deviation from the {{Proportional Hazards Assumption}} in {{Randomized Phase}} 3 {{Clinical Trials}} in {{Oncology}}: {{Prevalence}}, {{Associated Factors}} and {{Implications}}},
  shorttitle = {Deviation from the {{Proportional Hazards Assumption}} in {{Randomized Phase}} 3 {{Clinical Trials}} in {{Oncology}}},
  author = {Rahman, Rifaquat M. and Fell, Geoffrey and Ventz, Steffen and Arfe, Andrea and Vanderbeek, Alyssa M. and Trippa, Lorenzo and Alexander, Brian Michael},
  date = {2019-01-01},
  journaltitle = {Clin Cancer Res},
  eprint = {31345838},
  eprinttype = {pmid},
  pages = {clincanres.3999.2018},
  issn = {1078-0432, 1557-3265},
  doi = {10.1158/1078-0432.CCR-18-3999},
  url = {http://clincancerres.aacrjournals.org/content/early/2019/07/25/1078-0432.CCR-18-3999},
  urldate = {2019-08-05},
  abstract = {Purpose: Deviations from proportional hazards (DPH), which may be more prevalent in the era of precision medicine and immunotherapy, can lead to under-powered trials or misleading conclusions. We used a meta-analytic approach to estimate DPH across cancer trials, investigate associated factors, and evaluate data-analysis approaches for future trials. Experimental Design: We searched PubMed for phase III trials in breast, lung, prostate, and colorectal cancer published in a pre-selected list of journals between 2014-2016 and extracted individual patient-level data (IPLD) from Kaplan-Meier curves. We re-analyzed IPLD to identify DPH. Potential efficiency gains, when DPHs were present, of alternative statistical methods relative to standard log-rank based analysis were expressed as sample-size requirements for a fixed power level. Results: From 152 trials, we obtained IPLD on 129,401 patients. Among 304 Kaplan-Meier figures, 75 (24.7\%) exhibited evidence of DPH, including 8 of 14 (57\%) KM pairs from immunotherapy trials. Trial type (immunotherapy, odds ratio (OR) 4.29, 95\%CI 1.11-16.6), metastatic patient population (OR 3.18, 95\%CI 1.26-8.05), and non-OS endpoints (OR 3.23, 95\%CI 1.79-5.88) were associated with DPH. In immunotherapy trials, alternative statistical approaches allowed for more efficient clinical trials with fewer patients (up to 74\% reduction) relative to log-rank testing. Conclusions: DPH was found in a notable proportion of time-to-event outcomes in published clinical trials in oncology and was more common for immunotherapy trials and non-OS endpoints. Alternative statistical methods, without proportional hazards assumptions, should be considered in the design and analysis of clinical trials when the likelihood of DPH is high. Purpose: Deviations from proportional hazards (DPH), which may be more prevalent in the era of precision medicine and immunotherapy, can lead to under-powered trials or misleading conclusions. We used a meta-analytic approach to estimate DPH across cancer trials, investigate associated factors, and evaluate data-analysis approaches for future trials. Experimental Design: We searched PubMed for phase III trials in breast, lung, prostate, and colorectal cancer published in a pre-selected list of journals between 2014-2016 and extracted individual patient-level data (IPLD) from Kaplan-Meier curves. We re-analyzed IPLD to identify DPH. Potential efficiency gains, when DPHs were present, of alternative statistical methods relative to standard log-rank based analysis were expressed as sample-size requirements for a fixed power level. Results: From 152 trials, we obtained IPLD on 129,401 patients. Among 304 Kaplan-Meier figures, 75 (24.7\%) exhibited evidence of DPH, including 8 of 14 (57\%) KM pairs from immunotherapy trials. Trial type (immunotherapy, odds ratio (OR) 4.29, 95\%CI 1.11-16.6), metastatic patient population (OR 3.18, 95\%CI 1.26-8.05), and non-OS endpoints (OR 3.23, 95\%CI 1.79-5.88) were associated with DPH. In immunotherapy trials, alternative statistical approaches allowed for more efficient clinical trials with fewer patients (up to 74\% reduction) relative to log-rank testing. Conclusions: DPH was found in a notable proportion of time-to-event outcomes in published clinical trials in oncology and was more common for immunotherapy trials and non-OS endpoints. Alternative statistical methods, without proportional hazards assumptions, should be considered in the design and analysis of clinical trials when the likelihood of DPH is high.},
  langid = {english},
  keywords = {non-ph,non-proportional-hazards}
}

@article{raj10joi,
  title = {Joint Modeling of Missing Data Due to Non-Participation and Death in Longitudinal Aging Studies},
  author = {Rajan, K. B. and Leurgans, S. E.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {2260--2268},
  citeulike-article-id = {13265900},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {interruption-of-longitudinal-data},
  note = {important letter to the editor Stat in Med 30:2663-2665;2011}
}

@article{ram15mod,
  title = {A Model-Informed Rank Test for Right-Censored Data with Intermediate States},
  author = {Ramchandani, Ritesh and Finkelstein, Dianne M. and Schoenfeld, David A.},
  date = {2015-04},
  journaltitle = {Stat Med},
  volume = {34},
  number = {9},
  pages = {1454--1466},
  issn = {02776715},
  doi = {10.1002/sim.6417},
  url = {http://dx.doi.org/10.1002/sim.6417},
  citeulike-article-id = {14214858},
  citeulike-attachment-1 = {ram15mod.pdf; /pdf/user/harrelfe/article/14214858/1092994/ram15mod.pdf; 039b43a4db4289d8e754de32d44ef0ad4632effb},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6417},
  day = {30},
  posted-at = {2016-11-25 19:03:18},
  priority = {0},
  keywords = {multi-state-model,multiple-endpoints,transition-model}
}

@article{ram89bin,
  title = {Binomial Regression with Monotone Splines: {{A}} Psychometric Approach},
  author = {Ramsay JO, Abrahamowicz M.},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {906--915},
  citeulike-article-id = {13264724},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {general,regression}
}

@article{ram89mon,
  title = {Monotone Regression Splines in Action (with Discussion)},
  author = {Jo, Ramsay},
  date = {1989},
  journaltitle = {Stat Sci},
  volume = {3},
  pages = {425--461},
  citeulike-article-id = {13264725},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {general,graphical-methods,regression}
}

@article{ran04rul,
  title = {Rules of Evidence for Cancer Molecular-Marker Discovery and Validation},
  author = {Ransohoff, David F.},
  date = {2004},
  journaltitle = {Nat Rev},
  volume = {4},
  pages = {309--314},
  citeulike-article-id = {13265495},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {biomarker,overfitting},
  note = {need for confidence limits on accuracy;the many definitions of validation according to type of study;validation criteria}
}

@article{ran05bia,
  title = {Bias as a Threat to Validity of Cancer Molecular-Marker Research},
  author = {Ransohoff, David F.},
  date = {2005},
  journaltitle = {Nat Rev},
  volume = {5},
  pages = {142--149},
  citeulike-article-id = {13265496},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {biomarker,study-design},
  note = {"Biases might pose a special challenge for laboratory researchers who are used to biological reasoning and the tightly controlled conditions of experimental research. Such researchers unwittingly become non-experimental observational epidemiologists when they apply molecular assays in studies of diagnosis and prognosis, for which the experimental method is not available and for which biological reasoning might have limited usefulness."}
}

@article{ran06mea,
  title = {Measuring the Therapeutic Efficacy of Coronary Revascularization: {{Implications}} for Future Management},
  author = {Rankin, J. Scott and Harrell, Frank E.},
  date = {2006},
  journaltitle = {J Thorac Cardiovasc Surg},
  volume = {131},
  pages = {944--948},
  citeulike-article-id = {13265549},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  annotation = {editorial}
}

@article{ran07how,
  title = {How to Improve Reliability and Efficiency of Research about Molecular Markers: Roles of Phases, Guidelines, and Study Design (with Discussion)},
  author = {Ransohoff, David F.},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {1205--1228},
  citeulike-article-id = {13265645},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {diagnosis,genomics,molecular-markers,prognosis,proteomics,screening},
  note = {good survey of strong claims found not to be reliable; "Although it is common in science for initial enthusiasm to be tempered, this degree of both initial enthusiasm and subsequent tempering [in discovery-based serum proteomics] seems extreme"; summary of threats to validity; problems caused by researchers trying more than one model or analytic technique; serial hypothesis generation;role of phases and guidelines;excellent bibliography;"Every study, even "early" ones, must be "reliable";quotes Platt 1964 Science article Strong Inference: "productive fields are those where investigators systematically and thoroughly consider 'alternative explanations' for results";we should rely on principles, not rules; problems of convenience samples; need for strong unbiased specimens; study design is the most crucial aspect of molecular marker research}
}

@article{ran98und,
  title = {Understanding Articles Describing Clinical Prediction Tools},
  author = {Randolph, Adrienne G. and Guyatt, Gordon H. and Calvin, James E. and Doig, Gordon and Richardson, W. Scott and {the Evidence Based Medicine in Critical Care Group}},
  date = {1998},
  journaltitle = {Crit Care Med},
  volume = {26},
  pages = {1603--1612},
  citeulike-article-id = {13264726},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {clinical-prediction,prognosis,teaching-mds},
  note = {article fails to grasp problems caused by stepwise variable selection techniques}
}

@book{rao73,
  title = {Linear {{Statistical Inference}} and {{Its Applications}}},
  author = {Rao, C. R.},
  date = {1973},
  edition = {Second},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264727},
  posted-at = {2014-07-14 14:09:41},
  priority = {0}
}

@article{rao88res,
  title = {Resampling Inference with Complex Survey Data},
  author = {Rao, J. N. K. and Wu, C. F. J.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {231--241},
  citeulike-article-id = {13264728},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {bootstrap,cluster-sampling,jackknife,resampling}
}

@article{ray16wha,
  title = {What to {{Do When K-Means Clustering Fails}}: {{A Simple}} yet {{Principled Alternative Algorithm}}},
  author = {Raykov, Yordan P. and Boukouvalas, Alexis and Baig, Fahd and Little, Max A.},
  date = {2016-09},
  journaltitle = {PLOS ONE},
  volume = {11},
  number = {9},
  pages = {e0162259+},
  publisher = {Public Library of Science},
  doi = {10.1371/journal.pone.0162259},
  url = {http://dx.doi.org/10.1371/journal.pone.0162259},
  abstract = {The K-means algorithm is one of the most popular clustering algorithms in current use as it is relatively fast yet simple to understand and deploy in practice. Nevertheless, its use entails certain restrictive assumptions about the data, the negative consequences of which are not always immediately apparent, as we demonstrate. While more flexible algorithms have been developed, their widespread use has been hindered by their computational and technical complexity. Motivated by these considerations, we present a flexible alternative to K-means that relaxes most of the assumptions, whilst remaining almost as fast and simple. This novel algorithm which we call MAP-DP (maximum a-posteriori Dirichlet process mixtures), is statistically rigorous as it is based on nonparametric Bayesian Dirichlet process mixture modeling. This approach allows us to overcome most of the limitations imposed by K-means. The number of clusters K is estimated from the data instead of being fixed a-priori as in K-means. In addition, while K-means is restricted to continuous data, the MAP-DP framework can be applied to many kinds of data, for example, binary, count or ordinal data. Also, it can efficiently separate outliers from the data. This additional flexibility does not incur a significant computational overhead compared to K-means with MAP-DP convergence typically achieved in the order of seconds for many practical problems. Finally, in contrast to K-means, since the algorithm is based on an underlying statistical model, the MAP-DP framework can deal with missing data and enables model testing such as cross validation in a principled way. We demonstrate the simplicity and effectiveness of this algorithm on the health informatics problem of clinical sub-typing in a cluster of diseases known as parkinsonism.},
  citeulike-article-id = {14544164},
  citeulike-attachment-1 = {raykov₁6<sub>w</sub>hat₁131101.pdf; /pdf/user/harrelfe/article/14544164/1131101/raykov₁6<sub>w</sub>hat₁131101.pdf; c7f4f4ca10d3d96ebdeb2cb94699ba4e7681a4ad},
  citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0162259},
  day = {26},
  posted-at = {2018-03-04 14:33:33},
  priority = {2},
  keywords = {clustering}
}

@article{raz90,
  title = {Testing for No Effect When Estimating a Smooth Function by Nonparametric Regression: {{A}} Randomization Approach},
  author = {{Raz}},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {132--138},
  citeulike-article-id = {13264729},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {distribution-free-methods,general,predictive-methods}
}

@article{reb00com,
  title = {Programs for Computing Group Sequential Boudaries Using the {{Lan-DeMets}} Method},
  author = {Reboussin, D. M. and DeMets, D. L. and Kim, K and Lan, K. K. G.},
  date = {2000},
  journaltitle = {Controlled Clin Trials},
  volume = {21},
  pages = {190--207},
  citeulike-article-id = {13265350},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  note = {see also http://www.medsch.wisc.edu/landemets}
}

@article{red19ran,
  title = {Random Effects Models for Estimation of the Probability and Time to Progression of a Continuous Biomarker},
  author = {Reddy, Tarylee and Molenberghs, Geert and Bruckers, Liesbeth and Njagi, Edmund-Njeru and Aerts, Marc and Schurink, Geert Willem},
  date = {2019},
  journaltitle = {Pharmaceutical Statistics},
  volume = {0},
  number = {0},
  issn = {1539-1612},
  doi = {10.1002/pst.1956},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1956},
  urldate = {2019-07-16},
  abstract = {Biomarkers play a key role in the monitoring of disease progression. The time taken for an individual to reach a biomarker exceeding or lower than a meaningful threshold is often of interest. Due to the inherent variability of biomarkers, persistence criteria are sometimes included in the definitions of progression, such that only two consecutive measurements above or below the relevant threshold signal that “true” progression has occurred. In previous work, a novel approach was developed, which allowed estimation of the time to threshold using the parameters from a linear mixed model where the residual variance was assumed to be pure measurement error. In this paper, we extend this methodology so that serial correlation can be accommodated. Assuming that the Markov property holds and applying the chain rule of probabilities, we found that the probability of progression at each timepoint can be expressed simply as the product of conditional probabilities. The methodology is applied to a cohort of HIV positive individuals, where the time to reach a CD4 count threshold is estimated. The second application we present is based on a study on abdominal aortic aneurysms, where the time taken for an individual to reach a diameter exceeding 55 mm is studied. We observed that erroneously ignoring the residual correlation when it is strong may result in substantial overestimation of the time to threshold. The estimated probability of the biomarker reaching a threshold of interest, expected time to threshold, and confidence intervals are presented for selected patients in both applications.},
  langid = {english},
  keywords = {biomarker,longitudinal,random-effects,serial}
}

@article{rei03con,
  title = {Confidence Intervals for the Binomial Parameter: Some New Considerations},
  author = {Reiczigel, Jen˝o},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {611--621},
  citeulike-article-id = {13265313},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {clopper-pearson-exact-interval,one-sample-binomial-confidence-limits,proportion},
  note = {Cloppr-Pearson is conservative because it tries to assign equal coverage probability to each side}
}

@article{rei06tra,
  title = {Translating Clinical Research into Clinical Practice: {{Impact}} of Using Prediction Rules to Make Decisions},
  author = {Reilly, Brendan M. and Evans, Arthur T.},
  date = {2006},
  journaltitle = {Ann Int Med},
  volume = {144},
  pages = {201--209},
  citeulike-article-id = {13265532},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {clinical-prediction-rule,impact,planning-for-modeling},
  note = {impact analysis;example of decision aid being ignored or overruled making MD decisions worse;assumed utilities are constant across subjects by concluding that directives have more impact than predictions;Goldman-Cook clinical prediction rule in AMI}
}

@article{rei07sma,
  title = {Small-Sample Degrees of Freedom for Multi-Component Significance Tests with Multiple Imputation for Missing Data},
  author = {Reiter, J. P.},
  date = {2007-02},
  journaltitle = {Biometrika},
  volume = {94},
  number = {2},
  pages = {502--508},
  publisher = {Oxford University Press},
  issn = {0006-3444},
  doi = {10.1093/biomet/asm028},
  url = {http://dx.doi.org/10.1093/biomet/asm028},
  abstract = {When performing multi-component significance tests with multiply-imputed datasets, analysts can use a Wald-like test statistic and a reference F-distribution. The currently employed degrees of freedom in the denominator of this F-distribution are derived assuming an infinite sample size. For modest complete-data sample sizes, this degrees of freedom can be unrealistic; for example, it may exceed the complete-data degrees of freedom. This paper presents an alternative denominator degrees of freedom that is always less than or equal to the complete-data denominator degrees of freedom, and equals the currently employed denominator degrees of freedom for infinite sample sizes. Its advantages over the currently employed degrees of freedom are illustrated with a simulation.},
  citeulike-article-id = {10655638},
  citeulike-attachment-1 = {rei07sma.pdf; /pdf/user/harrelfe/article/10655638/1097933/rei07sma.pdf; 94ecf6cdf957f1b3ac4bc362ea7e190a90efee50},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biomet/asm028},
  citeulike-linkout-1 = {http://biomet.oxfordjournals.org/content/94/2/502.abstract},
  citeulike-linkout-2 = {http://biomet.oxfordjournals.org/content/94/2/502.full.pdf},
  day = {28},
  posted-at = {2017-01-14 20:25:12},
  priority = {0},
  keywords = {missing-data,multiple-imputation}
}

@article{rei11hop,
  title = {Hop Tests Correlate with {{IKDC}} and {{KOOS}} at Minimum of 2 Years after Primary {{ACL}} Reconstruction},
  author = {Reinke, E. K. and Spindler, K. P. and Lorring, D. and Jones, M. H. and Schmitz, L. and Flanigan, D. C. and An, A. Q. and Quiram, A. R. and Preston, E. and Martin, M. and Schroeder, B. and Parker, R. D. and Kaeding, C. C. and Borzi, L. and Pedroza, A. and Huston, L. J. and Harrell, F. E. and Dunn, W. R.},
  date = {2011-11},
  journaltitle = {Knee Surg Sports Traumatol Arthrosc},
  volume = {19},
  pages = {1806--1816},
  citeulike-article-id = {13265913},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@article{rei12emp,
  title = {Empirical {{Power}} and {{Sample Size Calculations}} for {{Cluster-Randomized}} and {{Cluster-Randomized Crossover Studies}}},
  author = {Reich, Nicholas G. and Myers, Jessica A. and Obeng, Daniel and Milstone, Aaron M. and Perl, Trish M.},
  date = {2012-04},
  journaltitle = {PLOS ONE},
  volume = {7},
  number = {4},
  pages = {e35564+},
  publisher = {Public Library of Science},
  doi = {10.1371/journal.pone.0035564},
  url = {http://dx.doi.org/10.1371/journal.pone.0035564},
  abstract = {In recent years, the number of studies using a cluster-randomized design has grown dramatically. In addition, the cluster-randomized crossover design has been touted as a methodological advance that can increase efficiency of cluster-randomized studies in certain situations. While the cluster-randomized crossover trial has become a popular tool, standards of design, analysis, reporting and implementation have not been established for this emergent design. We address one particular aspect of cluster-randomized and cluster-randomized crossover trial design: estimating statistical power. We present a general framework for estimating power via simulation in cluster-randomized studies with or without one or more crossover periods. We have implemented this framework in the clusterPower software package for R, freely available online from the Comprehensive R Archive Network. Our simulation framework is easy to implement and users may customize the methods used for data analysis. We give four examples of using the software in practice. The clusterPower package could play an important role in the design of future cluster-randomized and cluster-randomized crossover studies. This work is the first to establish a universal method for calculating power for both cluster-randomized and cluster-randomized clinical trials. More research is needed to develop standardized and recommended methodology for cluster-randomized crossover studies.},
  citeulike-article-id = {14333067},
  citeulike-attachment-1 = {rei12emp.pdf; /pdf/user/harrelfe/article/14333067/1106844/rei12emp.pdf; 156bcc1ea90dc3377d39225094dd99e6c20bd30c},
  citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0035564},
  day = {27},
  posted-at = {2017-04-06 22:10:32},
  priority = {2},
  keywords = {cluster-randomization,cluster-randomized-trial,cluster-randomized-trials,crossover,crossover-study,pragmatic-trial}
}

@article{rei91neu,
  title = {Neural Networks as a Tool for Utilizing Laboratory Information: Comparison with Linear Discriminant Analysis and Classification and Regression Trees},
  author = {Reibnegger, G. and Weiss, G. and {Werner-Felmayer} and Judmaier, G. and Wachter, H.},
  date = {1991},
  journaltitle = {PNAS},
  volume = {88},
  pages = {11426--11430},
  citeulike-article-id = {13264730},
  posted-at = {2014-07-14 14:09:41},
  priority = {0}
}

@article{rei97rel,
  title = {The Relationship between Hot-Deck Multiple Imputation and Weighted Likelihood},
  author = {Reilly, Marie and Pepe, Margaret},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {5--19},
  citeulike-article-id = {13264731},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {hot-deck-imputation,mean-score,missing-covariable-values,missing-data,weighted-likelihood},
  note = {comparing finite number of imputation to infinite number;expected value of finite number case given the data equals the infinite number estimate}
}

@article{rem21int,
  title = {Interleukin-6 {{Receptor Antagonists}} in {{Critically Ill Patients}} with {{Covid-19}}},
  author = {REMAP-CAP Investigators},
  date = {2021},
  journaltitle = {New England Journal of Medicine},
  publisher = {{Massachusetts Medical Society}},
  issn = {0028-4793},
  doi = {10.1056/nejmoa2100433},
  url = {https://dx.doi.org/10.1056/nejmoa2100433},
  keywords = {adaptive,adaptive-clinical-trials,bayes,ordinal,reporting,reporting-clinical-trials,teaching-mds}
}

@article{rey92sin,
  title = {Single vs. Double Data Entry in {{CAST}}},
  author = {Reynolds-Haertle, R. A. and McBride, R.},
  date = {1992},
  journaltitle = {Controlled Clin Trials},
  volume = {13},
  pages = {487--494},
  citeulike-article-id = {13265263},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-trials,data-management,double-data-entry,rct},
  note = {Study demonstrated double vs. single data entry in a remote data entry environment decreased error rates from 0.17\% to 0.05\%. The authors also noted the data entry process time increased 37\%, and concluded the increased time was justified to achieve higher accuracy and data entry verification should be employed.}
}

@article{ric21imp,
  title = {Improving Adaptive Seamless Designs through {{Bayesian}} Optimization},
  author = {Richter, Jakob and Friede, Tim and Rahnenführer, Jörg},
  date = {2021},
  journaltitle = {Biometrical Journal},
  volume = {n/a},
  number = {n/a},
  issn = {1521-4036},
  doi = {10.1002/bimj.202000389},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000389},
  urldate = {2022-02-28},
  abstract = {We propose to use Bayesian optimization (BO) to improve the efficiency of the design selection process in clinical trials. BO is a method to optimize expensive black-box functions, by using a regression as a surrogate to guide the search. In clinical trials, planning test procedures and sample sizes is a crucial task. A common goal is to maximize the test power, given a set of treatments, corresponding effect sizes, and a total number of samples. From a wide range of possible designs, we aim to select the best one in a short time to allow quick decisions. The standard approach to simulate the power for each single design can become too time consuming. When the number of possible designs becomes very large, either large computational resources are required or an exhaustive exploration of all possible designs takes too long. Here, we propose to use BO to quickly find a clinical trial design with high power from a large number of candidate designs. We demonstrate the effectiveness of our approach by optimizing the power of adaptive seamless designs for different sets of treatment effect sizes. Comparing BO with an exhaustive evaluation of all candidate designs shows that BO finds competitive designs in a fraction of the time.},
  langid = {english},
  keywords = {adaptive-clinical-trials,adaptive-design,bayes,design,optimal-design,optimality,seamless-designs},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000389}
}

@article{ric88,
  title = {A New Probability Model for Determining Exact {{P-values}} for 2x2 Contingency Tables When Comparing Binomial Proportions},
  author = {Rice, W. R.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {1--22},
  citeulike-article-id = {13264732},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,statistical-computation-algorithms}
}

@article{rik14eff,
  title = {Effects of Time-Invariant Covariates on the Estimation of Longitudinal Trends for Transition Mixed Models},
  author = {Rikhtehgaran, Reyhaneh and Kazemi, Iraj and Verbeke, Geert},
  date = {2014-11},
  journaltitle = {Stat Med},
  volume = {33},
  number = {27},
  pages = {4743--4755},
  doi = {10.1002/sim.6270},
  url = {http://dx.doi.org/10.1002/sim.6270},
  abstract = {In this paper, we investigate the impact of time-invariant covariates when fitting transition mixed models. This is carried out by emphasizing on the role of baseline responses on the estimation process. Transition models are allowed for two cases of exogenous and endogenous baseline responses. We illustrate these concepts in the special case of transition linear mixed models with centered time-varying covariates. Results of our simulation studies show that the omission, or the inclusion, of time-invariant covariates is not important in models with exogenous baseline responses, while it has an essential effect on fitting models with the endogenous baseline responses. It is also emphasized that the effect becomes minor when the endogeneity issue is handled. The practical consequences are illustrated in the analysis of a real data set taken from medical sciences.},
  citeulike-article-id = {13444232},
  citeulike-attachment-1 = {rik14eff.pdf; /pdf/user/harrelfe/article/13444232/995478/rik14eff.pdf; b44208c9930509d2bf611f24f409ad37b8757fe6},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6270},
  day = {30},
  posted-at = {2014-11-24 18:14:26},
  priority = {0},
  keywords = {longitudinal-data,mixed-models,serial-data,transition-model}
}

@article{ril07prog,
  title = {Prognosis Research: Toward Evidence-Based Results and a {{Cochran}} Methods Group},
  author = {Riley, Richard D. and Ridley, Greta and Williams, Katrina and Altman, Douglas G. and Hayden, Jill and de Vet, Henrica C. W.},
  options = {useprefix=true},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {863--866},
  citeulike-article-id = {13265606},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  annotation = {letter to the editor},
  note = {letter to Hathaway article, with rejoinder;many references to prognostic standards}
}

@article{ril19min,
  title = {Minimum Sample Size for Developing a Multivariable Prediction Model: {{Part I}} – {{Continuous}} Outcomes},
  shorttitle = {Minimum Sample Size for Developing a Multivariable Prediction Model},
  author = {Riley, Richard D. and Snell, Kym I. E. and Ensor, Joie and Burke, Danielle L. and Harrell, Frank E. and Moons, Karel G. M. and Collins, Gary S.},
  date = {2019-03-30},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {7},
  pages = {1276--1296},
  issn = {1097-0258},
  doi = {10.1002/sim.7993},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7993},
  urldate = {2019-01-19},
  abstract = {In the medical literature, hundreds of prediction models are being developed to predict health outcomes in individuals. For continuous outcomes, typically a linear regression model is developed to predict an individual's outcome value conditional on values of multiple predictors (covariates). To improve model development and reduce the potential for overfitting, a suitable sample size is required in terms of the number of subjects (n) relative to the number of predictor parameters (p) for potential inclusion. We propose that the minimum value of n should meet the following four key criteria: (i) small optimism in predictor effect estimates as defined by a global shrinkage factor of ≥0.9; (ii) small absolute difference of ≤ 0.05 in the apparent and adjusted R2; (iii) precise estimation (a margin of error ≤ 10\% of the true value) of the model's residual standard deviation; and similarly, (iv) precise estimation of the mean predicted outcome value (model intercept). The criteria require prespecification of the user's chosen p and the model's anticipated R2 as informed by previous studies. The value of n that meets all four criteria provides the minimum sample size required for model development. In an applied example, a new model to predict lung function in African-American women using 25 predictor parameters requires at least 918 subjects to meet all criteria, corresponding to at least 36.7 subjects per predictor parameter. Even larger sample sizes may be needed to additionally ensure precise estimates of key predictor effects, especially when important categorical predictors have low prevalence in certain categories.},
  langid = {english},
  keywords = {rms,sample-size,study-design}
}

@article{ril19mina,
  title = {Minimum Sample Size for Developing a Multivariable Prediction Model: {{PART II}} - Binary and Time-to-Event Outcomes},
  shorttitle = {Minimum Sample Size for Developing a Multivariable Prediction Model},
  author = {Riley, Richard D. and Snell, Kym IE and Ensor, Joie and Burke, Danielle L. and Jr, Frank E. Harrell and Moons, Karel GM and Collins, Gary S.},
  date = {2019-03-30},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {7},
  pages = {1276--1296},
  issn = {1097-0258},
  doi = {10.1002/sim.7992},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7992},
  urldate = {2019-01-19},
  abstract = {When designing a study to develop a new prediction model with binary or time-to-event outcomes, researchers should ensure their sample size is adequate in terms of the number of participants (n) and outcome events (E) relative to the number of predictor parameters (p) considered for inclusion. We propose that the minimum values of n and E (and subsequently the minimum number of events per predictor parameter, EPP) should be calculated to meet the following three criteria: (i) small optimism in predictor effect estimates as defined by a global shrinkage factor of ≥0.9, (ii) small absolute difference of ≤ 0.05 in the model's apparent and adjusted Nagelkerke's R2, and (iii) precise estimation of the overall risk in the population. Criteria (i) and (ii) aim to reduce overfitting conditional on a chosen p, and require prespecification of the model's anticipated Cox-Snell R2, which we show can be obtained from previous studies. The values of n and E that meet all three criteria provides the minimum sample size required for model development. Upon application of our approach, a new diagnostic model for Chagas disease requires an EPP of at least 4.8 and a new prognostic model for recurrent venous thromboembolism requires an EPP of at least 23. This reinforces why rules of thumb (eg, 10 EPP) should be avoided. Researchers might additionally ensure the sample size gives precise estimates of key predictor effects; this is especially important when key categorical predictors have few events in some categories, as this may substantially increase the numbers required.},
  langid = {english},
  keywords = {rms,sample-size,study-design}
}

@article{ril19minb,
  title = {Minimum Sample Size for Developing a Multivariable Prediction Model: {{PART II}} - Binary and Time-to-Event Outcomes},
  shorttitle = {Minimum Sample Size for Developing a Multivariable Prediction Model},
  author = {Riley, Richard D. and Snell, Kym Ie and Ensor, Joie and Burke, Danielle L. and Harrell, Frank E. and Moons, Karel Gm and Collins, Gary S.},
  date = {2019-03-30},
  journaltitle = {Stat Med},
  volume = {38},
  number = {7},
  eprint = {30357870},
  eprinttype = {pmid},
  pages = {1276--1296},
  issn = {1097-0258},
  doi = {10.1002/sim.7992},
  abstract = {When designing a study to develop a new prediction model with binary or time-to-event outcomes, researchers should ensure their sample size is adequate in terms of the number of participants (n) and outcome events (E) relative to the number of predictor parameters (p) considered for inclusion. We propose that the minimum values of n and E (and subsequently the minimum number of events per predictor parameter, EPP) should be calculated to meet the following three criteria: (i) small optimism in predictor effect estimates as defined by a global shrinkage factor of ≥0.9, (ii) small absolute difference of ≤ 0.05 in the model's apparent and adjusted Nagelkerke's R2 , and (iii) precise estimation of the overall risk in the population. Criteria (i) and (ii) aim to reduce overfitting conditional on a chosen p, and require prespecification of the model's anticipated Cox-Snell R2 , which we show can be obtained from previous studies. The values of n and E that meet all three criteria provides the minimum sample size required for model development. Upon application of our approach, a new diagnostic model for Chagas disease requires an EPP of at least 4.8 and a new prognostic model for recurrent venous thromboembolism requires an EPP of at least 23. This reinforces why rules of thumb (eg, 10 EPP) should be avoided. Researchers might additionally ensure the sample size gives precise estimates of key predictor effects; this is especially important when key categorical predictors have few events in some categories, as this may substantially increase the numbers required.},
  langid = {english},
  pmcid = {PMC6519266},
  keywords = {methodology,prediction,sample-size}
}

@article{ril19minc,
  title = {Minimum Sample Size for Developing a Multivariable Prediction Model: {{Part I}}~-~{{Continuous}} Outcomes},
  shorttitle = {Minimum Sample Size for Developing a Multivariable Prediction Model},
  author = {Riley, Richard D. and Snell, Kym I. E. and Ensor, Joie and Burke, Danielle L. and Harrell, Frank E. and Moons, Karel G. M. and Collins, Gary S.},
  date = {2019-03-30},
  journaltitle = {Stat Med},
  volume = {38},
  number = {7},
  eprint = {30347470},
  eprinttype = {pmid},
  pages = {1262--1275},
  issn = {1097-0258},
  doi = {10.1002/sim.7993},
  abstract = {In the medical literature, hundreds of prediction models are being developed to predict health outcomes in individuals. For continuous outcomes, typically a linear regression model is developed to predict an individual's outcome value conditional on values of multiple predictors (covariates). To improve model development and reduce the potential for overfitting, a suitable sample size is required in terms of the number of subjects (n) relative to the number of predictor parameters (p) for potential inclusion. We propose that the minimum value of n should meet the following four key criteria: (i) small optimism in predictor effect estimates as defined by a global shrinkage factor of ≥0.9; (ii) small absolute difference of ≤ 0.05 in the apparent and adjusted R2 ; (iii) precise estimation (a margin of error ≤ 10\% of the true value) of the model's residual standard deviation; and similarly, (iv) precise estimation of the mean predicted outcome value (model intercept). The criteria require prespecification of the user's chosen p and the model's anticipated R2 as informed by previous studies. The value of n that meets all four criteria provides the minimum sample size required for model development. In an applied example, a new model to predict lung function in African-American women using 25 predictor parameters requires at least 918 subjects to meet all criteria, corresponding to at least 36.7 subjects per predictor parameter. Even larger sample sizes may be needed to additionally ensure precise estimates of key predictor effects, especially when important categorical predictors have low prevalence in certain categories.},
  langid = {english},
  keywords = {prediction,sample-size}
}

@article{ril20cal,
  title = {Calculating the Sample Size Required for Developing a Clinical Prediction Model},
  author = {Riley, Richard D. and Ensor, Joie and Snell, Kym I. E. and Harrell, Frank E. and Martin, Glen P. and Reitsma, Johannes B. and Moons, Karel G. M. and Collins, Gary and van Smeden, Maarten},
  date = {2020-03-18},
  journaltitle = {BMJ},
  volume = {368},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.m441},
  url = {https://www.bmj.com/content/368/bmj.m441},
  urldate = {2020-03-19},
  abstract = {{$<$}p{$>$}Clinical prediction models aim to predict outcomes in individuals, to inform diagnosis or prognosis in healthcare. Hundreds of prediction models are published in the medical literature each year, yet many are developed using a dataset that is too small for the total number of participants or outcome events. This leads to inaccurate predictions and consequently incorrect healthcare decisions for some individuals. In this article, the authors provide guidance on how to calculate the sample size required to develop a clinical prediction model.{$<$}/p{$>$}},
  langid = {english},
  keywords = {clinical-prediction,prediction,sample-size}
}

@article{ril20cala,
  title = {Calculating the Sample Size Required for Developing a Clinical Prediction Model},
  author = {Riley, Richard D. and Ensor, Joie and Snell, Kym I. E. and Harrell, Frank E. and Martin, Glen P. and Reitsma, Johannes B. and Moons, Karel G. M. and Collins, Gary and van Smeden, Maarten},
  options = {useprefix=true},
  date = {2020-03-18},
  journaltitle = {BMJ},
  volume = {368},
  eprint = {32188600},
  eprinttype = {pmid},
  pages = {m441},
  issn = {1756-1833},
  doi = {10.1136/bmj.m441},
  langid = {english},
  keywords = {prediction,sample-size}
}

@article{ril20pen,
  title = {Penalisation and Shrinkage Methods Produced Unreliable Clinical Prediction Models Especially When Sample Size Was Small},
  author = {Riley, Richard D. and Snell, Kym I. E. and Martin, Glen P. and Whittle, Rebecca and Archer, Lucinda and Sperrin, Matthew and Collins, Gary S.},
  date = {2020-12-08},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2020.12.005},
  url = {https://www.jclinepi.com/article/S0895-4356(20)31209-9/abstract},
  urldate = {2020-12-08},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objectives{$<$}/h3{$><$}p{$>$}When developing a clinical prediction model, penalisation techniques are recommended to address overfitting, as they shrink predictor effect estimates towards the null and reduce mean-square prediction error in new individuals. However, shrinkage and penalty terms (‘tuning parameters') are estimated with uncertainty from the development dataset. We examined the magnitude of this uncertainty and the subsequent impact on prediction model performance.{$<$}/p{$><$}h3{$>$}Study design and setting{$<$}/h3{$><$}p{$>$}Applied examples and a simulation study of the following methods: uniform shrinkage (estimated via a closed-form solution or bootstrapping), ridge regression, the lasso, and elastic net{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}In a particular model development dataset, penalisation methods can be unreliable because tuning parameters are estimated with large uncertainty. This is of most concern when development datasets have a small effective sample size and the model's Cox-Snell {$<$}mml:math{$><$}mml:mrow{$><$}mml:msup{$><$}mml:mi{$>$}R{$<$}/mml:mi{$><$}mml:mn{$>$}2{$<$}/mml:mn{$><$}/mml:msup{$><$}/mml:mrow{$><$}/mml:math{$>$} is low. The problem can lead to considerable miscalibration of model predictions in new individuals.{$<$}/p{$><$}h3{$>$}Conclusions{$<$}/h3{$><$}p{$>$}Penalisation methods are not a ‘carte blanche'; they do not guarantee a reliable prediction model is developed. They are more unreliable when needed most (i.e. when overfitting may be large). We recommend they are best applied with large effective sample sizes, as identified from recent sample size calculations that aim to minimise the potential for model overfitting and precisely estimate key parameters.{$<$}/p{$>$}},
  langid = {english},
  keywords = {penalization,sample-size,shrinkage}
}

@article{ril21min,
  title = {Minimum Sample Size for External Validation of a Clinical Prediction Model with a Binary Outcome},
  author = {Riley, Richard D. and Debray, Thomas P. A. and Collins, Gary S. and Archer, Lucinda and Ensor, Joie and van Smeden, Maarten and Snell, Kym I. E.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9025},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9025},
  urldate = {2021-05-25},
  abstract = {In prediction model research, external validation is needed to examine an existing model's performance using data independent to that for model development. Current external validation studies often suffer from small sample sizes and consequently imprecise predictive performance estimates. To address this, we propose how to determine the minimum sample size needed for a new external validation study of a prediction model for a binary outcome. Our calculations aim to precisely estimate calibration (Observed/Expected and calibration slope), discrimination (C-statistic), and clinical utility (net benefit). For each measure, we propose closed-form and iterative solutions for calculating the minimum sample size required. These require specifying: (i) target SEs (confidence interval widths) for each estimate of interest, (ii) the anticipated outcome event proportion in the validation population, (iii) the prediction model's anticipated (mis)calibration and variance of linear predictor values in the validation population, and (iv) potential risk thresholds for clinical decision-making. The calculations can also be used to inform whether the sample size of an existing (already collected) dataset is adequate for external validation. We illustrate our proposal for external validation of a prediction model for mechanical heart valve failure with an expected outcome event proportion of 0.018. Calculations suggest at least 9835 participants (177 events) are required to precisely estimate the calibration and discrimination measures, with this number driven by the calibration slope criterion, which we anticipate will often be the case. Also, 6443 participants (116 events) are required to precisely estimate net benefit at a risk threshold of 8\%. Software code is provided.},
  langid = {english},
  keywords = {binary-data,binary-endpoint,external-validation,sample-size,validation},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9025}
}

@article{ril21mina,
  title = {Minimum Sample Size Calculations for External Validation of a Clinical Prediction Model with a Time-to-Event Outcome},
  author = {Riley, Richard D. and Collins, Gary S. and Ensor, Joie and Archer, Lucinda and Booth, Sarah and Mozumder, Sarwar I. and Rutherford, Mark J. and van Smeden, Maarten and Lambert, Paul C. and Snell, Kym I. E.},
  options = {useprefix=true},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9275},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9275},
  urldate = {2021-12-27},
  abstract = {Previous articles in Statistics in Medicine describe how to calculate the sample size required for external validation of prediction models with continuous and binary outcomes. The minimum sample size criteria aim to ensure precise estimation of key measures of a model's predictive performance, including measures of calibration, discrimination, and net benefit. Here, we extend the sample size guidance to prediction models with a time-to-event (survival) outcome, to cover external validation in datasets containing censoring. A simulation-based framework is proposed, which calculates the sample size required to target a particular confidence interval width for the calibration slope measuring the agreement between predicted risks (from the model) and observed risks (derived using pseudo-observations to account for censoring) on the log cumulative hazard scale. Precise estimation of calibration curves, discrimination, and net-benefit can also be checked in this framework. The process requires assumptions about the validation population in terms of the (i) distribution of the model's linear predictor and (ii) event and censoring distributions. Existing information can inform this; in particular, the linear predictor distribution can be approximated using the C-index or Royston's D statistic from the model development article, together with the overall event risk. We demonstrate how the approach can be used to calculate the sample size required to validate a prediction model for recurrent venous thromboembolism. Ideally the sample size should ensure precise calibration across the entire range of predicted risks, but must at least ensure adequate precision in regions important for clinical decision-making. Stata and R code are provided.},
  langid = {english},
  keywords = {external-validation,sample-size,study-design,time-to-event,validation},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9275}
}

@article{ril21not,
  title = {A Note on Estimating the {{Cox-Snell R2}} from a Reported {{C}} Statistic ({{AUROC}}) to Inform Sample Size Calculations for Developing a Prediction Model with a Binary Outcome},
  author = {Riley, Richard D. and Calster, Ben Van and Collins, Gary S.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8806},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8806},
  urldate = {2020-12-08},
  abstract = {In 2019 we published a pair of articles in Statistics in Medicine that describe how to calculate the minimum sample size for developing a multivariable prediction model with a continuous outcome, or with a binary or time-to-event outcome. As for any sample size calculation, the approach requires the user to specify anticipated values for key parameters. In particular, for a prediction model with a binary outcome, the outcome proportion and a conservative estimate for the overall fit of the developed model as measured by the Cox-Snell R2 (proportion of variance explained) must be specified. This proposal raises the question of how to identify a plausible value for R2 in advance of model development. Our articles suggest researchers should identify R2 from closely related models already published in their field. In this letter, we present details on how to derive R2 using the reported C statistic (AUROC) for such existing prediction models with a binary outcome. The C statistic is commonly reported, and so our approach allows researchers to obtain R2 for subsequent sample size calculations for new models. Stata and R code is provided, and a small simulation study.},
  langid = {english},
  keywords = {clinical-prediction,prediction,sample-size},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8806}
}

@article{rin10sta,
  title = {Statistical Models for Heart Rate Correction of the {{QT}} Interval},
  author = {Ring, Arne},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {786--796},
  citeulike-article-id = {13265810},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {clinical-safety,ecg,multilevel-modeling,pharmaceutical-research,qt-prolongation,repeated-measures}
}

@article{rin20rep,
  title = {Reporting {{Bayesian Results}}},
  author = {Rindskopf, David},
  date = {2020-12-30},
  journaltitle = {Eval Rev},
  pages = {0193841X20977619},
  publisher = {{SAGE Publications Inc}},
  issn = {0193-841X},
  doi = {10.1177/0193841X20977619},
  url = {https://doi.org/10.1177/0193841X20977619},
  urldate = {2021-01-05},
  abstract = {Because of the different philosophy of Bayesian statistics, where parameters are random variables and data are considered fixed, the analysis and presentation of results will differ from that of frequentist statistics. Most importantly, the probabilities that a parameter is in certain regions of the parameter space are crucial quantities in Bayesian statistics that are not calculable (or considered important) in the frequentist approach that is the basis of much of traditional statistics. In this article, I discuss the implications of these differences for presentation of the results of Bayesian analyses. In doing so, I present more detailed guidelines than are usually provided and explain the rationale for my suggestions.},
  langid = {english},
  keywords = {bayes,rct,reporting,reporting-clinical-trials,reporting-guidelines,reporting-statistical-results,teaching-mds}
}

@incollection{rip93sta,
  title = {Statistical Aspects of Neural Networks},
  booktitle = {Chaos and {{Networks}} - {{Statistical}} and {{Probabilistic Aspects}}},
  author = {Ripley, Brian D.},
  editor = {Bandorff-Nielsen, O. E. and Cox, D. R. and Jensen, J. L. and Kendall, W. S.},
  date = {1993},
  publisher = {{Chapman and Hall}},
  location = {{New York}},
  citeulike-article-id = {13264733},
  posted-at = {2014-07-14 14:09:41},
  priority = {0}
}

@article{rip95sta,
  title = {Statistical Models for Prevalent Cohort Data},
  author = {Ripley, Brian D. and Solomon, P. J.},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {373--374},
  citeulike-article-id = {13264734},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {left-filtering,left-truncation}
}

@article{ris09int,
  title = {Interaction between the Serotonin Transporter Gene (5-{{HTTLPR}}), Stressful Life Events, and Risk of Depression: {{A}} Meta-Analysis},
  author = {Risch, Neil and Herrell, Richard and Lehner, Thomas and {Others}},
  date = {2009},
  journaltitle = {JAMA},
  volume = {301},
  number = {23},
  pages = {2462--2471},
  citeulike-article-id = {13265848},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  note = {"This meta-analysis yielded no evidence that the serotonin transporter genotype alone or in interaction with stressful life events is associated with an elevated risk of depression ..."; OR for an increase in number of stressful events of one was 1.41, genotype 1.05;see http://www.medscape.com/viewarticle/704520;pushback from Avshalom Caspi of Duke/King's College London}
}

@book{rms,
  title = {Regression {{Modeling Strategies}}, with {{Applications}} to {{Linear Models}}, {{Survival Analysis}} and {{Logistic Regression}}},
  author = {Harrell, Frank E.},
  date = {2001},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13264735},
  posted-at = {2014-07-14 14:09:41},
  priority = {0}
}

@book{rms2,
  title = {Regression {{Modeling Strategies}}, with {{Applications}} to {{Linear Models}}, {{Logistic}} and {{Ordinal Regression}}, and {{Survival Analysis}}},
  author = {Harrell, Frank E.},
  date = {2015},
  edition = {Second edition},
  publisher = {{Springer}},
  location = {{New York}},
  issn = {0172-7397},
  doi = {10.1007/978-3-319-19425-7},
  url = {http://dx.doi.org/10.1007/978-3-319-19425-7},
  citeulike-article-id = {13677366},
  citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-319-19425-7},
  isbn = {978-3-319-19424-0},
  posted-at = {2015-07-19 14:25:00},
  priority = {2},
  keywords = {group-rms}
}

@article{rob00mar,
  title = {Marginal Structural Models and Causal Inference in Epidemiology},
  author = {Robins, James M. and Hernan, Miguel A. and Brumback, Babette},
  date = {2000},
  journaltitle = {Epi},
  volume = {11},
  pages = {550--560},
  citeulike-article-id = {13265199},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {bias-induced-by-controlling-for-a-variable-affected-by-treatment,causal-inference,counterfactuals,marginal-structural-model,repeated-measures,time-dependent-treatment}
}

@article{rob19goo,
  title = {Good {{Plot Symbols}} by {{Default}}},
  author = {Robinson, Heman},
  date = {2019-07-01},
  journaltitle = {Journal of Computational and Graphical Statistics},
  pages = {1--6},
  issn = {1061-8600},
  doi = {10.1080/10618600.2019.1637746},
  url = {https://amstat.tandfonline.com/doi/abs/10.1080/10618600.2019.1637746},
  urldate = {2019-12-16},
  abstract = {Scatterplots require different symbols for different purposes. For presentation, aesthetically pleasing symbols are popular. For analysis, highly discriminable symbols aid pattern detection. This study identifies a default symbol set suitable for both presentation and analysis. This is achieved by using popular symbols with preattentive differences. Supplemental materials for this article are available online.},
  keywords = {graphics},
  note = {plot symbols}
}

@article{rob21eig,
  title = {Eigenvectors from {{Eigenvalues Sparse Principal Component Analysis}}},
  author = {Robert Frost, H.},
  date = {2021-10-01},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {0},
  number = {0},
  pages = {1--16},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1080/10618600.2021.1987254},
  url = {https://doi.org/10.1080/10618600.2021.1987254},
  urldate = {2021-11-20},
  abstract = {We present a novel technique for sparse principal component analysis. This method, named eigenvectors from eigenvalues sparse principal component analysis (EESPCA), is based on the formula for computing squared eigenvector loadings of a Hermitian matrix from the eigenvalues of the full matrix and associated sub-matrices. We explore two versions of the EESPCA method: a version that uses a fixed threshold for inducing sparsity and a version that selects the threshold via cross-validation. Relative to the state-of-the-art sparse PCA methods of Witten et al., Yuan and Zhang, and Tan et al., the fixed threshold EESPCA technique offers an order-of-magnitude improvement in computational speed, does not require estimation of tuning parameters via cross-validation, and can more accurately identify true zero principal component loadings across a range of data matrix sizes and covariance structures. Importantly, the EESPCA method achieves these benefits while maintaining out-of-sample reconstruction error and PC estimation error close to the lowest error generated by all evaluated approaches. EESPCA is a practical and effective technique for sparse PCA with particular relevance to computationally demanding statistical problems such as the analysis of high-dimensional datasets or application of statistical techniques like resampling that involve the repeated calculation of sparse PCs. Supplementary materials for this article are available online.},
  keywords = {data-reduction,pca,principal-component-analysis,sparse-pc,sparse-principal-components,unsupervised-learning},
  annotation = {\_eprint: https://doi.org/10.1080/10618600.2021.1987254},
  note = {R package \href{https://cran.r-project.org/web/packages/EESPCA/index.html}{https://cran.r-project.org/web/packages/EESPCA/index.html}
\par
Excellent simulation setup and measuring quality of result by ability to recover original dataset}
}

@article{rob83pro,
  title = {The Prognosis for Patients with New-Onset Angina Who Have Undergone Cardiac Catheterization},
  author = {Roberts, K. B. and Califf, R. M. and Harrell, F. E. and Lee, K. L. and Pryor, D. B. and Rosati, R. A.},
  date = {1983},
  journaltitle = {Circ},
  volume = {68},
  pages = {970--978},
  citeulike-article-id = {13264736},
  posted-at = {2014-07-14 14:09:41},
  priority = {0}
}

@inproceedings{rob87sas,
  title = {A {{SAS}} Macro for Estimating Missing Values in Multivariate Data},
  booktitle = {Proceedings of the {{Twelfth Annual SAS Users Group International Conference}}},
  author = {Roberts, James S. and Capalbo, Gina M.},
  date = {1987},
  pages = {939--941},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary, NC}},
  citeulike-article-id = {13264737},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {missing-data}
}

@article{rob89con,
  title = {The Control of Confounding by Intermediate Variables},
  author = {Robins, James},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {679--701},
  citeulike-article-id = {13264738},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {confounding,dynamic-propensity-score,propensity-score,time-dependent-treatment}
}

@article{rob91som,
  title = {Some Surprising Results about Covariate Adjustment in Logistic Regression Models},
  author = {Robinson, L. D. and Jewell, N. P.},
  date = {1991},
  journaltitle = {Int Stat Rev},
  volume = {59},
  pages = {227--240},
  citeulike-article-id = {13264739},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {covariable-adjustment,logistic-model,study-design}
}

@article{rob92est,
  title = {Estimation of the Time-Dependent Accelerated Failure Time Model in the Presence of Confounding Factors},
  author = {Robins, James},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {321--334},
  citeulike-article-id = {13264740},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {accelerated-failure-time-model,tdc}
}

@article{rob92esti,
  title = {Estimating Exposure Effects by Modeling the Expectation of Exposure Conditional on Confounders},
  author = {Robins, James M. and Mark, Steven D. and Newey, Whitney K.},
  date = {1992},
  journaltitle = {Biometrics},
  volume = {48},
  pages = {479--495},
  citeulike-article-id = {13264741},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {causality,confounding,continuous-exposure,propensity-score}
}

@article{rob92sem,
  title = {Semiparametric Estimation of an Accelerated Failure Time Model with Time-Dependent Covariates},
  author = {Robins, James and Tsiatis, Anastasios A.},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {311--319},
  citeulike-article-id = {13264742},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {accelerated-failure-time-model,tdc}
}

@article{roc20mea,
  title = {On the {{Measurement}} of {{Subjective Apprehension Risk}}},
  author = {Roche, Sean Patrick and Pickett, Justin T. and Intravia, Jonathan and Thompson, Andrew J.},
  date = {2020-12-16},
  journaltitle = {Criminal Justice Review},
  pages = {0734016820978827},
  publisher = {{SAGE Publications Inc}},
  issn = {0734-0168},
  doi = {10.1177/0734016820978827},
  url = {https://doi.org/10.1177/0734016820978827},
  urldate = {2020-12-16},
  abstract = {Do people think about offending risk in verbal or numerical terms? Does the elicitation method affect reported subjective probabilities? Rational choice models require potential outcomes (e.g., benefits/costs) to be weighted by their probability of occurrence. Indeed, the subjective likelihood of being apprehended is the central construct in criminological deterrence theory—the so-called certainty principle. Yet, extant literature has measured the construct inconsistently and with little attention to potential consequences. Using a series of randomized experiments conducted with nationwide samples of American adults (aged 18 and over), this study examines the degree of correspondence between verbal and numeric measures of apprehension risk, assesses the durability of numeric estimates specifically, and attempts to elicit how respondents naturally think about apprehension risk. The findings suggest that laypeople are somewhat inconsistent in their use of both verbal and numeric descriptors of probability, their numeric estimates of probability are unlikely to be precise or durable, and many seem to prefer thinking of risk in verbal terms (compared to numeric terms). Researchers should consider including both verbal and numeric measures of probability and explore alternative measurement strategies, including anchoring vignettes, which have been valuable in standardizing verbal responses in other disciplines.},
  langid = {english},
  keywords = {probability,risk-communication}
}

@article{roc95sup,
  title = {Supplementing the Intent-to-Treat Analysis: {{Accounting}} for Covariates Observed Postrandomization in Clinical Trials},
  author = {Rochon, James},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {292--300},
  citeulike-article-id = {13264743},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {compound-endpoints,tdc}
}

@article{roc96acc,
  title = {Accounting for Covariates Observed Post Randomization for Discrete and Continuous Repeated Measures Data},
  author = {Rochon, James},
  date = {1996},
  journaltitle = {J Roy Stat Soc B},
  volume = {58},
  pages = {205--219},
  citeulike-article-id = {13264744},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {compliance,gee,longitudinal-data,multiple-endpoints,repeated-measures},
  note = {post-randomization covariables treated as response variables}
}

@article{rod89,
  title = {How to Establish Equivalence between Treatments: {{A}} One-Sided Clinical Trial in Paediatric Oncology},
  author = {Rodary, C. and Com-Nougue, C. and Tournade, M. F.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {593--598},
  doi = {10.1002/sim.4780080508},
  url = {http://dx.doi.org/10.1002/sim.4780080508},
  citeulike-article-id = {13264745},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780080508},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {equivalence,pharmaceutical,rct,teaching-mds}
}

@article{roe91pre,
  title = {Prediction Error and Its Estimation for Subset-Selected Models},
  author = {Roecker, Ellen B.},
  date = {1991},
  journaltitle = {Technometrics},
  volume = {33},
  pages = {459--468},
  citeulike-article-id = {13264746},
  posted-at = {2014-07-14 14:09:41},
  priority = {0}
}

@article{rog93reg,
  title = {Regression Standard Errors in Clustered Samples},
  author = {Rogers, William H.},
  date = {1993-05},
  journaltitle = {Stata Tech Bull},
  volume = {STB-13},
  pages = {19--23},
  url = {http://www.stata.com/products/stb/journals/stb13.pdf},
  citeulike-article-id = {13264747},
  citeulike-linkout-0 = {http://www.stata.com/products/stb/journals/stb13.pdf},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {cluster-sampling,dependent-observations,maximum-likelihood},
  annotation = {http://www.stata.com/products/stb/journals/stb13.pdf}
}

@article{roi19new,
  title = {A New Approach for Sizing Trials with Composite Binary Endpoints Using Anticipated Marginal Values and Accounting for the Correlation between Components},
  author = {Roig, Marta Bofill and Melis, Guadalupe Gómez},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {11},
  pages = {1935--1956},
  issn = {1097-0258},
  doi = {10.1002/sim.8092},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8092},
  urldate = {2019-04-06},
  abstract = {Composite binary endpoints are increasingly used as primary endpoints in clinical trials. When designing a trial, it is crucial to determine the appropriate sample size for testing the statistical differences between treatment groups for the primary endpoint. As shown in this work, when using a composite binary endpoint to size a trial, one needs to specify the event rates and the effect sizes of the composite components as well as the correlation between them. In practice, the marginal parameters of the components can be obtained from previous studies or pilot trials; however, the correlation is often not previously reported and thus usually unknown. We first show that the sample size for composite binary endpoints is strongly dependent on the correlation and, second, that slight deviations in the prior information on the marginal parameters may result in underpowered trials for achieving the study objectives at a pre-specified significance level. We propose a general strategy for calculating the required sample size when the correlation is not specified and accounting for uncertainty in the marginal parameter values. We present the web platform CompARE to characterize composite endpoints and to calculate the sample size just as we propose in this paper. We evaluate the performance of the proposal with a simulation study and illustrate it by means of a real case study using CompARE.},
  langid = {english},
  keywords = {binary-endpoint,composite-endpoint,multiple-endpoints,study-design}
}

@article{roi19newa,
  title = {A New Approach for Sizing Trials with Composite Binary Endpoints Using Anticipated Marginal Values and Accounting for the Correlation between Components},
  author = {Roig, Marta Bofill and Melis, Guadalupe Gómez},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8092},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8092},
  urldate = {2019-01-17},
  abstract = {Composite binary endpoints are increasingly used as primary endpoints in clinical trials. When designing a trial, it is crucial to determine the appropriate sample size for testing the statistical differences between treatment groups for the primary endpoint. As shown in this work, when using a composite binary endpoint to size a trial, one needs to specify the event rates and the effect sizes of the composite components as well as the correlation between them. In practice, the marginal parameters of the components can be obtained from previous studies or pilot trials; however, the correlation is often not previously reported and thus usually unknown. We first show that the sample size for composite binary endpoints is strongly dependent on the correlation and, second, that slight deviations in the prior information on the marginal parameters may result in underpowered trials for achieving the study objectives at a pre-specified significance level. We propose a general strategy for calculating the required sample size when the correlation is not specified and accounting for uncertainty in the marginal parameter values. We present the web platform CompARE to characterize composite endpoints and to calculate the sample size just as we propose in this paper. We evaluate the performance of the proposal with a simulation study and illustrate it by means of a real case study using CompARE.},
  langid = {english},
  keywords = {multiple-endpoints,rct,sample-size}
}

@article{roo89,
  title = {Risk Adjustment in Claims-Based Research: The Search for Efficient Approaches},
  author = {Roos, L. L. and Sharp, S. M. and Cohen, M. M. and Wajda, A.},
  date = {1989},
  journaltitle = {J Clin Epi},
  volume = {42},
  pages = {1193--1206},
  citeulike-article-id = {13264748},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {binary-random-var,bootstrapping,discriminant-analysis,jackknifing,logistic-model}
}

@article{Roriginal,
  title = {R: {{A Language}} for {{Data Analysis}} and {{Graphics}}},
  author = {Ihaka, Ross and Gentleman, Robert},
  date = {1996},
  journaltitle = {J Comp Graph Stat},
  volume = {5},
  pages = {299--314},
  url = {http://www.r-project.org},
  citeulike-article-id = {13265183},
  citeulike-linkout-0 = {http://www.r-project.org},
  posted-at = {2014-07-14 14:09:51},
  priority = {0}
}

@article{ros06dif,
  title = {Differential Effects and Generic Biases in Observational Studies},
  author = {Rosenbaum, Paul R.},
  date = {2006},
  journaltitle = {Biometrika},
  volume = {93},
  pages = {573--586},
  citeulike-article-id = {13265545},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {differential-effects,differential-observed-bias,double-pairs-design,generic-unobserved-bias,observational-study,seat-belts,sensitivity-analysis,traffic-safety}
}

@article{ros06per,
  title = {Perceived Increase in Mortality after Process and Policy Changes Implemented with Computerized Physician Order Entry},
  author = {Rosenbloom, S. T. and Harrell, F. E. and Lehmann, C. U. and Schneider, J. H. and Spooner, S. A. and Johnson, K. B.},
  date = {2006},
  journaltitle = {Pediatrics},
  volume = {117},
  pages = {1452--1455},
  citeulike-article-id = {13265548},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  annotation = {letter to the editor}
}

@article{ros08han,
  title = {Handling Covariates in the Design of Clinical Trials},
  author = {Rosenberger, William F. and Sverdlov, Oleksandr},
  date = {2008},
  journaltitle = {Stat Sci},
  volume = {23},
  number = {3},
  pages = {404--419},
  doi = {10.1214/08-STS269},
  url = {http://dx.doi.org/10.1214/08-STS269},
  citeulike-article-id = {13265796},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/08-STS269},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {ancova,balance,baseline,covariable-adjustment,covariate-adaptive-randomization,covariate-adjusted-response-adaptive-randomization,covariate-adjustment,efficiency,ethics,rct},
  note = {nice summary of controversies surrounding need for randomization, balance, or covariate-adaptive randomization;quote from Senn about whether achieving balance is good if it requires discarding data;binary endpoint trial designed by minimizing total number of events;over-emphasis on randomization test;failed to question the use of statistical comparisons for deciding which covariates to adjust for;nice review of covariate-adaptive randomization, e.g., minimization}
}

@article{ros11imp,
  title = {The Impact of Randomization on the Analysis of Clinical Trials},
  author = {Rosenkranz, Gerd K.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  number = {30},
  pages = {3475--3487},
  doi = {10.1002/sim.4376},
  url = {http://dx.doi.org/10.1002/sim.4376},
  abstract = {The design of a comparative clinical trial involves a method of allocating treatments to patients. Usually, this assignment is performed to achieve several objectives: to minimize selection and accidental bias, to achieve balanced treatment assignment in order to maximize the power of the comparison, and most importantly, to obtain the basis for a valid statistical inference. In this paper, we are concerned exclusively with the last point. In our investigation, we will assume that measurements can be decomposed in a patient-specific effect, a treatment effect, and a measurement error. If the patient can be considered to be randomly drawn from a population, the randomization method does not affect the analysis. In fact, under this so-called population model, randomization would be unnecessary to obtain a valid inference. However, when individuals cannot be considered randomly selected, the patient effects may become fixed but unknown constants. In this case, randomization is necessary to obtain valid statistical analyses, and it cannot be precluded that the randomization method has an impact on the results. This paper elaborates that the impact can be substantial even for a two-sample comparison when a standard t-test is used for data analysis. We provide some theoretical results as well as simulations.},
  citeulike-article-id = {13265916},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4376},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {dynamic-randomization,forced-allocation,nonrandom-sample,randomization,rct}
}

@article{ros82pro,
  title = {Problems and Advantages of an Observational Data Base Approach to Evaluating the Effect of Therapy on Outcome},
  author = {Rosati, R. A. and Lee, K. L. and Califf, R. M. and Pryor, D. B. and Harrell, F. E.},
  date = {1982},
  journaltitle = {Circ},
  volume = {65:II},
  pages = {27--32},
  citeulike-article-id = {13264749},
  posted-at = {2014-07-14 14:09:41},
  priority = {0}
}

@article{ros83ass,
  title = {Assessing Sensitivity to an Unobserved Binary Covariate in an Observational Study with Binary Outcome},
  author = {Rosenbaum, Paul R. and Rubin, Donald B.},
  date = {1983},
  journaltitle = {J Roy Stat Soc B},
  volume = {45},
  pages = {212--218},
  citeulike-article-id = {13264750},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {cabg,confounding,duke-data,propensity-score,sensitivity-analysis,treatment-by-indication}
}

@article{ros83cen,
  title = {The Central Role of the Propensity Score in Observational Studies for Causal Effects},
  author = {Rosenbaum, P. R. and Rubin, D.},
  date = {1983},
  journaltitle = {Biometrika},
  volume = {70},
  pages = {41--55},
  citeulike-article-id = {13264751},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {propensity-score}
}

@article{ros83ens,
  title = {Ensemble Adjusted p Values},
  author = {Rosenthal, Robert and Rubin, Donald B.},
  date = {1983},
  journaltitle = {Psych Bull},
  volume = {94},
  pages = {540--541},
  citeulike-article-id = {13264752},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {alpha-spending,multiple-comparisons,prioritization-of-p-values,study-design}
}

@article{ros84,
  title = {Reducing Bias in Observational Studies Using Subclassification on the Propensity Score},
  author = {Rosenbaum, P. R. and Rubin, D. B.},
  date = {1984},
  journaltitle = {J Am Stat Assoc},
  volume = {79},
  pages = {516--524},
  citeulike-article-id = {13264753},
  posted-at = {2014-07-14 14:09:41},
  priority = {0}
}

@article{ros85con,
  title = {Constructing a Control Group Using Multivariate Matched Sampling Methods That Incorporate the Propensity Score},
  author = {Rosenbaum, Paul R. and Rubin, Donald B.},
  date = {1985},
  journaltitle = {Am Statistician},
  volume = {39},
  pages = {33--38},
  citeulike-article-id = {13264754},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {bias,confounding,matching,propensity-score}
}

@article{ros87,
  title = {Sensitivity Analysis for Certain Permutational Inferences in Matched Observational Studies},
  author = {Rosenbaum, P. R.},
  date = {1987},
  journaltitle = {Biometrika},
  volume = {74},
  pages = {13--26},
  citeulike-article-id = {13264755},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {distribution-free-methods,study-design-and-stopping-rules}
}

@article{ros88,
  title = {Significance Testing for Correlated Binary Outcome Data},
  author = {Rosner, B. and Milton, R. C.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {505--512},
  citeulike-article-id = {13264756},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{ros89exp,
  title = {Exploratory Plots for Paired Data},
  author = {Rosenbaum, P. R.},
  date = {1989},
  journaltitle = {Am Statistician},
  volume = {43},
  pages = {108--109},
  citeulike-article-id = {13264757},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {graphical-methods,measurement,research-methods}
}

@article{ros89rol,
  title = {The Role of Known Effects in Observational Studies},
  author = {{Rosenbaum}},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {557--569},
  citeulike-article-id = {13264758},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {measurement,research-methods,study-design-and-stopping-rules}
}

@article{ros92det,
  title = {Detecting Bias with Confidence in Observational Studies},
  author = {Rosenbaum, Paul R.},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {367--374},
  citeulike-article-id = {13264759},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {bias,multiple-endpoints,observational-study,study-design}
}

@article{ros95bay,
  title = {A {{Bayesian}} Group Sequential Design for a Multiple Arm Randomized Clinical Trial},
  author = {Rosner, G. L. and Berry, D. A.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {381--394},
  doi = {10.1002/sim.4780140405},
  url = {http://dx.doi.org/10.1002/sim.4780140405},
  citeulike-article-id = {13264760},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780140405},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {bayesian-inference,clinical-trials,rct,sequential-monitoring,study-design}
}

@article{ros95con,
  title = {Constructing a Bootstrap Confidence Interval for the Unknown Concentration in Radioimmunoassay},
  author = {Rosen, Ori and Cohen, Ayala},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {935--952},
  citeulike-article-id = {13265813},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {calibration,inverse-regression,titration}
}

@article{ros95imp,
  title = {The Importance of Severity of Illness Adjustment in Predicting Adverse Outcomes in the {{Medicare}} Population},
  author = {Rosen, Amy K. and Ash, Arlene S. and McNiff, Kathleen J. and Moskowitz, Mark A.},
  date = {1995},
  journaltitle = {J Clin Epi},
  volume = {48},
  pages = {631--643},
  citeulike-article-id = {13264761},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {case-mix,mortality-models,severity-of-disease,severity-of-illness}
}

@book{ros95obs,
  title = {Observational {{Studies}}},
  author = {Rosenbaum, Paul R.},
  date = {1995},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13264762},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {observational-studies,propensity-score,see-gre96rev}
}

@article{ros96sem,
  title = {A Semiparametric Proportional Odds Regression Model for the Analysis of Current Status Data},
  author = {Rossini, A. J. and Tsiatis, A. A.},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {713--721},
  citeulike-article-id = {13264763},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {current-status-data,discrete-survival-model,interval-censoring}
}

@article{ros97mul,
  title = {Multivariate Methods for Clustered Ordinal Data with Applications to Survival Analysis},
  author = {Rosner, Bernard and Glynn, Robert J.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {357--372},
  citeulike-article-id = {13264764},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {clustered-data,extensions-of-logistic-ordinal-model,multivariate-categorical-data,ordinal-response,survival-analysis}
}

@article{ros99ran,
  title = {Randomized Play-the-Winner Clinical Trials: {{Review}} and Recommendations},
  author = {Rosenberger, William F.},
  date = {1999},
  journaltitle = {Controlled Clin Trials},
  volume = {20},
  pages = {328--342},
  citeulike-article-id = {13264765},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {adaptive-design,ethics-in-clinical-trials,randomization,randomized-play-the-winner,treatment-allocation}
}

@article{ros99use,
  title = {Use of the {{Mann-Whitney U-test}} for Clustered Data},
  author = {Rosner, B. and Grove, D.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1387--1400},
  citeulike-article-id = {13264766},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {clustered-data,simulation-setup,wilcoxon-mann-whitney}
}

@article{rot18pla,
  title = {Planning {{Study Size Based}} on {{Precision Rather}} than {{Power}}.},
  author = {Rothman, Kenneth J. and Greenland, Sander},
  date = {2018-06},
  journaltitle = {Epi},
  eprint = {29912015},
  eprinttype = {pmid},
  issn = {1531-5487},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/29912015},
  abstract = {Study size has typically been planned based on statistical power and therefore has been heavily influenced by the philosophy of statistical hypothesis testing. A worthwhile alternative is to plan study size based on precision, for example, by aiming to obtain a desired width of a confidence interval for the targeted effect. This paper presents formulas for planning the size of an epidemiologic study based on the desired precision of the basic epidemiologic effect measures.},
  citeulike-article-id = {14608454},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/29912015},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=29912015},
  day = {14},
  posted-at = {2018-06-27 13:40:03},
  priority = {2},
  keywords = {epidemiology,precision,study-design}
}

@article{rot78sho,
  title = {A Show of Confidence},
  author = {Rothman, Kenneth J.},
  date = {1978},
  journaltitle = {NEJM},
  volume = {299},
  pages = {1362--3},
  doi = {10.1056/NEJM197812142992410},
  url = {http://dx.doi.org/10.1056/NEJM197812142992410},
  citeulike-article-id = {13264767},
  citeulike-linkout-0 = {http://dx.doi.org/10.1056/NEJM197812142992410},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {confidence-intervals,statistical-significance,teacing-mds},
  annotation = {Editorial}
}

@article{rot86sig,
  title = {Significance Questing},
  author = {Rothman, Kenneth J.},
  date = {1986},
  journaltitle = {Ann Int Med},
  volume = {105},
  pages = {445--447},
  doi = {10.7326/0003-4819-105-3-445},
  url = {http://dx.doi.org/10.7326/0003-4819-105-3-445},
  citeulike-article-id = {13264768},
  citeulike-linkout-0 = {http://dx.doi.org/10.7326/0003-4819-105-3-445},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {statistical-significance,teaching-mds}
}

@article{rot90hyp,
  title = {Hypothesis Testing of Regression Parameters in Semiparametric Generalized Linear Models for Cluster Correlated Data},
  author = {Rotnitzky, Andrea and Jewell, Nicholas P.},
  date = {1990},
  journaltitle = {Biometrika},
  volume = {77},
  pages = {485--497},
  citeulike-article-id = {13264769},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {adjustments-to-wald,clustered-data,lr-tests,score}
}

@article{rot90no,
  title = {No Adjustments Are Needed for Multiple Comparisons},
  author = {Rothman, Kenneth J.},
  date = {1990},
  journaltitle = {Epi},
  volume = {1},
  pages = {43--46},
  citeulike-article-id = {13264770},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  note = {"The theoretical basis for advocating a routine adjustment for multiple comparisons is the `universal null hypothesis' that `chance' serves as the first-order explanation for observed phenomena. This hypothesis undermines the basic premises of empirical research, which holds that nature follows regular laws that may be studied through observations. A policy of not making adjustments for multiple comparisons is preferable because it will lead to fewer errors of interpretation when the data under evaluation are not random numbers but actual observations on nature. Furthermore, scientists should not be so reluctant to explore leads that may turn out to be wrong that they penalize themselves by missing possibly important findings."}
}

@article{rou90,
  title = {The Remedian: {{A}} Robust Averaging Method for Large Data Sets},
  author = {Rousseeuw PJ, Bassett G. W.},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {97--104},
  citeulike-article-id = {13264771},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {order-statistics,quantiles}
}

@article{roy05mis,
  title = {Missing Covariates in Longitudinal Data with Informative Dropouts: {{Bias}} Analysis and {{Inference}}},
  author = {Roy, Jason and Lin, Xihong},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  pages = {837--846},
  citeulike-article-id = {13265440},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {asymptotic-bias,em-algorithm,hers,locf,missing-data,random-effects,sensitivity-analysis,transition-model},
  note = {using only baseline values, assuming ignorable missing are all biased}
}

@article{roy06dic,
  title = {Dichotomizing Continuous Predictors in Multiple Regression: A Bad Idea},
  author = {Royston, Patrick and Altman, Douglas G. and Sauerbrei, Willi},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {127--141},
  doi = {10.1002/sim.2331},
  url = {http://dx.doi.org/10.1002/sim.2331},
  citeulike-article-id = {13265458},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2331},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {categorization,clinical-research,continuous-covariates,cutpoints,dichotomization,efficiency,regression,residual-confounding,teaching-mds},
  note = {destruction of statistical inference when cutpoints are chosen using the response variable; varying effect estimates when change cutpoints;difficult to interpret effects when dichotomize;nice plot showing effect of categorization; PBC data}
}

@article{roy13res,
  title = {Restricted Mean Survival Time: An Alternative to the Hazard Ratio for the Design and Analysis of Randomized Trials with a Time-to-Event Outcome},
  shorttitle = {Restricted Mean Survival Time},
  author = {Royston, Patrick and Parmar, Mahesh KB},
  date = {2013-12-07},
  journaltitle = {BMC Medical Research Methodology},
  volume = {13},
  number = {1},
  pages = {152},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-13-152},
  url = {https://doi.org/10.1186/1471-2288-13-152},
  urldate = {2021-07-27},
  abstract = {Designs and analyses of clinical trials with a time-to-event outcome almost invariably rely on the hazard ratio to estimate the treatment effect and implicitly, therefore, on the proportional hazards assumption. However, the results of some recent trials indicate that there is no guarantee that the assumption will hold. Here, we describe the use of the restricted mean survival time as a possible alternative tool in the design and analysis of these trials.},
  keywords = {non-ph,restricted-mean-life}
}

@article{roy86eff,
  title = {The Effect of Sample Size on the Meaning of Significance Tests},
  author = {Royall, Richard M.},
  date = {1986},
  journaltitle = {Am Statistician},
  volume = {40},
  pages = {313--315},
  citeulike-article-id = {13264772},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  note = {"contradictory interpretations of how the meaning of a significance test depends on the sample size are examined"; equal p-values do not provide equal evidence about a hypothesis; likelihood ratio; If use p{$<$}0.05 as a binary event, evidence is stronger in larger studies; if use actual p-value, evidence is smaller studies is stronger}
}

@article{roy94reg,
  title = {Regression {{Using Fractional Polynomials}} of {{Continuous Covariates}}: {{Parsimonious Parametric Modelling}}},
  author = {Royston, Patrick and Altman, Douglas G.},
  date = {1994},
  journaltitle = {ApplStat},
  volume = {43},
  pages = {429--453},
  citeulike-article-id = {13264773},
  posted-at = {2014-07-14 14:09:41},
  priority = {0},
  keywords = {cox-regression,logistic-regression},
  annotation = {Discussion pp. 453-467}
}

@article{roy95com,
  title = {Comparing Non-Nested Regression Models},
  author = {Royston, Patrick and Thompson, Simon G.},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {114--127},
  citeulike-article-id = {13264774},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {comparing-models,non-nested-models}
}

@book{roy97sta,
  title = {Statistical {{Evidence}}: {{A Likelihood Paradigm}}},
  author = {Royall, R. M.},
  date = {1997},
  publisher = {{Chapman and Hall}},
  location = {{New York}},
  citeulike-article-id = {13265743},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@article{roz60fal,
  title = {The {{Fallacy}} of the {{Null-Hypothesis Significance Test}}},
  author = {Rozeboom, William},
  date = {1960},
  journaltitle = {Psychological Bulletin},
  volume = {57},
  pages = {416},
  issn = {0033-2909},
  langid = {english},
  keywords = {hypothesis-testing,p-value}
}

@book{rpart,
  title = {Rpart: {{Recursive Partitioning}}},
  author = {Therneau, Terry M. and {port by Brian Ripley}},
  date = {2010},
  url = {http://CRAN.R-project.org/package=rpart},
  citeulike-article-id = {13265838},
  citeulike-linkout-0 = {http://CRAN.R-project.org/package=rpart},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  annotation = {R package version 3.1-46}
}

@article{rstan,
  title = {Stan: {{A C}}++ {{Library}} for {{Probability}} and {{Sampling}}},
  author = {Stan Development Team,},
  date = {2020},
  url = {https://cran.r-project.org/package=rstan},
  citeulike-article-id = {14179501},
  citeulike-linkout-0 = {https://cran.r-project.org/package=rstan},
  citeulike-linkout-1 = {http://mc-stan.org},
  posted-at = {2016-11-08 21:03:13},
  priority = {2},
  keywords = {bayesian-inference,bayesian-modeling,statistical-computing}
}

@book{Rsystem,
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  author = {R Development Team,},
  date = {2020},
  location = {{Vienna, Austria}},
  url = {http://www.R-project.org},
  citeulike-article-id = {13265184},
  citeulike-linkout-0 = {http://www.R-project.org},
  organization = {R Foundation for Statistical Computing},
  posted-at = {2014-07-14 14:09:51},
  priority = {0}
}

@article{rub00com,
  title = {Combining Propensity Score Matching with Additional Adjustments for Prognostic Covariates},
  author = {Rubin, Donald B. and Thomas, Neal},
  date = {2000},
  journaltitle = {J Am Stat Assoc},
  volume = {95},
  pages = {573--585},
  citeulike-article-id = {13265133},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {bias-reduction,causal-inference,covariable-adjustment,observational-study,propensity-score}
}

@article{rub05des,
  title = {Design Issues of Randomized Phase {{II}} Trials and a Proposal for Phase {{II}} Screening Trials},
  author = {Rubenstein, Lawrence V. and Korn, Edward L. and Freidlin, Boris and Hunsberger, Sally and Ivy, S. Percy and Smith, Malcolm A.},
  date = {2005},
  journaltitle = {J Clin Oncol},
  volume = {23},
  pages = {7199--7206},
  citeulike-article-id = {13265658},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {oncology-rct,phase-ii-screening-trial}
}

@article{rub07des,
  title = {The Design versus the Analysis of Observational Studies for Causal Effects: {{Parallels}} with the Design of Randomized Studies},
  author = {Rubin, Donald B.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {20--36},
  citeulike-article-id = {13265546},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {assignment-mechanism,blinding-as-much-of-the-analysis-to-outcome-data-as-possible,causal-inference,good-review-article,objective-analysis-of-observational-studies,objective-design,propensity-score,tobacco-litigation}
}

@article{rub08obj,
  title = {For Objective Causal Inference, Design Trumps Analysis},
  author = {Rubin, Donald B.},
  date = {2008},
  journaltitle = {Ann Appl Stat},
  volume = {2},
  number = {3},
  pages = {808--840},
  citeulike-article-id = {13265708},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {average-causal-effect,causal-effects,causal-model,complier-average-causal-effect,instrumental-variable,noncompliance,observational-studies,propensity-scores,randomized-experiments},
  note = {making observational research more rigorous;observational studies as approximations of randomized experiments;design observational studies to approximate randomized trials;make sure key covariates are measured well}
}

@article{rub10lim,
  title = {On the Limitations of Comparative Effectiveness Research},
  author = {Rubin, Donald B.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {1991--1995},
  citeulike-article-id = {13265862},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {cer,comparative-effectiveness-research},
  note = {"... it is better, for eventual progress, to know that we cannot yet reliable answer questions than to pretend that we know the answers based on bogus assumptions and hopelessly inadequate data.";carefully define the causal question;determine covariates used by physicians to select treatments;what data are available and what properties they should possess;if complete and of adequate quality determine if sufficient overlap in covariates between treatment groups}
}

@article{rub20det,
  title = {Détente: {{A Practical Understanding}} of {{P-values}} and {{Bayesian Posterior Probabilities}}},
  shorttitle = {Détente},
  author = {Ruberg, Stephen J.},
  date = {2020},
  journaltitle = {Clinical Pharmacology \& Therapeutics},
  volume = {n/a},
  number = {n/a},
  issn = {1532-6535},
  doi = {10.1002/cpt.2004},
  url = {https://ascpt.onlinelibrary.wiley.com/doi/abs/10.1002/cpt.2004},
  urldate = {2020-08-06},
  abstract = {Null hypothesis significance testing (NHST) with its benchmark p-value{$<$}0.05 has long been a stalwart of scientific reporting and such statistically significant findings have been used to imply scientifically or clinically significant findings. Challenges to this approach have arisen over the past six decades, but they have largely been unheeded. There is a growing movement for using Bayesian statistical inference to quantify the probability that a scientific finding is credible. There have been differences of opinion between the frequentist (i.e. NHST) and Bayesian schools of inference, and warnings about the use or misuse of p-values have come from both schools of thought spanning many decades. Controversies in this arena have been heightened by the American Statistical Association statement on p-values and the further denouncement of the term “statistical significance” by others. My experience has been that many scientists, including many statisticians, do not have a sound conceptual grasp of the fundamental differences in these approaches, thereby creating even greater confusion and acrimony. If we let A represent the observed data, and B represent the hypothesis of interest, then the fundamental distinction between these two approaches can be described as the frequentist approach using the conditional probability pr(A|B), i.e. the p-value, and the Bayesian approach using pr(B|A), the posterior probability. This article will further explain the fundamental differences in NHST and Bayesian approaches and demonstrate how they can co-exist harmoniously to guide clinical trial design and inference.},
  langid = {english},
  keywords = {bayes,p-value,teaching-mds},
  annotation = {\_eprint: https://ascpt.onlinelibrary.wiley.com/doi/pdf/10.1002/cpt.2004}
}

@article{rub81bay,
  title = {The {{Bayesian}} Bootstrap},
  author = {Rubin, Donald B.},
  date = {1981},
  journaltitle = {Appl Stat},
  volume = {9},
  pages = {130--134},
  citeulike-article-id = {13264775},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {bayesian-inference,bootstrap},
  note = {points to Efron showing bootstrap distribution of sample proportions}
}

@book{rub87mul,
  title = {Multiple {{Imputation}} for {{Nonresponse}} in {{Surveys}}},
  author = {Rubin, Donald B.},
  date = {1987},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264776},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {imputatation,missing-data}
}

@article{rub91mul,
  title = {Multiple Imputation in Health-Care Data Bases: {{An}} Overview and Some Applications},
  author = {Rubin, D. and Schenker, N.},
  date = {1991},
  journaltitle = {Stat Med},
  volume = {10},
  pages = {585--598},
  citeulike-article-id = {13264777},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {approximate-bayesian-bootstrap,missing-data,multiple-imputation,outcomes-research}
}

@article{rub96mat,
  title = {Matching Using Estimated Propensity Scores: {{Relating}} Theory to Practice},
  author = {Rubin, Donald B. and Thomas, Neal},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {249--264},
  citeulike-article-id = {13264778},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {confounding,propensity-score}
}

@article{rub97est,
  title = {Estimating Causal Effects from a Large Data Set Using the Propensity Score},
  author = {Rubin, Donald B.},
  date = {1997},
  journaltitle = {Ann Int Med},
  volume = {127},
  pages = {757--763},
  citeulike-article-id = {13264779},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {causal-inference,observational-study,propensity-score,teaching-mds}
}

@article{ruf10use,
  title = {Use of {{Brier}} Score to Assess Binary Predictions (Letter to the Editor)},
  author = {Rufibach, Kaspar},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {938--939},
  citeulike-article-id = {13265827},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {brier-score,calibration-accuracy,proper-scoring-rule,spiegelhalter-z-test},
  note = {for calibration;see spi86;Brier score combines calibration and sharpness (discrimination) and can't be used to rank calibration accuracy of competing models}
}

@article{run20add,
  title = {Adding 3-Month Patient Data Improves Prognostic Models of 12-Month Disability, Pain, and Satisfaction after Specific Lumbar Spine Surgical Procedures: Development and Validation of a Prediction Model},
  shorttitle = {Adding 3-Month Patient Data Improves Prognostic Models of 12-Month Disability, Pain, and Satisfaction after Specific Lumbar Spine Surgical Procedures},
  author = {Rundell, Sean D. and Pennings, Jacquelyn S. and Nian, Hui and Harrell, Frank E. and Khan, Inamullah and Bydon, Mohamad and Asher, Anthony L. and Devin, Clinton J. and Archer, Kristin R.},
  date = {2020-04},
  journaltitle = {Spine J},
  volume = {20},
  number = {4},
  eprint = {31863935},
  eprinttype = {pmid},
  pages = {600--613},
  issn = {1878-1632},
  doi = {10.1016/j.spinee.2019.12.010},
  abstract = {BACKGROUND CONTEXT: Prognostic models including early postoperative variables may provide optimal estimates of long-term outcomes and help direct postoperative care. PURPOSE: To develop and validate prognostic models for 12-month disability, back pain, leg pain, and satisfaction among patients undergoing microdiscectomy, laminectomy, and laminectomy with fusion for degenerative lumbar conditions. STUDY DESIGN/SETTING: Retrospective cohort study using the Quality Outcomes Database. PATIENT SAMPLE: Patients receiving elective lumbar spine surgery due to degenerative spine conditions. OUTCOME MEASURES: Oswestry Disability Index, pain numerical rating scale, and NASS Patient Satisfaction Index. METHODS: Prognostic models were developed using proportional odds ordinal logistic regression using patient characteristics and baseline and 3-month patient-reported outcome scores. Models were fit for each outcome stratified by type of surgical procedure. Adjusted odds ratio and 95\% confidence intervals were reported for all predictors by procedure. Models were internally validated using bootstrap resampling. Discrimination was reported as the c-index and calibration was presented using the calibration slope. We compared the performance of models with and without 3-month patient-reported variables. This research was supported by the Foundation for Physical Therapy's Center of Excellence in Physical Therapy Health Services, and Health Policy Research and Training grant. RESULTS: The sample consisted of 5,840 patients receiving a microdiscectomy (n=2,085), laminectomy (n=1,837), or laminectomy with fusion (n=1,918). The 3-month Oswestry score was the strongest and most consistent predictor associated with 12-month outcomes. All prognostic models performed well with overfitting-corrected c-index values ranging from 0.718 to 0.795 and all optimism corrected calibration slopes over 0.92. The increase in c-index values ranged from 0.09 to 0.21 when adding 3-month patient-reported outcome scores. CONCLUSIONS: Models had good discrimination and were well calibrated for estimating 12-month disability, back pain, leg pain, and satisfaction. Patient-reported outcomes at 3 months after surgery, especially 3-month Oswestry scores, improved the 12-month performance of all prognostic models beyond using only baseline variables.},
  langid = {english},
  keywords = {collaboration}
}

@article{rup95non,
  title = {Nonparametric Estimation of the Transformation in the Transform-Both-Sides Regression Model},
  author = {Wang, Naisyin and Ruppert, David},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {522--534},
  citeulike-article-id = {13264780},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {restriction,transform-both-sides},
  note = {same transformation restriction}
}

@article{rus11gen,
  title = {Generalized Method for Adaptive Randomization in Clinical Trials},
  author = {Russell, D. and Hoare, Z. S. J. and Whitaker, Rh and Whitaker, C. J.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  pages = {922--934},
  citeulike-article-id = {13265874},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {adaptive-randomization,blinding,dynamic-adaptive,randomization,rct,treatment-allocation},
  note = {approaches to computing next allocation probability;appears to be a quite general approach;preserving blinding}
}

@book{rus82tea,
  title = {Teaching of {{Statistics}} and {{Statistical Consulting}}},
  editor = {Rustagi, Jagdish S. and Wolfe, Douglas A.},
  date = {1982},
  publisher = {{Academic Press}},
  location = {{New York}},
  citeulike-article-id = {13265336},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  note = {contains amazing article by Seymour Geisser}
}

@article{rut89,
  title = {A Historical Perspective of Elevated Systolic vs Diastolic Blood Pressure from an Epidemiological and Clinical Trial Viewpoint},
  author = {Rutan GH, Kuller L. H.},
  date = {1989},
  journaltitle = {J Clin Epi},
  volume = {42},
  pages = {663--673},
  doi = {10.1016/0895-4356(89)90010-3},
  url = {http://dx.doi.org/10.1016/0895-4356(89)90010-3},
  citeulike-article-id = {13264781},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0895-4356(89)90010-3},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {blood-pressure,pharmaceutical,rct,study-design-and-stopping-rules}
}

@article{rut94ana,
  title = {Analysis of Longitudinal Data: {{Random}} Coefficient Regression Modelling},
  author = {Rutter, C. M. and Elashoff, R. M.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1211--1231},
  citeulike-article-id = {13265097},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {random-coefficient-model,repeated-measurements,serial-data}
}

@article{rut94sta,
  title = {Statistical Analysis of Cost Outcomes in a Randomized Controlled Clinical Trial},
  author = {Rutten-van Mölken, Maureen P. M. H. and van Doorslaer, Eddy K. A. and Vliet, Renè C. J. A.},
  options = {useprefix=true},
  date = {1994},
  journaltitle = {J Hlth Econ},
  volume = {3},
  pages = {333--345},
  citeulike-article-id = {13264782},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {analysis-of-cost,censoring,cost-effectiveness,transformation}
}

@book{rux17exp,
  title = {Experimental {{Design}} for the {{Life Sciences}}},
  author = {{Ruxton, Graeme D.} and {Colegrave, Nick}},
  date = {2017-10-15},
  edition = {Fourth Edition},
  publisher = {{Oxford University Press}},
  location = {{Oxford, New York}},
  abstract = {The careful design of experiments lies at the core of good research. Experimental Design for the Life Sciences equips you with the skills you need to effectively design experiments, making this essential aspect of the research process readily understandable. It demonstrates how good experimental design relies on clear thinking and biological understanding, not mathematical or statistical complexity. With a refreshingly approachable and articulate style, the book walks you through the considerations that go into designing an experiment in clear, practical terms. Using examples drawn from across the life sciences - from ecology, biochemistry, molecular biology, genetics, and health sciences - the authors illustrate how these concepts are applied within the broad context of real biological research.Online Resource CentreThe Online Resource centre to accompany Experimental Design for the Life Sciences features:For students: DT Self-test questions and answersDT Additional examplesDT Supplementary sections discuss complex concepts and statistical issues in more depthDT Links to useful websites and free softwareFor lecturers:DT Suggested course structures, complete with practical exercisesDT Figures from the book, available to download             Previous publication dates            October 2010, March 2006, February 2003},
  isbn = {978-0-19-871735-5},
  pagetotal = {208},
  keywords = {experimental-design}
}

@article{sac87met,
  title = {Meta-Analyses of Randomized Controlled Trials},
  author = {Sacks, H. S. and Berrier, J. and Reitman, D. and Ancona-Berk, V. A. and Chalmers, T. C.},
  date = {1987},
  journaltitle = {NEJM},
  volume = {316},
  pages = {450--455},
  doi = {10.1056/NEJM198702193160806},
  url = {http://dx.doi.org/10.1056/NEJM198702193160806},
  citeulike-article-id = {13264783},
  citeulike-linkout-0 = {http://dx.doi.org/10.1056/NEJM198702193160806},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {meta-analysis,publication-bias,quality-of-studies,rct,teaching-mds}
}

@article{sac92pri,
  title = {The Rational Clinical Examination: {{A}} Primer on the Precision and Accuracy of the Clinical Examination},
  author = {Sackett, David L.},
  date = {1992},
  journaltitle = {JAMA},
  volume = {267},
  pages = {2638--2644},
  doi = {10.1001/jama.1992.03480190080037},
  url = {http://dx.doi.org/10.1001/jama.1992.03480190080037},
  citeulike-article-id = {13264784},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.1992.03480190080037},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {diagnosis,reporting-of-diagnostic-tests,teaching-mds,testing}
}

@article{sac99pval,
  title = {P Values as Random Variables---{{Expected P}} Values},
  author = {Sackrowitz, Harold and Samuel-Cahn, Ester},
  date = {1999},
  journaltitle = {Am Statistician},
  volume = {53},
  pages = {326--331},
  citeulike-article-id = {13264785},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {expected-p-values,power,random-p-value}
}

@article{sad20thr,
  title = {A Threshold-Free Summary Index for Quantifying the Capacity of Covariates to Yield Efficient Treatment Rules},
  author = {Sadatsafavi, Mohsen and Mansournia, Mohammad Ali and Gustafson, Paul},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8481},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8481},
  urldate = {2020-02-02},
  abstract = {When data on treatment assignment, outcomes, and covariates from a randomized trial are available, a question of interest is to what extent covariates can be used to optimize treatment decisions. Statistical hypothesis testing of covariate-by-treatment interaction is ill-suited for this purpose. The application of decision theory results in treatment rules that compare the expected benefit of treatment given the patient's covariates against a treatment threshold. However, determining treatment threshold is often context-specific, and any given threshold might seem arbitrary when the overall capacity towards predicting treatment benefit is of concern. We propose the Concentration of Benefit index (Cb), a threshold-free metric that quantifies the combined performance of covariates towards finding individuals who will benefit the most from treatment. The construct of the proposed index is comparing expected treatment outcomes with and without knowledge of covariates when one of a two randomly selected patients is to be treated. We show that the resulting index can also be expressed in terms of the integrated efficiency of individualized treatment decision over the entire range of treatment thresholds. We propose parametric and semiparametric estimators, the latter being suitable for out-of-sample validation and correction for optimism. We used data from a clinical trial to demonstrate the calculations in a step-by-step fashion https://github.com/msadatsafavi/txBenefit. The proposed index has intuitive and theoretically sound interpretation and can be estimated with relative ease for a wide class of regression models. Beyond the conceptual developments, various aspects of estimation and inference for such a metric need to be pursued in future research. R code that implements the method for a variety of regression models is provided at (https://github.com/msadatsafavi/txBenefit).},
  langid = {english},
  keywords = {concordance,differential-effects,hte,interaction}
}

@article{sah11som,
  title = {Some Diagnostic Plots and Corrective Adjustments for the Proportional Hazards Regression Model},
  author = {Sahoo, Shyamsundar and Sengupta, Debasis},
  date = {2011},
  journaltitle = {J Comp Graph Stat},
  volume = {20},
  number = {2},
  pages = {375--394},
  citeulike-article-id = {13265888},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {assessing-ph-assumption,assumptions,diagnostics,graphical-methods,ph-model},
  note = {assessing PHeparately from whether the other model assumptions hold}
}

@article{sah96for,
  title = {Formulae and Tables for the Determination of Sample Sizes and Power in Clinical Trials for Testing Differences in Proportions for the Two-Sample Design: {{A}} Review (Corrections, 16:479-480)},
  author = {Sahai, Hardeo and Khurshid, Anwer},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1--21},
  citeulike-article-id = {13264786},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {binary-response,computational,planning,power,sample-size,study-design}
}

@article{sai18pre,
  title = {Predictive Probability of Success Using Surrogate Endpoints},
  author = {Saint‐Hilary, Gaelle and Barboux, Valentine and Pannaux, Matthieu and Gasparini, Mauro and Robert, Veronique and Mastrantonio, Gianluca},
  date = {2018},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8060},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8060},
  urldate = {2018-12-17},
  abstract = {The predictive probability of success of a future clinical trial is a key quantitative tool for decision-making in drug development. It is derived from prior knowledge and available evidence, and the latter typically comes from the accumulated data on the clinical endpoint of interest in previous clinical trials. However, a surrogate endpoint could be used as primary endpoint in early development and, usually, no or limited data are collected on the clinical endpoint of interest. We propose a general, reliable, and broadly applicable methodology to predict the success of a future trial from surrogate endpoints, in a way that makes the best use of all the available evidence. The predictions are based on an informative prior, called surrogate prior, derived from the results of past trials on one or several surrogate endpoints. If available, in a Bayesian framework, this prior could be combined with data from past trials on the clinical endpoint of interest. Two methods are proposed to address a potential discordance between the surrogate prior and the data on the clinical endpoint. We investigate the patterns of behavior of the predictions in a comprehensive simulation study, and we present an application to the development of a drug in Multiple Sclerosis. The proposed methodology is expected to support decision-making in many different situations, since the use of predictive markers is important to accelerate drug developments and to select promising drug candidates, better and earlier.},
  langid = {english},
  keywords = {predictive-distribution,prior,surrogate,surrogate-endpoint}
}

@article{sai19pre,
  title = {Predictive Probability of Success Using Surrogate Endpoints},
  author = {Saint‐Hilary, Gaelle and Barboux, Valentine and Pannaux, Matthieu and Gasparini, Mauro and Robert, Veronique and Mastrantonio, Gianluca},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {10},
  pages = {1753--1774},
  issn = {1097-0258},
  doi = {10.1002/sim.8060},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8060},
  urldate = {2019-04-03},
  abstract = {The predictive probability of success of a future clinical trial is a key quantitative tool for decision-making in drug development. It is derived from prior knowledge and available evidence, and the latter typically comes from the accumulated data on the clinical endpoint of interest in previous clinical trials. However, a surrogate endpoint could be used as primary endpoint in early development and, usually, no or limited data are collected on the clinical endpoint of interest. We propose a general, reliable, and broadly applicable methodology to predict the success of a future trial from surrogate endpoints, in a way that makes the best use of all the available evidence. The predictions are based on an informative prior, called surrogate prior, derived from the results of past trials on one or several surrogate endpoints. If available, in a Bayesian framework, this prior could be combined with data from past trials on the clinical endpoint of interest. Two methods are proposed to address a potential discordance between the surrogate prior and the data on the clinical endpoint. We investigate the patterns of behavior of the predictions in a comprehensive simulation study, and we present an application to the development of a drug in Multiple Sclerosis. The proposed methodology is expected to support decision-making in many different situations, since the use of predictive markers is important to accelerate drug developments and to select promising drug candidates, better and earlier.},
  langid = {english},
  keywords = {bayes,rct,surrogate,surrogate-endpoint,surrogate-endpoint-criteria}
}

@article{sal90,
  title = {Hypothesis versus Significance Testing for Controlled Clinical Trials: {{A}} Dialoge},
  author = {{Salsburg}},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {201--211},
  citeulike-article-id = {13264787},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {miscellaneous,study-design-and-stopping-rules}
}

@article{sam10com,
  title = {Composite Outcomes: Weighting Component Events According to Severity Assisted Interpretation but Reduced Statistical Power},
  author = {Sampson, Uchechukwu K. A. and Metcalf, Chris and Pfeffer, Marc A. and Solomon, Scott D. and Zou, Kelly H.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {1156--1158},
  citeulike-article-id = {13265857},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {binary-outcomes,composite-endpoints,composite-score,disease-burden,power,rct,treatment-effect,weighted-endpoints}
}

@article{sam11qua,
  title = {Quantitative Estimates of Variability of in Vivo Sonographic Measurements of the Mouse Aorta for Studies of Abdominal Aortic Aneurysms and Related Arterial Diseases},
  author = {Sampson, Uchechukwu K. and Perati, Prudhvidhar R. and Prins, Petra A. and Pham, Wellington and Liu, Zhouwen and Harrell, Frank E. and Linton, MacRae F. and Gore, John C. and Kon, Valentina and Fazio, Sergio},
  date = {2011},
  journaltitle = {J Ultrasound Med},
  volume = {30},
  pages = {773--784},
  citeulike-article-id = {13265877},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {aortic-aneurysm,bootstrap,graphics,measurement-error,smooth-bland-altman-plots}
}

@article{sam13not,
  title = {Notes on Two Sample Tests for Partially Correlated (Paired) Data},
  author = {Samawi, Hani M. and Vogel, Robert},
  journaltitle = {J Appl Stat},
  volume = {0},
  number = {0},
  eprint = {http://www.tandfonline.com/doi/pdf/10.1080/02664763.2013.830285},
  pages = {1--9},
  doi = {10.1080/02664763.2013.830285},
  url = {http://www.tandfonline.com/doi/abs/10.1080/02664763.2013.830285},
  abstract = {We provide several methods to compare two Gaussian distributed means in the two sample location problems under the assumption of partially dependent observations. Simulation studies indicate that our test procedure is frequently more powerful than other methods depending on the ratio of the unpaired data and the strength and direction of the correlation between the two variables. The tests used in our comparative study are illustrated with an example based on data from a small gynecological study.},
  citeulike-article-id = {13265982},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/02664763.2013.830285},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/02664763.2013.830285},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{sam14est,
  title = {Estimation of {{Global}} and {{Regional Incidence}} and {{Prevalence}} of {{Abdominal Aortic Aneurysms}} 1990 to 2010},
  author = {Sampson, Uchechukwu K. A. and Norman, Paul E. and {Fowkes} and Aboyans, Victor and Song, Yanna and Harrell, Frank E. and Forouzanfar, Mohammad H. and Naghavi, Mohsen and Denenberg, Julie O. and McDermott, Mary M. and Criqui, Michael H. and Mensah, George A. and Ezzati, Majid and Murray, Christopher},
  date = {2014-03},
  journaltitle = {Global Heart},
  volume = {9},
  number = {1},
  pages = {159--170},
  issn = {22118160},
  doi = {10.1016/j.gheart.2013.12.009},
  url = {http://dx.doi.org/10.1016/j.gheart.2013.12.009},
  abstract = {The global burden of abdominal aortic aneurysm (AAA) has not been studied previously. Such information is important given the emergence of cardiovascular diseases in developing countries. We conducted a systematic literature review and estimated the global and regional incidence and prevalence of AAA in 21 world regions by age and sex. The search for prevalence and incidence of AAA using standard clinical and epidemiological terms was conducted using MEDLINE (1950 to 2010), EMBASE (1980 to 2010), AMED (1985 to 2010), CINAHL (1982 to 2010), and LILACS (2008 to 2010). Data abstracted from the systematic review served as priors for Bayesian meta-regression analyses. The analysis drew from 26 high-quality studies to estimate AAA prevalence and incidence. In 1990, the global age-specific prevalence rate per 100,000 ranged from 8.43 (95\% CI: 7.03 to 10.14) in the 40 to 44 years age group to 2,422.53 (95\% CI: 2,298.63 to 2,562.25) in the 75 to 79 years age group; the corresponding range in 2010 was 7.88 (95\% CI: 6.54 to 9.59) to 2,274.82 (95\% CI: 2,149.77 to 2,410.17). Prevalence was higher in developed versus developing nations, and the rates within each development stratum decreased between 1990 and 2010. Globally, the age-specific annual incidence rate per 100,000 in 1990 ranged from 0.89 (95\% CI: 0.66 to 1.17) in 40 to 44 years age group to 176.08 (95\% CI: 162.72 to 190.28) in the 75 to 79 years age group. In 2010, this range was 0.83 (95\% CI: 0.61 to 1.11) to 164.57 (95\% CI: 152.20 to 178.78). The highest prevalence in 1990 was in Australasia and North America high income regions: 382.65 (95\% CI: 356.27 to 410.88) and 300.59 (95\% CI: 280.93 to 321.54), respectively. Australasia had the highest prevalence in 2010, although the prevalence decreased to 310.27 (95\% CI: 289.01 to 332.94). Regional prevalence increased in Oceania, tropical Latin America, Asia Pacific high income, Southern Sub-Saharan Africa (SSA), Central SSA, South Asia, Western SSA, and Central Asia. AAA global prevalence and incidence rates have decreased over the last 20 years. However, rising rates in some regions highlight the need for policies to enhance global disease surveillance and prevention.},
  citeulike-article-id = {13449217},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.gheart.2013.12.009},
  posted-at = {2014-12-01 12:34:36},
  priority = {2},
  keywords = {collaboration,cv,geography}
}

@article{sam15car,
  title = {Carotid Adventitial Vasa Vasorum and Intima-Media Thickness in a Primary Prevention Population.},
  author = {Sampson, Uchechukwu K. and Harrell, Frank E. and Fazio, Sergio and Nwosu, Sam and Mercaldo, Nate and Mensah, George A. and Davidson, Michael H. and Coll, Blai and Feinstein, Steve B.},
  date = {2015-02},
  journaltitle = {Echocard},
  volume = {32},
  number = {2},
  eprint = {24930883},
  eprinttype = {pmid},
  pages = {264--270},
  issn = {1540-8175},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/24930883},
  abstract = {Vasa vasorum (VV) vessels are critical in the genesis of atherosclerosis. Therefore, we assessed measures of carotid VV, intima-media thickness (CIMT), and patient risk factors in a primary prevention population. We used multivariable linear models to evaluate the relationship between baseline covariates and a measure of carotid VV (VV ratio) and CIMT among 324 diabetics and 141 nondiabetics. Median CIMT (in mm) and VV ratio among nondiabetics were 0.82 ± 0.22 and 0.80 ± 0.19, respectively, and 1.06 ± 0.19 and 1.21 ± 0.26 among diabetics (P {$<$} 0.0001). Diabetes was associated with 36\% (95\% CI: 24.3-48.0, P {$<$} 0.001) higher VV ratio whereas a unit change in BMI was associated with ≈1\% (95\% CI: 0.5-1.4, P {$<$} 0.001) change in VV ratio. A 10-year increase in age was associated with 4\% (95\% CI: 1-7, P = 0.005) higher CIMT. Each 10 mmHg increase in mean systolic blood pressure was associated with 2\% (95\% CI: 1-4, P = 0.003) higher CIMT whereas diabetes conferred 31\% (95\% CI: 19.1-42.1, P {$<$} 0.001) higher CIMT. Female sex was associated with a 9\% (95\% CI: -12.9 to -4.1, P {$<$} 0.001) lower CIMT. Low density lipoprotein (LDL) cholesterol, blood pressure, and CIMT were not significantly associated with VV ratio. In this cohort of patients with low CIMT, VV ratio, and CIMT were distinctly unrelated, but each independently associated with diabetes. VV ratio and CIMT relationships warrant further investigation in large-scale studies and across a spectrum of atherosclerostic states.  2014, Wiley Periodicals, Inc.},
  citeulike-article-id = {14102498},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/24930883},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=24930883},
  posted-at = {2016-07-26 21:28:16},
  priority = {2},
  keywords = {collaboration}
}

@article{san14use,
  title = {Use of Composite Endpoints in Clinical Trials},
  author = {Sankoh, Abdul J. and Li, Haihong and D'Agostino, Ralph B.},
  date = {2014-11},
  journaltitle = {Stat Med},
  volume = {33},
  number = {27},
  pages = {4709--4714},
  doi = {10.1002/sim.6205},
  url = {http://dx.doi.org/10.1002/sim.6205},
  abstract = {The success of a confirmatory clinical trial designed to demonstrate the efficacy of a new treatment is highly dependent on the choice of valid primary efficacy endpoint(s). The optimal clinical and statistical situation for the design of such a trial is one that starts with the selection of a single primary efficacy endpoint that completely characterizes the disease under study, admits the most efficient clinical and statistical evaluation of treatment effect, and provides clear and broad interpretation of drug effect. For diseases with multidimensional presentations, however, the selection of such an endpoint may not be possible, and so drug effectiveness is often characterized by the use of composite or multiple efficacy endpoint(s). The use of a composite endpoint with components that are only slightly correlated but not quite dissimilar in their recognized clinical relevance could lead to a more sensitive statistical test and thus, adequately powered trials with smaller sample size. This note discusses the utility of composite endpoints in clinical trials and some of the common approaches for dealing with multiplicity arising from their use.},
  citeulike-article-id = {13444213},
  citeulike-attachment-1 = {san14use.pdf; /pdf/user/harrelfe/article/13444213/995473/san14use.pdf; 3bb1605202e935977a8acd3e2ad7a7c55037e82a},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6205},
  day = {30},
  posted-at = {2014-11-24 17:28:10},
  priority = {0},
  keywords = {composite-endpoints,multiple-endpoints,multiple-events,multiplicity},
  note = {Very incomplete literature review, especially about O'Brien's multivariate test, MacMahon's test, use of ordinal outcomes, assessing patient utilities, lack of need for multiplicity adjustment in some settings where a strong priority ordering is pre-specified. Does not mention the biggest unmet need: ordinal outcomes incorporating time to events.}
}

@article{san21bes,
  title = {Best Practices in Statistical Computing},
  author = {Sanchez, Ricardo and Griffin, Beth Ann and Pane, Joseph and McCaffrey, Daniel F.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9169},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9169},
  urldate = {2021-09-07},
  abstract = {The world is becoming increasingly complex, both in terms of the rich sources of data we have access to and the statistical and computational methods we can use on data. These factors create an ever-increasing risk for errors in code and the sensitivity of findings to data preparation and the execution of complex statistical and computing methods. The consequences of coding and data mistakes can be substantial. In this paper, we describe the key steps for implementing a code quality assurance (QA) process that researchers can follow to improve their coding practices throughout a project to assure the quality of the final data, code, analyses, and results. These steps include: (i) adherence to principles for code writing and style that follow best practices; (ii) clear written documentation that describes code, workflow, and key analytic decisions; (iii) careful version control; (iv) good data management; and (v) regular testing and review. Following these steps will greatly improve the ability of a study to assure results are accurate and reproducible. The responsibility for code QA falls not only on individual researchers but institutions, journals, and funding agencies as well.},
  langid = {english},
  keywords = {computational,computing,practice-guidelines,statistical-computing},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9169}
}

@article{san98bal,
  title = {Balancing Phase {{II}} and {{III}} Efficacy Trials},
  author = {Sandage, Bobby W.},
  date = {1998},
  journaltitle = {Drug Info J},
  volume = {32},
  pages = {977--980},
  citeulike-article-id = {13264788},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {combining-phase-ii-and-iii-trials}
}

@article{sar01com,
  title = {Comparison of Artificial Neural Networks with Other Statistical Approaches},
  author = {Sargent, Daniel J.},
  date = {2001},
  journaltitle = {Cancer},
  volume = {91},
  pages = {1636--1642},
  citeulike-article-id = {13265208},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {ann,artificial-neural-networks,cox-regression,excellent-discussion-of-publication-bias,excellent-literature-review-of-comparative-studies,funnel-plot,logistic-regression}
}

@article{sar08pra,
  title = {On the Practice of Rescaling Covariates},
  author = {Sardy, Sylvain},
  date = {2008},
  journaltitle = {Int Stat Rev},
  volume = {76},
  pages = {285--297},
  abstract = {Whether doing parametric or nonparametric regression with shrinkage, thresholding, penalized likelihood, Bayesian posterior estimators (e.g., ridge regression, lasso, principal component regression, waveshrink or Markov random field), it is common practice to rescale covariates by dividing by their respective standard errors ρ. The stated goal of this operation is to provide unitless covariates to compare like with like, especially when penalized likelihood or prior distributions are used. We contend that this vision is too simplistic. Instead, we propose to take into account a more essential component of the structure of the regression matrix by rescaling the covariates based on the diagonal elements of the covariance matrix Σ of the maximum-likelihood estimator. We illustrate the differences between the standard ρ and proposed Σ-rescalings with various estimators and data sets.},
  citeulike-article-id = {13265780},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {lasso,lnu-prior,penalization,principal-component-regression,ridge-regression,scaling,standardization,wavelets}
}

@unpublished{sar96hie,
  title = {A Hierarchical Model Method for Subgroup Analysis of Time-to-Event Data in the {{Cox}} Regression Setting},
  author = {Sargent, Daniel J. and Hodges, James S.},
  date = {1996},
  citeulike-article-id = {13264789},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {cox-model,differential-treatment-effect,mmc,shrinkage,shrinkage-of-treatment-by-covariable-interaction,subgroup-analysis},
  annotation = {Presented at the Joint Statistical Meetings, Chicago; see and99tes}
}

@book{sas610,
  title = {{{SAS}}/{{STAT Software}}: {{Changes}} and {{Enhancements}}, {{Release}} 6.10},
  author = {{SAS Institute, Inc.}},
  date = {1994},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary NC}},
  citeulike-article-id = {13264790},
  posted-at = {2014-07-14 14:09:42},
  priority = {0}
}

@article{sas96dot,
  title = {Dotplots},
  author = {Sasieni, Peter D. and Royston, Patrick},
  date = {1996},
  journaltitle = {Appl Stat},
  volume = {45},
  pages = {219--234},
  citeulike-article-id = {13264791},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {dot-charts,graphics}
}

@book{sasstat1,
  title = {{{SAS}}/{{STAT User}}'s {{Guide}}},
  author = {{SAS Institute, Inc.}},
  date = {1990},
  edition = {fourth},
  volume = {1},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary NC}},
  url = {http://support.sas.com/documentation/onlinedoc/stat},
  citeulike-article-id = {13264792},
  citeulike-linkout-0 = {http://support.sas.com/documentation/onlinedoc/stat},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {anova-freq}
}

@book{sasstat2,
  title = {{{SAS}}/{{STAT User}}'s {{Guide}}},
  author = {{SAS Institute, Inc.}},
  date = {1990},
  edition = {fourth},
  volume = {2},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary NC}},
  url = {http://support.sas.com/documentation/onlinedoc/stat},
  citeulike-article-id = {13264793},
  citeulike-linkout-0 = {http://support.sas.com/documentation/onlinedoc/stat},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {glm-varcomp}
}

@article{sat96ran,
  title = {Rank-Based Inference in the Proportional Hazards Model for Interval Censored Data},
  author = {Satten, G. A.},
  date = {1996},
  journaltitle = {Biometrika},
  volume = {83},
  pages = {355--370},
  citeulike-article-id = {13264794},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {cox-model-extensions,interval-censoring}
}

@article{sau07mod,
  title = {Modelling to Extract More Information from Clinical Trials Data: {{On}} Some Roles for the Bootstrap},
  author = {Sauerbrei, Willi and Royston, Patrick},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4989--5001},
  doi = {10.1002/sim.2954},
  url = {http://dx.doi.org/10.1002/sim.2954},
  citeulike-article-id = {13265638},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2954},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {clinical-trials,future-of-bootstrap,interaction,modeling,rct,using-bootstrap-to-adjust-for-post-hoc-nature-of-interaction-tests}
}

@article{sau20sta,
  title = {State of the Art in Selection of Variables and Functional Forms in Multivariable Analysis-Outstanding Issues},
  author = {Sauerbrei, Willi and Perperoglou, Aris and Schmid, Matthias and Abrahamowicz, Michal and Becher, Heiko and Binder, Harald and Dunkler, Daniela and Harrell, Frank E. and Royston, Patrick and Heinze, Georg and {for TG2 of the STRATOS initiative}},
  date = {2020},
  journaltitle = {Diagn Progn Res},
  volume = {4},
  eprint = {32266321},
  eprinttype = {pmid},
  pages = {3},
  issn = {2397-7523},
  doi = {10.1186/s41512-020-00074-3},
  abstract = {Background: How to select variables and identify functional forms for continuous variables is a key concern when creating a multivariable model. Ad hoc 'traditional' approaches to variable selection have been in use for at least 50\,years. Similarly, methods for determining functional forms for continuous variables were first suggested many years ago. More recently, many alternative approaches to address these two challenges have been proposed, but knowledge of their properties and meaningful comparisons between them are scarce. To define a state of the art and to provide evidence-supported guidance to researchers who have only a basic level of statistical knowledge, many outstanding issues in multivariable modelling remain. Our main aims are to identify and illustrate such gaps in the literature and present them at a moderate technical level to the wide community of practitioners, researchers and students of statistics. Methods: We briefly discuss general issues in building descriptive regression models, strategies for variable selection, different ways of choosing functional forms for continuous variables and methods for combining the selection of variables and functions. We discuss two examples, taken from the medical literature, to illustrate problems in the practice of modelling. Results: Our overview revealed that there is not yet enough evidence on which to base recommendations for the selection of variables and functional forms in multivariable analysis. Such evidence may come from comparisons between alternative methods. In particular, we highlight seven important topics that require further investigation and make suggestions for the direction of further research. Conclusions: Selection of variables and of functional forms are important topics in multivariable analysis. To define a state of the art and to provide evidence-supported guidance to researchers who have only a basic level of statistical knowledge, further comparative research is required.},
  langid = {english},
  pmcid = {PMC7114804},
  keywords = {methodology,rms}
}

@article{sau92boo,
  title = {A Bootstrap Resampling Procedure for Model Building: {{Application}} to the {{Cox}} Regression Model},
  author = {Sauerbrei, Willi and Schumacher, Martin},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {2093--2109},
  citeulike-article-id = {13264795},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {bayesian-variable-selection,bootstrap,post-hoc-power,variable-selection}
}

@article{sav21inc,
  title = {On the Inconsistency of Matching without Replacement},
  author = {Sävje, Fredrik},
  date = {2021-06-22},
  journaltitle = {Biometrika},
  issn = {0006-3444},
  doi = {10.1093/biomet/asab035},
  url = {https://doi.org/10.1093/biomet/asab035},
  urldate = {2021-06-23},
  abstract = {The paper shows that matching without replacement on propensity scores produces estimators that generally are inconsistent for the average treatment effect of the treated. To achieve consistency, practitioners must either assume that no units exist with propensity scores greater than one-half or assume that there is no confounding among such units. The result is not driven by the use of propensity scores, and similar artifacts arise when matching on other scores as long as it is without replacement.},
  issue = {asab035},
  keywords = {matching,propensity}
}

@book{Sblue,
  title = {The {{New S Language}}},
  author = {Becker, Richard A. and Chambers, John M. and Wilks, Allan R.},
  date = {1988},
  publisher = {{Wadsworth and Brooks/Cole}},
  location = {{Pacific Grove, CA}},
  citeulike-article-id = {13264796},
  posted-at = {2014-07-14 14:09:42},
  priority = {0}
}

@article{sch00gen,
  title = {General Linear Models for Multicenter Clinical Trials},
  author = {Schwemer, Greg},
  date = {2000},
  journaltitle = {Controlled Clin Trials},
  volume = {21},
  pages = {21--29},
  citeulike-article-id = {13265103},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {interaction,multicenter-rct,pooling,treatment-by-center-interaction,treatment-by-site,type-ii-ss,type-iii-ss}
}

@article{sch00pre,
  title = {Predictive Accuracy and Explained Variation in {{Cox}} Regression},
  author = {Schemper, Michael and Henderson, Robin},
  date = {2000},
  journaltitle = {Biometrics},
  volume = {56},
  pages = {249--255},
  citeulike-article-id = {13265172},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {explained-variation,predictive-accuracy}
}

@article{sch01ana,
  title = {Analysis of Change in the Presence of Informative Censoring: Application to a Longitudinal Clinical Trial of Progressive Renal Disease},
  author = {Schluchter, Mark D. and Greene, Tom and Beck, Gerald J.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {989--1007},
  doi = {10.1002/sim.720},
  url = {http://dx.doi.org/10.1002/sim.720},
  citeulike-article-id = {13265189},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.720},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {change,dropout,informative-censoring,informative-dropout,non-ignorable-non-response,nonrandom-dropout,repeated-measures,serial-data},
  note = {uses em to deal with joint likelihood of serial data and time-to-event}
}

@article{sch01jud,
  title = {On Judging the Significance of Differences by Examining the Overlap between Confidence Intervals},
  author = {Schenker, Nathaniel and Gentleman, Jane F.},
  date = {2001},
  journaltitle = {Am Statistician},
  volume = {55},
  pages = {182--186},
  doi = {10.1198/000313001317097960},
  url = {http://dx.doi.org/10.1198/000313001317097960},
  citeulike-article-id = {13265217},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/000313001317097960},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {confidence-intervals,improper-use,literature-search,teaching-mds}
}

@article{sch02mis,
  title = {Missing Data: {{Our}} View of the State of the Art},
  author = {Schafer, Joseph L. and Graham, John W.},
  date = {2002},
  journaltitle = {Psych Meth},
  volume = {7},
  pages = {147--177},
  citeulike-article-id = {13265300},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {imputation,missing-data},
  note = {excellent review and overview of missing data and imputation;problems with MICE;less technical description of 3 types of missing data}
}

@article{sch03pre,
  title = {Predictive Accuracy and Explained Variation},
  author = {Schemper, Michael},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {2299--2308},
  citeulike-article-id = {13265341},
  citeulike-attachment-1 = {schemper₀3ₚredictive₁134972.pdf; /pdf/user/harrelfe/article/13265341/1134972/schemper₀3ₚredictive₁134972.pdf; d3717805dd4a07ab4225adb0e1ba8449c5975f19},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {absolute-vs-relative-measures,cox-regression,explained-variation,general-linear-model,logistic-regression,ph-model,poisson-regression,prediction-error,predictive-accuracy,r2},
  note = {value of R² with binary response data;measures of average absolute prediction errors with continuous response}
}

@article{sch07bay,
  title = {Bayesian Predictive Power for Interim Adaptions in Seamless Phase {{II}}/{{III}} Trials Where the Endpoint Is Survival up to Some Specified Timepoint},
  author = {Schmidli, Heinz and Bretz, Frank and Racine-Poon, Amy},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4925--4938},
  citeulike-article-id = {13265654},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {bayesian-methods,rct,seamless-phase-ii-iii}
}

@article{sch08ana,
  title = {Analysis of Longitudinal Laboratory Data in the Presence of Common Selection Mechanisms: {{A}} View towards Greater Emphasis on Pre-Marketing Pharmaceutical Safety},
  author = {Schildcrout, Jonathan S. and Jenkins, Cathy A. and Ostroff, Jack H. and Gillen, Daniel L. and Harrell, Frank E. and Trost, Donald C.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {2248--2266},
  citeulike-article-id = {13265675},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {clinical-laboratory-data,dynamic-treatment-effects,longitudinal-data,pathodynamics,pharmaceutical-safety}
}

@article{sch08qua,
  title = {Quantifying the Predictive Performance of Prognostic Models for Censored Survival Data with Time-Dependent Covariates},
  author = {Schoop, R. and Graf, E. and Schumacher, M.},
  date = {2008},
  journaltitle = {Biometrics},
  volume = {64},
  number = {2},
  pages = {603--610},
  citeulike-article-id = {13265672},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {assessing-value-of-updated-prognostic-estimates,failure-time-data,prediction,prediction-error-curves,predictive-accuracy,prognosis,prognostic-accuracy,proper-scoring-rule,tdc}
}

@article{sch09est,
  title = {Estimating the Effect of a Time-Dependent Treatment by Levels of an Internal Time-Dependent Covariate: {{Application}} to the Contrast between Liver Wait-List and Posttransplant Mortality},
  author = {Schaubel, Douglas E. and Wolfe, Robert A. and Merion, Robert M.},
  date = {2009},
  journaltitle = {J Am Stat Assoc},
  volume = {104},
  number = {485},
  pages = {49--59},
  citeulike-article-id = {13265756},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {tdc,transplant},
  note = {"We propose a novel method for estimating the effect of a time-dependent treatment by levels of an internal time-dependent covariate. The method yields parameter estimates which, rather than applying to the patient's current health status, average over future potential changes in health status."}
}

@article{sch12com,
  title = {A Comparison of Estimators to Evaluate the Discriminatory Power of Time-to-Event Models},
  author = {Schmid, Matthias and Potapov, Sergej},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {23},
  pages = {2588--2609},
  doi = {10.1002/sim.5464},
  url = {http://dx.doi.org/10.1002/sim.5464},
  abstract = {Discrimination measures for continuous time-to-event outcomes have become an important tool in medical decision making. The idea behind discrimination measures is to evaluate the performance of a prediction model by measuring its ability to distinguish between observations having an event and those having no event. Researchers proposed a variety of approaches to estimate discrimination measures from a set of right-censored data. These approaches rely on different regularity assumptions that are needed to ensure consistency of the respective estimators. Typical examples of regularity assumptions include the proportional hazards assumption in Cox regression and the random censoring assumption. Because regularity assumptions are often violated in practice, conducting a sensitivity analysis of the estimators is of considerable interest. The aim of the paper is to analyze and to compare the most popular estimators of discrimination measures for event time outcomes. On the basis of the results of an extensive simulation study and the analysis of molecular data, we investigate the behavior of the estimators in situations where the underlying regularity assumptions do not hold. We show that violations of the regularity assumptions may induce a nonignorable bias and may therefore result in biased medical decision making.},
  citeulike-article-id = {13265947},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5464},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {concordance-probability,cox-regression,discrimination-measures,molecular-markers,risk-prediction,survival-analysis}
}

@article{sch13une,
  title = {Unexpected Predictor-Outcome Associations in Clinical Prediction Research: Causes and Solutions},
  author = {Schuit, E. and Groenwold, R. H. and Harrell, F. E. and de Kort, W. L. and Kwee, A. and Mol, B. W. and Riley, R. D. and Moons, K. G.},
  options = {useprefix=true},
  date = {2013-07},
  journaltitle = {Can Med Assoc J},
  pages = {E499-E505},
  doi = {10.1503/cmaj.120812},
  url = {http://dx.doi.org/10.1503/cmaj.120812},
  citeulike-article-id = {13265954},
  citeulike-linkout-0 = {http://dx.doi.org/10.1503/cmaj.120812},
  posted-at = {2014-07-14 14:10:08},
  priority = {0}
}

@article{sch14rob,
  title = {Robust Meta-Analytic-Predictive Priors in Clinical Trials with Historical Control Information},
  author = {Schmidli, Heinz and Gsteiger, Sandro and Roychoudhury, Satrajit and O'Hagan, Anthony and Spiegelhalter, David and Neuenschwander, Beat},
  date = {2014-12},
  journaltitle = {Biometrics},
  volume = {70},
  number = {4},
  pages = {1023--1032},
  issn = {0006341X},
  doi = {10.1111/biom.12242},
  url = {http://dx.doi.org/10.1111/biom.12242},
  citeulike-article-id = {14287913},
  citeulike-attachment-1 = {sch14rob.pdf; /pdf/user/harrelfe/article/14287913/1103337/sch14rob.pdf; 96d13da94bcc08eba74fd3c5ccbc926beba09261},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/biom.12242},
  posted-at = {2017-02-26 23:07:08},
  priority = {3},
  keywords = {bayes,bayesian-inference,choice-of-prior,historical-data}
}

@article{sch15bia,
  title = {Biased Sampling Designs to Improve Research Efficiency: {{Factors}} Influencing Pulmonary Function over Time in Children with Asthma},
  author = {Schildcrout, J. S. and Rathouz, P. J. and Zelnick, L. R. and Garbett, S. P. and Heagerty, P. J.},
  date = {2015},
  journaltitle = {Ann Appl Stat},
  volume = {9},
  number = {2},
  pages = {731--753},
  citeulike-article-id = {14032332},
  posted-at = {2016-05-10 23:09:53},
  priority = {2},
  keywords = {ctsafac}
}

@article{sch16pro,
  title = {A Prognostic Model Based on Readily Available Clinical Data Enriched a Pre-Emptive Pharmacogenetic Testing Program},
  author = {Schildcrout, J. S. and Shi, Y. and Danciu, I. and Bowton, E. and Field, J. R. and Pulley, J. M. and Basford, M. A. and Gregg, W. and Cowan, J. D. and Harrell, F. E. and Roden, D. M. and Peterson, J. F. and Denny, J. C.},
  date = {2016},
  journaltitle = {J Clin Epidemiol},
  volume = {72},
  pages = {107--115},
  citeulike-article-id = {14032325},
  posted-at = {2016-05-10 23:09:00},
  priority = {2},
  keywords = {ctsafac}
}

@article{sch17pro,
  title = {Propensity Score Model Overfitting Led to Inflated Variance of Estimated Odds Ratios},
  author = {Schuster, Tibor and Lowe, Wilfrid K. and Platt, Robert W.},
  date = {2016-09},
  journaltitle = {J Clin Epi},
  issn = {08954356},
  doi = {10.1016/j.jclinepi.2016.05.017},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2016.05.017},
  citeulike-article-id = {14220515},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2016.05.017},
  posted-at = {2016-12-06 02:38:48},
  priority = {2},
  keywords = {epub-replace,overfitting,propensity-score,stratification}
}

@article{sch19gra,
  title = {Graphical {{Depiction}} of {{Longitudinal Study Designs}} in {{Health Care Databases}}},
  author = {Schneeweiss, Sebastian and Rassen, Jeremy A. and Brown, Jeffrey S. and Rothman, Kenneth J. and Happe, Laura and Arlett, Peter and Dal Pan, Gerald and Goettsch, Wim and Murk, William and Wang, Shirley V.},
  date = {2019-03-12},
  journaltitle = {Annals of Internal Medicine},
  issn = {0003-4819},
  doi = {10.7326/M18-3079},
  url = {http://annals.org/article.aspx?doi=10.7326/M18-3079},
  urldate = {2019-03-13},
  langid = {english},
  keywords = {graphical-methods,longitudinal,rct,serial}
}

@article{sch78est,
  title = {Estimating the Dimension of a Model},
  author = {Schwarz, Gideon},
  date = {1978},
  journaltitle = {Ann Stat},
  volume = {6},
  pages = {461--464},
  citeulike-article-id = {13264797},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {accuracy,aic,akaike-information-criterion,bayesian-methods,penalty}
}

@article{sch82,
  title = {Partial Residuals for the Proportional Hazards Regression Model},
  author = {Schoenfeld, D.},
  date = {1982},
  journaltitle = {Biometrika},
  volume = {69},
  pages = {239--241},
  citeulike-article-id = {13264798},
  posted-at = {2014-07-14 14:09:42},
  priority = {0}
}

@article{sch82plo,
  title = {Plots of {{P-values}} to Evaluate Many Tests Simultaneously},
  author = {Schweder, T. and Spjotvoll, E.},
  date = {1982},
  journaltitle = {Biometrika},
  volume = {69},
  pages = {492--502},
  citeulike-article-id = {13264799},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {estimating-number-of-true-null-hypotheses}
}

@article{sch83sam,
  title = {Sample Size Formulae for the Proportional Hazards Regression Model},
  author = {Schoenfeld, David A.},
  date = {1983},
  journaltitle = {Biometrics},
  volume = {39},
  pages = {499--503},
  citeulike-article-id = {13264800},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {cox-model,sample-size,study-design}
}

@article{sch84ana,
  title = {Analyses of Associations with Censored Data by Generalized {{Mantel}} and {{Breslow}} Tests and Generalized {{Kendall}} Correlation},
  author = {Schemper, Michael},
  date = {1984},
  journaltitle = {Biometrical J},
  volume = {26},
  pages = {309--318},
  citeulike-article-id = {13264801},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {censored-data,predictive-accuracy,rank-correlation}
}

@article{sch88non,
  title = {Non-Parametric Analysis of Treatment-Covariate Interaction in the Presence of Censoring},
  author = {Schemper, Michael},
  date = {1988},
  journaltitle = {Stat Med},
  volume = {7},
  pages = {1257--1266},
  citeulike-article-id = {13264802},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {censoring,interaction}
}

@article{sch89,
  title = {A Measure of Similarity for Response Curves Based on Ranks},
  author = {Schulgen, G.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {1401--1411},
  citeulike-article-id = {13264803},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {distribution-free-methods,multivariate-analysis}
}

@article{sch89pre,
  title = {Predicting Criminal Recidivism Using `split Population' Survival Time Models},
  author = {Schmidt, P. and Witte, A. D.},
  date = {1989},
  journaltitle = {J Econometrics},
  volume = {40},
  pages = {141--159},
  citeulike-article-id = {13264804},
  posted-at = {2014-07-14 14:09:42},
  priority = {0}
}

@article{sch90,
  title = {The Explained Variation in Proportional Hazards Regression (Correction in 81:631, 1994)},
  author = {Schemper, M.},
  date = {1990},
  journaltitle = {Biometrika},
  volume = {77},
  pages = {216--218},
  citeulike-article-id = {13264805},
  posted-at = {2014-07-14 14:09:42},
  priority = {0}
}

@article{sch90eff,
  title = {Efficient Evaluation of Treatment Effects in the Presence of Missing Covariate Values},
  author = {Schemper, Michael and Smith, Terry L.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {777--784},
  citeulike-article-id = {13264806},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {missing-data,survival-analysis}
}

@article{sch92cox,
  title = {Cox Analysis of Survival Data with Non-Proportional Hazard Functions},
  author = {Schemper, Michael},
  date = {1992},
  journaltitle = {The Statistician},
  volume = {41},
  pages = {445--455},
  citeulike-article-id = {13264807},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {assessing-proportional-hazards,cox-model}
}

@article{sch92fur,
  title = {Further Results on the Explained Variation in Proportional Hazards Regression},
  author = {Schemper, M.},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {202--204},
  citeulike-article-id = {13264808},
  posted-at = {2014-07-14 14:09:42},
  priority = {0}
}

@article{sch93com,
  title = {Comparison of the {{Cox}} Model and the Regression Tree Procedure in Analysing a Randomized Clinical Trial},
  author = {Schmoor, Claudia and Ulm, Kurt and Schumacher, Martin},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2351--2366},
  citeulike-article-id = {13264809},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {cart,cox-model,interaction,survival-analysis}
}

@article{sch93rel,
  title = {The Relative Importance of Prognostic Factors in Studies of Survival},
  author = {Schemper, Michael},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2377--2382},
  citeulike-article-id = {13264810},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {bootstrap,explained-variation,likelihood,r-squared,testing}
}

@article{sch94out,
  title = {Outcome-Oriented Cutpoints in Quantitative Exposure},
  author = {Schulgen, G. and Lausen, B. and Olsen, J. and Schumacher, M.},
  date = {1994},
  journaltitle = {Am J Epi},
  volume = {120},
  pages = {172--184},
  citeulike-article-id = {13265375},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {categorizing-continuous-variables,cutpoints,dichotomization,teaching-mds}
}

@article{sch96eco,
  title = {The Economic Evaluation of the {{FIRST Study}}:{{Design}} of a Prospective Analysis alongside a Multinational {{Phase III}} Clinical Trial},
  author = {Schulman, Kevin A. and Glick, Henry and Buxton, Martin and Sculpher, Mark and Backhouse, Martin and Bell, Larry and Eisenberg, John M.},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {304--315},
  doi = {10.1016/0197-2456(95)00166-2},
  url = {http://dx.doi.org/10.1016/0197-2456(95)00166-2},
  citeulike-article-id = {13264811},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0197-2456(95)00166-2},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {clinical-trials,economic-evaluation-of-rct,economics,rct,study-design}
}

@article{sch96exp,
  title = {Explained Variation in Survival Analysis},
  author = {Schemper, Michael and Stare, Janez},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1999--2012},
  citeulike-article-id = {13264812},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {ease-of-interpretation-of-indexes-of-explained-variation,explained-variation}
}

@article{sch96pva,
  title = {P {{Values}}: {{What}} They Are and What They Are Not},
  author = {Schervish, Mark J.},
  date = {1996},
  journaltitle = {Am Statistician},
  volume = {50},
  pages = {203--206},
  citeulike-article-id = {13264813},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  note = {Bayesian inference;problems with frequentist inference;P-values;interval H\_0;inability of P-values to provide evidence in favor of a hypothesis;"posterior probabilities are intended for measuring support for hypotheses when the data are fixed (the true state of affairs after the data are observed)";incoherence of P-values - e.g., P-value can indicate more support for H\_0: M ∈[-.5,.5] than for H\_0: M ∈[-.82,.52] even though the first implies the second}
}

@article{sch96ran,
  title = {Randomized and Non-Randomized Patients in Clinical Trials: {{Experiences}} with Comprehensive Cohort Studies},
  author = {Schmoor, Claudia and Olschewski, Manfred and Schumacher, Martin},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {263--271},
  citeulike-article-id = {13264814},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {bias,generalizability-of-rcts,observational-studies}
}

@book{sch97ana,
  title = {Analysis of {{Incomplete Multivariate Data}}},
  author = {Schafer, Joseph L.},
  date = {1997},
  publisher = {{Chapman \& Hall}},
  location = {{London}},
  citeulike-article-id = {13264815},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {missing-data}
}

@article{sch97log,
  title = {A Logistic Regression Model When Some Events Precede Treatment: {{The}} Effect of Thrombolytic Therapy for Acute Myocardial Infarction on the Risk of Cardiac Arrest},
  author = {Schmid, Christopher H. and D'Agostino, Ralph B. and Griffith, John L. and Beshansky, Joni R. and Selker, Harry P.},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {1219--1229},
  citeulike-article-id = {13264816},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {events-before-treatment,intention-to-treat,logistic-model-for-time-dependent-covariables,per-protocol}
}

@article{sch97pro,
  title = {Probability Imputation Revisited for Prognostic Factor Studies},
  author = {Schemper, Michael and Heinze, Georg},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {73--80},
  citeulike-article-id = {13264817},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {imputation,logistic-model,prostate-cancer-dataset},
  note = {imputation of missing covariables using logistic model;comparison with multiple imputation;analysis of prostate cancer dataset}
}

@article{sch97tri,
  title = {A Trial of Church-Based Smoking Cessation Interventions for Rural {{African-Americans}}},
  author = {Schorling, John B. and Roach, Julienne and Siegel, Marjorie and Baturka, Natalie and Hunt, Dawn E. and Guterbock, Thomas M. and Stewart, Herbert L.},
  date = {1997},
  journaltitle = {Prev Med},
  volume = {26},
  pages = {92--101},
  doi = {10.1006/pmed.1996.9988},
  url = {http://dx.doi.org/10.1006/pmed.1996.9988},
  citeulike-article-id = {13265120},
  citeulike-linkout-0 = {http://dx.doi.org/10.1006/pmed.1996.9988},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {data,diabetes},
  note = {source reference for diabetes dataset;see also wil97pre}
}

@article{sch98emp,
  title = {An Empirical Study of the Effect of the Control Rate as a Predictor of Treatment Efficacy in Meta-Analysis of Clinical Trials},
  author = {Schmid, Christopher H. and Lau, Joseph and McIntosh, Martin W. and Cappelleri, Joseph C.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1923--1942},
  citeulike-article-id = {13264818},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {absolute-vs-relative-treatment-effect,baseline-risk,meta-analysis}
}

@article{sch99leg,
  title = {The Legacy of {{SUPPORT}}},
  author = {Schroeder, Steven A.},
  date = {1999},
  journaltitle = {Ann Int Med},
  volume = {131},
  pages = {780--781},
  citeulike-article-id = {13264819},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  annotation = {Editorial}
}

@article{sco55rel,
  title = {Reliability of Content Analysis: {{The}} Case of Nominal Scale Coding},
  author = {Scott, W. A.},
  date = {1955},
  journaltitle = {Pub Opn Qtr},
  volume = {19},
  pages = {321--325},
  citeulike-article-id = {13265794},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  note = {invented Scott's π which Cohen re-invented as κ}
}

@article{sco89,
  title = {Hypothesis Testing in Case-Control Studies},
  author = {Scott, A. J. and Wild, C. J.},
  date = {1989},
  journaltitle = {Biometrika},
  volume = {76},
  pages = {806--808},
  citeulike-article-id = {13264820},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {case-control-studies,logistic-model-extensions,matching}
}

@article{sco97sta,
  title = {Statistical Assessment of Ordinal Outcomes in Comparative Studies},
  author = {Scott, Susan C. and Goldberg, Mark S. and Mayo, Nancy E.},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {45--55},
  citeulike-article-id = {13264821},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {assessing-assumptions,continuation-ratio,ordinal-logistic-regression,ordinal-response,proportional-odds,sas-code}
}

@article{sco98int,
  title = {Interpretation of Subgroup Analyses in Medical Device Clinical Trials},
  author = {Scott, Pamela E. and Campbell, Gregory},
  date = {1998},
  journaltitle = {Drug Info J},
  volume = {32},
  pages = {213--220},
  citeulike-article-id = {13264822},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {differential-treatment-effects,empirical-bayes,shrinkage,subgroup-analysis,teaching}
}

@inproceedings{scu97dev,
  title = {Development of an Enterprise-Wide Clinical Data Repository: {{Merging}} Multiple Legacy Databases},
  booktitle = {Proceedings of the {{American Medical Informatics Aassociation Annual Fall Symposium}}},
  author = {Scully, K. W. and Pates, R. D. and Desper, G. S. and Connors, A. F. and Harrell, F. E. and Pieper, K. S. and Hannan, R. L. and Reynolds, R. E.},
  date = {1997},
  pages = {32--36},
  citeulike-article-id = {13264823},
  posted-at = {2014-07-14 14:09:42},
  priority = {0}
}

@article{seb03sta,
  title = {Statistical Challenges in Functional Genomics (with Discussion)},
  author = {Sebastiani, Paola and Gussoni, Emanuela and Kohane, Isaac S. and Ramoni, Marco F.},
  date = {2003},
  journaltitle = {Stat Sci},
  volume = {18},
  pages = {33--70},
  citeulike-article-id = {13265349},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {bayesian-methods,bioinformatics,classification,clustering,differential-gene-expression,functional-genomics,microarray,transformation},
  note = {excellent overview of genetics, DNA, microarray; other interesting articles follow}
}

@article{see04com,
  title = {Complex Systems and the Technology of Variability Analysis},
  author = {Seely, Andrew J. E. and Macklem, Peter T.},
  date = {2004},
  journaltitle = {Critical Care},
  volume = {8},
  pages = {R367-R384},
  url = {http://ccforum.com/content/8/6/R367},
  citeulike-article-id = {13265448},
  citeulike-linkout-0 = {http://ccforum.com/content/8/6/R367},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {approximate-entropy,complex-systems,critical-illness,detrended-fluctuation-and-power-law-analysis,entropy,multiscale-entropy,regularity,sample-entropy,signal-processing,spectral-analysis,stationarity-assumption,therapeutic-monitoring,time-domain,variability}
}

@article{seg88,
  title = {Regression Trees for Censored Data},
  author = {Segal, Mark R.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {35--47},
  citeulike-article-id = {13264824},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {general,predictive-methods,survival-analysis-non-regression}
}

@article{seg89,
  title = {A Comparison of Estimated Proportional Hazards Models and Regression Trees},
  author = {Segal, Mark and Bloch, Daniel},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {539--550},
  citeulike-article-id = {13264825},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {general,predictive-methods,survival-analysis-proportional-hazards-model}
}

@article{seg94rep,
  title = {Representative Curves for Longitudinal Data via Regression Trees},
  author = {Segal, Mark R.},
  date = {1994},
  journaltitle = {J Comp Graph Stat},
  volume = {3},
  pages = {214--233},
  citeulike-article-id = {13265416},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {graphics,profile,representative-curves,typical}
}

@article{sei89,
  title = {Should Data Be Collected on a Dependent Variable Late in a Clinical Trial If Not Measured at Baseline?},
  author = {{Seigel}},
  date = {1989},
  journaltitle = {Am Statistician},
  volume = {43},
  pages = {184--185},
  doi = {10.1080/00031305.1989.10475652},
  url = {http://dx.doi.org/10.1080/00031305.1989.10475652},
  citeulike-article-id = {13264826},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00031305.1989.10475652},
  posted-at = {2014-07-14 14:09:42},
  priority = {0},
  keywords = {ancova,baseline-adjustment,baseline-variable,rct,study-design-and-stopping-rules}
}

@article{sel10gly,
  title = {Glycated Hemoglobin, Diabetes, and Cardiovascular Risk in Nondiabetic Adults},
  author = {Selvin, E. and Steffes, M. W. and Zhu, H. and Matsushita, K. and Wagenknecht, L. and Pankow, J. and Coresh, J. and Brancati, F. L.},
  date = {2010-03},
  journaltitle = {NEJM},
  volume = {362},
  number = {9},
  pages = {800--811},
  doi = {10.1056/NEJMoa0908359},
  url = {http://dx.doi.org/10.1056/NEJMoa0908359},
  abstract = {Fasting glucose is the standard measure used to diagnose diabetes in the United States. Recently, glycated hemoglobin was also recommended for this purpose. We compared the prognostic value of glycated hemoglobin and fasting glucose for identifying adults at risk for diabetes or cardiovascular disease. We measured glycated hemoglobin in whole-blood samples from 11,092 black or white adults who did not have a history of diabetes or cardiovascular disease and who attended the second visit (occurring in the 1990-1992 period) of the Atherosclerosis Risk in Communities (ARIC) study. The glycated hemoglobin value at baseline was associated with newly diagnosed diabetes and cardiovascular outcomes. For glycated hemoglobin values of less than 5.0\%, 5.0 to less than 5.5\%, 5.5 to less than 6.0\%, 6.0 to less than 6.5\%, and 6.5\% or greater, the multivariable-adjusted hazard ratios (with 95\% confidence intervals) for diagnosed diabetes were 0.52 (0.40 to 0.69), 1.00 (reference), 1.86 (1.67 to 2.08), 4.48 (3.92 to 5.13), and 16.47 (14.22 to 19.08), respectively. For coronary heart disease, the hazard ratios were 0.96 (0.74 to 1.24), 1.00 (reference), 1.23 (1.07 to 1.41), 1.78 (1.48 to 2.15), and 1.95 (1.53 to 2.48), respectively. The hazard ratios for stroke were similar. In contrast, glycated hemoglobin and death from any cause were found to have a J-shaped association curve. All these associations remained significant after adjustment for the baseline fasting glucose level. The association between the fasting glucose levels and the risk of cardiovascular disease or death from any cause was not significant in models with adjustment for all covariates as well as glycated hemoglobin. For coronary heart disease, measures of risk discrimination showed significant improvement when glycated hemoglobin was added to models including fasting glucose. In this community-based population of nondiabetic adults, glycated hemoglobin was similarly associated with a risk of diabetes and more strongly associated with risks of cardiovascular disease and death from any cause as compared with fasting glucose. These data add to the evidence supporting the use of glycated hemoglobin as a diagnostic test for diabetes.},
  citeulike-article-id = {13265989},
  citeulike-linkout-0 = {http://dx.doi.org/10.1056/NEJMoa0908359},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {diabetes}
}

@article{sel88,
  title = {Power/Sample Size Calculations for Generalized Linear Models},
  author = {Self, S. G. and Mauritsen, R. H.},
  date = {1988},
  journaltitle = {Biometrics},
  volume = {44},
  pages = {79--86},
  citeulike-article-id = {13264827},
  posted-at = {2014-07-14 14:09:43},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,sample-size-estimation}
}

@article{sen00rep,
  title = {Repeated Measures in Clinical Trials: {{Simple}} Strategies for Analysis Using Summary Measures},
  author = {Senn, Stephen and Stevens, Lynda and Chaturvedi, Nish},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {861--877},
  doi = {10.1002/(SICI)1097-0258(20000330)19:6<861::AID-SIM407>3.0.CO;2-F},
  url = {https://pubmed.ncbi.nlm.nih.gov/10734289},
  citeulike-article-id = {13265118},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/(SICI)1097-0258(20000330)19:6%3C861::AID-SIM407%3E3.0.CO;2-F},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {auc,repeated-measures,serial-data,slope,summary-measures,teaching-mds}
}

@article{sen01ind,
  title = {Individual Therapy: {{New}} Dawn or False Dawn?},
  author = {Senn, Stephen},
  date = {2001},
  journaltitle = {Drug Info J},
  volume = {35},
  pages = {1479--1494},
  citeulike-article-id = {13265850},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {cross-over-trials,effect-sizes,n-of-1-trialsl,patient-by-treatment-interaction}
}

@article{sen04con,
  title = {Controversies Concerning Randomization and Additivity in Clinical Trials},
  author = {Senn, Stephen},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  pages = {3729--3753},
  doi = {10.1002/sim.2074},
  url = {http://dx.doi.org/10.1002/sim.2074},
  citeulike-article-id = {13265395},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2074},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {additivity,baseline,covariable-adjustment,covariate-adjustment,randomization,rct,study-design},
  note = {p. 3735: "in the pharmaceutical industry, in analyzing the data, if a linear model is employed, it is usual to fit centre as a factor but unusual to fit block.";p. 3739: a large trial "is not less vulnerable to chance covariate imbalance";p. 3741:"There is no place, in my view, for classical minimization" (vs. the method of Atkinson);"If an investigator uses such [allocation based on covariates] schemes, she or he is honour bound, in my opinion, as a very minimum, to adjust for the factors used to balance, since the fact that they are being used to balance is an implicit declaration that they will have prognostic value.";"The point of view is sometimes defended that analyses that ignore covariates are superior because they are simpler. I do not accept this. A value of \$\textbackslash pi=3\$ is a simple one and accurate to one significant figure ... However very few would seriously maintain that if should generally be adopted by engineers.";p. 3742: "as Fisher pointed out ... if we balance by a predictive covariate but do not fit the covariate in the model, not only do we not exploit the covariate, we actually increase the expected declared standard error."; p. 3744:"I would like to see standard errors for group means abolished."; p. 3744:"A common habit, however, in analyzing trials with three or more arms is to pool the variances from all arms when calculating the standard error of a given contrast. In my view this is a curious practice ... it relies on an assumption of additivity of {$<$}i{$>$}all{$<$}/all{$>$} treatments when comparing only {$<$}i{$>$}two{$<$}/i{$>$}. ... a classical t-test is robust to heteroscedasticity provide that sample sizes are equal in the groups being compared and that the variance is internal to those two groups but is not robust where an external estimate is being used."; p. 3745: "By adjusting main effects for interactions a type III analysis is similarly illogical to Neyman's hypothesis test."; "Guyatt {$<$}i{$>$}et al.{$<$}/i{$>$} ... found a 'method for estimating the proportion of patients who benefit from a treatment ... In fact they had done no such thing."; p. 3746: "When I checked the Web of Science on 29 June 2003, the paper by Horwitz {$<$}i{$>$}et al.{$<$}/i{$>$} had been cited 28 times and that by Guyatt {$<$}i{$>$}et al.{$<$}/i{$>$} had been cited 79 times. The letters pointing out the fallacies had been cited only 8 and 5 times respectively."; "if we pool heterogeneous strata, the odds ratio of the treatment effect will be different from that in every stratum, even if from stratum to stratum it does not vary."; p. 3747: "Part of the problem with Poisson, proportional hazard and logistic regression approaches is that they use a single parameter, the linear predictor, with no equivalent of the variance parameter in the Normal case. This means that lack of fit impacts on the estimate of the predictor. ... what is the value of randomization if, in all except the Normal case, we cannot guarantee to have unbiased estimates. My view ... was that the form of analysis envisaged (that is to say, which factors and covariates should be fitted) justified the allocation and {$<$}i{$>$}not vice versa{$<$}/i{$>$}."; "use the additive measure at the point of analysis and transform to the relevant scale at the point of implementation. This transformation at the point of medical decision-making will require auxiliary information on the level of background risk of the patient."; p. 3748:"The decision to fit prognostic factors has a far more dramatic effect on the precision of our inferences than the choice of an allocation based on covariates or randomization approach and one of my chief objections to the allocation based on covariates approach is that trialists have tended to use the fact that they have balanced as an excuse for not fitting. This is a grave mistake."}
}

@article{sen04ind,
  title = {Individual Response to Treatment: Is It a Valid Assumption?},
  author = {Senn, Stephen},
  date = {2004},
  journaltitle = {BMJ},
  volume = {329},
  pages = {966--968},
  citeulike-article-id = {13265461},
  posted-at = {2014-07-14 14:09:57},
  priority = {0}
}

@inproceedings{sen05dic,
  title = {Dichotomania: An Obsessive Compulsive Disorder That Is Badly Affecting the Quality of Analysis of Pharmaceutical Trials},
  booktitle = {Proceedings of the {{International Statistical Institute}}, 55th {{Session}}},
  author = {Senn, Stephen J.},
  date = {2005},
  location = {{Sydney}},
  url = {http://hbiostat.org/papers/Senn/dichotomania.pdf},
  keywords = {categorization,categorizing-continuous-variables,dichotomization,dichotomizing-continuous-variables}
}

@article{sen06cha,
  title = {Change from Baseline and Analysis of Covariance Revisited},
  author = {Senn, Stephen},
  date = {2006},
  journaltitle = {Stat Med},
  volume = {25},
  pages = {4334--4344},
  citeulike-article-id = {13265683},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {analysis-of-covariance,ancova,baselines,change,change-from-baseline,change-score,lords-paradox,repeated-measures},
  note = {shows that claims that in a 2-arm study it is not true that ANCOVA requires the population means at baseline to be identical;refutes some claims of lia00lon;problems with counterfactuals;temporal additivity ("amounts to supposing that despite the fact that groups are difference at baseline they would show the same evolution over time");causal additivity;is difficult to design trials for which simple analysis of change scores is unbiased, ANCOVA is biased, and a causal interpretation can be given;temporally and logically, a "baseline cannot be a {$<$}i{$>$}response{$<$}/i{$>$} to treatment", so baseline and response cannot be modeled in an integrated framework as Laird and Ware's model has been used;"one should focus clearly on `outcomes' as being the only values that can be influenced by treatment and examine critically any schemes that assume that these are linked in some rigid and deterministic view to `baseline' values. An alternative tradition sees a baseline as being merely one of a number of measurements capable of improving predictions of outcomes and models it in this way.";"You cannot establish necessary conditions for an estimator to be valid by nominating a model and seeing what the model implies unless the model is universally agreed to be impeccable. On the contrary it is appropriate to start with the estimator and see what assumptions are implied by valid conclusions.";this is in distinction to lia00lon}
}

@article{sen07str,
  title = {Stratification for the Propensity Score Compared with Linear Regression Techniques to Assess the Effect of Treatment or Exposure},
  author = {Senn, Stephen and Graf, Erika and Caputo, Angelika},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {5529--5544},
  citeulike-article-id = {13265650},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {conditional-vs-marginal-independence,confounding,linear-models,propensity-score},
  note = {propensity adjustment puts all emphasis on bias at the cost of variance}
}

@article{sen07try,
  title = {Trying to Be Precise about Vagueness},
  author = {Senn, Stephen},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {1417--1430},
  citeulike-article-id = {13265565},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {bayesian-methods,concise-criticism-of-meta-analysis,difficulty-of-choosing-prior-distribution-for-variance-of-random-effects,fixed-effects,graphical-representation,hglm,meta-analysis,profile-likelihood,random-effects}
}

@article{sen08not,
  title = {A Note Concerning a Selection “Paradox” of {{Dawid}}'s},
  author = {Senn, Stephen},
  date = {2008},
  journaltitle = {Am Statistician},
  volume = {62},
  number = {3},
  pages = {206--210},
  citeulike-article-id = {13265685},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {bayesian-inference,hierarchical-models,prior-distributions,selection-paradox},
  note = {selecting the treatment with the largest observed mean;"choice of prior is a delicate matter";"... the Bayesian may find it difficult to escape from prior experience when seeking to make a valid inference but find it equally difficult to recognize exactly what that prior experience is.";"... the values of other means in the experiment have no influence. They are simply a random subset of the infiniity of means from which this one has been drawn and with which it is {$<$}i{$>$}already implicitly being compared{$<$}/i{$>$}."}
}

@article{sen09mea,
  title = {Measurement in Clinical Trials: {{A}} Neglected Issue for Statisticians? (With Discussion)},
  author = {Senn, Stephen and Julious, Steven},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {3189--3225},
  citeulike-article-id = {13265786},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {baselines,bp,dichtomization,nnt,number-needed-to-treat,ordered-categorical-data,qt,responder-analysis,titration},
  note = {complex blood pressure rules for success;corrected QT with formulas failing to respect dimensionality analysis;"Clearly, the dependence of the proportional odds model on the assumption of proportionality can be overstressed. Suppose that two different statisticians would cut the same three-point scale at different cut points. It is hard to see how anybody who could accept either dichotomy could object to the compromise answer produced by the proportional odds model.";nice derivation of efficiency loss from creating dichotomies;further loss from using change scores to create dichotomies}
}

@article{sen09thr,
  title = {Three Things That Every Medical Writer Should Know about Statistics},
  author = {Senn, Stephen},
  date = {2009},
  journaltitle = {Write Stuff},
  volume = {18},
  number = {3},
  pages = {159--162},
  citeulike-article-id = {13265853},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {error-of-the-transposed-conditional,individual-response,regression-to-the-mean}
}

@article{sen10com,
  title = {Comparisons of Minimization and {{Atkinson}}'s Algorithm},
  author = {Senn, Stephen and Anisimov, Vladimir V. and Fedorov, Valerii V.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {721--730},
  citeulike-article-id = {13265809},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {clniical-trials,covariate-balance,covariates,dynamic-allocation,optimal-design,randomization,rct},
  note = {"fitting covariates may make a more valuable and instructive contribution to inferences about treatment effects than only balancing them"}
}

@article{sen13beia,
  title = {Being {{Efficient About Efficacy Estimation}}},
  author = {Senn, Stephen},
  date = {2013-08-01},
  journaltitle = {Statistics in Biopharmaceutical Research},
  volume = {5},
  number = {3},
  pages = {204--210},
  publisher = {{Taylor \& Francis}},
  issn = {null},
  doi = {10.1080/19466315.2012.754726},
  url = {https://doi.org/10.1080/19466315.2012.754726},
  urldate = {2021-04-22},
  abstract = {I consider Bob O’Neill's important role in promoting regulatory science and, in particular, through the very influential series of lectures he gave in Basel more than 20 years ago, the effect on statistics in European regulation and ultimately on regulatory science in the United States. I provide a simple model of disappointment in drug development. I consider three approaches to improving efficiency in drug development and conclude that there are simple things we could be doing to reduce the cost with which information is obtained in drug development.},
  keywords = {covariate-adjustment,futility,rct,sequential},
  annotation = {\_eprint: https://doi.org/10.1080/19466315.2012.754726},
  note = {"Every time the statistician working in the pharmaceutical industry does a sample size determination for a trial using a responder analysis, he or she should do the same calculation using the original measure.~ If the dichotomy is preferred, an explanation as to why the extra millions are going to be spent should be provided."}
}

@article{sen93inh,
  title = {Inherent Difficulties with Active Control Equivalence Studies},
  author = {Senn, Stephen},
  date = {1993},
  journaltitle = {Statistics in Medicine},
  volume = {12},
  number = {24},
  pages = {2367--2375},
  issn = {1097-0258},
  doi = {10.1002/sim.4780122412},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780122412},
  urldate = {2021-09-04},
  abstract = {A simple model is used to investigate the relevance of ‘competence’ to active control equivalence studies )ACES(. It is shown that to the extent that such trials are successful the results of such trials must raise doubts regarding their competence. ACES are thus more problematic than classical clinical trials and the problems with such studies cannot be solved simply by exchanging the usual roles of null and alternative hypotheses.},
  langid = {english},
  keywords = {drug-development,equivalence,equivalence-trial,non-inferiority,rct},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.4780122412}
}

@article{sen94tes,
  title = {Testing for Baseline Balance in Clinical Trials},
  author = {Senn, Stephen},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1715--1726},
  citeulike-article-id = {13264828},
  posted-at = {2014-07-14 14:09:43},
  priority = {0},
  keywords = {clinical-trials,randomization,rct,study-design}
}

@article{sen95per,
  title = {A Personal View of Some Controversies in Allocating Treatment to Patients in Clinical Trials},
  author = {Senn, Stephen},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2661--2674},
  citeulike-article-id = {13264829},
  posted-at = {2014-07-14 14:09:43},
  priority = {0},
  keywords = {blinding,crossover-study,ethics,multi-center-study,placebo,randomization,run-in,study-design,treatment-allocation}
}

@article{sen96opt,
  title = {Optimal Statistics?},
  author = {Senn, Stephen},
  date = {1996-06},
  journaltitle = {Newsl Int Soc Clin Biostat},
  number = {20},
  pages = {24--25},
  citeulike-article-id = {13264830},
  posted-at = {2014-07-14 14:09:43},
  priority = {0},
  keywords = {crossover-studies,study-design}
}

@article{sen96som,
  title = {Some Statistical Issues in Project Prioritization in the Pharmaceutical Industry},
  author = {Senn, Stephen},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2689--2702},
  citeulike-article-id = {13264831},
  posted-at = {2014-07-14 14:09:43},
  priority = {0},
  keywords = {pharmaceutical-industry,pharmaco-economics,probability-architecture,probability-laws,project-staging},
  note = {advantage of breaking projects into stages}
}

@book{sen97sta,
  title = {Statistical {{Issues}} in {{Drug Development}}},
  author = {Senn, Stephen},
  date = {1997},
  publisher = {{Wiley}},
  location = {{Chichester, England}},
  citeulike-article-id = {13264832},
  posted-at = {2014-07-14 14:09:43},
  priority = {0}
}

@article{sen97wis,
  title = {On Wisdom after the Event},
  author = {Senn, Stephen and Harrell, Frank E.},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {749--751},
  citeulike-article-id = {13265306},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  annotation = {Refereed letter to the editor}
}

@article{sen98som,
  title = {Some Controversies in Planning and Analysing Multi-Centre Trials},
  author = {Senn, Stephen},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1753--1765},
  citeulike-article-id = {13264834},
  posted-at = {2014-07-14 14:09:43},
  priority = {0},
  keywords = {multi-center-rct,power,treatment-by-center-interaction,type-iii-test}
}

@article{sen98sub,
  title = {On Subgroups and Groping for Significance},
  author = {Senn, Stephen and Harrell, Frank E.},
  date = {1998},
  journaltitle = {J Clin Epi},
  volume = {51},
  pages = {1367--1368},
  citeulike-article-id = {13265304},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  annotation = {refereed letter to the editor}
}

@book{sensta,
  title = {Statistical {{Issues}} in {{Drug Development}}},
  author = {Senn, Stephen},
  date = {2008},
  edition = {Second},
  publisher = {{Wiley}},
  location = {{Chichester, England}},
  citeulike-article-id = {13264833},
  posted-at = {2014-07-14 14:09:43},
  priority = {0}
}

@article{sha03las,
  title = {Last Observation Carry-Forward and Last Observation Analysis},
  author = {Shao, Jun and Zhong, Bob},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {2429--2441},
  citeulike-article-id = {13265344},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {anova,informative-drop-out,last-observation,last-observation-carried-forward,locf,post-stratification,size},
  note = {two-sample test asymptotically has size equal to nominal size when the two treatment groups have the same number of subjects, whether or not drop-out is informative. In other cases, size is not the nominal size and there is a loss of power. New test stratifying on visit of dropout}
}

@article{sha03max,
  title = {A Maximum Likelihood Approach for Estimating the {{QT}} Correction Factor Using Mixed Effects Model},
  author = {Shah, Amrik and Hajian, Gerald},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {1901--1909},
  citeulike-article-id = {13265327},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {clinical-safety,graphics,pharmaceutical-safety,qt-correction,qt-prolongation},
  note = {examples of bad graphics; You state on the top of P. 1902 that "Since the QT shortens as the heart rate increases and the heart rate, when modified pharmacologically, is not a constant, a correction factor is needed to assess the QT intervals." This does not seem to follow logically although it has certainly been the tradition. If a drug changes heart rate and this is prognostic of bad outcomes for the patient, and if correcting for the change in heart rate removes a bad prognostic effect of QT changes, can it not be a mistake to correct for heart rate changes? A good deal of the paper rests on the between-patient variance being greater than zero. The confidence interval for d11 is [.0018,.0190] which goes fairly close to zero. Isn't there a boundary problem at zero with MLE or REML estimates of variances? Has the confidence coverage of such confidence intervals (both tails being 0.025) been verified by simulation? Your model in section 4.2 is on the QT scale but your other models were on the log QT scale. How do you know which scale is appropriate for section 4.2? You have a lot of heart cycles per subject available for analysis. I am unclear how many were used per subject when fitting equation (3). It would make sense to use hundreds of cycles per subject when modeling within-patient heart rate dependency on QT intervals.}
}

@article{sha05pro,
  title = {Propensity Score Methods Gave Similar Results to Traditional Regression Modeling in Observational Studies: A Systematic Review},
  author = {Shah, Baiju R. and Laupacis, Andreas and Hux, Janet E. and Austin, Peter C.},
  date = {2005},
  journaltitle = {J Clin Epi},
  volume = {58},
  pages = {550--559},
  citeulike-article-id = {13265415},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {propensity-score},
  note = {"Propensity scores gave slightly weaker associations; however many of the reviewed studies did not implement propensity scores well.";e.g. many papers tried to be parsimoneous in the propensity model}
}

@article{sha20con,
  title = {Contribution of Individual Components to Composite End Points in Contemporary Cardiovascular Randomized Controlled Trials},
  author = {Shaikh, Asim and Ochani, Rohan Kumar and Khan, Muhammad Shahzeb and Riaz, Haris and Khan, Safi U. and Sreenivasan, Jayakumar and Mookadam, Farouk and Doukky, Rami and Butler, Javed and Michos, Erin D. and Kalra, Ankur and Krasuski, Richard A.},
  date = {2020-09-15},
  journaltitle = {Am Heart J},
  volume = {230},
  eprint = {32941789},
  eprinttype = {pmid},
  pages = {71--81},
  issn = {1097-6744},
  doi = {10.1016/j.ahj.2020.09.001},
  abstract = {Cardiovascular randomized controlled trials (RCTs) typically set composite end points as the primary outcome to enhance statistical power. However, influence of individual component end points on overall composite outcomes remains understudied. METHODS: We searched MEDLINE for RCTs published in 6 high-impact journals (The Lancet, the New England Journal of Medicine, Journal of the American Medical Association, Circulation, Journal of the American College of Cardiology and the European Heart Journal) from 2011 to 2017. Two-armed, parallel-design cardiovascular RCTs which reported composite outcomes were included. All-cause or cardiovascular mortality, myocardial infarction, heart failure, and stroke were deemed "hard" end points, whereas hospitalization, angina, and revascularization were identified as "soft" end points. Type of outcome (primary or secondary), event rates in treatment and control groups for the composite outcome and of its components according to predefined criteria. RESULTS: Of the 45.8\% (316/689) cardiovascular RCTs which used a composite outcome, 79.4\% set the composite as the primary outcome. Death was the most common component (89.8\%) followed by myocardial infarction (66.1\%). About 80\% of the trials reported complete data for each component. One hundred forty-seven trials (46.5\%) incorporated a "soft" end point as part of their composite. Death contributed the least to the estimate of effects (R2 change\,=\,0.005) of the composite, whereas revascularization contributed the most (R2 change\,=\,0.423). CONCLUSIONS: Cardiovascular RCTs frequently use composite end points, which include "soft" end points, as components in nearly 50\% of studies. Higher event rates in composite end points may create a misleading interpretation of treatment impact due to large contributions from end points with less clinical significance.},
  langid = {english},
  keywords = {composite-endpoint,multiple-endpoints,outcomes,rct}
}

@article{sha93lin,
  title = {Linear Model Selection by Cross-Validation},
  author = {Shao, Jun},
  date = {1993},
  journaltitle = {J Am Stat Assoc},
  volume = {88},
  pages = {486--494},
  citeulike-article-id = {13264835},
  posted-at = {2014-07-14 14:09:43},
  priority = {0},
  keywords = {bootstrap,cross-validation,jackknife,model-validation,regression-general,variable-selection}
}

@article{sha96boo.imp,
  title = {Bootstrap for Imputed Survey Data},
  author = {Shao, Jun and Sitter, Randy R.},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {1278--1288},
  citeulike-article-id = {13264836},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bootstrap,imputation},
  note = {bootstrap variance estimates by imitating imputation process}
}

@article{sha96boo.mod,
  title = {Bootstrap Model Selection},
  author = {Shao, Jun},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {655--665},
  citeulike-article-id = {13264837},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bootstrap,model-selection,variable-selection},
  note = {found bootstrap samples should be of size m, m {$<$} n}
}

@article{sha96rel,
  title = {The Relation between Treatment Benefit and Underlying Risk in Meta-Analysis},
  author = {Sharp, S. J. and Thompson, S. G. and Altman, D. G.},
  date = {1996},
  journaltitle = {BMJ},
  volume = {313},
  pages = {735--738},
  doi = {10.1136/bmj.313.7059.735},
  url = {http://dx.doi.org/10.1136/bmj.313.7059.735},
  citeulike-article-id = {13264838},
  citeulike-linkout-0 = {http://dx.doi.org/10.1136/bmj.313.7059.735},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {meta-analysis,publication-bias,random-effects,regression-to-the-mean,teaching-mds,underlying-risk}
}

@article{sha97met,
  title = {Is Meta-Analysis a Valid Approach to the Evaluation of Small Effects in Observational Studies?},
  author = {Shapiro, Samuel},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {223--229},
  doi = {10.1016/S0895-4356(96)00360-5},
  url = {http://dx.doi.org/10.1016/S0895-4356(96)00360-5},
  citeulike-article-id = {13264839},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0895-4356(96)00360-5},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {meta-analysis,observational-studies,publication-bias,teaching-mds},
  note = {meta-analysis of observational studies;bias;errors don't always cancel}
}

@article{sha98use,
  title = {Use of a Prognostic Treadmill Score in Identifying Diagnostic Coronary Disease Subgroups},
  author = {Shaw, L. J. and Peterson, E. D. and Shaw, L. K. and Kesler, K. L. and DeLong, E. R. and Harrell, F. E. and Muhlbaier, L. H. and Mark, D. B.},
  date = {1998},
  journaltitle = {Circ},
  volume = {98},
  pages = {1622--1630},
  citeulike-article-id = {13264840},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {adequacy-index}
}

@article{she04inf,
  title = {Inference after Model Selection},
  author = {Shen, Xiaotong and Huang, Hsin-Cheng and Ye, Jimmy},
  date = {2004},
  journaltitle = {J Am Stat Assoc},
  volume = {99},
  pages = {751--762},
  citeulike-article-id = {13265541},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {model-approximation,model-selection,model-uncertainty,pre-conditioning,variable-selection},
  note = {uses optimal approximation for estimating mean and variance of complex statistics adjusting for model selection}
}

@article{she90,
  title = {Kernel Quantile Estimators},
  author = {Sheather, S. J. and Marron, J. S.},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {410--416},
  citeulike-article-id = {13264841},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {order-statistics,quantiles}
}

@article{she91int,
  title = {The Intellectual Health of Clinical Drug Evaluation},
  author = {Sheiner, Lewis B.},
  date = {1991},
  journaltitle = {Clin Pharm Ther},
  volume = {50},
  pages = {4--9},
  doi = {10.1038/clpt.1991.97},
  url = {http://dx.doi.org/10.1038/clpt.1991.97},
  citeulike-article-id = {13264842},
  citeulike-linkout-0 = {http://dx.doi.org/10.1038/clpt.1991.97},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bayesian-inference,clinical-trials,compliance,hypothesis-testing,rct,reporting,review,statistical-significance,teaching-mds},
  note = {problems with traditional statistical approaches to drug evaluation;problems with under-emphasis of type II error}
}

@article{she95int,
  title = {Intention-to-Treat Analysis and the Goals of Clinical Trials},
  author = {Sheiner, Lewis B. and Rubin, Donald B.},
  date = {1995},
  journaltitle = {Clin Pharm Ther},
  volume = {57},
  pages = {6--15},
  citeulike-article-id = {13264843},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bias,compliance,instrumental-variables,intention-to-treat,method-effectiveness,problems-with-as-treated-and-per-protocol,problems-with-intent-to-treat,rct,study-design,use-effectiveness}
}

@article{she97lea,
  title = {Commentary: {{Learning}} versus Confirming in Clinical Drug Development},
  author = {Sheiner, Lewis B.},
  date = {1997},
  journaltitle = {Clin Pharm Ther},
  volume = {61},
  pages = {275--291},
  citeulike-article-id = {13264844},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bayesian-modeling,drug-development-program,rct,study-design},
  note = {need for modeling in RCT to interpret complex quantitative experience;response surface;dose-finding;dose-ranging;confirmatory vs. exploratory study;study designs for learning and confirming;model-free means must pay the price of higher n;definitions of phases;modeling concentration first;model example;phase 2B "cannot be planned in one stroke with all important studies executed in parallel";"learning is intrisically sequential";learning can result in cost savings;list of what one wants to learn from drug development}
}

@article{she98par,
  title = {Parametric Likelihoods for Multiple Non-Fatal Competing Risks and Death},
  author = {Shen, Yu and Thall, Peter F.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {999--1015},
  citeulike-article-id = {13264845},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {competing-risk,multiple-states,parametric-survival-model},
  note = {dead state and multiple live states; multiple non-fatal competing risks;nice depiction of possible patient outcomes}
}

@article{she99est,
  title = {Estimation of Mean Quality Adjusted Survival Time},
  author = {Shen, L. Z. and Pulkstenis, E. and Hoseyni, M.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1541--1554},
  citeulike-article-id = {13264846},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {consistent-estimate,informative-censoring,qaly,quality-adjusted-survival-time},
  note = {uses only uncensored quality adjusted life years to estimate conditional mean QALY given survival time;see zha97con}
}

@article{shi04two,
  title = {Two-Stage Adaptive Strategy for Superiority and Non-Inferiority Hypotheses in Active Controlled Clinical Trials},
  author = {Shih, W. C. J. and Quan, H. and Li, G.},
  date = {2004},
  journaltitle = {Stat Med},
  volume = {23},
  number = {18},
  pages = {2781--2798},
  citeulike-article-id = {13265507},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{shi17rel,
  title = {Relative Efficiency of Precision Medicine Designs for Clinical Trials with Predictive Biomarkers},
  author = {Shih, Weichung J. and Lin, Yong},
  journaltitle = {Stat Med},
  pages = {n/a},
  doi = {10.1002/sim.7562},
  url = {http://dx.doi.org/10.1002/sim.7562},
  abstract = {Prospective randomized clinical trials addressing biomarkers are time consuming and costly, but are necessary for regulatory agencies to approve new therapies with predictive biomarkers. For this reason, recently, there have been many discussions and proposals of various trial designs and comparisons of their efficiency in the literature. We compare statistical efficiencies between the marker-stratified design and the marker-based precision medicine design regarding testing/estimating 4 hypotheses/parameters of clinical interest, namely, treatment effects in each marker-positive and marker-negative cohorts, marker-by-treatment interaction, and the marker's clinical utility. As may be expected, the stratified design is more efficient than the precision medicine design. However, it is perhaps surprising to find out how low the relative efficiency can be for the precision medicine design. We quantify the relative efficiency as a function of design factors including the marker-positive prevalence rate, marker assay and classification sensitivity and specificity, and the treatment randomization ratio. It is interesting to examine the trends of the relative efficiency with these design parameters in testing different hypotheses. We advocate to use the stratified design over the precision medicine design in clinical trials with predictive biomarkers.},
  citeulike-article-id = {14488139},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7562},
  posted-at = {2017-12-04 13:32:49},
  priority = {2},
  keywords = {experimental-design,interaction,personalized-medicine,study-design}
}

@article{shi18cum,
  title = {Cumulative Incidence of Neck Recurrence with Increasing Depth of Invasion},
  author = {Shinn, Justin R. and Wood, C. Burton and Colazo, Juan M. and Harrell, Frank E. and Rohde, Sarah L. and Mannion, Kyle},
  date = {2018-12-01},
  journaltitle = {Oral Oncology},
  volume = {87},
  pages = {36--42},
  issn = {1368-8375},
  doi = {10.1016/j.oraloncology.2018.10.015},
  url = {http://www.sciencedirect.com/science/article/pii/S1368837518303683},
  urldate = {2018-10-21},
  abstract = {Objective To determine if there is a critical depth of invasion that predicts micrometastasis in early oral tongue cancer. Methods Retrospective series identifying patients undergoing primary surgical resection of T1 or T2 oral tongue cancer who elected against neck treatment between 2000 and 2015. Cox proportional-hazard model compared the relative hazard and cumulative incidence of recurrence to depth of invasion. The model used a 2 parameter quadratic effect for depth that was chosen based on Akaike's information criterion. Results Ninety-three patients were identified with T1 or T2 oral tongue squamous cell carcinoma and clinically N0 neck undergoing glossectomy without elective neck treatment. 61\% were male and median age was 60\,years. Median follow up was 45 months, and 76 patients had at least two years of follow up. Thirty-six of 76 patients recurred (47.4\%), with 15 recurring in the oral cavity (19.7\%) and 21 developing nodal metastasis (27.6\%). Cox proportional-hazards quadratic polynomial showed increasing hazard of recurrence with depth of invasion and the cumulative incidence increased sharply within the range of data from 2 to 6~mm depth of invasion. Conclusions Depth of invasion is significantly associated with nodal metastasis and has been added to the 8th AJCC staging guidelines. Variable depths of invasion have been associated with regional metastasis; however, there is likely not a critical depth that predicts neck recurrence due to progressive hazards and cumulative risk of occult metastasis. The risk of regional metastasis is likely much greater than previously believed and increases progressively with increasing depth.},
  keywords = {cancer,categorization-of-continuous-variables,collaboration},
  note = {Nice example of not doing the originally requested dichotomous analysis of neck tumor depth}
}

@article{shi18cuma,
  title = {Cumulative Incidence of Neck Recurrence with Increasing Depth of Invasion},
  author = {Shinn, Justin R. and Wood, C. Burton and Colazo, Juan M. and Harrell, Frank E. and Rohde, Sarah L. and Mannion, Kyle},
  date = {2018-12},
  journaltitle = {Oral Oncol},
  volume = {87},
  eprint = {30527241},
  eprinttype = {pmid},
  pages = {36--42},
  issn = {1879-0593},
  doi = {10.1016/j.oraloncology.2018.10.015},
  abstract = {OBJECTIVE: To determine if there is a critical depth of invasion that predicts micrometastasis in early oral tongue cancer. METHODS: Retrospective series identifying patients undergoing primary surgical resection of T1 or T2 oral tongue cancer who elected against neck treatment between 2000 and 2015. Cox proportional-hazard model compared the relative hazard and cumulative incidence of recurrence to depth of invasion. The model used a 2 parameter quadratic effect for depth that was chosen based on Akaike's information criterion. RESULTS: Ninety-three patients were identified with T1 or T2 oral tongue squamous cell carcinoma and clinically N0 neck undergoing glossectomy without elective neck treatment. 61\% were male and median age was 60\,years. Median follow up was 45 months, and 76 patients had at least two years of follow up. Thirty-six of 76 patients recurred (47.4\%), with 15 recurring in the oral cavity (19.7\%) and 21 developing nodal metastasis (27.6\%). Cox proportional-hazards quadratic polynomial showed increasing hazard of recurrence with depth of invasion and the cumulative incidence increased sharply within the range of data from 2 to 6~mm depth of invasion. CONCLUSIONS: Depth of invasion is significantly associated with nodal metastasis and has been added to the 8th AJCC staging guidelines. Variable depths of invasion have been associated with regional metastasis; however, there is likely not a critical depth that predicts neck recurrence due to progressive hazards and cumulative risk of occult metastasis. The risk of regional metastasis is likely much greater than previously believed and increases progressively with increasing depth.},
  langid = {english},
  keywords = {collaboration}
}

@article{shi19dec,
  title = {A {{Decision-Theoretic Approach}} to {{Panel-Based}}, {{Preemptive Genotyping}}},
  author = {Shi, Yaping and Graves, John A. and Garbett, Shawn P. and Zhou, Zilu and Marathi, Ramya and Wang, Xiaoming and Harrell, Frank E. and Lasko, Thomas A. and Denny, Joshua C. and Roden, Dan M. and Peterson, Josh F. and Schildcrout, Jonathan S.},
  date = {2019},
  journaltitle = {MDM Policy Pract},
  volume = {4},
  number = {2},
  eprint = {31453360},
  eprinttype = {pmid},
  pages = {2381468319864337},
  issn = {2381-4683},
  doi = {10.1177/2381468319864337},
  abstract = {We discuss a decision-theoretic approach to building a panel-based, preemptive genotyping program. The method is based on findings that a large percentage of patients are prescribed medications that are known to have pharmacogenetic associations, and over time, a substantial proportion are prescribed additional such medication. Preemptive genotyping facilitates genotype-guided therapy at the time medications are prescribed; panel-based testing allows providers to reuse previously collected genetic data when a new indication arises. Because it is cost-prohibitive to conduct panel-based genotyping on all patients, we describe a three-step approach to identify patients with the highest anticipated benefit. First, we construct prediction models to estimate the risk of being prescribed one of the target medications using readily available clinical data. Second, we use literature-based estimates of adverse event rates, variant allele frequencies, secular death rates, and costs to construct a discrete event simulation that estimates the expected benefit of having an individual's genetic data in the electronic health record after an indication has occurred. Finally, we combine medication prescription risk with expected benefit of genotyping once a medication is indicated to calculate the expected benefit of preemptive genotyping. For each patient-clinic visit, we calculate this expected benefit across a range of medications and select patients with the highest expected benefit overall. We build a proof of concept implementation using a cohort of patients from a single academic medical center observed from July 2010 through December 2012. We then apply the results of our modeling strategy to show the extent to which we can improve clinical and economic outcomes in a cohort observed from January 2013 through December 2015.},
  langid = {english},
  pmcid = {PMC6699004},
  keywords = {methodology}
}

@article{shi21pow,
  title = {On the Power of {{Chatterjee}}’s Rank Correlation},
  author = {Shi, H and Drton, M and Han, F},
  date = {2021-04-29},
  journaltitle = {Biometrika},
  issn = {0006-3444},
  doi = {10.1093/biomet/asab028},
  url = {https://doi.org/10.1093/biomet/asab028},
  urldate = {2021-04-29},
  abstract = {Chatterjee (2021+) introduced a simple new rank correlation coefficient that has attracted much recent attention. The coefficient has the unusual appeal that it not only estimates a population quantity first proposed by Dette et al. (2013) that is zero if and only if the underlying pair of random variables is independent, but also is asymptotically normal under independence. This paper compares Chatterjee’s new correlation coefficient to three established rank correlations that also facilitate consistent tests of independence, namely, Hoeffding’s D, Blum–Kiefer– Rosenblatt’s R, and Bergsma–Dassios–Yanagimoto’s τ *. We contrast their computational efficiency in light of recent advances, and investigate their power against local rotation and mixture alternatives. Our main results show that Chatterjee’s coefficient is unfortunately rate sub-optimal compared to D, R, and τ *. The situation is more subtle for a related earlier estimator of Dette et al. (2013). These results favor D, R, and τ * over Chatterjee’s new correlation coefficient for the purpose of testing independence.},
  issue = {asab028},
  keywords = {correlation,hoeffding-test,rank-correlation}
}

@article{shi89,
  title = {The Analysis of Titration Studies in Phase {{III}} Clinical Trials},
  author = {Shih, Wj and Gould, Al and Hwang, Ik},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {583--591},
  citeulike-article-id = {13264847},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {pharmaceutical}
}

@article{shi97des,
  title = {Design for Sample Size Re-Estimation with Interim Data for Double-Blind Clinical Trials with Binary Outcomes},
  author = {Shih, Weichung J. and Zhao, Peng-Liang},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1913--1923},
  citeulike-article-id = {13264848},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {blinding,extending-a-study,internal-pilot-study,re-estimation-of-sample-size,response-rates,study-design}
}

@article{shi97tes,
  title = {Testing for Treatment Differences with Dropouts Present in Clinical Trials---{{A}} Composite Approach},
  author = {Shih, Weichung J. and Quan, Hui},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1225--1239},
  citeulike-article-id = {13264849},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {missing-data,serial-measurements},
  note = {use of means for completers along with probability of completion as opposed to hypothetical complete-data marginal means}
}

@article{shi98not,
  title = {A Note on Transforming a Response Variable to Linearity},
  author = {Shi, Peide and Fung, Wing-Kam},
  date = {1998},
  journaltitle = {Biometrika},
  volume = {85},
  pages = {749--754},
  citeulike-article-id = {13264850},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {b-spline,box-cox,canonical-correlation,canonical-variate,see-he97lin,simpler-approaches,transformation,transforming-left-hand-side}
}

@article{shr00bay,
  title = {A {{Bayesian-bandit}} Adaptive Design for {{N-of-1}} Clinical Trials},
  author = {Shrestha, Sama and Jain, Sonia},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8873},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8873},
  urldate = {2021-01-30},
  abstract = {N-of-1 trials, which are randomized, double-blinded, controlled, multiperiod, crossover trials on a single subject, have been applied to determine the heterogeneity of the individual's treatment effect in precision medicine settings. An aggregated N-of-1 design, which can estimate the population effect from these individual trials, is a pragmatic alternative when a randomized controlled trial (RCT) is infeasible. We propose a Bayesian adaptive design for both the individual and aggregated N-of-1 trials using a multiarmed bandit framework that is estimated via efficient Markov chain Monte Carlo. A Bayesian hierarchical structure is used to jointly model the individual and population treatment effects. Our proposed adaptive trial design is based on Thompson sampling, which randomly allocates individuals to treatments based on the Bayesian posterior probability of each treatment being optimal. While we use a subject-specific treatment effect and Bayesian posterior probability estimates to determine an individual's treatment allocation, our hierarchical model facilitates these individual estimates to borrow strength from the population estimates via shrinkage to the population mean. We present the design's operating characteristics and performance via a simulation study motivated by a recently completed N-of-1 clinical trial. We demonstrate that from a patient-centered perspective, subjects are likely to benefit from our adaptive design, in particular, for those individuals that deviate from the overall population effect.},
  langid = {english},
  keywords = {adaptive,bayes,n-of-1-trial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8873}
}

@article{shu05dia,
  title = {Diagnostics for Assumptions in Moderate to Large Simple Clinical Trials: Do They Really Help?},
  author = {Shuster, Jonathan J.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2431--2438},
  doi = {10.1002/sim.2175},
  url = {http://dx.doi.org/10.1002/sim.2175},
  citeulike-article-id = {13265433},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2175},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {assumptions,clinical-trials,permutation-test,rct,rerandomization,sap},
  note = {statistical analysis plan should be more locked-in; multi-step strategy of testing for equality of variances can make the final treatment comparison more conservative;the paper's conclusion that parametric tests are asymptotically robust is not fully warranted. We don't know what asymptotic means for a given dataset, and it ignores the poor power that parametric tests have when extreme skewness or kurtosis is present. Many students are confused by the central limit theorem, thinking it applies to both type I and II errors when it only applies to type I. There is another hazard to multi-step approaches, related to not preserving type I error. Companies may sometimes "forget" about their intention to test for normality, for example, if the t-test is significant.}
}

@article{shu21exp,
  title = {Exploration of an Alternative to Body Mass Index to Characterize the Relationship between Height and Weight for Prediction of Metabolic Phenotypes and Cardiovascular Outcomes},
  author = {Shuey, Megan M. and Huang, Shi and Levinson, Rebecca T. and Farber-Eger, Eric and Cahill, Katherine N. and Beckman, Joshua A. and Koethe, John R. and Silver, Heidi J. and Niswender, Kevin D. and Cox, Nancy J. and Harrell, Frank E. and Wells, Quinn S.},
  date = {2021},
  journaltitle = {Obesity Science \& Practice},
  volume = {n/a},
  number = {n/a},
  issn = {2055-2238},
  doi = {10.1002/osp4.543},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/osp4.543},
  urldate = {2021-08-17},
  abstract = {Objective Body mass index (BMI) is the most commonly used predictor of weight-related comorbidities and outcomes. However, the presumed relationship between height and weight intrinsic to BMI may introduce bias with respect to prediction of clinical outcomes. A series of analyses comparing the performance of models representing weight and height as separate interacting variables to models using BMI were performed using Vanderbilt University Medical Center's deidentified electronic health records and landmark methodology. Methods Use of BMI or height-weight interaction in prediction models for established weight-related cardiometabolic traits and metabolic syndrome was evaluated. Specifically, prediction models for hypertension, diabetes mellitus, low high-density lipoprotein, and elevated triglycerides, atrial fibrillation, coronary artery disease, heart failure, and peripheral artery disease were developed. Model performance was evaluated using likelihood ratio, R2, and Somers' Dxy rank correlation. Differences in model predictions were visualized using heat maps. Results Compared to BMI, the maximally flexible height-weight interaction model demonstrated improved prediction, higher likelihood ratio, R2, and Somers' Dxy rank correlation, for event-free probability for all outcomes. The degree of improvement to the prediction model differed based on the outcome and across the height and weight range. Conclusions Because alternative measures of body composition such as waist-to-hip ratio are not routinely collected in the clinic clinical risk models quantifying risk based on height and weight measurements alone are essential to improve practice. Compared to BMI, modeling height and weight as independent, interacting variables results in less bias and improved predictive accuracy for all tested traits. Considering an individual's height and weight opposed to BMI is a better method for quantifying individual disease risk.},
  langid = {english},
  keywords = {bmi,collaboration,cv},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/osp4.543}
}

@article{shy03sta,
  title = {Statistical Strategies for Analyzing the Microarray Data in Human Lung Cancer},
  author = {Shyr, Y.},
  date = {2003},
  journaltitle = {Lung Ca},
  volume = {41},
  pages = {90--91},
  citeulike-article-id = {13265503},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{sid08mul,
  title = {Multiple Imputation Using an Iterative Hot-Deck with Distance-Based Donor Selection},
  author = {Siddique, Juned},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {83--102},
  citeulike-article-id = {13265659},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {approximate-bayesian-bootstrap,distance-weighting,implicit-model,missing-data,pmm,predictive-mean-matching}
}

@book{sie85seq,
  title = {Sequential {{Analysis}}: {{Tests}} and {{Confidence Intervals}}},
  author = {Siegmund, D.},
  date = {1985},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13265744},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@article{sie89cli,
  title = {Clinical Correlates and Prognostic Significance of {{Type A}} Behavior and Silent Myocardial Ischemia on the Treadmill},
  author = {Siegel, W. C. and Mark, D. B. and Hlatky, M. A. and Harrell FE, D. B. and Barefoot, J. C. and Williams, R. B.},
  date = {1989},
  journaltitle = {Am J Card},
  volume = {64},
  pages = {1280--1283},
  citeulike-article-id = {13264851},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{sie90eff,
  title = {Effect of Type {{A}} Behavior on Exercise Test Outcome in Coronary Artery Disease},
  author = {Siegel, W. C. and Hlatky, M. A. and Mark, D. B. and Barefoot, J. C. and Harrell, F. E. and Pryor, D. B. and Williams, R. B.},
  date = {1990},
  journaltitle = {Am J Card},
  volume = {66},
  pages = {179--182},
  citeulike-article-id = {13264852},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{sie96rec,
  title = {Recommendations for Reporting Cost-Effectiveness Analyses},
  author = {Siegel, J. E. and Weinstein, M. C. and Russell, L. B. and Gold, M. R. and {The Panel on Cost-Effectiveness in Health and Medicine}},
  date = {1996},
  journaltitle = {JAMA},
  volume = {276},
  pages = {1339--1341},
  citeulike-article-id = {13264853},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {cost-effectiveness,economic-evaluation,teaching-mds}
}

@article{sie96sta,
  title = {Statistical Methods for Cost-Effectiveness Analyses},
  author = {Siegel, Carole and Laska, Eugene and Meisner, Morris},
  date = {1996},
  journaltitle = {Controlled Clin Trials},
  volume = {17},
  pages = {387--406},
  citeulike-article-id = {13264854},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {c-e-preference,cost-effectiveness,cost-utility,economic-study,non-responder-models}
}

@article{sig99tre,
  title = {Treatment Effects in a Logistic Model Involving the {{Box-Cox}} Transformation},
  author = {Sigueira, Arminda L. and Taylor, Jeremy M. G.},
  date = {1999},
  journaltitle = {J Am Stat Assoc},
  volume = {94},
  pages = {240--246},
  citeulike-article-id = {13264855},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  note = {Box-Cox transformation of a covariable;validity of inference for treatment effect when treat exponent for covariable as fixed}
}

@book{sil12sig,
  title = {The {{Signal}} and the {{Noise}}: {{Why So Many Predictions Fail--but Some Don}}'t},
  author = {Silver, Nate},
  date = {2012},
  edition = {1},
  publisher = {{Penguin Books}},
  url = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0143125087},
  citeulike-article-id = {13675156},
  citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0143125087},
  citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0143125087},
  citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0143125087},
  citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0143125087},
  citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0143125087/citeulike00-21},
  citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0143125087},
  citeulike-linkout-6 = {http://www.worldcat.org/isbn/0143125087},
  citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0143125087},
  citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0143125087&index=books&linkCode=qs},
  citeulike-linkout-9 = {http://www.librarything.com/isbn/0143125087},
  howpublished = {Paperback},
  isbn = {0-14-312508-7},
  posted-at = {2016-11-07 13:36:07},
  priority = {0},
  keywords = {bayesian-inference,prediction}
}

@article{sil95com,
  title = {Comparing the Contributions of Groups of Predictors: {{Which}} Outcomes Vary with Hospital Rather than Patient Characteristics?},
  author = {Silber, Jeffrey H. and Rosenbaum, Paul R. and Ross, Richard N.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  citeulike-article-id = {13264856},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {hospital-outliers,hospital-quality-control,logistic-model-residuals,mortality-models,variation-explained}
}

@article{sil97non,
  title = {Nonparametric Classes of Weight Functions to Model Publication Bias},
  author = {Silliman, Nancy P.},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {909--918},
  citeulike-article-id = {13264857},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {meta-analysis,publication-bias}
}

@article{sim10lin,
  title = {A Linear Exponent {{AR}}(1) Family of Correlation Structures},
  author = {Simpson, Sean L. and Edwards, Lloyd J. and Muller, Keith E. and Sen, Pranab K. and Styner, Martin A.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {1825--1838},
  citeulike-article-id = {13265836},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {correlation-structure,longitudinal-model,repeated-measurements,serial-data}
}

@article{sim12siz,
  title = {The Size of a Pilot Study for a Clinical Trial Should Be Calculated in Relation to Considerations of Precision and Efficiency},
  author = {Sim, J. and Lewis, M.},
  date = {2012-03},
  journaltitle = {J Clin Epi},
  volume = {65},
  pages = {301--308},
  doi = {10.1016/j.jclinepi.2011.07.011},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2011.07.011},
  abstract = {To investigate methods to determine the size of a pilot study to inform a power calculation for a randomized controlled trial (RCT) using an interval/ratio outcome measure.  Calculations based on confidence intervals (CIs) for the sample standard deviation (SD).  Based on CIs for the sample SD, methods are demonstrated whereby (1) the observed SD can be adjusted to secure the desired level of statistical power in the main study with a specified level of confidence; (2) the sample for the main study, if calculated using the observed SD, can be adjusted, again to obtain the desired level of statistical power in the main study; (3) the power of the main study can be calculated for the situation in which the SD in the pilot study proves to be an underestimate of the true SD; and (4) an "efficient" pilot size can be determined to minimize the combined size of the pilot and main RCT.  Trialists should calculate the appropriate size of a pilot study, just as they should the size of the main RCT, taking into account the twin needs to demonstrate efficiency in terms of recruitment and to produce precise estimates of treatment effect.},
  citeulike-article-id = {13265921},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2011.07.011},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {pilot,pilot-study,rct,sample-size,study-design}
}

@article{sim13spa,
  title = {A Sparse-Group Lasso},
  author = {Simon, Noah and Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  date = {2013},
  journaltitle = {J Comp Graph Stat},
  volume = {22},
  number = {2},
  eprint = {http://www.tandfonline.com/doi/pdf/10.1080/10618600.2012.681250},
  pages = {231--245},
  doi = {10.1080/10618600.2012.681250},
  url = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2012.681250},
  abstract = {For high-dimensional supervised learning problems, often using problem-specific assumptions can lead to greater accuracy. For problems with grouped covariates, which are believed to have sparse effects both on a group and within group level, we introduce a regularized model for linear regression with l1 and l2 penalties. We discuss the sparsity and other regularization properties of the optimal fit for this model, and show that it has the desired effect of group-wise and within group sparsity. We propose an algorithm to fit the model via accelerated generalized gradient descent, and extend this model and algorithm to convex loss functions. We also demonstrate the efficacy of our model and the efficiency of our algorithm on simulated data. This article has online supplementary material.},
  citeulike-article-id = {13265969},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/10618600.2012.681250},
  citeulike-linkout-1 = {http://www.tandfonline.com/doi/abs/10.1080/10618600.2012.681250},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  note = {sparse effects both on a group and within group levels;can also be considered special case of group lasso allowing overlap between groups}
}

@article{sim84non,
  title = {A Non-Parametric Graphical Representation of the Relationship between Survival and the Occurrence of an Event: {{Application}} to Responder versus Non-Responder Bias},
  author = {Simon, Richard and Makuch, Robert W.},
  date = {1984},
  journaltitle = {Stat Med},
  volume = {3},
  pages = {35--44},
  citeulike-article-id = {13264858},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {left-truncation,responder-bias}
}

@article{sim86con,
  title = {Confidence Intervals for Reporting Results of Clinical Trials},
  author = {Simon, Richard},
  date = {1986},
  journaltitle = {Ann Int Med},
  volume = {105},
  pages = {429--435},
  doi = {10.7326/0003-4819-105-3-429},
  url = {http://dx.doi.org/10.7326/0003-4819-105-3-429},
  citeulike-article-id = {13264859},
  citeulike-linkout-0 = {http://dx.doi.org/10.7326/0003-4819-105-3-429},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {confidence-intervals,reporting-clinical-trials,teaching-mds}
}

@article{sim86imp,
  title = {An Improved {{Bonferroni}} Procedure for Multiple Tests of Significance},
  author = {Simes, R. J.},
  date = {1986},
  journaltitle = {Biometrika},
  volume = {73},
  pages = {751--754},
  citeulike-article-id = {13264860},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bonferroni,multiple-comparison-procedures,p-value-adjustments,simultaneous-tests}
}

@article{sim97bay,
  title = {Bayesian Design and Analysis of Two Two Factorial Clinical Trials},
  author = {Simon, Richard and Freedman, Laurence S.},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {456--464},
  keywords = {bayesian-inference,differential-treatment-effect,factorial-design,interaction,interaction-test,prior-distribution-for-interaction-effect,study-design}
}

@article{sim97unu,
  title = {The “{{Unusual Episode}}” and a Second Statistics Course},
  author = {Simonoff, J. S.},
  date = {1997},
  journaltitle = {J Stat Edu},
  volume = {5},
  number = {1},
  citeulike-article-id = {13265155},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {categorical-analysis-of-titanic},
  annotation = {Online journal at www.amstat.­org/­publications/­jse/­v5n1/­simonoff.­html}
}

@article{sin21rec,
  title = {Recent Health-Related Quality of Life, but Not Change, Predicted Mortality and Healthcare Utilization: {{Health-related}} Quality of Life Is a Predictor of Mortality and Utilization},
  shorttitle = {Recent Health-Related Quality of Life, but Not Change, Predicted Mortality and Healthcare Utilization},
  author = {Singh, Jasvinder A. and Nelson, David B. and Nichol, Kristin L.},
  date = {2021-08-22},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.08.023},
  url = {https://www.jclinepi.com/article/S0895-4356(21)00268-7/abstract},
  urldate = {2021-08-22},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objective{$<$}/h3{$><$}p{$>$}To assess whether change in HRQOL over a seven-year period was associated with subsequent mortality and hospitalization, after adjusting for important covariates, in a cohort of U.S. Veterans.{$<$}/p{$><$}h3{$>$}Methods{$<$}/h3{$><$}p{$>$}We used data from a cohort of Veterans who completed a HRQOL survey in 1998 (Short-Form 36 for Veterans [SF-36V]) and a 2006 follow-up (SF-12V) HRQOL survey and SF12V scores were calculated at both time-points. We used logistic regression analyses to model the relationship between changes in the SF12-V physical component (PCS) and mental health component (MCS) scores and 1-year hospitalization and 1-year and 3.3-year mortality after the 2006 follow-up survey.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}13,900 participants provided data for both the initial and follow-up surveys. We found no significant associations between changes in PCS or MCS and one-year hospitalization after adjusting for follow-up HRQOL and other covariates. We found significant but relatively weak associations between changes in MCS and our mortality outcomes.{$<$}/p{$><$}h3{$>$}Conclusions{$<$}/h3{$><$}p{$>$}Given the follow-up MCS and PCS, change in PCS over the previous 7 years added little information for predicting mortality and hospitalization while the change in MCS added some information for predicting mortality. Therefore, knowledge of patient's current HRQOL generally provides meaningful information for predicting subsequent mortality and hospitalization.{$<$}/p{$>$}},
  langid = {english},
  keywords = {change,change-score,qol}
}

@article{sin21tun,
  title = {To Tune or Not to Tune, a Case Study of Ridge Logistic Regression in Small or Sparse Datasets},
  author = {Šinkovec, Hana and Heinze, Georg and Blagus, Rok and Geroldinger, Angelika},
  date = {2021-09-30},
  journaltitle = {BMC Medical Research Methodology},
  volume = {21},
  number = {1},
  pages = {199},
  issn = {1471-2288},
  doi = {10.1186/s12874-021-01374-y},
  url = {https://doi.org/10.1186/s12874-021-01374-y},
  urldate = {2021-10-06},
  abstract = {For finite samples with binary outcomes penalized logistic regression such as ridge logistic regression has the potential of achieving smaller mean squared errors (MSE) of coefficients and predictions than maximum likelihood estimation. There is evidence, however, that ridge logistic regression can result in highly variable calibration slopes in small or sparse data situations.},
  keywords = {penalization,pmle,shrinkage,stability}
}

@article{sin91mod,
  title = {Modeling the Days of Our Lives: {{Using}} Survival Analysis When Designing and Analyzing Longitudinal Studies of Duration and the Timing of Events},
  author = {Singer, Judith D. and Willett, John B.},
  date = {1991},
  journaltitle = {Psych Bull},
  volume = {110},
  pages = {268--290},
  citeulike-article-id = {13264862},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{sin93gra,
  title = {Graphical Display of Categorical Data},
  author = {Singer, Peter A. and Feinstein, Alvan R.},
  date = {1993},
  journaltitle = {J Clin Epi},
  volume = {46},
  pages = {231--236},
  doi = {10.1016/0895-4356(93)90070-H},
  url = {http://dx.doi.org/10.1016/0895-4356(93)90070-H},
  citeulike-article-id = {13264863},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0895-4356(93)90070-H},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {dot-charts,graphics,teaching-mds}
}

@article{sin94cli,
  title = {Clinically Useful Measures of Effect in Binary Analyses of Randomized Trials},
  author = {Sinclair, John C. and Bracken, Michael B.},
  date = {1994},
  journaltitle = {J Clin Epi},
  volume = {47},
  pages = {881--889},
  citeulike-article-id = {13264864},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {odds-ratio-vs-risk-difference}
}

@article{sin97reg,
  title = {Regression Models for the Analysis of Pretest/Posttest Data},
  author = {Singer, Julio M. and Andrade, Dalton F.},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {729--735},
  doi = {10.2307/2533973},
  url = {http://dx.doi.org/10.2307/2533973},
  citeulike-article-id = {13264865},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2533973},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {analysis-of-change,baseline-measurement-as-covariable,change,multiplicative-model,pretest-posttest,repeated-measures,serial-data,teaching-mds},
  note = {problems with using baseline measurement as covariate}
}

@article{sin97sem,
  title = {Semiparametric {{Bayesian}} Analysis of Survival Data},
  author = {Sinha, Debajyoti and Dey, Dipak K.},
  date = {1997},
  journaltitle = {J Am Stat Assoc},
  volume = {92},
  pages = {1195--1212},
  citeulike-article-id = {13264866},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bayesian-inference,survival-models}
}

@article{siv19len,
  title = {Is {{Length}} of {{Stay Influenced}} by the {{Weekday On Which Lumbar Surgery}} Is {{Performed}}?},
  author = {Sivaganesan, Ahilan and Devin, Clinton J. and Khan, Inamullah and Kerezoudis, Panagiotis and Nian, Hui and Harrell, Frank E. and Bydon, Mohamad and Asher, Anthony L.},
  date = {2019-10-01},
  journaltitle = {Neurosurgery},
  volume = {85},
  number = {4},
  eprint = {30165453},
  eprinttype = {pmid},
  pages = {494--499},
  issn = {1524-4040},
  doi = {10.1093/neuros/nyy382},
  abstract = {BACKGROUND: Reducing length of stay (LOS) in a safe manner has the potential to save significant costs for the care of patients undergoing elective lumbar spine surgery. Due to the relative absence on weekends of staff required for discharging patients to rehabilitation or nursing facilities, we hypothesize that patients undergoing lumbar surgery later in the week have a longer LOS than their counterparts. OBJECTIVE: To analyze the effect of day of the week for lumbar surgery on LOS. METHODS: Patients undergoing surgery for lumbar degenerative disease were prospectively enrolled in the multicenter quality and outcomes database registry. A multivariable proportional odds regression model was built with LOS as the outcome of interest and patient and surgical variables as covariates. RESULTS: A total of 11 897 patients were analyzed. Among those discharged home, the regression analysis demonstrated significantly higher odds of longer LOS for patients undergoing surgery on Friday as compared to Monday (P~{$<~$}.001). Among those discharged to a facility, there were significantly higher odds of longer LOS for patients undergoing surgery on Wednesday (P~{$<~$}.001), Thursday (P~{$<~$}.001), and Friday (P~=~.002) as compared to Monday. CONCLUSION: The findings of this study suggest that lumbar patients undergoing fusions and those discharged to a facility have longer LOS when surgery is later in the week. Scheduling these patients for surgery earlier in the week and ensuring adequate resources for patient disposition on weekends may lead to LOS reduction and cost savings for hospitals, payers, and patients alike.},
  langid = {english},
  keywords = {collaboration}
}

@article{siv19pre,
  title = {Predictive {{Model}} for {{Medical}} and {{Surgical Readmissions Following Elective Lumbar Spine Surgery}}: {{A National Study}} of 33,674 {{Patients}}},
  shorttitle = {Predictive {{Model}} for {{Medical}} and {{Surgical Readmissions Following Elective Lumbar Spine Surgery}}},
  author = {Sivaganesan, Ahilan and Zuckerman, Scott and Khan, Inamullah and Nian, Hui and Harrell, Frank E. and Pennings, Jacquelyn S. and Harbaugh, Robert and Foley, Kevin T. and Bydon, Mohamad and Asher, Anthony L. and Devin, Clinton J. and Archer, Kristin R.},
  date = {2019-04-15},
  journaltitle = {Spine (Phila Pa 1976)},
  volume = {44},
  number = {8},
  eprint = {30247371},
  eprinttype = {pmid},
  pages = {588--600},
  issn = {1528-1159},
  doi = {10.1097/BRS.0000000000002883},
  abstract = {STUDY DESIGN: This study retrospectively analyzes prospectively collected data. OBJECTIVE: Here we aim to develop predictive models for 3-month medical and surgical readmission after elective lumbar surgery, based on a multi-institutional, national spine registry. SUMMARY OF BACKGROUND DATA: Unplanned readmissions place considerable stress on payers, hospitals, and patients. Medicare data reveals a 30-day readmission rate of 7.8\% for lumbar-decompressions and 13.0\% for lumbar-fusions, and hospitals are now being penalized for excessive 30-day readmission rates by virtue of the Hospital Readmissions Reduction Program. METHODS: The Quality and Outcomes Database (QOD) was queried for patients undergoing elective lumbar surgery for degenerative diseases. The QOD prospectively captures 3-month readmissions through electronic medical record (EMR) review and self-reported outcome questionnaires. Distinct multivariable logistic regression models were fitted for surgery-related and medical readmissions adjusting for patient and surgery-specific variables. RESULTS: Of the total 33,674 patients included in this study 2079 (6.15\%) reported at least one readmission during the 90-day postoperative period. The odds of medical readmission were significantly higher for older patients, males versus females, African Americans versus Caucasion, those with higher American Society of Anesthesiologists (ASA) grade, diabetes, coronary artery disease, higher numbers of involved levels, anterior only or anterior-posterior versus posterior approach; also, for patients who were unemployed compared with employed patients and those with high baseline Oswestry Disability Index (ODI). The odds of surgery-related readmission were significantly greater for patients with a higher body mass index (BMI), a higher ASA grade, female versus male, and African Americans versus Caucasians; also, for patients with severe depression, more involved spinal levels, anterior-only surgical approaches and higher baseline ODI scores. CONCLUSION: In this study we present internally validated predictive models for medical and surgical readmission after elective lumbar spine surgery. These findings set the stage for targeted interventions with a potential to reduce unnecessary readmissions, and also suggest that medical and surgical readmissions be treated as distinct clinical events. LEVEL OF EVIDENCE: 3.},
  langid = {english},
  keywords = {collaboration}
}

@article{siv19str,
  title = {A {{Strategy}} for {{Risk-adjusted Ranking}} of {{Surgeons}} and {{Practices Based}} on {{Patient-reported Outcomes After Elective Lumbar Surgery}}},
  author = {Sivaganesan, Ahilan and Asher, Anthony L. and Bydon, Mohamad and Khan, Inamullah and Kerezoudis, Panagoitis and Foley, Kevin T. and Nian, Hui and Harrell, Frank E. and Archer, Kristin R. and Devin, Clinton J.},
  date = {2019-05-01},
  journaltitle = {Spine (Phila Pa 1976)},
  volume = {44},
  number = {9},
  eprint = {30312268},
  eprinttype = {pmid},
  pages = {670--677},
  issn = {1528-1159},
  doi = {10.1097/BRS.0000000000002894},
  abstract = {STUDY DESIGN: This study retrospectively analyzes prospectively collected data. OBJECTIVE: The primary aim of this study is to present a scheme for patient-reported outcome (PRO)-based, risk-adjusted rankings of spine surgeons and sites that perform elective lumbar surgery, using the Quality and Outcomes Database (QOD). SUMMARY OF BACKGROUND DATA: There is currently no means of determining which spine surgeons or centers are positive or negative outliers with respect to PROs for elective lumbar surgery. This is a critical gap as we move toward a value-based model of health care in which providers assume more accountability for the effectiveness of their treatments. METHODS: Random effects regression models were fit for the following outcomes, with QOD site as a fixed effect but surgeon ID as a random effect: Oswestry Disability Index, EQ-5D, back pain and leg pain, and satisfaction. Hierarchical Bayesian models were also fit for each outcome, with QOD site as a random effect and surgeon as a nested random effect. RESULTS: Our study cohort consists of 8834 patients who underwent surgery by 124 QOD surgeons, for the degenerative lumbar diseases. Nonoverlapping Bayesian credible intervals demonstrate that the variance attributed to QOD site was greater than the nested variance attributed to surgeon ID for the included PROs. CONCLUSION: This study presents a novel strategy for the risk-adjusted, PRO-based ranking of spine surgeons and practices. This can help identify positive and negative outliers, thereby forming the basis for large-scale quality improvement. Assuming adequate coverage of baseline risk adjustment, the choice of surgeon matters when considering PROs after lumbar surgery; however, the choice of site appears to matter more. LEVEL OF EVIDENCE: 3.},
  langid = {english},
  keywords = {collaboration}
}

@article{sjo13ign,
  title = {Ignoring the Matching Variables in Cohort Studies - When Is It Valid and Why?},
  author = {Sjölander, Arvid and Greenland, Sander},
  date = {2013-11},
  journaltitle = {Stat Med},
  volume = {32},
  number = {27},
  eprint = {23761197},
  eprinttype = {pmid},
  pages = {4696--4708},
  issn = {1097-0258},
  doi = {10.1002/sim.5879},
  url = {http://dx.doi.org/10.1002/sim.5879},
  abstract = {In observational studies of the effect of an exposure on an outcome, the exposure–outcome association is usually confounded by other causes of the outcome (potential confounders). One common method to increase efficiency is to match the study on potential confounders. Matched case-control studies are relatively common and well covered by the literature. Matched cohort studies are less common but do sometimes occur. It is often argued that it is valid to ignore the matching variables, in the analysis of matched cohort data. In this paper, we provide analyses delineating the scope and limits of this argument. We discuss why the argument does not carry over to effect estimation in matched case-control studies, although it does carry over to null-hypothesis testing. We also show how the argument does not extend to matched cohort studies when one adjusts for additional confounders in the analysis. Ignoring the matching variables can sometimes reduce variance, even though this is not guaranteed. We investigate the trade-off between bias and variance in deciding whether adjustment for matching factors is advisable.},
  citeulike-article-id = {12464813},
  citeulike-attachment-1 = {sjo13ign.pdf; /pdf/user/harrelfe/article/12464813/995435/sjo13ign.pdf; c3b8cb6b574e6b80e53d08ba516da3e8d6c4800b},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5879},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/23761197},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=23761197},
  day = {30},
  posted-at = {2014-11-24 12:37:42},
  priority = {2},
  keywords = {covariable-adjustment,covariate-adjustment,matching},
  note = {From the Conclusion section: “…ignoring the matching variables ina cohort study can leave bias if there are additional confounders, even with adjustment for the additionalconfounders. This bias can be avoided by adjusting for the matching variables.For linear and logistic models, we have shown that the bias induced by ignoring the matching vari-ables can be outweighed by variance reduction, but this is not guaranteed. For linear models we observedthat on average we tend to increase MSE when ignoring the matching variable. For logistic models weobserved no major impact on average of ignoring the matching variable. Thus, as a tentative heuristicwe would recommend some adjustment for the matching variables when analyzing matched cohort data,although a matched analyses per se is not needed.”}
}

@article{sla87out,
  title = {Outcome in Suspected Acute Myocardial Infarction with Normal or Minimally Abnormal Admission Electrocardiographic Findings},
  author = {Slater, D. K. and Hlatky, M. A. and Mark, D. B. and Harrell, F. E. and Pryor, D. B. and Califf, R. M.},
  date = {1987},
  journaltitle = {Am J Card},
  volume = {60},
  pages = {766--770},
  citeulike-article-id = {13264867},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{sle90,
  title = {Regression Splines in the {{Cox}} Model with Application to Covariate Effects in Liver Disease},
  author = {Sleeper, L. A. and Harrington, D. P.},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {941--949},
  citeulike-article-id = {13264868},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{slu97sem,
  title = {Semiparametric Two-Sample Tests in Clinical Trials with a Post-Randomization Response Indicator},
  author = {Slud, Eric V. and Korn, Edward L.},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {221--230},
  citeulike-article-id = {13264869},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {auxiliary-endpoints,cox-model,partial-likelihood,stratification,surrogate-endpoints,two-stage-estimation-of-survival-probabilities-using-a-surrogate-endpoint}
}

@article{sme21cli,
  title = {Clinical Prediction Models: Diagnosis versus Prognosis},
  shorttitle = {Clinical Prediction Models},
  author = {van Smeden, Maarten and Reitsma, Johannes B. and Riley, Richard D. and Collins, Gary S. and Moons, Karel GM},
  date = {2021-04-01},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {132},
  pages = {142--145},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.01.009},
  url = {https://www.jclinepi.com/article/S0895-4356(21)00013-5/abstract},
  urldate = {2021-03-29},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}p{$>$}Clinical prediction models play an increasingly important role in contemporary clinical care, by informing healthcare professionals, patients and their relatives about outcome risks, with the aim to facilitate (shared) medical decision making and improve health outcomes. Diagnostic prediction models aim to calculate an individual's risk that a disease is already present, whilst prognostic prediction models aim to calculate the risk of particular heath states occurring in the future. This article serves as a primer for diagnostic and prognostic clinical prediction models, by discussing the basic terminology, some of the inherent challenges, and the need for validation of predictive performance and the evaluation of impact of these models in clinical care.{$<$}/p{$>$}},
  langid = {english},
  keywords = {clinical-prediction,diagnosis,prognosis,teaching-mds}
}

@article{smi03for,
  title = {Foreword to the Papers on `{{The}} Communication of Risk'},
  author = {Smith, Adrian},
  date = {2003},
  journaltitle = {J Roy Stat Soc A},
  pages = {205--206},
  citeulike-article-id = {13265343},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {risk-communication},
  note = {`I think it should be compulsory for all statisticians to study a little brochure issued by the Science Media Centre, entitled 'Communicating Risk in a Soundbite: A Guide for Scientists' (see http://www.ScienceMediaCentre.org). This provides a wonderfully succinct overview of do's and don'ts in communicating quantitative information."}
}

@article{smi11epi,
  title = {Epidemiology, Epigenetics and the '{{Gloomy Prospect}}': Embracing Randomness in Population Health Research and Practice},
  author = {Smith, George D.},
  date = {2011-06},
  journaltitle = {Int J Epi},
  volume = {40},
  number = {3},
  eprint = {21807641},
  eprinttype = {pmid},
  pages = {537--562},
  publisher = {Oxford University Press},
  issn = {1464-3685},
  doi = {10.1093/ije/dyr117},
  url = {http://dx.doi.org/10.1093/ije/dyr117},
  abstract = {Epidemiologists aim to identify modifiable causes of disease, this often being a prerequisite for the application of epidemiological findings in public health programmes, health service planning and clinical medicine. Despite successes in identifying causes, it is often claimed that there are missing additional causes for even reasonably well-understood conditions such as lung cancer and coronary heart disease. Several lines of evidence suggest that largely chance events, from the biographical down to the sub-cellular, contribute an important stochastic element to disease risk that is not epidemiologically tractable at the individual level. Epigenetic influences provide a fashionable contemporary explanation for such seemingly random processes. Chance events—such as a particular lifelong smoker living unharmed to 100 years—are averaged out at the group level. As a consequence population-level differences (for example, secular trends or differences between administrative areas) can be entirely explicable by causal factors that appear to account for only a small proportion of individual-level risk. In public health terms, a modifiable cause of the large majority of cases of a disease may have been identified, with a wild goose chase continuing in an attempt to discipline the random nature of the world with respect to which particular individuals will succumb. The quest for personalized medicine is a contemporary manifestation of this dream. An evolutionary explanation of why randomness exists in the development of organisms has long been articulated, in terms of offering a survival advantage in changing environments. Further, the basic notion that what is near-random at one level may be almost entirely predictable at a higher level is an emergent property of many systems, from particle physics to the social sciences. These considerations suggest that epidemiological approaches will remain fruitful as we enter the decade of the epigenome.},
  citeulike-article-id = {9708027},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/ije/dyr117},
  citeulike-linkout-1 = {http://ije.oxfordjournals.org/content/40/3/537.abstract},
  citeulike-linkout-2 = {http://ije.oxfordjournals.org/content/40/3/537.full.pdf},
  citeulike-linkout-3 = {http://www.ingentaconnect.com/content/oup/ije/2011/00000040/00000003/art00002},
  citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/21807641},
  citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=21807641},
  day = {1},
  posted-at = {2018-06-21 16:08:33},
  priority = {0},
  keywords = {epidemiology,genetics,personalized-medicine}
}

@article{smi18app,
  title = {Applications of {{Bayesian}} Statistical Methodology to Clinical Trial Design: {{A}} Case Study of a Phase 2 Trial with an Interim Futility Assessment in Patients with Knee Osteoarthritis},
  shorttitle = {Applications of {{Bayesian}} Statistical Methodology to Clinical Trial Design},
  author = {Smith, Claire L. and Jin, Yan and Raddad, Eyas and McNearney, Terry A. and Ni, Xiao and Monteith, David and Brown, Roger and Deeg, Mark A. and Schnitzer, Thomas},
  date = {2018},
  journaltitle = {Pharmaceutical Statistics},
  volume = {0},
  number = {0},
  issn = {1539-1612},
  doi = {10.1002/pst.1906},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1906},
  urldate = {2018-10-16},
  abstract = {Development of new pharmacological treatments for osteoarthritis that address unmet medical needs in a competitive market place is challenging. Bayesian approaches to trial design offer advantages in defining treatment benefits by addressing clinically relevant magnitude of effects relative to comparators and in optimizing efficiency in analysis. Such advantages are illustrated by a motivating case study, a proof of concept, and dose finding study in patients with osteoarthritis. Patients with osteoarthritis were randomized to receive placebo, celecoxib, or 1 of 4 doses of galcanezumab. Primary outcome measure was change from baseline WOMAC pain after 8 weeks of treatment. Literature review of clinical trials with targeted comparator therapies quantified treatment effects versus placebo. Two success criteria were defined: one to address superiority to placebo with adequate precision and another to ensure a clinically relevant treatment effect. Trial simulations used a Bayesian dose response and longitudinal model. An interim analysis for futility was incorporated. Simulations indicated the study had ≥85\% power to detect a 14-mm improvement and ≤1\% risk for a placebo-like drug to pass. The addition of the second success criterion substantially reduced the risk of an inadequate, weakly efficacious drug proceeding to future development. The study was terminated at the interim analysis due to inadequate analgesic efficacy. A Bayesian approach using probabilistic statements enables clear understanding of success criteria, leading to informed decisions for study conduct. Incorporating an interim analysis can effectively reduce sample size, save resources, and minimize exposure of patients to an inadequate treatment.},
  langid = {english},
  keywords = {bayes,design,rct}
}

@article{smi19app,
  title = {Applications of {{Bayesian}} Statistical Methodology to Clinical Trial Design: {{A}} Case Study of a Phase 2 Trial with an Interim Futility Assessment in Patients with Knee Osteoarthritis},
  shorttitle = {Applications of {{Bayesian}} Statistical Methodology to Clinical Trial Design},
  author = {Smith, Claire L. and Jin, Yan and Raddad, Eyas and McNearney, Terry A. and Ni, Xiao and Monteith, David and Brown, Roger and Deeg, Mark A. and Schnitzer, Thomas},
  date = {2019},
  journaltitle = {Pharmaceutical Statistics},
  volume = {18},
  number = {1},
  pages = {39--53},
  issn = {1539-1612},
  doi = {10.1002/pst.1906},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1906},
  urldate = {2019-01-26},
  abstract = {Development of new pharmacological treatments for osteoarthritis that address unmet medical needs in a competitive market place is challenging. Bayesian approaches to trial design offer advantages in defining treatment benefits by addressing clinically relevant magnitude of effects relative to comparators and in optimizing efficiency in analysis. Such advantages are illustrated by a motivating case study, a proof of concept, and dose finding study in patients with osteoarthritis. Patients with osteoarthritis were randomized to receive placebo, celecoxib, or 1 of 4 doses of galcanezumab. Primary outcome measure was change from baseline WOMAC pain after 8 weeks of treatment. Literature review of clinical trials with targeted comparator therapies quantified treatment effects versus placebo. Two success criteria were defined: one to address superiority to placebo with adequate precision and another to ensure a clinically relevant treatment effect. Trial simulations used a Bayesian dose response and longitudinal model. An interim analysis for futility was incorporated. Simulations indicated the study had ≥85\% power to detect a 14-mm improvement and ≤1\% risk for a placebo-like drug to pass. The addition of the second success criterion substantially reduced the risk of an inadequate, weakly efficacious drug proceeding to future development. The study was terminated at the interim analysis due to inadequate analgesic efficacy. A Bayesian approach using probabilistic statements enables clear understanding of success criteria, leading to informed decisions for study conduct. Incorporating an interim analysis can effectively reduce sample size, save resources, and minimize exposure of patients to an inadequate treatment.},
  langid = {english},
  keywords = {bayes,drug-development,futility}
}

@article{smi21pow,
  title = {Power and Sample Size for Multistate Model Analysis of Longitudinal Discrete Outcomes in Disease Prevention Trials},
  author = {Smith, Isabelle L. and Nixon, Jane E. and Sharples, Linda},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8882},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8882},
  urldate = {2021-02-12},
  abstract = {For clinical trials where participants pass through a number of discrete health states resulting in longitudinal measures over time, there are several potential primary estimands for the treatment effect. Incidence or time to a particular health state are commonly used outcomes but the choice of health state may not be obvious and these estimands do not make full use of the longitudinal assessments. Multistate models have been developed for some diseases and conditions with the purpose of understanding their natural history and have been used for secondary analysis to understand mechanisms of action of treatments. There is little published on the use of multistate models as the primary analysis method and potential implications on design features, such as assessment schedules. We illustrate methods via analysis of data from a motivating example; a Phase III clinical trial of pressure ulcer prevention strategies. We clarify some of the possible estimands that might be considered and we show, via a simulation study, that under some circumstances the sample size could be reduced by half using a multistate model based analysis, without adversely affecting the power of the trial.},
  langid = {english},
  keywords = {key,longitudinal,markov,multi-state-model,multiple-endpoints,multiple-states,ordinal,power,rct,sample-size,serial,teaching-mds,transition-model},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8882}
}

@article{smi74ear,
  title = {Early Sequential Changes in Left Ventricular Dimensions and Filling Pressure in Patients after Myocardial Infarction},
  author = {Smith, M. and Ratshin, R. A. and Harrell, F. E. and Russell, R. O. and Rackley, C. E.},
  date = {1974},
  journaltitle = {Am J Card},
  volume = {33},
  pages = {363--369},
  citeulike-article-id = {13264870},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{smi79,
  title = {Splines as a Useful and Convenient Statistical Tool},
  author = {Smith, P. L.},
  date = {1979},
  journaltitle = {Am Statistician},
  volume = {33},
  pages = {57--62},
  citeulike-article-id = {13264871},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{smi80bay,
  title = {Bayes Factors and Choice Criteria for Linear Models},
  author = {Smith, A. F. M. and Spiegelhalter, D. J.},
  date = {1980},
  journaltitle = {J Roy Stat Soc B},
  volume = {42},
  pages = {213--220},
  citeulike-article-id = {13264872},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {aic,bayes-factor,bayesian-inference,bic,maximum-likelihood,model-selection,variable-selection}
}

@article{smi91det,
  title = {Determinants of Early versus Late Cardiac Death in Patients Undergoing Coronary Artery Bypass Surgery},
  author = {Smith, L. R. and Harrell, F. E. and Rankin, S. J. and Califf, R. M. and Pryor, D. B. and Muhlbaier LH, K. L. and Mark, D. B. and Jones, R. H. and Oldham, H. N. and Glower, D. D. and Reves, J. G. and Sabiston, D. C.},
  date = {1991},
  journaltitle = {Circ},
  volume = {84 (Suppl III)},
  pages = {245--253},
  citeulike-article-id = {13264873},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{smi92bay,
  title = {Bayesian Statistics without Tears: {{A}} Sampling-Resampling Perspective},
  author = {Smith, A. F. M. and Gelfand, A. E.},
  date = {1992},
  journaltitle = {Am Statistician},
  volume = {46},
  pages = {84--88},
  citeulike-article-id = {13264874},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bayesian-inference,changing-prior,sampling-importance-resampling,teaching,weighted-bootstrap}
}

@incollection{smi92pro,
  title = {Problems and Potentials in Modeling Survival},
  booktitle = {Medical {{Effectiveness Research Data Methods}} ({{Summary Report}}), {{AHCPR Pub}}. {{No}}. 92-0056},
  author = {Smith, L. R. and Harrell, F. E. and Muhlbaier, L. H.},
  editor = {Grady, Mary L. and Schwartz, Harvey A.},
  date = {1992},
  pages = {151--159},
  publisher = {{US Dept. of Health and Human Services, Agency for Health Care Policy and Research}},
  location = {{Rockville, MD}},
  url = {https://hbiostat.org/bib/papers/smi92pro.pdf},
  keywords = {cox-model,data-reduction,number-of-covariables,overfitting,predictive-accuracy}
}

@article{smi94adj,
  title = {Evaluating Risk Adjustment by Partitioning Variation in Hospital Mortality Rates},
  author = {Smith, David W.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1001--1013},
  citeulike-article-id = {13264876},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {mortality-models,risk-adjustment}
}

@article{smi94pre,
  title = {Preoperative Determinants of Postoperative Costs Associated with Coronary Artery Bypass Graft Surgery},
  author = {Smith, Lloyd R. and Milano, Carmelo A. and Molter, Beth S. and Elberry, Joseph R. and Sabiston, David C. and Smith, Peter K.},
  date = {1994},
  journaltitle = {Circ},
  volume = {90 [part 2]},
  citeulike-article-id = {13264877},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {analysis-of-financial-data,cabg,cost}
}

@article{smi95bay,
  title = {Bayesian Approaches to Random-Effects Meta-Analysis: {{A}} Comparative Study},
  author = {Smith, Teresa A. and Spiegelhalter, David J. and Thomas, Andrew},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2685--2699},
  citeulike-article-id = {13264878},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {bayesian-inference,bugs,meta-analysis,random-effects,uncertainty},
  note = {advantages over DerSimonian and Laird which ignores uncertainty in some parameter estimates}
}

@article{smi95lat,
  title = {Late Withdrawal of Cyclosporine in Stable Renal Transplant Recipients},
  author = {Smith, S. R. and Minda, S. A. and Samsa, G. P. and Harrell, F. E. and Gunnells, J. C. and Coffman, T. M. and Butterly, D. W.},
  date = {1995},
  journaltitle = {Am J Kidney Dis},
  volume = {26},
  pages = {487--494},
  citeulike-article-id = {13264879},
  posted-at = {2014-07-14 14:09:44},
  priority = {0}
}

@article{sna07res,
  title = {Responder Analyses and the Assessment of a Clinically Relevant Treatment Effect},
  author = {Snapinn, Steven M. and Jiang, Qi},
  date = {2007-10-25},
  journaltitle = {Trials},
  volume = {8},
  number = {1},
  pages = {31},
  issn = {1745-6215},
  doi = {10.1186/1745-6215-8-31},
  url = {https://doi.org/10.1186/1745-6215-8-31},
  urldate = {2019-09-14},
  abstract = {Ideally, a clinical trial should be able to demonstrate not only a statistically significant improvement in the primary efficacy endpoint, but also that the magnitude of the effect is clinically relevant. One proposed approach to address this question is a responder analysis, in which a continuous primary efficacy measure is dichotomized into "responders" and "non-responders." In this paper we discuss various weaknesses with this approach, including a potentially large cost in statistical efficiency, as well as its failure to achieve its main goal. We propose an approach in which the assessments of statistical significance and clinical relevance are separated.},
  keywords = {rct,responder-analysis}
}

@article{sna11cli,
  title = {On the Clinical Meaningfulness of a Treatment's Effect on a Time-to-Event Variable},
  author = {Snapinn, Steven and Jiang, Qi},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  pages = {2341--2348},
  doi = {10.1002/sim.4256},
  url = {http://dx.doi.org/10.1002/sim.4256},
  citeulike-article-id = {13265890},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4256},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {clinical-meaningfulness,event-rates,hazard-ratio,median-survival-times,time-to-event},
  note = {difference in medians and different in event rates contradict each other}
}

@article{sna17som,
  title = {Some Remaining Challenges Regarding Multiple Endpoints in Clinical Trials},
  author = {Snapinn, Steven},
  date = {2017-06},
  journaltitle = {Stat Med},
  issn = {02776715},
  doi = {10.1002/sim.7390},
  url = {http://dx.doi.org/10.1002/sim.7390},
  citeulike-article-id = {14385705},
  citeulike-attachment-1 = {sna17som.pdf; /pdf/user/harrelfe/article/14385705/1113001/sna17som.pdf; 6bb7af5c63760f31a4c6ed9e6aea630918b51441},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7390},
  day = {30},
  posted-at = {2017-06-30 14:13:53},
  priority = {0},
  keywords = {multiple-endpoints,rct}
}

@article{sna86,
  title = {Tests of Significance Using Regression Models for Ordered Categorical Data},
  author = {Snapinn, S. M. and Small, R. D.},
  date = {1986},
  journaltitle = {Biometrics},
  volume = {42},
  pages = {583--592},
  citeulike-article-id = {13264880},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {distribution-free-methods,logistic-ordinal-model}
}

@article{sna98int,
  title = {Interpreting Interaction: {{The}} Classical Approach},
  author = {Snappin, Steven M.},
  date = {1998},
  journaltitle = {Drug Info J},
  volume = {32},
  pages = {433--438},
  citeulike-article-id = {13264881},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {interaction,nonparametric,qualitative-interaction,rank-transformation,treatment-by-center-interaction}
}

@article{sna98sur,
  title = {Survival Analysis with Uncertain Endpoints},
  author = {Snapinn, Steven M.},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {209--218},
  citeulike-article-id = {13264882},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {endpoints,rct,study-design},
  note = {endpoint committee; inclusion of all candidate endpoints with degree of certainty of each in a Cox model}
}

@article{sne21ext,
  title = {External Validation of Clinical Prediction Models: Simulation-Based Sample Size Calculations Were More Reliable than Rules-of-Thumb},
  shorttitle = {External Validation of Clinical Prediction Models},
  author = {Snell, Kym IE and Archer, Lucinda and Ensor, Joie and Bonnett, Laura J. and Debray, Thomas PA and Phillips, Bob and Collins, Gary S. and Riley, Richard D.},
  date = {2021-02-14},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2021.02.011},
  url = {http://www.jclinepi.com/article/S0895-4356(21)00048-2/abstract},
  urldate = {2021-02-14},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Introduction{$<$}/h3{$><$}p{$>$}Sample size ‘rules-of-thumb' for external validation of clinical prediction models suggest at least 100 events and 100 non-events. Such blanket guidance is imprecise, and not specific to the model or validation setting. We investigate factors affecting precision of model performance estimates upon external validation, and propose a more tailored sample size approach.{$<$}/p{$><$}h3{$>$}Methods{$<$}/h3{$><$}p{$>$}Simulation of logistic regression prediction models to investigate factors associated with precision of performance estimates. Then, explanation and illustration of a simulation-based approach to calculate the minimum sample size required to precisely estimate a model's calibration, discrimination and clinical utility.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Precision is affected by the model's linear predictor (LP) distribution, in addition to number of events and total sample size. Sample sizes of 100 (or even 200) events and non-events can give imprecise estimates, especially for calibration. The simulation-based calculation accounts for the LP distribution and (mis)calibration in the validation sample. Application identifies 2430 required participants (531 events) for external validation of a deep vein thrombosis diagnostic model.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}Where researchers can anticipate the distribution of the model's LP (e.g. based on development sample, or a pilot study), a simulation-based approach for calculating sample size for external validation offers more flexibility and reliability than rules-of-thumb.{$<$}/p{$>$}},
  langid = {english},
  keywords = {calibration,discrimination,external-validation,sample-size,validation}
}

@article{sno89,
  title = {Years of Life with Good and Poor Mental and Physical Function in the Elderly},
  author = {Snowdon, D. A. and Ostwald, S. K. and Kane, R. L. and Keenan, N. L.},
  date = {1989},
  journaltitle = {J Clin Epi},
  volume = {42},
  pages = {1055--1066},
  citeulike-article-id = {13264883},
  posted-at = {2014-07-14 14:09:44},
  priority = {0},
  keywords = {measurement,research-methods,survival-analysis-non-regression}
}

@book{sog93dru,
  title = {Drug {{Safety Assessment}} in {{Clinical Trials}}},
  editor = {Gilbert-Sogliero, Gene},
  date = {1993},
  publisher = {{Marcel Dekker}},
  location = {{New York}},
  citeulike-article-id = {13265309},
  posted-at = {2014-07-14 14:09:54},
  priority = {0}
}

@article{som62new,
  title = {A New Asymmetric Measure of Association for Ordinal Variables},
  author = {Somers, Robert H.},
  date = {1962},
  journaltitle = {Am Soc Rev},
  volume = {27},
  pages = {799--811},
  citeulike-article-id = {13264884},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {rank-correlation}
}

@article{sou10cor,
  title = {Correspondence Analysis Is a Useful Tool to Uncover the Relationships among Categorical Variables},
  author = {Sourial, Nadia and Wolfson, Christina and Zhu, Bin and Quail, Jacqueline and Fletcher, John and Karunananthan, Sathya and Bandeen-Roche, Karen and {Others}},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {638--646},
  citeulike-article-id = {13265819},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {categorical-data,correspondence-analysis,data-reduction,graphics,multivariate-graphical-analysis},
  annotation = {erratum 63:809;2010 (bug in SAS PROC)}
}

@article{soz10sam,
  title = {Sample Size Determination in Clinical Trials with Multiple Co-Primary Binary Endpoints},
  author = {Sozu, Takashi and Sugimoto, Tomoyumi and Hamasaki, Toshimitsu},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {2169--2179},
  citeulike-article-id = {13265844},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {arcsine-transformation,association-measures,co-primary-endpoints,continuity-correction,correlated-endpoints,design-of-rct,fishers-exact-test,multiple-endpoints,multivariate-bernoulli}
}

@article{spa09bay,
  title = {Bayesian Adaptive Non-Inferiority with Safety Assessment: {{Retrospective}} Case Study to Highlight Potential Benefits and Limitations of the Approach},
  author = {Spann, Melissa and Lindborg, Stacy and Seaman, John and Baker, Robert and Dunayevich, Eduardo and Breier, Alan},
  date = {2009},
  journaltitle = {J Psych Res},
  volume = {43},
  pages = {561--567},
  doi = {10.1016/j.jpsychires.2008.07.009},
  url = {http://dx.doi.org/10.1016/j.jpsychires.2008.07.009},
  citeulike-article-id = {13265734},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jpsychires.2008.07.009},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {adaptive,bayes,bayesian-adaptive-trial,joint-predictive-probability,non-inferiority,rct,schizophrenia},
  note = {adaptation based on product of posterior probabilities of efficacy and not having a certain adverse event;retrospective re-running a finished trial, incorportation adaptive allocation by using only part of the stream of patients in the original order of enrollment;nice background of Bayesian method;used predictive probabilities}
}

@article{spa89,
  title = {Differential Diagnosis of Acute Meningitis: {{An}} Analysis of the Predictive Value of Initial Observations},
  author = {Spanos, Alan and Harrell, Frank E. and Durack, David T.},
  date = {1989},
  journaltitle = {JAMA},
  volume = {262},
  pages = {2700--2707},
  doi = {10.1001/jama.262.19.2700},
  url = {http://dx.doi.org/10.1001/jama.262.19.2700},
  citeulike-article-id = {13264885},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.262.19.2700},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {diagnosis,logistic-model,meningitis,multivariable-modeling}
}

@article{spe20hea,
  title = {Health-{{Status Outcomes}} with {{Invasive}} or {{Conservative Care}} in {{Coronary Disease}}},
  author = {Spertus, John A. and Jones, Philip G. and Maron, David J. and O'Brien, Sean M. and Reynolds, Harmony R. and Rosenberg, Yves and Stone, Gregg W. and Harrell, Frank E. and Boden, William E. and Weintraub, William S. and Baloch, Khaula and Mavromatis, Kreton and Diaz, Ariel and Gosselin, Gilbert and Newman, Jonathan D. and Mavromichalis, Stavroula and Alexander, Karen P. and Cohen, David J. and Bangalore, Sripal and Hochman, Judith S. and Mark, Daniel B. and {ISCHEMIA Research Group}},
  date = {2020-04-09},
  journaltitle = {N Engl J Med},
  volume = {382},
  number = {15},
  eprint = {32227753},
  eprinttype = {pmid},
  pages = {1408--1419},
  issn = {1533-4406},
  doi = {10.1056/NEJMoa1916370},
  abstract = {BACKGROUND: In the ISCHEMIA trial, an invasive strategy with angiographic assessment and revascularization did not reduce clinical events among patients with stable ischemic heart disease and moderate or severe ischemia. A secondary objective of the trial was to assess angina-related health status among these patients. METHODS: We assessed angina-related symptoms, function, and quality of life with the Seattle Angina Questionnaire (SAQ) at randomization, at months 1.5, 3, and 6, and every 6 months thereafter in participants who had been randomly assigned to an invasive treatment strategy (2295 participants) or a conservative strategy (2322). Mixed-effects cumulative probability models within a Bayesian framework were used to estimate differences between the treatment groups. The primary outcome of this health-status analysis was the SAQ summary score (scores range from 0 to 100, with higher scores indicating better health status). All analyses were performed in the overall population and according to baseline angina frequency. RESULTS: At baseline, 35\% of patients reported having no angina in the previous month. SAQ summary scores increased in both treatment groups, with increases at 3, 12, and 36 months that were 4.1 points (95\% credible interval, 3.2 to 5.0), 4.2 points (95\% credible interval, 3.3 to 5.1), and 2.9 points (95\% credible interval, 2.2 to 3.7) higher with the invasive strategy than with the conservative strategy. Differences were larger among participants who had more frequent angina at baseline (8.5 vs. 0.1 points at 3 months and 5.3 vs. 1.2 points at 36 months among participants with daily or weekly angina as compared with no angina). CONCLUSIONS: In the overall trial population with moderate or severe ischemia, which included 35\% of participants without angina at baseline, patients randomly assigned to the invasive strategy had greater improvement in angina-related health status than those assigned to the conservative strategy. The modest mean differences favoring the invasive strategy in the overall group reflected minimal differences among asymptomatic patients and larger differences among patients who had had angina at baseline. (Funded by the National Heart, Lung, and Blood Institute and others; ISCHEMIA ClinicalTrials.gov number, NCT01471522.).},
  langid = {english},
  pmcid = {PMC7261489},
  keywords = {collaboration,cv}
}

@article{spe93rem,
  title = {A Remarkable Scatterplot},
  author = {Spence, Ian and Garrison, Robert F.},
  date = {1993},
  journaltitle = {Am Statistician},
  volume = {47},
  pages = {12--19},
  citeulike-article-id = {13264886},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {exploratory-data-analysis,graphical-methods,outliers,resistent-fits}
}

@book{spe94int,
  title = {An {{Introduction}} to {{S}} and {{S-Plus}}},
  author = {Spector, Phil},
  date = {1994},
  publisher = {{Duxbury Press}},
  location = {{Belmont, CA}},
  citeulike-article-id = {13264887},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {s-plus}
}

@article{spi04ant,
  title = {Anterior Cruciate Ligament Reconstruction Autograft Choice: {{Bone-tendon-bone}} versus Hamstring: {{Does}} It Really Matter? {{A}} Systemic Review},
  author = {Spindler, Kurt P. and Kuhn, John E. and Freedman, Kevin B. and Matthews, Charles E. and Dittus, Robert S. and Harrell, Frank E.},
  date = {2004},
  journaltitle = {Am J Sports Med},
  volume = {32},
  pages = {1986--1995},
  citeulike-article-id = {13265391},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {acl,anterior-cruciate-ligament,evidence-based-medicine,outcomes,review}
}

@book{spi04bay,
  title = {Bayesian {{Approaches}} to {{Clinical Trials}} and {{Health-Care Evaluation}}},
  author = {Spiegelhalter, David J. and Abrams, Keith R. and Myles, Jonathan P.},
  date = {2004},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13265619},
  posted-at = {2014-07-14 14:10:00},
  priority = {0}
}

@article{spi05rea,
  title = {Reading and Reviewing the Orthopaedic Literature: {{A}} Systematic, Evidence-Based Medicine Approach},
  author = {Spindler, Kurt P. and Kuhn, John E. and Dunn, Warren and Matthews, Charles E. and Harrell, Frank E. and Dittus, Robert S.},
  date = {2005},
  journaltitle = {J Am Acad Ortho Surgeons},
  volume = {13},
  pages = {220--229},
  citeulike-article-id = {13265427},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {ebm,evidence-based-medicine,review-checklist,teaching-mds}
}

@article{spi11pro,
  title = {The Prognosis and Predictors of Sports Function and Activity at Minimum 6 Years after Anterior Cruciate Ligament Reconstruction: A Population Cohort Study},
  author = {Spindler, K. P. and Huston, L. J. and Wright, R. W. and Kaeding, C. C. and Marx, R. G. and Amendola, A. and {Parker} and Andrish, J. T. and Reinke, E. K. and Harrell, F. E. and {MOON Group}},
  date = {2011},
  journaltitle = {Am J Sports Med},
  volume = {39},
  number = {2},
  pages = {348--359},
  citeulike-article-id = {13265879},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {moon,sports-medicine}
}

@article{spi13pro,
  title = {Prognosis and Predictors of {{ACL}} Reconstructions Using the {{MOON}} Cohort: {{A}} Model for Comparative Effectiveness Studies},
  author = {Spindler, Kurt P. and Parker, Richard D. and Andrish, Jack T. and Kaeding, Christopher C. and Wright, Rick W. and Marx, Robert G. and McCarty, Eric C. and Amendola, Annunziato and Dunn, Warren R. and Huston, Laura J. and Harrell, Frank E. and Group, MOON},
  date = {2013-01},
  journaltitle = {J Ortho Res},
  volume = {31},
  number = {1},
  pages = {2--9},
  doi = {10.1002/jor.22201},
  url = {http://dx.doi.org/10.1002/jor.22201},
  abstract = {Injury to the anterior cruciate ligament (ACL) threatens an active lifestyle and exposes the patient to risk of early osteoarthritis (OA). ACL reconstruction is typically chosen by individuals to allow a return to their previous work and sports activities. Primary ACL reconstruction (ACLR) has in general been effective at restoring functional stability, but patients' modifiable predictors of both short- and long-term validated outcomes and OA are largely unknown. The Multicenter Orthopaedic Outcomes Network (MOON) consortium was established in 2002 to enroll and longitudinally follow a population cohort of ACL reconstructed patients. The objective was to establish patient-specific predictive models of clinically important outcomes. Over the past 10 years, the overarching aims of this NIAMS-funded prospective multicenter cohort of ACL reconstructions has been threefold: (1) to identify both short- and long-term prognosis and predictors of sports function, activity level, and general health through validated patient-reported outcomes, (2) to identify the symptoms and signs of OA, and (3) to quantify the incidence of ACL reconstruction graft and/or contralateral ACL failures and additional surgical procedures. This manuscript summarizes the Kappa Delta Ann Doner Vaughan Award paper and presentation at the 2012 ORS/AAOS Annual Meeting.},
  citeulike-article-id = {13265936},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/jor.22201},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {acl-reconstruction,moon,multivariable-analysis,predictors,prognosis}
}

@article{spi86,
  title = {Probabilistic Prediction in Patient Management and Clinical Trials},
  author = {Spiegelhalter, D. J.},
  date = {1986},
  journaltitle = {Stat Med},
  volume = {5},
  pages = {421--433},
  doi = {10.1002/sim.4780050506},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4780050506},
  keywords = {calibration-test,general,idiot-bayes,independence-model,nonparametric-calibration-curve,prediction,predictive-accuracy,shrinkage},
  note = {z-test for calibration inaccuracy (implemented in Stata, and R Hmisc package's val.prob function)}
}

@article{spi86pre,
  title = {A Predictive Approach to Selecting the Size of a Clinical Trial, Based on Subjective Clinical Opinion},
  author = {Spiegelhalter, David J. and Freedman, Lawrence S.},
  date = {1986},
  journaltitle = {Stat Med},
  volume = {5},
  pages = {1--13},
  doi = {10.1002/sim.4780050103},
  url = {http://dx.doi.org/10.1002/sim.4780050103},
  citeulike-article-id = {13264889},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780050103},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {bayesian-inference,predictive-distributions,rct,sample-size,study-design}
}

@article{spi93app,
  title = {Applying {{Bayesian}} Ideas in Drug Development and Clinical Trials},
  author = {Spiegelhalter, David J. and Freedman, L. S. and Parmar, M. K. B.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {1501--1511},
  doi = {10.1002/sim.4780121516},
  url = {http://dx.doi.org/10.1002/sim.4780121516},
  citeulike-article-id = {13264890},
  citeulike-attachment-1 = {spi93app.pdf; /pdf/user/harrelfe/article/13264890/1092998/spi93app.pdf; 4c166454c10614c4d04e5d4d5d206982fd1a9fc4},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780121516},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {bayesian-inference,clinical-trials,rct}
}

@article{spi94bay,
  title = {Bayesian Approaches to Randomized Trials},
  author = {Spiegelhalter, David J. and Freedman, Laurence S. and Parmar, Mahesh K. B.},
  date = {1994},
  journaltitle = {J Roy Stat Soc A},
  volume = {157},
  pages = {357--416},
  doi = {10.2307/2983527},
  url = {https://doi.org/10.2307/2983527},
  citeulike-article-id = {13264891},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {bayesian-inference,early-termination,equivalence,interpreting-study-results,sequential-testing,skeptical-priors}
}

@article{spi98bay,
  title = {Bayesian Graphical Modelling: A Case-Study in Monitoring Health Outcomes},
  author = {Spiegelhalter, David J.},
  date = {1998},
  journaltitle = {Appl Stat},
  volume = {19},
  pages = {115--133},
  citeulike-article-id = {13264892},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {bugs-code,cancer-incidence,cervical-screening,gibbs-sampling,hierarchical-models,mcmc}
}

@article{spi99sur,
  title = {Surgical Audit: Statistical Lessons from {{Nightingale}} and {{Codman}}},
  author = {Spiegelhalter, David J.},
  date = {1999},
  journaltitle = {J Roy Stat Soc A},
  volume = {162},
  pages = {45--58},
  doi = {10.1111/1467-985X.00120},
  url = {http://dx.doi.org/10.1111/1467-985X.00120},
  citeulike-article-id = {13264893},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/1467-985X.00120},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {cumulative-sums,evidence-based-medicine,hospital-statistics,league-table,provider-profiling,quality-management,scorecard,surgical-outcomes},
  note = {mathematical model for individual surgeon performance}
}

@book{Splus,
  title = {\textsc{S-}{{\textsc{Plus}}} {{User}}'s {{Guide}}},
  author = {{Insightful}},
  date = {2007},
  location = {{Seattle, WA}},
  url = {http://www.insightful.com/support/documentation.asp},
  citeulike-article-id = {13264894},
  citeulike-linkout-0 = {http://www.insightful.com/support/documentation.asp},
  posted-at = {2014-07-14 14:09:45},
  priority = {0}
}

@book{Splus.se,
  title = {S-{{Plus Student Edition User}}'s {{Guide}}},
  author = {{MathSoft Data Analysis Products Division}},
  date = {1999},
  publisher = {{Duxbury Press}},
  location = {{Pacific Grove}},
  citeulike-article-id = {13264895},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {teaching-s-plus}
}

@book{spStatGuide,
  title = {S-{{PLUS Guide}} to {{Statistics}}},
  author = {{Insightful}},
  date = {2007},
  location = {{Seattle, WA}},
  url = {http://www.insightful.com/support/documentation.asp},
  citeulike-article-id = {13264896},
  citeulike-linkout-0 = {http://www.insightful.com/support/documentation.asp},
  organization = {Insightful Corporation},
  posted-at = {2014-07-14 14:09:45},
  priority = {0}
}

@article{sta01bj,
  title = {{{BJ}}: {{An}} {{{\textsc{S-Plus}}}} Program to Fit Linear Regression Models to Censored Data Using the {{Buckley}} and {{James}} Method},
  author = {Stare, Janez and Harrell, Frank E. and Heinzl, Harald},
  date = {2001},
  journaltitle = {Comp Meth Prog Biomed},
  volume = {64},
  pages = {45--52},
  citeulike-article-id = {13265112},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{sta09sim,
  title = {Simple Tests for the External Validation of Mortality Prediction Scores},
  author = {Stallard, Nigel},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {377--388},
  doi = {10.1002/sim.3393},
  url = {http://dx.doi.org/10.1002/sim.3393},
  citeulike-article-id = {13265727},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.3393},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {external-validation,validation},
  note = {low power of older Hosmer-Lemeshow test;avoiding grouping of predicted risks;logarithmic and quadratic test;scaled χ² approximation;simulation setup; best power seems to be for the logarithmic (deviance) statistic and for the chi-square statistics that is like the sum of squared errors statistic except that each observation is weighted by p(1-p)}
}

@article{sta19ana,
  title = {Analysis of Paediatric Visual Acuity Using {{Bayesian}} Copula Models with Sinh-Arcsinh Marginal Densities},
  author = {Stander, Julian and Valle, Luciana Dalla and Taglioni, Charlotte and Liseo, Brunero and Wade, Angie and Cortina‐Borja, Mario},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {18},
  pages = {3421--3443},
  issn = {1097-0258},
  doi = {10.1002/sim.8176},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8176},
  urldate = {2019-07-07},
  abstract = {We analyse paediatric ophthalmic data from a large sample of children aged between 3 and 8 years. We use a Bayesian additive conditional bivariate copula regression model with sinh-arcsinh marginal densities with location, scale, and shape parameters that depend smoothly on a covariate. We perform Bayesian inference about the unknown quantities of our model using a specially tailored Markov chain Monte Carlo algorithm. We gain new insights about the processes, which determine transformations in visual acuity with respect to age, including the nature of joint changes in both eyes as modelled with the age-related copula dependence parameter. We analyse posterior predictive distributions to identify children with unusual sight characteristics, distinguishing those who are bivariate, but not univariate outliers. In this way, we provide an innovative tool that enables clinicians to identify children with unusual sight who may otherwise be missed. We compare our simultaneous Bayesian method with a two-step frequentist generalised additive modelling approach.},
  langid = {english},
  keywords = {copula,multiple-endpoints}
}

@article{sta19anaa,
  title = {Analysis of Paediatric Visual Acuity Using {{Bayesian}} Copula Models with Sinh-Arcsinh Marginal Densities},
  author = {Stander, Julian and Valle, Luciana Dalla and Taglioni, Charlotte and Liseo, Brunero and Wade, Angie and Cortina‐Borja, Mario},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8176},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8176},
  urldate = {2019-06-01},
  abstract = {We analyse paediatric ophthalmic data from a large sample of children aged between 3 and 8 years. We use a Bayesian additive conditional bivariate copula regression model with sinh-arcsinh marginal densities with location, scale, and shape parameters that depend smoothly on a covariate. We perform Bayesian inference about the unknown quantities of our model using a specially tailored Markov chain Monte Carlo algorithm. We gain new insights about the processes, which determine transformations in visual acuity with respect to age, including the nature of joint changes in both eyes as modelled with the age-related copula dependence parameter. We analyse posterior predictive distributions to identify children with unusual sight characteristics, distinguishing those who are bivariate, but not univariate outliers. In this way, we provide an innovative tool that enables clinicians to identify children with unusual sight who may otherwise be missed. We compare our simultaneous Bayesian method with a two-step frequentist generalised additive modelling approach.},
  langid = {english},
  keywords = {bayes,copula}
}

@article{sta80on,
  title = {On the Complexity of Investigating Chronic Illness},
  author = {Starmer, C. F. and Lee, K. L. and Harrell, F. E. and Rosati, R. A.},
  date = {1980},
  journaltitle = {Biometrics},
  volume = {36},
  pages = {335--345},
  citeulike-article-id = {13264897},
  posted-at = {2014-07-14 14:09:45},
  priority = {0}
}

@article{sta81ana,
  title = {Analysis of Survival Data with Nonproportional Hazard Functions},
  author = {Stablein, D. M. and Carter, W. H. and Novak, J. W.},
  date = {1981},
  journaltitle = {Controlled Clin Trials},
  volume = {2},
  pages = {149--159},
  citeulike-article-id = {13264898},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {assessing-ph,tdc}
}

@article{sta89,
  title = {Growth Curve Models of Repeated Binary Response},
  author = {Stanek, E. J. and Diehl, S. R.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {973--983},
  citeulike-article-id = {13264899},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {logistic-model-extensions,multivariate-analysis}
}

@article{sta94pro,
  title = {A Proposal for Structured Reporting of Randomized Controlled Trials},
  author = {{The Standards of Reporting Trials Group}},
  date = {1994},
  journaltitle = {JAMA},
  volume = {272},
  pages = {1926--1931},
  doi = {10.1001/jama.272.24.1926},
  url = {http://dx.doi.org/10.1001/jama.272.24.1926},
  citeulike-article-id = {13264900},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.272.24.1926},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {clinical-trials,rct,reporting,statistical-results,teaching-mds}
}

@article{sta95pre,
  title = {Prediction and Decision Making Using {{Bayesian}} Hierarchical Models},
  author = {Stangl, Dalene K.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2173--2190},
  citeulike-article-id = {13264901},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {bayesian-methods,bayesian-survival-analysis,mixed-model,multi-center-study,qoi,quantity-of-interest,random-effects-model,shrinkage,site-effects,site-variation}
}

@article{sta98sam,
  title = {Sample Size Determination for Phase {{II}} Clinical Trials Based on {{Bayesian}} Decision Theory},
  author = {Stallard, Nigel},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {279--294},
  citeulike-article-id = {13264902},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {backwards-induction,bayesian-inference,cost-benefit-analysis,gain-function-used-to-consider-costs-of-drug-development,group-sequential,multistage-design,optimal-stopping,rct,sample-size,study-design}
}

@article{stan17,
  title = {Stan: {{A Probabilistic Programming Language}}},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  date = {2017},
  journaltitle = {J Stat Software},
  volume = {76},
  number = {1},
  pages = {1--32},
  doi = {10.18637/jss.v076.i01},
  url = {https://www.jstatsoft.org/v076/i01},
  abstract = {Stan is a probabilistic programming language for specifying statistical models. A Stan program imperatively defines a log probability function over parameters conditioned on specified data and constants. As of version 2.14.0, Stan provides full Bayesian inference for continuous-variable models through Markov chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling. Penalized maximum likelihood estimates are calculated using optimization methods such as the limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm. Stan is also a platform for computing log densities and their gradients and Hessians, which can be used in alternative algorithms such as variational Bayes, expectation propagation, and marginal inference using approximate integration. To this end, Stan is set up so that the densities, gradients, and Hessians, along with intermediate quantities of the algorithm such as acceptance probabilities, are easily accessible. Stan can be called from the command line using the cmdstan package, through R using the rstan package, and through Python using the pystan package. All three interfaces support sampling and optimization-based inference with diagnostics and posterior analysis. rstan and pystan also provide access to log probabilities, gradients, Hessians, parameter transforms, and specialized plotting.},
  citeulike-article-id = {14573584},
  citeulike-linkout-0 = {http://dx.doi.org/10.18637/jss.v076.i01},
  citeulike-linkout-1 = {https://www.jstatsoft.org/v076/i01},
  posted-at = {2018-04-22 23:40:19},
  priority = {2},
  keywords = {bayes,bayesian-inference,bayesian-modeling,stan,statistical-computing}
}

@article{ste00cli,
  title = {Clinical Trials in Acute Myocardial Infarction: {{Should}} We Adjust for Baseline Characteristics?},
  author = {Steyerberg, Ewout W. and Bossuyt, Patrick M. M. and Lee, Kerry L.},
  date = {2000},
  journaltitle = {Am Heart J},
  volume = {139},
  pages = {745--751},
  doi = {10.1016/S0002-8703(00)90001-2},
  url = {http://dx.doi.org/10.1016/S0002-8703(00)90001-2},
  citeulike-article-id = {13264905},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0002-8703(00)90001-2},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {ancova,covariable-adjustment},
  annotation = {Editorial, pp. 761-763}
}

@article{ste00pro,
  title = {Prognostic Modelling with Logistic Regression Analysis: {{A}} Comparison of Selection and Estimation Methods in Small Data Sets},
  author = {Steyerberg, Ewout W. and Eijkemans, Marinus J. C. and Harrell, Frank E. and Habbema, J. D. F.},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {1059--1079},
  citeulike-article-id = {13265125},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {external-information,gusto,lasso,predictive-accuracy,shrinkage,sign-of-regression-coefficient,variable-selection}
}

@article{ste01int,
  title = {Internal Validation of Predictive Models: {{Efficiency}} of Some Procedures for Logistic Regression Analysis},
  author = {Steyerberg, Ewout W. and Harrell, Frank E. and Borsboom, Gerard J. J. M. and Eijkemans, M. J. C. and Vergouwe, Yvonne and Habbema, J. D. F.},
  date = {2001},
  journaltitle = {J Clin Epi},
  volume = {54},
  pages = {774--781},
  citeulike-article-id = {13265211},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {bootstrap,model-validation}
}

@article{ste01pro,
  title = {Prognostic Modeling with Logistic Regression Analysis: {{In}} Search of a Sensible Strategy in Small Data Sets},
  author = {Steyerberg, Ewout W. and Eijkemans, Marinus J. C. and Harrell, Frank E. and Habbema, J. D. F.},
  date = {2001},
  journaltitle = {Med Decis Mak},
  volume = {21},
  pages = {45--56},
  citeulike-article-id = {13265157},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {calibration,dichotomization-of-continuous-varibles,shrinkage,sign-of-regression-coefficient,validation,variable-selection}
}

@article{ste01res,
  title = {Residual Mass Histology in Testicular Cancer: Development and Validation of a Clinical Prediction Rule},
  author = {Steyerberg, Ewout W. and Vergouwe, Yvonne and Keizer, H. Jan and Habbema, J. D. F.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {3847--3859},
  citeulike-article-id = {13265256},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {clinical-prediction-rule,point-scoring,point-tables,r,scoring-table},
  note = {examples of using the Design library to fit restricted cubic splines and graph them and to do external validations of logistic models}
}

@article{ste01sif,
  title = {Sifting the Evidence--{{What}}'s Wrong with Significance Tests?},
  author = {Sterne, Jonathan A. C. and Smith, George D.},
  date = {2001},
  journaltitle = {BMJ},
  volume = {322},
  pages = {226--231},
  citeulike-article-id = {13265643},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {p-values,teaching-mds},
  note = {excellent summary of problems with P-values and summary of a Bayesian approach;recommendation to use 0.9 confidence intervals to avoid confusion with testing at P=.05}
}

@article{ste03int,
  title = {Internal and External Validation of Predictive Models: {{A}} Simulation Study of Bias and Precision in Small Samples},
  author = {Steyerberg, Ewout W. and Bleeker, Sacha E. and Moll, Henriëtte A. and Grobbee, Diederick E. and Moons, Karel G. M.},
  date = {2003-05},
  journaltitle = {J Clin Epi},
  volume = {56},
  number = {5},
  pages = {441--447},
  issn = {08954356},
  doi = {10.1016/s0895-4356(03)00047-7},
  url = {http://dx.doi.org/10.1016/s0895-4356(03)00047-7},
  abstract = {We performed a simulation study to investigate the accuracy of bootstrap estimates of optimism (internal validation) and the precision of performance estimates in independent validation samples (external validation). We combined two data sets containing children presenting with fever without source ( n \textasciitilde =~376~+~179~=~555; 120 bacterial infections). Random samples were drawn from this combined data set for the development ( n \textasciitilde =~376) and validation ( n \textasciitilde =~179) of logistic regression models. The models included statistically significant predictors for infection selected from a set of 57 candidate predictors. Model development, including the selection of predictors, and validation were repeated in a bootstrapping procedure. The resulting expected optimism estimate in the receiver operating characteristic (ROC) area was compared with the observed optimism according to independent validation samples. The average apparent ROC area was 0.74, which was expected (based on bootstrapping) to decrease by 0.07 to 0.67, whereas the observed decrease in the validation samples was 0.09 to 0.65. Omitting the selection of predictors from the bootstrap procedure led to a severe underestimation of the optimism (decrease 0.006). The standard error of the observed ROC area in the independent validation samples was large (0.05). We recommend bootstrapping for internal validation because it gives reasonably valid estimates of the expected optimism in predictive performance provided that any selection of predictors is taken into account. For external validation, substantial sample sizes should be used for sufficient power to detect clinically important changes in performance as compared with the internally validated estimate.},
  citeulike-article-id = {5904570},
  citeulike-attachment-1 = {ste03int.pdf; /pdf/user/harrelfe/article/5904570/983624/ste03int.pdf; 52288a95e01c11486c1df72838023c9d7ae05ef8},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0895-4356(03)00047-7},
  posted-at = {2014-09-04 23:33:43},
  priority = {0},
  keywords = {bootstrap,diagnosis,internal-and-external-validation,validation},
  note = {useful simulation showing the number of bootstrap samples needed to obtain stable estimates of optimism of ROC area, R², and shrinkage factor;demonstrates that bootstrap estimates of optimism are nearly unbiased when compared to simulated external estimates;discusses problems with precision of estimates of accuracy, especially when using external validation on small samples;validation criteria}
}

@article{ste03sta,
  title = {Statistical Analyses of Trauma Outcome: When Is More Too Much?},
  author = {Steyerberg, E. W. and Frankema, S. P. and Harrell, F. E.},
  date = {2003},
  journaltitle = {J Trauma},
  volume = {54},
  pages = {1256--1257},
  citeulike-article-id = {13265351},
  posted-at = {2014-07-14 14:09:54},
  priority = {0}
}

@article{ste04bas,
  title = {Basing Intention-to-Treat on Cause and Effect Criteria},
  author = {Stewart, William H.},
  date = {2004},
  journaltitle = {Drug Info J},
  volume = {38},
  pages = {361--369},
  citeulike-article-id = {13265390},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {intent-to-treat,rct},
  note = {nice description of things that can go wrong (e.g., protocol violations) and when it is reasonable to exclude patients from ITT analyses}
}

@article{ste04gen,
  title = {A General Multilevel Multistate Competing Risks Model for Event History Data, with an Application to a Study of Contraceptive Use Dynamics:},
  shorttitle = {A General Multilevel Multistate Competing Risks Model for Event History Data, with an Application to a Study of Contraceptive Use Dynamics},
  author = {Steele, Fiona and Goldstein, Harvey and Browne, William},
  date = {2004},
  journaltitle = {Statistical Modelling},
  publisher = {{Sage PublicationsSage CA: Thousand Oaks, CA}},
  doi = {10.1191/1471082X04st069oa},
  url = {https://journals.sagepub.com/doi/10.1191/1471082X04st069oa},
  urldate = {2020-10-24},
  abstract = {We propose a general discrete time model for multilevel event history data. The model is developed for the analysis of longitudinal repeated episodes within ind...},
  langid = {english},
  keywords = {competing-risk,logistic,longitudinal,mixed-model,multilevel-models,random-effects,transition-model}
}

@article{ste10ass,
  title = {Assessing the {{Performance}} of {{Prediction Models}}},
  author = {Steyerberg, Ewout W. and Vickers, Andrew J. and Cook, Nancy R. and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J. and Kattan, Michael W.},
  date = {2010-01},
  journaltitle = {Epi},
  volume = {21},
  number = {1},
  eprint = {20010215},
  eprinttype = {pmid},
  pages = {128--138},
  issn = {1044-3983},
  doi = {10.1097/ede.0b013e3181c30fb2},
  url = {http://dx.doi.org/10.1097/ede.0b013e3181c30fb2},
  abstract = {The performance of prediction models can be assessed using a variety of methods and metrics. Traditional measures for binary and survival outcomes include the Brier score to indicate overall model performance, the concordance (or c) statistic for discriminative ability (or area under the receiver operating characteristic [ROC] curve), and goodness-of-fit statistics for calibration.Several new measures have recently been proposed that can be seen as refinements of discrimination measures, including variants of the c statistic for survival, reclassification tables, net reclassification improvement (NRI), and integrated discrimination improvement (IDI). Moreover, decision-analytic measures have been proposed, including decision curves to plot the net benefit achieved by making decisions based on model predictions.We aimed to define the role of these relatively novel approaches in the evaluation of the performance of prediction models. For illustration, we present a case study of predicting the presence of residual tumor versus benign tissue in patients with testicular cancer (n = 544 for model development, n = 273 for external validation).We suggest that reporting discrimination and calibration will always be important for a prediction model. Decision-analytic measures should be reported if the predictive model is to be used for clinical decisions. Other measures of performance may be warranted in specific applications, such as reclassification metrics to gain insight into the value of adding a novel predictor to an established model.},
  citeulike-article-id = {6593396},
  citeulike-linkout-0 = {http://dx.doi.org/10.1097/ede.0b013e3181c30fb2},
  citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3575184/},
  citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/20010215},
  citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=20010215},
  pmcid = {PMC3575184},
  posted-at = {2015-04-14 14:09:06},
  priority = {2},
  keywords = {predictive-accuracy}
}

@article{ste11log,
  title = {Logistic Regression Modeling and the Number of Events per Variable: Selection Bias Dominates.},
  author = {Steyerberg, EW and {Schemper, M} and Harrell, FE},
  date = {2011-12},
  journaltitle = {J Clin Epi},
  volume = {64},
  number = {12},
  pages = {1464--1465},
  doi = {10.1016/j.jclinepi.2011.06.016},
  url = {http://pubget.com/paper/22032755},
  citeulike-article-id = {13265905},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2011.06.016},
  citeulike-linkout-1 = {http://pubget.com/paper/22032755},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  annotation = {Letter to the editor}
}

@article{ste14tow,
  title = {Towards Better Clinical Prediction Models: Seven Steps for Development and an {{ABCD}} for Validation.},
  author = {Steyerberg, Ewout W. and Vergouwe, Yvonne},
  date = {2014-08},
  journaltitle = {Eur Heart J},
  volume = {35},
  number = {29},
  eprint = {24898551},
  eprinttype = {pmid},
  pages = {1925--1931},
  publisher = {The Oxford University Press},
  issn = {1522-9645},
  doi = {10.1093/eurheartj/ehu207},
  url = {http://dx.doi.org/10.1093/eurheartj/ehu207},
  abstract = {Clinical prediction models provide risk estimates for the presence of disease (diagnosis) or an event in the future course of disease (prognosis) for individual patients. Although publications that present and evaluate such models are becoming more frequent, the methodology is often suboptimal. We propose that seven steps should be considered in developing prediction models: (i) consideration of the research question and initial data inspection; (ii) coding of predictors; (iii) model specification; (iv) model estimation; (v) evaluation of model performance; (vi) internal validation; and (vii) model presentation. The validity of a prediction model is ideally assessed in fully independent data, where we propose four key measures to evaluate model performance: calibration-in-the-large, or the model intercept (A); calibration slope (B); discrimination, with a concordance statistic (C); and clinical usefulness, with decision-curve analysis (D). As an application, we develop and validate prediction models for 30-day mortality in patients with an acute myocardial infarction. This illustrates the usefulness of the proposed framework to strengthen the methodological rigour and quality for prediction models in cardiovascular research. Published on behalf of the European Society of Cardiology. All rights reserved.  The Author 2014. For permissions please email: journals.permissions@oup.com.},
  citeulike-article-id = {13244779},
  citeulike-attachment-1 = {ste14tow.pdf; /pdf/user/harrelfe/article/13244779/978712/ste14tow.pdf; 5a29fe709dd6d87be27e4adb71a13c7a2adfa777},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/eurheartj/ehu207},
  citeulike-linkout-1 = {http://eurheartj.oxfordjournals.org/content/early/2014/06/03/eurheartj.ehu207.abstract},
  citeulike-linkout-2 = {http://eurheartj.oxfordjournals.org/content/early/2014/06/03/eurheartj.ehu207.full.pdf},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/24898551},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=24898551},
  day = {1},
  posted-at = {2014-08-04 19:56:45},
  priority = {4},
  keywords = {calibration,clinical-prediction,teaching-mds,tutorial,validation}
}

@article{ste16pre,
  title = {Prediction Models Need Appropriate Internal, Internal-External, and External Validation.},
  author = {Steyerberg, Ewout W. and Harrell, Frank E.},
  date = {2016-01},
  journaltitle = {J Clin Epi},
  volume = {69},
  eprint = {25981519},
  eprinttype = {pmid},
  pages = {245--247},
  issn = {1878-5921},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25981519},
  citeulike-article-id = {13936242},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25981519},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25981519},
  posted-at = {2016-07-26 21:14:00},
  priority = {2},
  keywords = {validation}
}

@article{ste18vala,
  title = {Validation in Prediction Research: The Waste by Data-Splitting},
  shorttitle = {Validation in Prediction Research},
  author = {Steyerberg, Ewout W.},
  date = {2018-07-28},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2018.07.010},
  url = {https://www.jclinepi.com/article/S0895-4356(18)30485-2/abstract},
  urldate = {2018-07-30},
  langid = {english},
  keywords = {external-validation,sample-size,validation}
}

@article{ste20ran,
  title = {Random Effects Dynamic Panel Models for Unequally Spaced Multivariate Categorical Repeated Measures: An Application to Child–Parent Exchanges of Support},
  shorttitle = {Random Effects Dynamic Panel Models for Unequally Spaced Multivariate Categorical Repeated Measures},
  author = {Steele, Fiona and Grundy, Emily},
  date = {2020},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume = {n/a},
  number = {n/a},
  issn = {1467-9876},
  doi = {10.1111/rssc.12446},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12446},
  urldate = {2020-11-22},
  abstract = {Exchanges of practical or financial help between people living in different households are a major component of intergenerational exchanges within families and an increasingly important source of support for individuals in need. Using longitudinal data, bivariate dynamic panel models can be applied to study the effects of changes in individual circumstances on help given to and received from non-coresident parents and the reciprocity of exchanges. However, the use of a rotating module for collection of data on exchanges leads to data where the response measurements are unequally spaced and taken less frequently than for the time-varying covariates. Existing approaches to this problem focus on fixed effects linear models for univariate continuous responses. We propose a random effects estimator for a family of dynamic panel models that can handle continuous, binary or ordinal multivariate responses. The performance of the estimator is assessed in a simulation study. A bivariate probit dynamic panel model is then applied to estimate the effects of partnership and employment transitions in the previous year and the presence and age of children in the current year on an individual’s propensity to give or receive help. Annual data on respondents’ partnership, employment status and dependent children, and data on exchanges of help collected at 2- and 5-year intervals are used in this study.},
  langid = {english},
  keywords = {longitudinal,multivariate,ordinal,serial},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssc.12446},
  note = {Method is purely autoregressive without a marginal interpretation (i.e., is non-causal for treatment comparisons)}
}

@article{ste95pra,
  title = {Practical Methodology of Meta-Analyses (Overviews) Using Updated Individual Patient Data},
  author = {Stewart, Lesley A. and Clarke, Michael J.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {2057--2079},
  citeulike-article-id = {13264903},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {data-quality,fte,literature-search,meta-analysis,time-requirements}
}

@book{ste96pro,
  title = {Prognostic {{Modeling}} for {{Clinical Decision Making}}},
  author = {Steyerberg, Ewout W.},
  date = {1996},
  publisher = {{E. W. Steyerberg}},
  location = {{Department of Public Health, Ee2091, Erasmus University, P.O. Box 1738, 3000 DR Rotterdam}},
  citeulike-article-id = {13264904},
  posted-at = {2014-07-14 14:09:45},
  priority = {0}
}

@article{ste98neu,
  title = {Neural Networks, Logistic Regression, and Calibration},
  author = {Steyerberg, Ewout W. and Harrell, Frank E. and Goodman, Philip H.},
  date = {1998},
  journaltitle = {Med Decis Mak},
  volume = {18},
  pages = {349--350},
  citeulike-article-id = {13265305},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  annotation = {Refereed letter to the editor}
}

@article{ste98tes,
  title = {Tests for Publication Bias in Meta-Analysis},
  author = {Steichen, Thomas J.},
  date = {1998-01},
  journaltitle = {Stata Tech Bull},
  volume = {STB-41},
  pages = {9--15},
  citeulike-article-id = {13264906},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {meta-analysis,publication-bias}
}

@article{ste98vio,
  title = {Violin Plots},
  author = {Steichen, Thomas J.},
  date = {1998-11},
  journaltitle = {Stata Tech Bull},
  volume = {STB-46},
  pages = {13--18},
  citeulike-article-id = {13264907},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  note = {nice examples from different distributions;nice depiction of ordinary box plot inside violin plot;ineffective side-by-side plots for multiple groups}
}

@book{ste99wri,
  title = {Writing {{Apache Modules}} with {{Perl}} and {{C}}: {{The Apache API}} and Mod\_perl},
  author = {Stein, Lincoln},
  date = {1999},
  publisher = {{O'Reilly}},
  citeulike-article-id = {13265242},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {data-management,perl,web-server}
}

@article{sti84ran,
  title = {Random Effects Models for Serial Observations with Binary Response},
  author = {Stiratelli, R. and Laird, N. and Ware, J. H.},
  date = {1984},
  journaltitle = {Biometrics},
  volume = {40},
  pages = {961--971},
  citeulike-article-id = {13264908},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {clustered-data,extensions-of-logistic-model,random-effects,repeated-measures}
}

@article{sto07rel,
  title = {Relationship of Hemoglobin {{A1c}} to Mortality in Nonsmoking Insurance Applicants},
  author = {Stout, R. L. and Fulks, M. and Dolan, V. F. and Magee, M. E. and Suarez, L.},
  date = {2007},
  journaltitle = {J Insur Med},
  volume = {39},
  number = {3},
  pages = {174--181},
  abstract = {Determine the relationship between hemoglobin A1c value and 5-year, all-cause mortality in nonsmoking life insurance applicants.  By use of the Social Security Master Death Index, mortality was examined in 286,443 non-smoking insurance applicants aged 40 and up for whom blood samples for hemoglobin A1c were submitted to the Clinical Reference Laboratory. Results were stratified by hemoglobin A1c value, gender and age bands 40 to 59, 60 to 69 and 70 and up.  Increased mortality is apparent at hemoglobin A1c values of 6\% and above, is linear, and on a percentage basis decreases with age. Hemoglobin A1c values less than 5\% also are associated with increased mortality. Absolute mortality rates for females with elevated hemoglobin A1c are generally lower than rates for males, although mortality relative to the gender-specific reference group with hemoglobin A1c of 5\% to 5.9\% is generally the same for both.  The importance of even small elevations of hemoglobin A1c above 5.9\% is apparent. For screening, it is the degree of blood sugar elevation as measured by hemoglobin A1c rather than any diagnostic label that is critical in risk assessment.},
  citeulike-article-id = {13265990},
  posted-at = {2014-07-14 14:10:09},
  priority = {0},
  keywords = {diabetes}
}

@article{sto19pre,
  title = {Prediction and {{Inference With Missing Data}} in {{Patient Alert Systems}}},
  author = {Storlie, Curtis B. and Therneau, Terry M. and Carter, Rickey E. and Chia, Nicholas and Bergquist, John R. and Huddleston, Jeanne M. and Romero-Brufau, Santiago},
  date = {2019-04-23},
  journaltitle = {Journal of the American Statistical Association},
  volume = {0},
  number = {0},
  pages = {1--28},
  issn = {0162-1459},
  doi = {10.1080/01621459.2019.1604359},
  url = {https://doi.org/10.1080/01621459.2019.1604359},
  urldate = {2019-06-20},
  abstract = {We describe the Bedside Patient Rescue (BPR) project, the goal of which is risk prediction of adverse events for non-intensive care unit patients using ∼100 variables (vitals, lab results, assessments, etc.). There are several missing predictor values for most patients, which in the health sciences is the norm, rather than the exception. A Bayesian approach is presented that addresses many of the shortcomings to standard approaches to missing predictors: (i) treatment of the uncertainty due to imputation is straight-forward in the Bayesian paradigm, (ii) the predictor distribution is flexibly modeled as an infinite normal mixture with latent variables to explicitly account for discrete predictors (i.e., as in multivariate probit regression models), and (iii) certain missing not at random situations can be handled effectively by allowing the indicator of missingness into the predictor distribution only to inform the distribution of the missing variables. The proposed approach also has the benefit of providing a distribution for the prediction, including the uncertainty inherent in the imputation. Therefore, we can ask questions such as: is it possible this individual is at high risk but we are missing too much information to know for sure? How much would we reduce the uncertainty in our risk prediction by obtaining a particular missing value? This approach is applied to the BPR problem resulting in excellent predictive capability to identify deteriorating patients. Supplementary materials for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.},
  keywords = {bayes,dynamic-prediction,missing,prediction}
}

@inproceedings{sto85,
  title = {Additive Splines in Statistics},
  booktitle = {Proceedings of the {{Statistical Computing Section ASA}}},
  author = {Stone, C. J. and Koo, C. Y.},
  date = {1985},
  pages = {45--48},
  location = {{Washington, DC}},
  citeulike-article-id = {13264909},
  posted-at = {2014-07-14 14:09:45},
  priority = {0}
}

@article{sto86,
  title = {Comment: {{Generalized}} Additive Models},
  author = {Stone, C. J.},
  date = {1986},
  journaltitle = {Stat Sci},
  volume = {1},
  pages = {312--314},
  citeulike-article-id = {13264910},
  posted-at = {2014-07-14 14:09:45},
  priority = {0}
}

@article{sto90exa,
  title = {Exact Properties of Some Exact Test Statistics for Comparing Two Binomial Proportions},
  author = {Storer, B. E. and Kim, Choongrak},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {146--155},
  citeulike-article-id = {13264911},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model}
}

@article{sto90seq,
  title = {A Sequential Phase {{II}}/{{III}} Trial for Binary Outcomes},
  author = {Be, Storer},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {229--235},
  citeulike-article-id = {13264912},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {sequential-methods,study-design-and-stopping-rules}
}

@article{sto97pol,
  title = {Polynomial Splines and Their Tensor Products in Extended Linear Modeling (with Discussion)},
  author = {Stone, Charles J. and Hansen, Mark H. and Kooperberg, Charles and Truong, Young K.},
  date = {1997},
  journaltitle = {Ann Stat},
  volume = {25},
  pages = {1371--1470},
  citeulike-article-id = {13264913},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {b-spline,bic,hare,heft,polytomous-response,spline-basis,tensor-spline}
}

@article{str05qui,
  title = {Quick and Easy Choice Sets: {{Constructing}} Optimal and Nearly Optimal Stated Choice Experiments},
  shorttitle = {Quick and Easy Choice Sets},
  author = {Street, Deborah J. and Burgess, Leonie and Louviere, Jordan J.},
  date = {2005-12-01},
  journaltitle = {International Journal of Research in Marketing},
  volume = {22},
  number = {4},
  pages = {459--470},
  issn = {0167-8116},
  doi = {10.1016/j.ijresmar.2005.09.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0167811605000510},
  urldate = {2021-08-31},
  abstract = {In this paper we compare a number of common strategies for constructing discrete choice experiments. Two of the strategies, including one based on theoretical constructions for optimal discrete choice experiments, produce designs that are better than those that come about from random grouping and from using the LMA construction. A simple account of this theoretical construction is given.},
  langid = {english},
  keywords = {design,discrete-choice-models}
}

@article{str06a,
  title = {An Alternative Foundation for the Planning and Evaluation of Linkage Analysis: 1. {{Decoupling}} 'error Probabilities' from 'Measures of Evidence'},
  author = {Strug, L. and Hodge, S. E.},
  date = {2006},
  journaltitle = {Human Heredity},
  volume = {61},
  pages = {166--188},
  citeulike-article-id = {13265745},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@article{str06b,
  title = {An Alternative Foundation for the Planning and Evaluation of Linkage Analysis: 2. {{Implications}} for Multiple Test Adjustments},
  author = {Strug, L. and Hodge, S. E.},
  date = {2006},
  journaltitle = {Human Heredity},
  volume = {61},
  pages = {200--209},
  citeulike-article-id = {13265746},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@book{str07con,
  title = {The {{Construction}} of {{Optimal Stated Choice Experiments}}: {{Theory}} and {{Methods}}},
  author = {Street, Deborah J and Burgess, Leonie},
  date = {2007},
  publisher = {{Wiley and Sons}},
  url = {https://onlinelibrary-wiley-com.proxy.library.vanderbilt.edu/doi/book/10.1002/9780470148563},
  isbn = {978-0-470-05332-4},
  keywords = {design,discrete-choice-models}
}

@article{str88,
  title = {Analysis of Repeated Ordered Categorical Outcomes with Possible Missing Observations and Time-Dependent Covariates},
  author = {Stram, D. O. and Wei, L. J. and {Ware}},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {631--637},
  citeulike-article-id = {13264914},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {logistic-model-extensions,logistic-ordinal-model}
}

@article{str90sho,
  title = {Shortcut Method to Calculate the Sample Size in Trials of Screening for Chronic Disease},
  author = {{Straatman}},
  date = {1990},
  journaltitle = {J Clin Epi},
  volume = {43},
  pages = {1261--1266},
  citeulike-article-id = {13264915},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {sample-size-estimation}
}

@article{str90tes,
  title = {On Tests That Are Uniformly More Powerful than the {{Wilcoxon-Mann-Whitney}} Test},
  author = {{Streitberg}},
  date = {1990},
  journaltitle = {Biometrics},
  volume = {46},
  pages = {481--484},
  citeulike-article-id = {13264916},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {distribution-free-methods}
}

@article{str92man,
  title = {The Many Faces of Logistic Regression},
  author = {Strauss, David},
  date = {1992},
  journaltitle = {Ann Math Stat},
  volume = {46},
  pages = {321--327},
  citeulike-article-id = {13264917},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {logistic-model-extensions}
}

@article{str96eas,
  title = {Easy Implementaiton of Writing in Introductory Statistics Courses},
  author = {Stromberg, Arnold J. and Ramanathan, Subathra},
  date = {1996},
  journaltitle = {Am Statistician},
  volume = {50},
  pages = {159--163},
  citeulike-article-id = {13264918},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {stat-teaching-methods,technical-writing,writing}
}

@article{str96met,
  title = {Meta-Analysis of Published Data Using a Linear Mixed-Effects Model},
  author = {Stram, Daniel O.},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {536--544},
  citeulike-article-id = {13264919},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {meta-analysis,mixed-effects-model}
}

@article{str98ext,
  title = {An Extended {{Kaplan--Meier}} Estimator and Its Applications},
  author = {Strauss, David and Shavelle, Robert},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {971--982},
  citeulike-article-id = {13264920},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  note = {estimation of transition probabilities of an individual in state i at time x being in state j at a subsequent time t;dead state and multiple live states;prognostic chart;generalized uninformative censoring;multistate Kaplan-Meier estimator}
}

@article{stu04ana,
  title = {Analytic Strategies to Adjust Confounding Using Exposure Propensity Scores and Disease Risk Scores: {{Nonsteroidal}} Antiinflammatory Drugs and Short-Term Mortality in the Elderly},
  author = {Stürmer, Til and Schneeweiss, Sebastian and Brookhart, M. Alan and Rothman, Kenneth J. and Avorn, Jerry},
  date = {2004},
  journaltitle = {Am J Epi},
  volume = {161},
  pages = {891--898},
  citeulike-article-id = {13265413},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {bias,cohort-studies,confounding},
  note = {nice review of methods for adjusting for confounding including inverse probability of selection weighting with propensity scores;no advantage of disease risk score;paper failed to study standard errors or confidence coverage}
}

@article{stu04hos,
  title = {Hospital Discharge Abstract Data on Comorbidity Improved the Prediction of Death among Patients Hospitalized with Aspiration Pneumonia},
  author = {Stukenborg, G. J. and Wagner, D. P. and Harrell, F. E. and Oliver, M. N. and Kilbridge, K. and Lyman, J. and Einbinder, J. and Connors, A. F.},
  date = {2004},
  journaltitle = {J Clin Epi},
  volume = {57},
  pages = {522--532},
  citeulike-article-id = {13265371},
  posted-at = {2014-07-14 14:09:55},
  priority = {0}
}

@article{stu05pre,
  title = {Present-at-Admission Diagnoses Improve Mortality Risk-Adjustment and Allow More Accurate Assessment of the Relationship between Volume of Lung Cancer Operations and Mortality Risk},
  author = {Stukenborg, George F. and Kilbridge, Kerry L. and Wagner, Douglas P. and Harrell, Frank E. and Oliver, M. Norman and Lyman, Jason A. and Einbinder, Jonathan and Connors, Alfred F.},
  date = {2005},
  journaltitle = {Surg},
  volume = {138},
  pages = {498--507},
  citeulike-article-id = {13265443},
  posted-at = {2014-07-14 14:09:57},
  priority = {0}
}

@article{stu07pre,
  title = {Present-at-Admission Diagnoses Improved Mortality Risk Adjustment among Acute Myocardial Infarction Patients},
  author = {Stukenborg, George J. and Wagner, Douglas P. and Harrell, Frank E. and Oliver, M. Norman and Heim, Steven W. and Price, Amy L. and Han, Caroline K. and Wolf, Andrew M. D. and Connors, Alfred F.},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {142--154},
  citeulike-article-id = {13265533},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {comoridites,mortality-model,myocardial-infarction,present-at-admission,risk-adjustment,risk-model}
}

@article{stu07whi,
  title = {Which Hospitals Have Significantly Better or Worse than Expected Mortality Rates for Acute Myocardial Infarction Patients? {{Improved}} Risk Adjustment with Present-at-Admission Diagnoses.},
  author = {Stukenborg, George J. and Wagner, Douglas P. and Harrell, Frank E. and Oliver, M. Norman and Heim, S. W. and Price, A. L. and Han, C. K. and Wolf, A. M. and Connors, A. F.},
  date = {2007},
  journaltitle = {Circ},
  volume = {116},
  pages = {2960--2968},
  citeulike-article-id = {13265648},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {comorbidity,health-services-research}
}

@article{sub10gen,
  title = {Gene Expression-Based Prognostic Signatures in Lung Cancer: {{Ready}} for Clinical Use?},
  author = {Subramanian, Jyothi and Simon, Richard},
  date = {2010},
  journaltitle = {J Nat Cancer Inst},
  volume = {102},
  pages = {464--474},
  citeulike-article-id = {13265851},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {bioinformatics,biomarker,genomic-signatures,quality-assessment},
  note = {none demonstrated to have clinical utility;bioinformatics;quality scoring of papers}
}

@article{sui912x2,
  title = {The 2 2 Matched-Pairs Trial: {{Exact}} Unconditional Design and Analysis},
  author = {Suissa, S. and Shuster, J. J.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {361--372},
  citeulike-article-id = {13264921},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {exact-tests}
}

@article{sui94bin,
  title = {Binary Regression with Continuous Outcomes},
  author = {Suissa, Samy and Blais, Lucie},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {247--255},
  doi = {10.1002/sim.4780140303},
  url = {http://dx.doi.org/10.1002/sim.4780140303},
  citeulike-article-id = {13264922},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780140303},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {categorizing-continuous-variables,cutpoints,teaching-mds}
}

@article{sul15bia,
  title = {Bias and {{Precision}} of the “{{Multiple Imputation}}, {{Then Deletion}}” {{Method}} for {{Dealing With Missing Outcome Data}}},
  author = {Sullivan, Thomas R. and Salter, Amy B. and Ryan, Philip and Lee, Katherine J.},
  date = {2015-09-15},
  journaltitle = {American Journal of Epidemiology},
  volume = {182},
  number = {6},
  pages = {528--534},
  issn = {0002-9262},
  doi = {10.1093/aje/kwv100},
  url = {https://doi.org/10.1093/aje/kwv100},
  urldate = {2021-01-05},
  abstract = {Multiple imputation (MI) is increasingly being used to handle missing data in epidemiologic research. When data on both the exposure and the outcome are missing, an alternative to standard MI is the “multiple imputation, then deletion” (MID) method, which involves deleting imputed outcomes prior to analysis. While MID has been shown to provide efficiency gains over standard MI when analysis and imputation models are the same, the performance of MID in the presence of auxiliary variables for the incomplete outcome is not well understood. Using simulated data, we evaluated the performance of standard MI and MID in regression settings where data were missing on both the outcome and the exposure and where an auxiliary variable associated with the incomplete outcome was included in the imputation model. When the auxiliary variable was unrelated to missingness in the outcome, both standard MI and MID produced negligible bias when estimating regression parameters, with standard MI being more efficient in most settings. However, when the auxiliary variable was also associated with missingness in the outcome, alarmingly MID produced markedly biased parameter estimates. On the basis of these results, we recommend that researchers use standard MI rather than MID in the presence of auxiliary variables associated with an incomplete outcome.},
  keywords = {imputation,mi,multiple-imputation},
  note = {Disagrees with von Hippel approach of "impute then delete" for Y}
}

@article{sun00est,
  title = {Estimands in Hematologic Oncology Trials},
  author = {Sun, Steven and Weber, Hans-Jochen and Butler, Emily and Rufibach, Kaspar and Roychoudhury, Satrajit},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2108},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2108},
  urldate = {2021-03-09},
  abstract = {The estimand framework included in the addendum to the ICH E9 guideline facilitates discussions to ensure alignment between the key question of interest, the analysis, and interpretation. Therapeutic knowledge and drug mechanism play a crucial role in determining the strategy and defining the estimand for clinical trial designs. Clinical trials in patients with hematological malignancies often present unique challenges for trial design due to complexity of treatment options and existence of potential curative but highly risky procedures, for example, stem cell transplant or treatment sequence across different phases (induction, consolidation, maintenance). Here, we illustrate how to apply the estimand framework in hematological clinical trials and how the estimand framework can address potential difficulties in trial result interpretation. This paper is a result of a cross-industry collaboration to connect the International Conference on Harmonisation (ICH) E9 addendum concepts to applications. Three randomized phase 3 trials will be used to consider common challenges including intercurrent events in hematologic oncology trials to illustrate different scientific questions and the consequences of the estimand choice for trial design, data collection, analysis, and interpretation. Template language for describing estimand in both study protocols and statistical analysis plans is suggested for statisticians' reference.},
  langid = {english},
  keywords = {estimand,intercurrent-event,sensitivity-analysis},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2108},
  note = {Nicely laid out review article with useful sensitivity analyses and good discussion of intercurrent events.~ But tends to use "estimands" as an excuse for oversimplifying the primary analysis and doesn't count rescue therapy as a bad outcome from the patient's perspective.~ Too much acceptance of time until first event.~ Having an abundance of sensitivity analysis does not make the primary analysis more clear or more useful for public health and clinical decision making.}
}

@article{sun01sta,
  title = {Statistical Analysis of Repeated Measurements with Informative Censoring Times},
  author = {Sun, Jiangue and Song, Peter},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {63--73},
  citeulike-article-id = {13265174},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {informative-censoring,informative-dropout,repeated-measurements,serial-data},
  note = {stratifies on dropout time;assumes missingness is random conditional on time to dropout;claims that doctors are interested in differences in responses between two patients on different treatments who are on treatment the same duration}
}

@article{sun05red,
  title = {Reduction of Selection Bias in Genomewide Studies by Resampling},
  author = {Sun, Lei and Bull, Shelley B.},
  date = {2005},
  journaltitle = {Gen Epi},
  volume = {28},
  number = {4},
  pages = {352--367},
  doi = {10.1002/gepi.20068},
  url = {http://dx.doi.org/10.1002/gepi.20068},
  abstract = {The accuracy of gene localization, the reliability of locus-specific effect estimates, and the ability to replicate initial claims of linkage and/or association have emerged as major methodological concerns in genomewide studies of complex diseases and quantitative traits. To address the issue of multiple comparisons inherent in genomewide studies, the use of stringent criteria for assessing statistical significance has been generally acknowledged as a strategy to control type I error. However, the application of genomewide significance criteria does not take account of the selection bias introduced into parameter estimates, e.g., estimates of locus-specific effect size of disease/trait loci. Some have argued that reliable locus-specific parameter estimates can only be obtained in an independent sample. In this report, we examine statistical resampling techniques, including cross-validation and the bootstrap, applied to the initial sample to improve the estimation of locus-specific effects. We compare them with the naïve method in which all data are used for both hypothesis testing and parameter estimation, as well as with the split-sample approach in which part of the data are reserved for estimation. Upward bias of the naïve estimator and inadequacy of the split-sample approach are derived analytically under a simple quantitative trait model. Simulation studies of the resampling methods are performed for both the simple model and a more realistic genomewide linkage analysis. Our results suggest that cross-validation and bootstrap methods can substantially reduce the estimation bias, especially when the effect size is small or there is no genetic effect.},
  citeulike-article-id = {13265899},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/gepi.20068},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {biased-estimation,bootstrap,cross-validation,estimation-of-genetic-effect,linkage-analysis}
}

@article{sun17ana,
  title = {Analyzing Multiple Endpoints in a Confirmatory Randomized Clinical Trial-an Approach That Addresses Stratification, Missing Values, Baseline Imbalance and Multiplicity for Strictly Ordinal Outcomes},
  author = {Sun, Hengrui and Kawaguchi, Atsushi and Koch, Gary},
  date = {2017},
  journaltitle = {Pharm Stat},
  issn = {15391604},
  doi = {10.1002/pst.1799},
  url = {http://dx.doi.org/10.1002/pst.1799},
  citeulike-article-id = {14250284},
  citeulike-attachment-1 = {sun17ana.pdf; /pdf/user/harrelfe/article/14250284/1097573/sun17ana.pdf; b922180894effdc8fddaa8b6428c57a56c37c0e1},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1799},
  posted-at = {2017-01-11 13:42:30},
  priority = {2},
  keywords = {composite-endpoints,epub-replace,missing-data,multiple-endpoints}
}

@article{sun96ina,
  title = {Inappropriate Use of Bivariable Analysis to Screen Risk Factors for Use in Multivariable Analysis},
  author = {Sun, Guo-Wen and Shook, Thomas L. and Kay, Gregory L.},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {907--916},
  citeulike-article-id = {13264923},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {stepwise,univariable-screening,variable-selection}
}

@article{sun97reg,
  title = {Regression Analysis of Interval-Censored Failure Time Data},
  author = {Sun, Jianguo},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {497--504},
  citeulike-article-id = {13264924},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {interval-censoring}
}

@article{suncop,
  title = {Copula-Based Semiparametric Regression Method for Bivariate Data under General Interval Censoring},
  author = {Sun, Tao and Ding, Ying},
  journaltitle = {Biostatistics},
  doi = {10.1093/biostatistics/kxz032},
  url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz032/5567259},
  urldate = {2019-09-15},
  abstract = {Summary.  This research is motivated by discovering and underpinning genetic causes for the progression of a bilateral eye disease, age-related macular degenera},
  langid = {english},
  keywords = {copula,interval-censoring,semiparametric-model}
}

@article{sup95con,
  title = {A Controlled Trial to Improve Care for Seriously Ill Hospitalized Patients},
  author = {Investigators, The SUPPORT Principal},
  date = {1995},
  journaltitle = {JAMA},
  volume = {274},
  pages = {1591--1598},
  doi = {10.1001/jama.274.20.1591},
  url = {http://dx.doi.org/10.1001/jama.274.20.1591},
  citeulike-article-id = {13264925},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.274.20.1591},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {icu,propensity-score,rct,support}
}

@article{sur19gau,
  title = {A {{Gaussian}} Copula Approach for Dynamic Prediction of Survival with a Longitudinal Biomarker},
  author = {Suresh, Krithika and Taylor, Jeremy M. G. and Tsodikov, Alexander},
  date = {2019},
  journaltitle = {Biostatistics},
  doi = {10.1093/biostatistics/kxz049},
  url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxz049/5671595},
  urldate = {2019-12-16},
  abstract = {Summary.  Dynamic prediction uses patient information collected during follow-up to produce individualized survival predictions at given time points beyond trea},
  langid = {english},
  keywords = {copula,dynamic-prediction,longitudinal,survival}
}

@book{survival,
  title = {Survival: {{Survival}} Analysis, Including Penalised Likelihood},
  author = {Original, With},
  date = {2009},
  url = {http://r-forge.r-project.org},
  citeulike-article-id = {13265775},
  citeulike-linkout-0 = {http://r-forge.r-project.org},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  annotation = {R package version 2.37-7}
}

@article{sus10iv,
  title = {An {{IV}} for the {{RCT}}: Using Instrumental Variables to Adjust for Treatment Contamination in Randomised Controlled Trials},
  author = {Sussman, Jeremy B. and Hayward, Rodney A.},
  date = {2010},
  journaltitle = {BMJ},
  volume = {340},
  eprint = {https://www.bmj.com/content},
  publisher = {BMJ Publishing Group Ltd},
  doi = {10.1136/bmj.c2073},
  url = {https://www.bmj.com/content/340/bmj.c2073},
  abstract = {Although the randomised controlled trial is the “gold standard” for studying the efficacy and safety of medical treatments, it is not necessarily free from bias. When patients do not follow the protocol for their assigned treatment, the resultant “treatment contamination” can produce misleading findings. The methods used historically to deal with this problem, the “as treated” and “per protocol” analysis techniques, are flawed and inaccurate. Intention to treat analysis is the solution most often used to analyse randomised controlled trials, but this approach ignores this issue of treatment contamination. Intention to treat analysis estimates the effect of recommending a treatment to study participants, not the effect of the treatment on those study participants who actually received it. In this article, we describe a simple yet rarely used analytical technique, the “contamination adjusted intention to treat analysis,” which complements the intention to treat approach by producing a better estimate of the benefits and harms of receiving a treatment. This method uses the statistical technique of instrumental variable analysis to address contamination. We discuss the strengths and limitations of the current methods of addressing treatment contamination and the contamination adjusted intention to treat technique, provide examples of effective uses, and discuss how using estimates generated by contamination adjusted intention to treat analysis can improve clinical decision making and patient care.},
  citeulike-article-id = {14559644},
  citeulike-linkout-0 = {http://dx.doi.org/10.1136/bmj.c2073},
  citeulike-linkout-1 = {https://www.bmj.com/content/340/bmj.c2073},
  posted-at = {2018-04-01 15:07:32},
  priority = {1},
  keywords = {compliance,drug-development,instrumental-variables,nonadherence,rct}
}

@inproceedings{sweave,
  title = {Sweave: {{Dynamic Generation}} of {{Statistical Reports Using Literate Data Analysis}}},
  booktitle = {Compstat 2002 --- {{Proceedings}} in {{Computational Statistics}}},
  author = {Leisch, Friedrich},
  editor = {Härdle, Wolfgang and Rönz, Bernd},
  date = {2002},
  pages = {575--580},
  publisher = {{Physica Verlag, Heidelberg}},
  url = {http://www.stat.uni-muenchen.de/̃leisch/Sweave},
  citeulike-article-id = {13265839},
  citeulike-linkout-0 = {http://www.stat.uni-muenchen.de/̃leisch/Sweave},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  annotation = {ISBN 3-7908-1517-9}
}

@book{Swhite,
  title = {Statistical {{Models}} in {{S}}},
  editor = {Chambers, John M. and Hastie, Trevor J.},
  date = {1992},
  publisher = {{Wadsworth and Brooks/Cole}},
  location = {{Pacific Grove, CA}},
  citeulike-article-id = {13264926},
  posted-at = {2014-07-14 14:09:45},
  priority = {0}
}

@article{swi09doc,
  title = {Do Doctors Need Statistics? {{Doctors}}' Use of and Attitudes to Probability and Statistics},
  author = {Swift, Louise and Miles, Susan and Price, Gill M. and Shepstone, Lee and Leinster, Sam J.},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {1969--1981},
  citeulike-article-id = {13265771},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {teaching-mds},
  note = {doctors surveyed reported a significant need for statistics education; 63\% reported they could do things better or start doing them if they had an improved understanding;highlighted themes included critical evaluation of others' research, becoming more active in research, understanding risk better, and being able to better explain things to others}
}

@article{tai01com,
  title = {Competing Risks Analysis of Patients with Osteosarcoma: A Comparison of Four Different Approaches},
  author = {Tai, Bee-Choo and Machin, David and White, Ian and Gebski, Val},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {661--684},
  citeulike-article-id = {13265186},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {competing-risks,good-practical-overview}
}

@article{tak18bay,
  title = {Bayesian Dose-Finding Phase {{I}} Trial Design Incorporating Historical Data from a Preceding Trial},
  author = {Takeda, Kentaro and Morita, Satoshi},
  journaltitle = {Pharm Stat},
  pages = {n/a},
  doi = {10.1002/pst.1850},
  url = {http://dx.doi.org/10.1002/pst.1850},
  abstract = {We consider the problem of incorporating historical data from a preceding trial to design and conduct a subsequent dose-finding trial in a possibly different population of patients. In oncology, for example, after a phase I dose-finding trial is completed in Caucasian patients, investigators often conduct a further phase I trial to determine the maximum tolerated dose in Asian patients. This may be due to concerns about possible differences in treatment tolerability between populations. In this study, we propose to adaptively incorporate historical data into prior distributions assumed in a new dose-finding trial. Our proposed approach aims to appropriately borrow strength from a previous trial to improve the maximum tolerated dose determination in another patient population. We define a ” historical-to-current (H-C)” parameter representing the degree of borrowing based on a retrospective analysis of previous trial data. In simulation studies, we examine the operating characteristics of the proposed method in comparison with 3 alternative approaches and assess how the H-C parameter functions across a variety of realistic settings.},
  citeulike-article-id = {14523898},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/pst.1850},
  posted-at = {2018-01-26 19:15:59},
  priority = {2},
  keywords = {bayes,bayesian-inference,dose-response,drug-development,historical-data}
}

@article{tan05com,
  title = {A Comparison of Imputation Methods in a Longitudinal Randomized Clinical Trial},
  author = {Tang, Lingqi and Song, Juwon and Belin, Thomas R. and Unützer, Jürgen},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {2005},
  pages = {2111--2128},
  citeulike-article-id = {13265438},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {hot-deck,locf,missing-data,model-based-imputation,multiple-imputation,predictive-mean-matching},
  note = {LOCF and available-case method had poor coverage;imputation under a multivariate normal model did not produce correct coverage with highly skewed distributions;hot deck consistently have good nominal coverage and had CL widths 7 per cent larger on average than using multivariate normal imputation;approximate Bayesian bootstrap;different imputation methods used for item and for unit nonresponse;simulation setup;nice graphics;errata 25:1095;2006}
}

@article{tan14met,
  title = {Meta-{{Analysis}} of {{Sequencing Studies With Heterogeneous Genetic Associations}}},
  author = {Tang, Zheng-Zheng and Lin, Dan-Yu},
  date = {2014-07},
  journaltitle = {Gen Epi},
  volume = {38},
  number = {5},
  pages = {389--401},
  issn = {07410395},
  doi = {10.1002/gepi.21798},
  url = {http://dx.doi.org/10.1002/gepi.21798},
  citeulike-article-id = {14033218},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/gepi.21798},
  posted-at = {2016-05-11 12:54:14},
  priority = {2},
  keywords = {ctsafac}
}

@article{tan15met,
  title = {Meta-Analysis for {{Discovering Rare-Variant Associations}}: {{Statistical Methods}} and {{Software Programs}}},
  author = {Tang, Zheng-Zheng and Lin, Dan-Yu},
  date = {2015-07},
  journaltitle = {The Am J Hum Gen},
  volume = {97},
  number = {1},
  pages = {35--53},
  publisher = {Elsevier},
  issn = {00029297},
  doi = {10.1016/j.ajhg.2015.05.001},
  url = {http://dx.doi.org/10.1016/j.ajhg.2015.05.001},
  abstract = {There is heightened interest in using next-generation sequencing technologies to identify rare variants that influence complex human diseases and traits. Meta-analysis is essential to this endeavor because large sample sizes are required for detecting associations with rare variants. In this article, we provide a comprehensive overview of statistical methods for meta-analysis of sequencing studies for discovering rare-variant associations. Specifically, we discuss the calculation of relevant summary statistics from participating studies, the construction of gene-level association tests, the choice of transformation for quantitative traits, the use of fixed-effects versus random-effects models, and the removal of shadow association signals through conditional analysis. We also show that meta-analysis based on properly calculated summary statistics is as powerful as joint analysis of individual-participant data. In addition, we demonstrate the performance of different meta-analysis methods by using both simulated and empirical data. We then compare four major software packages for meta-analysis of rare-variant associations?MASS, RAREMETAL, MetaSKAT, and seqMeta?in terms of the underlying statistical methodology, analysis pipeline, and software interface. Finally, we present PreMeta, a software interface that integrates the four meta-analysis packages and allows a consortium to combine otherwise incompatible summary statistics.},
  citeulike-article-id = {13679588},
  citeulike-linkout-0 = {http://www.cell.com/ajhg/abstract/S0002-9297(15)00186-X},
  citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.ajhg.2015.05.001},
  day = {21},
  posted-at = {2016-05-11 12:55:53},
  priority = {2},
  keywords = {ctsafac}
}

@article{tan18bay,
  title = {Bayesian {{Inference}} for the {{One-Factor Copula Model}}},
  author = {Tan, Ban Kheng and Panagiotelis, Anastasios and Athanasopoulos, George},
  date = {2018-06-11},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {0},
  number = {0},
  pages = {1--19},
  issn = {1061-8600},
  doi = {10.1080/10618600.2018.1482765},
  url = {https://doi.org/10.1080/10618600.2018.1482765},
  urldate = {2018-09-08},
  abstract = {We develop efficient Bayesian inference for the one-factor copula model with two significant contributions over existing methodologies. First, our approach leads to straightforward inference on dependence parameters and the latent factor; only inference on the former is available under frequentist alternatives. Second, we develop a reversible jump Markov chain Monte Carlo algorithm that averages over models constructed from different bivariate copula building blocks. Our approach accommodates any combination of discrete and continuous margins. Through extensive simulations, we compare the computational and Monte Carlo efficiency of alternative proposed sampling schemes. The preferred algorithm provides reliable inference on parameters, the latent factor, and model space. The potential of the methodology is highlighted in an empirical study of 10 binary measures of socio-economic deprivation collected for 11,463 East Timorese households. The importance of conducting inference on the latent factor is motivated by constructing a poverty index using estimates of the factor. Compared to a linear Gaussian factor model, our model average improves out-of-sample fit. The relationships between the poverty index and observed variables uncovered by our approach are diverse and allow for a richer and more precise understanding of the dependence between overall deprivation and individual measures of well-being.},
  keywords = {bayes,copula,multiple-endpoints}
}

@article{tan19bay,
  title = {Bayesian {{Inference}} for the {{One-Factor Copula Model}}},
  author = {Tan, Ban Kheng and Panagiotelis, Anastasios and Athanasopoulos, George},
  date = {2019-01-02},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {28},
  number = {1},
  pages = {155--173},
  issn = {1061-8600},
  doi = {10.1080/10618600.2018.1482765},
  url = {https://doi.org/10.1080/10618600.2018.1482765},
  urldate = {2019-04-25},
  abstract = {We develop efficient Bayesian inference for the one-factor copula model with two significant contributions over existing methodologies. First, our approach leads to straightforward inference on dependence parameters and the latent factor; only inference on the former is available under frequentist alternatives. Second, we develop a reversible jump Markov chain Monte Carlo algorithm that averages over models constructed from different bivariate copula building blocks. Our approach accommodates any combination of discrete and continuous margins. Through extensive simulations, we compare the computational and Monte Carlo efficiency of alternative proposed sampling schemes. The preferred algorithm provides reliable inference on parameters, the latent factor, and model space. The potential of the methodology is highlighted in an empirical study of 10 binary measures of socio-economic deprivation collected for 11,463 East Timorese households. The importance of conducting inference on the latent factor is motivated by constructing a poverty index using estimates of the factor. Compared to a linear Gaussian factor model, our model average improves out-of-sample fit. The relationships between the poverty index and observed variables uncovered by our approach are diverse and allow for a richer and more precise understanding of the dependence between overall deprivation and individual measures of well-being.},
  keywords = {bayes,copula,multiple-endpoints,rct}
}

@article{tan19sam,
  title = {Sample Size Calculation for the {{Andersen-Gill}} Model Comparing Rates of Recurrent Events},
  author = {Tang, Yongqiang and Fitzpatrick, Ronan},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8335},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8335},
  urldate = {2019-08-10},
  abstract = {Recurrent events arise frequently in biomedical research, where the subject may experience the same type of events more than once. The Andersen-Gill (AG) model has become increasingly popular in the analysis of recurrent events particularly when the event rate is not constant over time. We propose a procedure for calculating the power and sample size for the robust Wald test from the AG model in superiority, noninferiority, and equivalence clinical trials. Its performance is demonstrated by numerical examples. Sample SAS code is provided in the Supplementary Material.},
  langid = {english},
  keywords = {recurrent-events,sample-size}
}

@article{tan89,
  title = {Design of Group Sequential Clinical Trials with Multiple Endpoints},
  author = {Tang DI, Geller N. L.},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {776--779},
  citeulike-article-id = {13264927},
  posted-at = {2014-07-14 14:09:45},
  priority = {0},
  keywords = {multivariate-analysis,study-design-and-stopping-rules}
}

@article{tan90,
  title = {Application of New Two-Sample Tests to Data from a Randomized Placebo-Controlled Heart-Failure Trial},
  author = {Tandon, P. K. and Stander, J. and Schwarz, R. P.},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {447--456},
  doi = {10.1002/sim.4780090415},
  url = {http://dx.doi.org/10.1002/sim.4780090415},
  citeulike-article-id = {13264928},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780090415},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {binary-random-var,discriminant-analysis,logistic-model,miscellaneous,rct,two-sample}
}

@article{tan98est,
  title = {Estimation of Age-Specific Reference Ranges via Smoother {{AVAS}}},
  author = {Tango, Toshiro},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1231--1243},
  citeulike-article-id = {13264929},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {age-centiles,avas,interpolation-and-back-transformation-using-avas,normal-ranges,reference-ranges,smoothing}
}

@article{tan99bay,
  title = {A {{Bayesian}} Hierarchical Model for Multi-Level Repeated Ordinal Data: {{Analysis}} of Oral Practice Examinations in a Large Anaesthesiology Training Programme},
  author = {Tan, Ming and Qu, Yinsheng and Mascha, Ed and Schubert, Armin},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1983--1992},
  citeulike-article-id = {13264930},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {bayesian-model,ordinal-regression,ordinal-response,repeated-measures,serial-data}
}

@article{tan99imp,
  title = {Improved Confidence Intervals for the Difference between Binomial Proportions Based on Paired Data},
  author = {Tango, T.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {3511--3513},
  citeulike-article-id = {13265089},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  annotation = {Letter to the Editor},
  note = {Letter to Newcombe RG SiM 17:2635-2650;1998; See also SiM 18:133-139;2000}
}

@article{tandes93,
  title = {On the Design and Analysis of Randomized Clinical Trials with Multiple Endpoints},
  author = {Tang, Dei-In and Geller, Nancy L. and Pocock, Stuart J.},
  date = {1993},
  journaltitle = {Biometrics},
  volume = {49},
  pages = {23--30},
  doi = {10.2307/2532599},
  url = {http://dx.doi.org/10.2307/2532599},
  citeulike-article-id = {13264931},
  citeulike-linkout-0 = {http://dx.doi.org/10.2307/2532599},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {clinical-trials,multiple-outcomes,rct}
}

@article{tar07lin,
  title = {Linear Transformations and the K-Means Clustering Algorithm: {{Applications}} to Clustering Curves},
  author = {Tarpey, Thaddeus},
  date = {2007},
  journaltitle = {Am Statistician},
  volume = {61},
  number = {1},
  pages = {34--40},
  citeulike-article-id = {13265553},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {allometric-extension,canonical-discriminant-analysis,orthogonal-design-matrix,principal-component-analysis,representative-curves}
}

@article{tar90,
  title = {Modular Nonparametric Subsurvival Estimation},
  author = {Tarter ME, Polissar L.},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {29--37},
  citeulike-article-id = {13264932},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {censored-data,general,survival-analysis-non-regression}
}

@article{tas95eco,
  title = {Economic Analysis of Health Care Technology. {{A}} Report on Principles},
  author = {{Task Force on Principles for Economic Analysis of Health Care Technology}},
  date = {1995},
  journaltitle = {Ann Int Med},
  volume = {123},
  pages = {61--70},
  citeulike-article-id = {13264933},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {analysis-of-cost,economic-analysis,health-care-technology,study-design,teaching-mds}
}

@article{tay02sta,
  title = {Statistical {{Techniques}} to {{Detect Fraud}} and Other {{Data Irregularities}} in {{Clinical Questionnaire Data}}},
  author = {Taylor, Rosemary N. and McEntegart, Damian J. and Stillman, Eleanor C.},
  date = {2002-01},
  journaltitle = {Drug Info J},
  volume = {36},
  number = {1},
  pages = {115--125},
  publisher = {SAGE Publications},
  issn = {2168-4804},
  doi = {10.1177/009286150203600115},
  url = {http://dx.doi.org/10.1177/009286150203600115},
  abstract = {The detection of fraud and other systematic data irregularities in clinical trials is an important issue. While awareness of the problem is growing and willingness to combat it is clear, there still appears to be a lack of detection procedures suitable for routine implementation by trial coordinators. The shortage is particularly acute for discrete data, since the majority of methods which are available have been developed for continuous responses. In this paper, we examine the suitability of existing methods for discrete outcomes and propose a new technique for questionnaire data in both an informal graphical mode and as a randomization test. This method exploits the underlying correlation structure of a questionnaire and the difficulty in fabricating such details. A data set concerning a trial of a novel drug for treatment of schizophrenia, in which the Brief Psychiatric Rating Scale was used to assess patient mental health, is used for illustration.},
  citeulike-article-id = {13349297},
  citeulike-linkout-0 = {http://dx.doi.org/10.1177/009286150203600115},
  citeulike-linkout-1 = {http://dij.sagepub.com/content/36/1/115.abstract},
  citeulike-linkout-2 = {http://dij.sagepub.com/content/36/1/115.full.pdf},
  day = {01},
  posted-at = {2014-09-06 14:50:15},
  priority = {0},
  keywords = {correlation-structure,fraud,graphics,multivariate-graphical-analysis,outlier,rct},
  note = {clinical questionnaires;correlation structure;S-Plus graphics;correlation matrix image plot;permutation test for testing for outlier within-site correlation matrix based on a distance metric;multivariate data display;star plot}
}

@article{tay03eff,
  title = {Effects of Adjunctive {{Swedish}} Massage and Vibration Therapy on Short-Term Postoperative Outcomes: {{A}} Randomized, Controlled Trial},
  author = {Taylor, Ann G. and Galper, Daniel I. and Taylor, Peyton and Rice, Laurel W. and Andersen, Willie and Irvin, William and Wang, Xin-Qun and Harrell, Frank E.},
  date = {2003},
  journaltitle = {J Alt Comp Med},
  volume = {9},
  pages = {77--89},
  doi = {10.1089/107555303321222964},
  url = {http://dx.doi.org/10.1089/107555303321222964},
  citeulike-article-id = {13265328},
  citeulike-linkout-0 = {http://dx.doi.org/10.1089/107555303321222964},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {alternative-medicine,rct}
}

@article{tay07ana,
  title = {Analysis on Binary Responses with Ordered Covariates and Missing Data},
  author = {Taylor, Jeremy M. G. and Wang, Lu and Li, Zhiguo},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {3443--3458},
  citeulike-article-id = {13265611},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {biomarkers,isotonic-regression,mixture-of-pool-adjacent-violators-and-gibbs-sampling,multiple-imputation,order-restrictions,ordinal-covariate,ordinal-predictor,parameter-constraints}
}

@article{tay87,
  title = {Kendall's and {{Spearman}}'s Correlation Coefficients in the Presence of a Blocking Variable},
  author = {Jmg, Taylor},
  date = {1987},
  journaltitle = {Biometrics},
  volume = {43},
  pages = {409--416},
  citeulike-article-id = {13264934},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {distribution-free-methods}
}

@article{tay96cos,
  title = {The Cost of Adding Parameters to a Model},
  author = {Taylor, Jeremy M. G. and Siqueira, Arminda L. and Weiss, Robert E.},
  date = {1996},
  journaltitle = {J Roy Stat Soc B},
  volume = {58},
  pages = {593--607},
  citeulike-article-id = {13264935},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {complexity,number-of-variables}
}

@article{tch05use,
  title = {On the Use of Discrete Choice Models for Causal Inference},
  author = {Tchernis, Rusty and Horvitz-Lennon, Marcela and Normand, Sharon-Lise T.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2197--2212},
  citeulike-article-id = {13265437},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {causal-inference,discrete-choice-models,matching-estimator,propensity-score},
  note = {multi-valued treatment propensity model using discrete choice model}
}

@article{tei09cor,
  title = {Correlated Bivariate Continuous and Binary Outcomes: {{Issues}} and Applications},
  author = {Teixeira-Pinto, Armando and Normand, Sharon-Lise T.},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {1753--1773},
  citeulike-article-id = {13265758},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {latent-variable,mixed-outcome,multivariate-models,non-commensurate,power,rct},
  note = {multiple outcomes on different scales in clinical trials; different outcomes depending on different covariate sets;power gains}
}

@article{tek11too,
  title = {Too Many Cohorts and Repeated Measurements Are a Waste of Resources.},
  author = {Tekle, Fetene B. and Tan, Frans E. S. and Berger, Martijn P. F.},
  date = {2011},
  journaltitle = {J Clin Epi},
  volume = {64},
  eprint = {21592727},
  eprinttype = {pubmed},
  pages = {1383--1390},
  abstract = {OBJECTIVE: Researchers in Health Sciences and Medicine often use cohort designs to study treatment effects and changes of outcome variables over time period. The costs of these studies can be reduced by choosing an optimal number of repeated measurements over time and by selecting cohorts of subjects more efficiently with optimal design procedures. The objective of this study is to provide evidence on how to design large-scale cohort studies with budget constraints as efficiently as possible. STUDY DESIGN AND SETTING: A linear cost function for repeated measurements is proposed, and this cost function is used in the optimization procedure. For a given budget/cost, different designs for linear mixed-effects models are compared by means of their efficiency. RESULTS: We found that adding more repeated measures is only beneficiary if the costs of selecting and measuring a new subject are much higher than the costs of obtaining an additional measurement for an already recruited subject. However, this gain in efficiency and power is not very large. CONCLUSION: Adding more cohorts or repeated measurements do not necessarily lead to a gain in efficiency of the estimated model parameters. A general guideline for the optimal choice of a cohort design in practice is required and we offer this guideline.},
  citeulike-article-id = {13265904},
  citeulike-linkout-0 = {http://www.ncbi.nlm.nih.gov/pubmed/21592727},
  posted-at = {2014-07-14 14:10:07},
  priority = {0},
  keywords = {designing-schedule,serial-data,study-design,time-allocation}
}

@article{ten00dec,
  title = {Decision-Making and Outcomes of Prolonged {{ICU}} Stays in Seriously Ill Patients},
  author = {Teno, Joan M. and Fisher, Elliot and Hamel, Mary B. and Wu, Albert W. and Murphy, Donald J. and Wenger, Neil S. and Lynn, Joanne and Harrell, Frank E.},
  date = {2000},
  journaltitle = {J Am Geriatric Soc},
  volume = {48},
  pages = {S70-S74},
  citeulike-article-id = {13265128},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{ten00pre,
  title = {Prediction of Survival for Older Hospitalized Patients: {{The HELP}} Survival Model},
  author = {Teno, Joan M. and Harrell, Frank E. and Knaus, William A. and Phillips, Russell S. and Wu, Albert W. and Connors, Alfred F. and Wenger, Neil S. and Wagner, Douglas and Galanos, Anthony and Desbiens, Norman A. and Lynn, Joanne},
  date = {2000},
  journaltitle = {J Am Geriatric Soc},
  volume = {48},
  pages = {S16-S24},
  citeulike-article-id = {13265127},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  note = {excellent examples of Design library output}
}

@article{ten94pro,
  title = {Prognosis-Based Futility Guidelines: {{Does}} Anyone Win?},
  author = {Teno, J. M. and Murphy, D. and Lynn, J. and Tosteson, A. and Desbiens, N. and Connors, A. F. and Hamel, M. B. and Wu, A. and Phillips, R. and Wenger, N. and Harrell, F. E. and Knaus, W. A. and Investigators, The S.},
  date = {1994},
  journaltitle = {J Am Geriatric Soc},
  volume = {42},
  pages = {1202--1207},
  citeulike-article-id = {13264936},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{ten95ass,
  title = {Association Models for Periodontal Disease Progression: {{A}} Comparison of Methods for Clustered Binary Data},
  author = {Ten Have, T. R. and Landis, J. R. and Weaver, S. L.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {413--429},
  citeulike-article-id = {13264937},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {clustered-data,logistic-model-extensions}
}

@article{ten96mix,
  title = {A Mixed Effects Model for Multivariate Ordinal Response Data Including Correlated Discrete Failure Times with Ordinal Responses},
  author = {Ten Have, Thomas R.},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {473--491},
  citeulike-article-id = {13264938},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {discrete-failure-time-model,log-gamma-random-effects,ordinal-failure,repeated-measures-ordinal-response,severity-of-timed-response,time-and-severity-of-event}
}

@article{ten98mix,
  title = {Mixed Effects Logistic Regression Models for Longitudinal Binary Response Data with Informative Drop-Out},
  author = {Ten Have, Thomas R. and Kunselman, Allen R. and Pulkstenis, Erik P. and Landis, J. Richard},
  date = {1998},
  journaltitle = {Biometrics},
  volume = {54},
  pages = {367--383},
  citeulike-article-id = {13264939},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {informative-drop-out,logistic-model,longditudinal-data,mixed-effects,random-effects,serial-data,shared-parameter}
}

@article{ter90,
  title = {Efficient Use of Endpoints in Clinical Trials: {{A}} Clinical Perspective},
  author = {Ml, Terrin},
  date = {1990},
  journaltitle = {Stat Med},
  volume = {9},
  pages = {155--160},
  citeulike-article-id = {13264940},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {study-design-and-stopping-rules}
}

@article{tha12pro,
  title = {Probabilistic Index Models},
  author = {Thas, Olivier and Neve, Jan De and Clement, Lieven and Ottoy, Jean-Pierre},
  date = {2012},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {74},
  number = {4},
  pages = {623--671},
  issn = {1467-9868},
  doi = {10.1111/j.1467-9868.2011.01020.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2011.01020.x},
  urldate = {2021-10-31},
  abstract = {Summary. We present a semiparametric statistical model for the probabilistic index which can be defined as P(YY*), where Y and Y* are independent random response variables associated with covariate patterns X and X* respectively. A link function defines the relationship between the probabilistic index and a linear predictor. Asymptotic normality of the estimators and consistency of the covariance matrix estimator are established through semiparametric theory. The model is illustrated with several examples, and the estimation theory is validated in a simulation study.},
  langid = {english},
  keywords = {c-index,concordance,probability-index,semi-parametric,semiparametric-model},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2011.01020.x},
  note = {Extensive discussion by Stephen Senn and many others.~ U-statistic estimator requiring huge computation time because all possible pairs must be examined.}
}

@book{tha20sta,
  title = {Statistical {{Remedies}} for {{Medical Researchers}}},
  author = {Thall, Peter F.},
  date = {2020},
  series = {Springer {{Series}} in {{Pharmaceutical Statistics}}},
  publisher = {{Springer International Publishing}},
  doi = {10.1007/978-3-030-43714-5},
  url = {https://www.springer.com/gp/book/9783030437138},
  urldate = {2021-01-09},
  abstract = {This book illustrates numerous statistical practices that are commonly used by medical researchers, but which have severe flaws that may not be obvious. For each example, it provides one or more alternative statistical methods that avoid misleading or incorrect inferences being made. The technical level is kept to a minimum to make the book accessible to non-statisticians. At the same time, since many of the examples describe methods used routinely by medical statisticians with formal statistical training, the book appeals to a broad readership in the medical research community.},
  isbn = {978-3-030-43713-8},
  langid = {english},
  keywords = {basic,bayes,teaching-mds}
}

@article{tha84,
  title = {Nonparametric Estimation of the Hazard Ratio},
  author = {Thaler, H. T.},
  date = {1984},
  journaltitle = {J Am Stat Assoc},
  volume = {79},
  pages = {290--293},
  citeulike-article-id = {13264941},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{tha86,
  title = {Assessment of Stratum-Covariate Interactions in {{Cox}}'s Proportional Hazards Regression Model},
  author = {Thall, P. F. and Lachin, J. M.},
  date = {1986},
  journaltitle = {Stat Med},
  volume = {5},
  pages = {73--83},
  citeulike-article-id = {13264942},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{tha88,
  title = {Analysis of Recurrent Events: Nonparametric Methods for Random-Interval Count Data},
  author = {Thall, P. F. and Lachin, J. M.},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {339--347},
  citeulike-article-id = {13264943},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {censored-data,general,survival-analysis-proportional-hazards-model}
}

@article{tha94bay,
  title = {A {{Bayesian}} Approach to Establishing Sample Size and Monitoring Criteria for Phase {{II}} Clinical Trials},
  author = {Thall, Peter F. and Simon, Richard},
  date = {1994},
  journaltitle = {Controlled Clin Trials},
  volume = {15},
  pages = {463--481},
  citeulike-article-id = {13264944},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  note = {Bayesian inference;sample size based on precision of posterior distribution}
}

@article{tha98som,
  title = {Some Extensions and Applications of a {{Bayesian}} Strategy for Monitoring Multiple Outcomes in Clinical Trials},
  author = {Thall, Peter F. and Sung, Hsi-Guang},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {1563--1580},
  citeulike-article-id = {13264945},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {bayesian,monitoring-study,multiple-endpoints,rct,study-design}
}

@book{the00mod,
  title = {Modeling {{Survival Data}}: {{Extending}} the {{Cox Model}}},
  author = {Therneau, Terry and Grambsch, Patricia},
  date = {2000},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13265150},
  posted-at = {2014-07-14 14:09:50},
  priority = {0}
}

@incollection{the86cox,
  title = {The {{COXREGR}} Procedure},
  booktitle = {{{SUGI Supplemental Library User}}'s {{Guide}}, {{Version}} 5 {{Edition}}},
  author = {Therneau, Terry M.},
  date = {1986},
  pages = {27--34},
  publisher = {{SAS Institute}},
  location = {{Cary NC}},
  citeulike-article-id = {13264946},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{the90,
  title = {Martingale-Based Residuals for Survival Models},
  author = {Therneau, T. M. and Grambsch, P. M. and Fleming, T. R.},
  date = {1990},
  journaltitle = {Biometrika},
  volume = {77},
  pages = {216--218},
  citeulike-article-id = {13264947},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@incollection{the90sur,
  title = {S-{{Plus User}}'s {{Manual}}},
  author = {Therneau, Terry M.},
  date = {1990},
  volume = {2},
  publisher = {{Statistical Sciences, Inc.}},
  location = {{Seattle}},
  chapter = {19},
  citeulike-article-id = {13264948},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {survdiff}
}

@article{the97rhd,
  title = {{{rhDNase}} as an Example of Recurrent Event Analysis},
  author = {Therneau, Terry M. and Hamilton, Scott A.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2029--2047},
  citeulike-article-id = {13264949},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {andersen-gill-model,clustered-survival-times,marginal-model,multiple-events,recurrent-events}
}

@book{thi88,
  title = {Elements of {{Statistical Computing}}},
  author = {Thisted, R. A.},
  date = {1988},
  publisher = {{Chapman and Hall}},
  location = {{New York}},
  citeulike-article-id = {13264950},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{tho88,
  title = {A Reappraisal of the Kappa Coefficient},
  author = {{Thompson} and Walter, S. D.},
  date = {1988},
  journaltitle = {J Clin Epi},
  volume = {41},
  pages = {949--958},
  citeulike-article-id = {13264951},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {categorical-data}
}

@article{tho93pro,
  title = {Proportional Hazards Model for Repeated Measures with Monotonic Ordinal Response},
  author = {Thornquist, Mark D.},
  date = {1993},
  journaltitle = {Biometrics},
  volume = {49},
  pages = {721--730},
  citeulike-article-id = {13264952},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {follow-up,ordinal-failures,ordinal-response,repeated-measures,time-and-severity-of-events}
}

@article{tho94emp,
  title = {Empirical {{Bayes}} Methods for Estimating Hospital-Specific Mortality Rates},
  author = {Thomas, Neal and Longford, Nicholas and Rolph, John E.},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {889--903},
  citeulike-article-id = {13264953},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {cluster-sampling,empirical-bayes,logistic-model-extensions,shrinkage}
}

@article{tho94why,
  title = {Why Sources of Heterogeneity in Meta-Analysis Should Be Investigated},
  author = {Thompson, S. G.},
  date = {1994},
  journaltitle = {BMJ},
  volume = {309},
  pages = {1351--1355},
  doi = {10.1136/bmj.309.6965.1351},
  url = {http://dx.doi.org/10.1136/bmj.309.6965.1351},
  citeulike-article-id = {13264954},
  citeulike-linkout-0 = {http://dx.doi.org/10.1136/bmj.309.6965.1351},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {heterogeneity,meta-analysis,publication-bias,random-effects,teaching-mds}
}

@article{tho97des,
  title = {The Design and Analysis of Paired Cluster Randomized Trials: {{An}} Application of Meta-Analysis Techniques},
  author = {Thompson, Simon G. and Pyke, Stephen D. M. and Hardy, Rebecca J.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2063--2079},
  citeulike-article-id = {13264955},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {cluster-randomization,clustered-data,meta-analysis,study-design}
}

@article{tho97inv,
  title = {Investigating Underlying Risk as a Source of Heterogeneity in Meta-Analysis},
  author = {Thompson, Simon G. and Smith, Teresa C. and Sharp, Stephen J.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2741--2758},
  citeulike-article-id = {13264956},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {baseline-risk,bayesian-inference,bugs,measurement-error,meta-analysis,random-effects-model,regression-to-the-mean,severity-of-disease},
  annotation = {See letter to the editor 18:110-115, 1999}
}

@article{tia07mod,
  title = {Model Evaluation Based on the Sampling Distribution of Estimated Absolute Prediction Error},
  author = {Tian, Lu and Cai, Tianxi and Goetghebeur, Els and Wei, L. J.},
  date = {2007},
  journaltitle = {Biometrika},
  volume = {94},
  pages = {297--311},
  citeulike-article-id = {13265587},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {absolute-prediction-error,bootstrap,cross-validation,model-and-variable-selection,perturbation-resampling,prediction,predictive-accuracy}
}

@article{tia07two,
  title = {A Two-Part Model for Censored Medical Cost Data},
  author = {Tian, Lu and Huang, Jie},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4273--4292},
  citeulike-article-id = {13265628},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {analysis-of-cost-data,clumping-at-zero,cost-data,cumulative-cost-function,health-economics,informative-censoring,inverse-probability-weighting,two-part-model}
}

@article{tia20emp,
  title = {An Empirical Comparison of Two Novel Transformation Models},
  author = {Tian, Yuqi and Hothorn, Torsten and Li, Chun and Harrell, Frank E. and Shepherd, Bryan E.},
  date = {2020-02-28},
  journaltitle = {Stat Med},
  volume = {39},
  number = {5},
  eprint = {31808976},
  eprinttype = {pmid},
  pages = {562--576},
  issn = {1097-0258},
  doi = {10.1002/sim.8425},
  abstract = {Continuous response variables are often transformed to meet modeling assumptions, but the choice of the transformation can be challenging. Two transformation models have recently been proposed: semiparametric cumulative probability models (CPMs) and parametric most likely transformation models (MLTs). Both approaches model the cumulative distribution function and require specifying a link function, which implicitly assumes that the responses follow a known distribution after some monotonic transformation. However, the two approaches estimate the transformation differently. With CPMs, an ordinal regression model is fit, which essentially treats each continuous response as a unique category and therefore nonparametrically estimates the transformation; CPMs are semiparametric linear transformation models. In contrast, with MLTs, the transformation is parameterized using flexible basis functions. Conditional expectations and quantiles are readily derived from both methods on the response variable's original scale. We compare the two methods with extensive simulations. We find that both methods generally have good performance with moderate and large sample sizes. MLTs slightly outperformed CPMs in small sample sizes under correct models. CPMs tended to be somewhat more robust to model misspecification and outcome rounding. Except in the simplest situations, both methods outperform basic transformation approaches commonly used in practice. We apply both methods to an HIV biomarker study.},
  langid = {english},
  pmcid = {PMC7537829},
  keywords = {methodology}
}

@article{tia20empa,
  title = {On the Empirical Choice of the Time Window for Restricted Mean Survival Time},
  author = {Tian, Lu and Jin, Hua and Uno, Hajime and Lu, Ying and Huang, Bo and Anderson, Keaven M. and Wei, L. J.},
  date = {2020},
  journaltitle = {Biometrics},
  volume = {76},
  number = {4},
  pages = {1157--1166},
  issn = {1541-0420},
  doi = {10.1111/biom.13237},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13237},
  urldate = {2021-08-06},
  abstract = {The t-year mean survival or restricted mean survival time (RMST) has been used as an appealing summary of the survival distribution within a time window [0, t]. RMST is the patient's life expectancy until time t and can be estimated nonparametrically by the area under the Kaplan-Meier curve up to t. In a comparative study, the difference or ratio of two RMSTs has been utilized to quantify the between-group-difference as a clinically interpretable alternative summary to the hazard ratio. The choice of the time window [0, t] may be prespecified at the design stage of the study based on clinical considerations. On the other hand, after the survival data have been collected, the choice of time point t could be data-dependent. The standard inferential procedures for the corresponding RMST, which is also data-dependent, ignore this subtle yet important issue. In this paper, we clarify how to make inference about a random “parameter.” Moreover, we demonstrate that under a rather mild condition on the censoring distribution, one can make inference about the RMST up to t, where t is less than or even equal to the largest follow-up time (either observed or censored) in the study. This finding reduces the subjectivity of the choice of t empirically. The proposal is illustrated with the survival data from a primary biliary cirrhosis study, and its finite sample properties are investigated via an extensive simulation study.},
  langid = {english},
  keywords = {restricted-mean-life,survival},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13237}
}

@article{tib82,
  title = {A Plain Man's Guide to the Proportional Hazards Model},
  author = {Tibshirani, R.},
  date = {1982},
  journaltitle = {Clin Inv Med},
  volume = {5},
  pages = {63--68},
  citeulike-article-id = {13264957},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{tib87,
  title = {Local Likelihood Estimation},
  author = {{Tibshirani} and Hastie, T.},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {559--567},
  citeulike-article-id = {13264958},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {graphical-methods,maximum-likelihood}
}

@article{tib88est,
  title = {Estimating Transformations for Regression via Additivity and Variance Stabilization},
  author = {Tibshirani, Robert},
  date = {1988},
  journaltitle = {J Am Stat Assoc},
  volume = {83},
  pages = {394--405},
  citeulike-article-id = {13264959},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {avas,generalized-additive-model,nonparametric-regression,variance-stabilization}
}

@article{tib89non,
  title = {Noninformative Priors for One Parameter of Many},
  author = {Tibshirani, Robert},
  date = {1989},
  journaltitle = {Biometrika},
  volume = {76},
  pages = {604--608},
  citeulike-article-id = {13264960},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {bayesian-inference,choice-of-prior}
}

@article{tib96reg,
  title = {Regression Shrinkage and Selection via the Lasso},
  author = {Tibshirani, Robert},
  date = {1996},
  journaltitle = {J Roy Stat Soc B},
  volume = {58},
  pages = {267--288},
  citeulike-article-id = {13264961},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {penalized-mle,ridge-regression,shrinkage,variable-selection}
}

@article{tib97las,
  title = {The Lasso Method for Variable Selection in the {{Cox}} Model},
  author = {Tibshirani, Robert},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {385--395},
  citeulike-article-id = {13264962},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {predictive-accuracy,shrinkage,variable-selection}
}

@report{tib97mod,
  title = {Model Search and Inference by Bootstrap “Bumping”},
  author = {Tibshirani, Robert and Knight, Keith},
  date = {1997},
  institution = {{Department of Statistics, University of Toronto}},
  citeulike-article-id = {13264963},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {cart,confidence-sets,constrained-optimization,simultaneous-confidence-regions},
  annotation = {http://www-stat.stanford.edu/∼tibs. Presented at the Joint Statistical Meetings, Chicago, August 1996},
  note = {improving performance of estimators via the bootstrap}
}

@article{tib99cov,
  title = {The Covariance Inflation Criterion for Adaptive Model Selection},
  author = {Tibshirani, Robert and Knight, Keith},
  date = {1999},
  journaltitle = {J Roy Stat Soc B},
  volume = {61},
  pages = {529--546},
  citeulike-article-id = {13264965},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {adaptive-prediction,bootstrap,cross-validation,effective-degrees-of-freedom,generalized-degrees-of-freedom,model-selection,model-uncertainty,model-validation,permutation-method,randomization-method,simulation-setup}
}

@article{tib99mod,
  title = {\{\vphantom\}{{Model}} Search by Bootstrap ''bumping''\vphantom\{\}},
  author = {Tibshirani, Robert and Knight, Keith},
  date = {1999},
  journaltitle = {J Comp Graph Stat},
  volume = {8},
  pages = {671--686},
  citeulike-article-id = {13264964},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{tim70est,
  title = {The Estimation of Variance-Covariance and Correlation Matrices from Incomplete Data},
  author = {Timm, N. H.},
  date = {1970},
  journaltitle = {Psychometrika},
  volume = {35},
  pages = {417--437},
  citeulike-article-id = {13264966},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {missing-data}
}

@article{tju09coe,
  title = {Coefficients of Determination in Logistic Regression Models---{{A}} New Proposal: {{The}} Coefficient of Discrimination},
  author = {Tjur, Tue},
  date = {2009},
  journaltitle = {Am Statistician},
  volume = {63},
  number = {4},
  pages = {366--372},
  citeulike-article-id = {13265790},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {coefficient-of-determination,explanatory-power,logistic-regression,r2}
}

@article{tob01tow,
  title = {Towards a Curriculum for the Constant Biostatistician: Identification of Central Disciplines},
  author = {Tobi, Hilde and Kuik, D. Joop and Bezemer, P. Dick and Ket, Paul},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {3921--3929},
  citeulike-article-id = {13265254},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {consulting,continuing-education,core-methodology-to-know,training}
}

@article{tod0725,
  title = {A 25-Year Review of Sequential Methodology in Clinical Trials},
  author = {Todd, S.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {237--252},
  citeulike-article-id = {13265655},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {rct,review,sequential-methods}
}

@article{tol96ord,
  title = {Ordinal Regression Methodology for {{ROC}} Curves Derived from Correlated Data},
  author = {Toledano, Alicia Y. and Gatsonis, Constantine},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {1807--1826},
  citeulike-article-id = {13264967},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {models-for-roc,roc-analysis,roc-area,roc-for-correlated-predictors}
}

@article{tom09suc,
  title = {Success of Meniscal Repair at Anterior Cruciate Ligament Reconstruction},
  author = {Toman, C. V. and Dunn, W. R. and Spindler, K. P. and Amendola, A. and Andrish, J. T. and Bergfeld, J. A. and Flanigan, D. and Jones, M. H. and Kaeding, C. C. and Marx, R. G. and Matava, M. J. and McCarty, E. C. and Parker, R. D. and Wolcott, M. and Vidal, A. and Wolf, B. R. and Huston, L. J. and Harrell, F. E. and Wright, R. W.},
  date = {2009},
  journaltitle = {Am J Sports Med},
  volume = {37},
  number = {6},
  pages = {1111--1115},
  citeulike-article-id = {13265777},
  posted-at = {2014-07-14 14:10:04},
  priority = {0}
}

@article{ton08pra,
  title = {Practical Guidelines for Assessing Power and False Discovery Rate for a Fixed Sample Size in Microarray Experiments},
  author = {Tong, Tiejun and Zhao, Hongyu},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {1960--1972},
  citeulike-article-id = {13265674},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {false-discovery-rate,fdr,gene-expression,gene-microarray,graphics,power,sample-size,t-statistic},
  note = {nice graphs relating power to FDR}
}

@article{tor85how,
  title = {How Should Relative Changes Be Measured?},
  author = {Törnqvist, L. and Vartia, P. and Vartia, Y. O.},
  date = {1985},
  journaltitle = {Am Statistician},
  volume = {39},
  pages = {43--46},
  doi = {10.1080/00031305.1985.10479385},
  url = {http://dx.doi.org/10.1080/00031305.1985.10479385},
  citeulike-article-id = {13264968},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00031305.1985.10479385},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {change,measuring-change,one-sample-problem,percent-change,teaching-mds}
}

@article{tou01imp,
  title = {Impact of Missing Data Due to Drop-Outs on Estimators for Rates of Change in Longitudinal Studies: A Simulation Study},
  author = {Touloumi, G. and Babiker, A. G. and Pocock, S. J. and Darbyshire, J. H.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {3715--3728},
  citeulike-article-id = {13265252},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {comparison-of-many-methods,large-bias-with-gee,longitudinal-data,nice-summary-of-each-method,non-random-dropouts,serial-data,simulation-setup}
}

@article{tou99est,
  title = {Estimation and Comparison of Rates of Change in Longitudinal Studies with Informative Drop-Outs},
  author = {Touloumi, G. and Pocock, S. J. and Babiker, A. G. and Darbyshire, J. H.},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1215--1233},
  citeulike-article-id = {13264969},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {cd4,graphics,informative-dropout,longitudinal-study,repeated-measures}
}

@article{tra00lat,
  title = {Latent {{Ornstein-Uhlenbeck}} Models for {{Bayesian}} Analysis of Multivariate Longitudinal Categorical Responses},
  author = {Tran, Trung Dung and Lesaffre, Emmanuel and Verbeke, Geert and Duyck, Joke},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13292},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13292},
  urldate = {2020-12-11},
  abstract = {We propose a Bayesian latent Ornstein-Uhlenbeck (OU) model to analyze unbalanced longitudinal data of binary and ordinal variables, which are manifestations of fewer continuous latent variables. We focus on the evolution of such latent variables when they continuously change over time. Existing approaches are limited to data collected at regular time intervals. Our proposal makes use of an OU process for the latent variables to overcome this limitation. We show that assuming real eigenvalues for the drift matrix of the OU process, as is frequently done in practice, can lead to biased estimates and/or misleading inference when the true process is oscillating. In contrast, our proposal allows for both real and complex eigenvalues. We illustrate our proposed model with a motivating dataset, containing patients with amyotrophic lateral sclerosis disease. We were interested in how bulbar, cervical, and lumbar functions evolve over time.},
  langid = {english},
  keywords = {bayes,categorical-data,ornstein-uhlenbeck,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13292}
}

@article{tra07glo,
  title = {Global Effects Estimation for Multidimensional Outcomes},
  author = {Travison, T. G. and Brookmeyer, R.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4845--4859},
  citeulike-article-id = {13265636},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {composit-endpoint,marginal-model,multiple-endpoints,multivariate-response,ranks,rct,treatment-effect},
  note = {use of common Lehmann alternative exponent (e.g., hazard ratio) to tie together the treatment ships of several related continuous responses}
}

@article{tra20gen,
  title = {Generating {{Optimal Designs}} for {{Discrete Choice Experiments}} in {{R}}: {{The}} Idefix {{Package}}},
  shorttitle = {Generating {{Optimal Designs}} for {{Discrete Choice Experiments}} in {{R}}},
  author = {Traets, Frits and Sanchez, Daniel Gil and Vandebroek, Martina},
  date = {2020-11-29},
  journaltitle = {Journal of Statistical Software},
  volume = {96},
  number = {1},
  pages = {1--41},
  issn = {1548-7660},
  doi = {10.18637/jss.v096.i03},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v096i03},
  urldate = {2020-12-08},
  issue = {1},
  langid = {english},
  keywords = {design,discrete-choice-models}
}

@article{tra21lat,
  title = {Latent {{Ornstein-Uhlenbeck}} Models for {{Bayesian}} Analysis of Multivariate Longitudinal Categorical Responses},
  author = {Tran, Trung Dung and Lesaffre, Emmanuel and Verbeke, Geert and Duyck, Joke},
  date = {2021},
  journaltitle = {Biometrics},
  volume = {77},
  number = {2},
  pages = {689--701},
  issn = {1541-0420},
  doi = {10.1111/biom.13292},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13292},
  urldate = {2021-06-22},
  abstract = {We propose a Bayesian latent Ornstein-Uhlenbeck (OU) model to analyze unbalanced longitudinal data of binary and ordinal variables, which are manifestations of fewer continuous latent variables. We focus on the evolution of such latent variables when they continuously change over time. Existing approaches are limited to data collected at regular time intervals. Our proposal makes use of an OU process for the latent variables to overcome this limitation. We show that assuming real eigenvalues for the drift matrix of the OU process, as is frequently done in practice, can lead to biased estimates and/or misleading inference when the true process is oscillating. In contrast, our proposal allows for both real and complex eigenvalues. We illustrate our proposed model with a motivating dataset, containing patients with amyotrophic lateral sclerosis disease. We were interested in how bulbar, cervical, and lumbar functions evolve over time.},
  langid = {english},
  keywords = {categorical-data,latent-variable,multiple-endpoints,ordinal,ordinal-endpoints,ornstein-uhlenbeck,serial,transition-model},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13292}
}

@article{tre96des,
  title = {Describing Risk in Long-Term Clinical Trials},
  author = {Tremmel, Lothar},
  date = {1996},
  journaltitle = {Biopharm Rep ASA},
  volume = {4},
  number = {2},
  pages = {5--8},
  citeulike-article-id = {13264970},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {absorbing-events,intensity-function,multiple-events,overview-of-survival-analysis,person-years,repeated-events,teaching-survival-analysis}
}

@article{tri01pre,
  title = {Predictive Modeling and Heterogeneity of Baseline Risk in Meta-Analysis of Individual Patient Data},
  author = {Trikalinos, Thomas A. and Ioannidis, John P. A.},
  date = {2001},
  journaltitle = {J Clin Epi},
  volume = {54},
  pages = {245--252},
  citeulike-article-id = {13265185},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {distribution-of-hazard-ratios,individual-patient-meta-analysis,patient-heterogeneity,risk-distribution}
}

@article{tri95int,
  title = {Interpreting the Standardized Difference},
  author = {Tritchler, David},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {351--353},
  citeulike-article-id = {13264971},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {natural-parameter},
  note = {see Senn, Stat in Med 25:3944-3946;2006}
}

@article{tri96exp,
  title = {Explanatory Analyses of Randomized Studies},
  author = {Tritchler, David},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {1450--1456},
  citeulike-article-id = {13264972},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {causality,confounding,directed-graph,encouragement-design,explanatory-trial,indirect-effects,intervention-study,noncompliance,pragmatic-trial,randomized-trials}
}

@article{tro97wei,
  title = {Weighted Estimating Equations with Nonignorably Missing Response Data},
  author = {Troxel, Andrea B. and Lipsitz, Stuart R. and Brennan, Troyen A.},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {857--869},
  citeulike-article-id = {13264973},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {complete-case-analysis,item-nonresponse,non-ignorable-missingness,non-random-missing}
}

@article{tru67,
  title = {A Multivariate Analysis of the Risk of Coronary Heart Disease in {{Framingham}}},
  author = {Truett, J. and Cornfield, J. and Kannel, W. B.},
  date = {1967},
  journaltitle = {J Chron Dis},
  volume = {20},
  pages = {511--524},
  citeulike-article-id = {13264974},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{tsa87not,
  title = {A Note on the Product Limit Estimator under Right Censoring and Left Truncation},
  author = {Tsai, W. Y. and Jewell, N. P. and Wang, M. C.},
  date = {1987},
  journaltitle = {Biometrika},
  volume = {74},
  pages = {883--886},
  citeulike-article-id = {13264975},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {censored-data,kaplan-meier,left-truncation}
}

@article{tsi00est,
  title = {Estimating the Distribution of Quality-Adjusted Life with Censored Data},
  author = {Tsiatis, Anastasios A.},
  date = {2000},
  journaltitle = {Am Heart J},
  volume = {139},
  pages = {S177-S181},
  citeulike-article-id = {13265140},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {cost-data,informative-censoring,quality-adjusted-survival-curve,quality-adjusted-survival-time}
}

@article{tsi03ine,
  title = {On the Inefficiency of the Adaptive Design for Monitoring Clinical Trials},
  author = {Tsiatis, A. A. and Mehta, C.},
  date = {2003},
  journaltitle = {Biometrika},
  volume = {90},
  pages = {367--378},
  citeulike-article-id = {13265518},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{tsi21est,
  title = {Estimating Vaccine Efficacy over Time after a Randomized Study Is Unblinded},
  author = {Tsiatis, Anastasios A. and Davidian, Marie},
  date = {2021},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13509},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13509},
  urldate = {2021-07-17},
  abstract = {The COVID-19 pandemic due to the novel coronavirus SARS CoV-2 has inspired remarkable breakthroughs in the development of vaccines against the virus and the launch of several phase 3 vaccine trials in Summer 2020 to evaluate vaccine efficacy (VE). Trials of vaccine candidates using mRNA delivery systems developed by Pfizer-BioNTech and Moderna have shown substantial VEs of 94-95\%, leading the US Food and Drug Administration to issue Emergency Use Authorizations and subsequent widespread administration of the vaccines. As the trials continue, a key issue is the possibility that VE may wane over time. Ethical considerations dictate that trial participants be unblinded and those randomized to placebo be offered study vaccine, leading to trial protocol amendments specifying unblinding strategies. Crossover of placebo subjects to vaccine complicates inference on waning of VE. We focus on the particular features of the Moderna trial and propose a statistical framework based on a potential outcomes formulation within which we develop methods for inference on potential waning of VE over time and estimation of VE at any post-vaccination time. The framework clarifies assumptions made regarding individual- and population-level phenomena and acknowledges the possibility that subjects who are more or less likely to become infected may be crossed over to vaccine differentially over time. The principles of the framework can be adapted straightforwardly to other trials. This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {blinding,covid19,vaccine},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13509}
}

@article{tsi81,
  title = {A Large Sample Study of {{Cox}}'s Regression Model},
  author = {Tsiatis, A. A.},
  date = {1981},
  journaltitle = {Ann Stat},
  volume = {9},
  pages = {93--108},
  citeulike-article-id = {13264976},
  posted-at = {2014-07-14 14:09:46},
  priority = {0}
}

@article{tsirej,
  title = {Rejoinder: {{Estimating}} Vaccine Efficacy over Time after a Randomized Study Is Unblinded},
  shorttitle = {Rejoinder},
  author = {Tsiatis, Anastasios A. and Davidian, Marie},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13539},
  url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13539},
  urldate = {2021-08-23},
  langid = {english},
  keywords = {vaccine},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.13539}
}

@article{tu07cor,
  title = {Correlation Analysis for Longitudinal Data: {{Applications}} to {{HIV}} and Psychosocial Research},
  author = {Tu, X. M. and Feng, C. and Kowalski, J. and Tang, W. and Wang, H. and Wan, C. and Ma, Y.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4116--4138},
  citeulike-article-id = {13265626},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {intraclass-correlation,missing-data,monotone-missingness,proxy-outcomes,u-statistics}
}

@article{tu08sim,
  title = {Simpson's {{Paradox}}, {{Lord}}'s {{Paradox}}, and {{Suppression Effects}} Are the Same Phenomenon Â the Reversal Paradox},
  author = {Tu, Yu-Kang and Gunnell, David and Gilthorpe, Mark S.},
  date = {2008-01},
  journaltitle = {Emerg Themes Epi},
  volume = {5},
  number = {1},
  eprint = {18211676},
  eprinttype = {pmid},
  pages = {2+},
  publisher = {BioMed Central Ltd},
  issn = {1742-7622},
  doi = {10.1186/1742-7622-5-2},
  url = {http://dx.doi.org/10.1186/1742-7622-5-2},
  abstract = {This article discusses three statistical paradoxes that pervade epidemiological research: Simpson's paradox, Lord's paradox, and suppression. These paradoxes have important implications for the interpretation of evidence from observational studies. This article uses hypothetical scenarios to illustrate how the three paradoxes are different manifestations of one phenomenon – the reversal paradox – depending on whether the outcome and explanatory variables are categorical, continuous or a combination of both; this renders the issues and remedies for any one to be similar for all three. Although the three statistical paradoxes occur in different types of variables, they share the same characteristic: the association between two variables can be reversed, diminished, or enhanced when another variable is statistically controlled for. Understanding the concepts and theory behind these paradoxes provides insights into some controversial or contradictory research findings. These paradoxes show that prior knowledge and underlying causal theory play an important role in the statistical modelling of epidemiological data, where incorrect use of statistical models might produce consistent, replicable, yet erroneous results.},
  citeulike-article-id = {2282389},
  citeulike-attachment-1 = {tu08sim.pdf; /pdf/user/harrelfe/article/2282389/986043/tu08sim.pdf; 2361f457b3ecc97f10c768554e805ef491c5d65b},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/1742-7622-5-2},
  citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/18211676},
  citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=18211676},
  day = {22},
  posted-at = {2014-09-21 15:12:27},
  priority = {2},
  keywords = {conditioning,lords-paradox,reversal-paradox,simpsons-paradox,suppression}
}

@book{tuf06bea,
  title = {Beautiful {{Evidence}}},
  author = {Tufte, Edward R.},
  date = {2006},
  publisher = {{Graphics Press}},
  location = {{Cheshire, CT}},
  citeulike-article-id = {13264980},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {graphics}
}

@book{tuf83vis,
  title = {The {{Visual Display}} of {{Quantitative Information}}},
  author = {Tufte, Edward R.},
  date = {1983},
  publisher = {{Graphics Press}},
  location = {{Cheshire, Connecticut}},
  citeulike-article-id = {13264977},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {graphics,teaching-mds}
}

@book{tuf90env,
  title = {Envisioning {{Information}}},
  author = {Tufte, Edward R.},
  date = {1990},
  publisher = {{Graphics Press}},
  location = {{Cheshire, Connecticut}},
  citeulike-article-id = {13264978},
  posted-at = {2014-07-14 14:09:46},
  priority = {0},
  keywords = {graphics}
}

@book{tuf97vis,
  title = {Visual {{Explanations}}},
  author = {Tufte, Edward R.},
  date = {1997},
  publisher = {{Graphics Press}},
  location = {{Cheshire, CT}},
  citeulike-article-id = {13264979},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {graphics,teaching-mds}
}

@article{tuk60con,
  title = {Conclusions vs {{Decisions}}},
  author = {Tukey, John W.},
  date = {1960},
  journaltitle = {Technometrics},
  volume = {2},
  number = {4},
  eprint = {1266451},
  eprinttype = {jstor},
  pages = {423--433},
  issn = {0040-1706},
  doi = {10.2307/1266451},
  abstract = {With the exception of appendices 2 and 3, the following is based on the after dinner talk given by Professor John W. Tukey at the first meeting of the Section of the Physical and Engineering Sciences of the American Statistical Association held in New York City on May 26, 1955. This talk was repeated at a later date before a dinner meeting of the Metropolitan Section of the American Society for Quality Control. On both occasions considerable discussion ensued. The talk is published here both for the record, and in the hope that some readers may be stimulated to prepare written rejoinders.},
  keywords = {decision-theory,inference,philosophy}
}

@article{tuk93tig,
  title = {Tightening the {{Clinical Trial}}},
  author = {Tukey, John W.},
  date = {1993},
  journaltitle = {Controlled Clin Trials},
  volume = {14},
  pages = {266--285},
  doi = {10.1016/0197-2456(93)90225-3},
  url = {http://dx.doi.org/10.1016/0197-2456(93)90225-3},
  citeulike-article-id = {13264981},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/0197-2456(93)90225-3},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {ancova,baseline,covariable-adjustment,randomization,rct,regression},
  note = {showed that asking clinicians to make up regression coefficients out of thin air is better than not adjusting for covariables}
}

@article{tur07ana,
  title = {Analysis of Cluster Randomized Cross-over Trial Data: A Comparison of Methods},
  author = {Turner, Rebecca M. and White, Ian R. and Croudace, Tim},
  date = {2007-01},
  journaltitle = {Stat Med},
  volume = {26},
  number = {2},
  pages = {274--289},
  issn = {02776715},
  doi = {10.1002/sim.2537},
  url = {http://dx.doi.org/10.1002/sim.2537},
  citeulike-article-id = {14361045},
  citeulike-attachment-1 = {tur07ana.pdf; /pdf/user/harrelfe/article/14361045/1110043/tur07ana.pdf; 1aa4fdb24ceee460b1d734ebb8dd9a215b5771d8},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.2537},
  day = {30},
  posted-at = {2017-05-21 19:45:41},
  priority = {0},
  keywords = {cluster-randomization,cluster-randomized-trial,cross-over-trials,crossover,crossover-study,rct}
}

@article{tur74non,
  title = {Nonparametric Estimation of a Survivorship Function with Doubly Censored Data},
  author = {Turnbull, Bruce W.},
  date = {1974},
  journaltitle = {J Am Stat Assoc},
  volume = {69},
  pages = {169--173},
  citeulike-article-id = {13264982},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {kaplan-meier,left-censoring,nonparametric,survival-analysis}
}

@article{tur97hig,
  title = {Highest Posterior Density Credible Region and Minimum Area Confidence Region: The Bivariate Case},
  author = {Turkkan, N. and Pham-Gia, T.},
  date = {1997},
  journaltitle = {Appl Stat},
  volume = {46},
  pages = {131--140},
  citeulike-article-id = {13264983},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {algorithm,bayesian-inference,credible-interval,credible-region,highest-posterior-density,minimum-volume-confidence-region,multivariate}
}

@article{twe98con,
  title = {Consulting: {{Real}} Problems, Real Interactions, Real Outcomes},
  author = {Tweedie, Richard},
  date = {1998},
  journaltitle = {Stat Sci},
  volume = {13},
  number = {1},
  pages = {1--3},
  citeulike-article-id = {13265652},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  note = {"It is hard to overestimate how powerfully our discipline trains us to think about complicated issues in ways that allow us to quickly diagnose difficulties in esoteric disciplines to which we have had only several minutes of introduction."}
}

@article{twi02att,
  title = {Attrition in Longitudinal Studies: {{How}} to Deal with Missing Data},
  author = {Twisk, Jos and de Vente, Wieke},
  options = {useprefix=true},
  date = {2002},
  journaltitle = {J Clin Epi},
  volume = {55},
  pages = {329--337},
  citeulike-article-id = {13265278},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {attrition,dropout,longitudinal-study,missing-data,multiple-imputation,repeated-measures,serial-data},
  note = {GEE did not require imputation using the author's approach;longitudinal imputation worked better than cross-sectional imputation;multiple imputation did not improve point estimates but did provide better variance estimates;with-subject imputation}
}

@article{twi13mul,
  title = {Multiple Imputation of Missing Values Was Not Necessary before Performing a Longitudinal Mixed-Model Analysis},
  author = {Twisk, Jos and de Boer, Michiel and de Vente, Wieke and Heymans, Martijn},
  options = {useprefix=true},
  date = {2013},
  journaltitle = {J Clin Epi},
  volume = {66},
  number = {9},
  pages = {1022--1028},
  doi = {10.1016/j.jclinepi.2013.03.017},
  url = {http://dx.doi.org/10.1016/j.jclinepi.2013.03.017},
  abstract = {As a result of the development of sophisticated techniques, such as multiple imputation, the interest in handling missing data in longitudinal studies has increased enormously in past years. Within the field of longitudinal data analysis, there is a current debate on whether it is necessary to use multiple imputations before performing a mixed-model analysis to analyze the longitudinal data. In the current study this necessity is evaluated. The results of mixed-model analyses with and without multiple imputation were compared with each other. Four data sets with missing values were created-one data set with missing completely at random, two data sets with missing at random, and one data set with missing not at random). In all data sets, the relationship between a continuous outcome variable and two different covariates were analyzed: a time-independent dichotomous covariate and a time-dependent continuous covariate. Although for all types of missing data, the results of the mixed-model analysis with or without multiple imputations were slightly different, they were not in favor of one of the two approaches. In addition, repeating the multiple imputations 100 times showed that the results of the mixed-model analysis with multiple imputation were quite unstable. It is not necessary to handle missing data using multiple imputations before performing a mixed-model analysis on longitudinal data.},
  citeulike-article-id = {13265981},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jclinepi.2013.03.017},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {imputation,lmm,longitudinal,missing}
}

@article{ulm89,
  title = {Assessing Antiarrhythmic Drug Efficacy: Multivariate Considerations},
  author = {Ulm, K. and Schmidt, G. and Barthel, P. and Linzmaier, A.},
  date = {1989},
  journaltitle = {Stat Med},
  volume = {8},
  pages = {1393--1400},
  citeulike-article-id = {13264984},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {multivariate-analysis,pharmaceutical}
}

@article{uml21bam,
  title = {Bamlss: {{A Lego Toolbox}} for {{Flexible Bayesian Regression}} (and {{Beyond}})},
  author = {Umlauf, Nikolaus and Klein, Nadja and Simon, Thorsten and Zeileis, Achim},
  date = {2021-11-30},
  journaltitle = {J. Stat. Soft.},
  volume = {100},
  number = {4},
  pages = {1--53},
  doi = {10.18637/jss.v100.i04},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v100i04},
  urldate = {2021-12-06},
  abstract = {\&lt;p\&gt;Over the last decades, the challenges in applied regression and in predictive modeling have been changing considerably: (1) More flexible regression model specifications are needed as data sizes and available information are steadily increasing, consequently demanding for more powerful computing infrastructure. (2) Full probabilistic models by means of distributional regression - rather than predicting only some underlying individual quantities from the distributions such as means or expectations - is crucial in many applications. (3) Availability of Bayesian inference has gained in importance both as an appealing framework for regularizing or penalizing complex models and estimation therein as well as a natural alternative to classical frequentist inference. However, while there has been a lot of research on all three challenges and the development of corresponding software packages, a modular software implementation that allows to easily combine all three aspects has not yet been available for the general framework of distributional regression. To fill this gap, the R package bamlss is introduced for Bayesian additive models for location, scale, and shape (and beyond) - with the name reflecting the most important distributional quantities (among others) that can be modeled with the software. At the core of the package are algorithms for highly-efficient Bayesian estimation and inference that can be applied to generalized additive models or generalized additive models for location, scale, and shape, or more general distributional regression models. However, its building blocks are designed as \&quot;Lego bricks\&quot; encompassing various distributions (exponential family, Cox, joint models, etc.), regression terms (linear, splines, random effects, tensor products, spatial fields, etc.), and estimators (MCMC, backfitting, gradient boosting, lasso, etc.). It is demonstrated how these can be easily combined to make classical models more flexible or to create new custom models for specific modeling challenges.\&lt;/p\&gt;},
  keywords = {bayes,gam,generalized-additive-model,smoothers},
  note = {Shows linkage between optimization and sampling; uses optimization to start sampling}
}

@article{unn01int,
  title = {Intention-to-Treat: Methods for Dealing with Missing Values in Clinical Trials of Progressively Deteriorating Diseases},
  author = {Unnebrink, Kristina and Windeler, Jürgen},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {3931--3946},
  citeulike-article-id = {13265255},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {dropouts,intention-to-treat,longitudinal-data,missing-data,serial-data,simulation,statistical-graphics,very-nice-graphical-summary-of-simulation-results}
}

@article{uno11c,
  title = {On the {{C-statistics}} for Evaluating Overall Adequacy of Risk Prediction Procedures with Censored Survival Data},
  author = {Uno, Hajime and Cai, Tianxi and Pencina, Michael J. and D'Agostino, Ralph B. and Wei, L. J.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  pages = {1105--1117},
  citeulike-article-id = {13265875},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {auc,c-index,cox-model,framingham-risk-score,ph-model,roc},
  note = {shows how C is a function of censoring distribution;new measure requires choice of a somewhat arbitrary time cutoff}
}

@article{upt01tor,
  title = {A Toroidal Scatter Diagram for Ternary Variables},
  author = {Upton, Graham J. G.},
  date = {2001},
  journaltitle = {Am Statistician},
  volume = {55},
  pages = {240--243},
  citeulike-article-id = {13265220},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {3-variables,compositions,statistical-graphics,ternary-diagram}
}

@article{urb20int,
  title = {Interim Recruitment Prediction for Multi-Center Clinical Trials},
  author = {Urbas, Szymon and Chris, Chris and Metcalfe, Paul},
  date = {2020},
  journaltitle = {Biostatistics},
  doi = {10.1093/biostatistics/kxaa036},
  url = {https://academic.oup.com/biostatistics/advance-article/doi/10.1093/biostatistics/kxaa036/5911853},
  urldate = {2020-09-27},
  abstract = {Summary.  We introduce a general framework for monitoring, modeling, and predicting the recruitment to multi-center clinical trials. The work is motivated by ov},
  langid = {english},
  keywords = {rct,recruitment}
}

@article{utt03wha,
  title = {What Educated Citizens Should Know about Statistics and Probability},
  author = {Utts, Jessica},
  date = {2003},
  journaltitle = {Am Statistician},
  volume = {57},
  pages = {74--79},
  citeulike-article-id = {13265319},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {coincidences,numeracy,practical-significance,statistical-literacy,statistics-education,survey-bias},
  note = {excellent examples from popular press of misinterpretations;teaching MDs;7 important topics: cause and effect, statistical vs. practical significance, absence of evidence vs. evidence of absence, survey biases, coincidences are not uncommon, confusion of inverse conditional probabilities, variability is natural}
}

@article{uzu92com,
  title = {A Comparison of Hazard Rate Estimators for Left Truncated and Right Censored Data},
  author = {Wang, Jane-Ling},
  date = {1992},
  journaltitle = {Biometrika},
  volume = {79},
  pages = {297--310},
  citeulike-article-id = {13264985},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {censored-data,left-truncation}
}

@article{vac93log,
  title = {Logistic Regression with Incompletely Observed Categorical Covariates: {{A}} Comparison of Three Approaches},
  author = {Vach, Werner and Schumacher, Martin},
  date = {1993},
  journaltitle = {Biometrika},
  volume = {80},
  pages = {353--362},
  citeulike-article-id = {13264986},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {binary-logistic-model,missing-data}
}

@book{vac94log,
  title = {Logistic {{Regression}} with {{Missing Values}} in the {{Covariates}}},
  author = {Vach, Werner},
  date = {1994},
  series = {Lecture {{Notes}} in {{Statistics}}},
  volume = {86},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13264987},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {imputation,logistic-regression,missing-values,modifications-of-mle,tables}
}

@article{vac95log,
  title = {Logistic Regression with Incompletely Observed Categorical Covariates---{{Investigating}} the Sensitivity against Violation of the Missing at Random Assumption},
  author = {Vach, Werner and Blettner, Maria},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1315--1329},
  citeulike-article-id = {13264988},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {em-algorithm,imputation,mar,missing-at-random,missing-data}
}

@article{vac97som,
  title = {Some Issues in Estimating the Effect of Prognostic Factors from Incomplete Covariate Data},
  author = {Vach, Werner},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {57--72},
  citeulike-article-id = {13264989},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {imputation,missing-covariable-values,mle-with-missing-data,sensitivity-analysis-to-check-missing-at-random-assumption}
}

@incollection{vac98mis,
  title = {Missing {{Data}} in {{Epidemiologic Studies}}},
  booktitle = {Ency of {{Biostatistics}}},
  author = {Vach, Werner and Blettner, Maria},
  date = {1998},
  pages = {2641--2654},
  publisher = {{Wiley}},
  location = {{New York}},
  citeulike-article-id = {13264990},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {missing-data}
}

@article{vai01pro,
  title = {Prospective Application of {{Bayesian}} Monitoring and Analysis in an `open' Randomized Clinical Trial},
  author = {Vail, A. and Hornbuckle, J. and Spiegelhalter, D. J. and Thornton, J. G.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {3777--3787},
  doi = {10.1002/sim.1171},
  url = {http://dx.doi.org/10.1002/sim.1171},
  citeulike-article-id = {13265253},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.1171},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {bayes,bayesian-inference,monitoring,priors,rct,sequential-monitoring},
  note = {use of stylized priors because of substantial variability of prior opinions;interim results released to investigators}
}

@article{val21eff,
  title = {Effect of {{Intravenous}} or {{Intraosseous Calcium}} vs {{Saline}} on {{Return}} of {{Spontaneous Circulation}} in {{Adults With Out-of-Hospital Cardiac Arrest}}: {{A Randomized Clinical Trial}}},
  shorttitle = {Effect of {{Intravenous}} or {{Intraosseous Calcium}} vs {{Saline}} on {{Return}} of {{Spontaneous Circulation}} in {{Adults With Out-of-Hospital Cardiac Arrest}}},
  author = {Vallentin, Mikael Fink and Granfeldt, Asger and Meilandt, Carsten and Povlsen, Amalie Ling and Sindberg, Birthe and Holmberg, Mathias J. and Iversen, Bo Nees and Mærkedahl, Rikke and Mortensen, Lone Riis and Nyboe, Rasmus and Vandborg, Mads Partridge and Tarpgaard, Maren and Runge, Charlotte and Christiansen, Christian Fynbo and Dissing, Thomas H. and Terkelsen, Christian Juhl and Christensen, Steffen and Kirkegaard, Hans and Andersen, Lars W.},
  date = {2021-11-30},
  journaltitle = {JAMA},
  issn = {0098-7484},
  doi = {10.1001/jama.2021.20929},
  url = {https://doi.org/10.1001/jama.2021.20929},
  urldate = {2021-12-02},
  abstract = {It is unclear whether administration of calcium has a beneficial effect in patients with cardiac arrest.To determine whether administration of calcium during out-of-hospital cardiac arrest improves return of spontaneous circulation in adults.This double-blind, placebo-controlled randomized clinical trial included 397 adult patients with out-of-hospital cardiac arrest and was conducted in the Central Denmark Region between January 20, 2020, and April 15, 2021. The last 90-day follow-up was on July 15, 2021.The intervention consisted of up to 2 intravenous or intraosseous doses with 5 mmol of calcium chloride (n\,=\,197) or saline (n\,=\,200). The first dose was administered immediately after the first dose of epinephrine.The primary outcome was sustained return of spontaneous circulation. The secondary outcomes included survival and a favorable neurological outcome (modified Rankin Scale score of 0-3) at 30 days and 90 days.Based on a planned interim analysis of 383 patients, the steering committee stopped the trial early due to concerns about harm in the calcium group. Of 397 adult patients randomized, 391 were included in the analyses (193 in the calcium group and 198 in the saline group; mean age, 68 [SD, 14] years; 114 [29\%] were female). There was no loss to follow-up. There were 37 patients (19\%) in the calcium group who had sustained return of spontaneous circulation compared with 53 patients (27\%) in the saline group (risk ratio, 0.72 [95\% CI, 0.49 to 1.03]; risk difference, −7.6\% [95\% CI, −16\% to 0.8\%]; P\,=\,.09). At 30 days, 10 patients (5.2\%) in the calcium group and 18 patients (9.1\%) in the saline group were alive (risk ratio, 0.57 [95\% CI, 0.27 to 1.18]; risk difference, −3.9\% [95\% CI, −9.4\% to 1.3\%]; P\,=\,.17). A favorable neurological outcome at 30 days was observed in 7 patients (3.6\%) in the calcium group and in 15 patients (7.6\%) in the saline group (risk ratio, 0.48 [95\% CI, 0.20 to 1.12]; risk difference, −4.0\% [95\% CI, −8.9\% to 0.7\%]; P\,=\,.12). Among the patients with calcium values measured who had return of spontaneous circulation, 26 (74\%) in the calcium group and 1 (2\%) in the saline group had hypercalcemia.Among adults with out-of-hospital cardiac arrest, treatment with intravenous or intraosseous calcium compared with saline did not significantly improve sustained return of spontaneous circulation. These results do not support the administration of calcium during out-of-hospital cardiac arrest in adults.ClinicalTrials.gov Identifier: NCT04153435},
  keywords = {bayes,rct,rct-interpretation,teaching-mds},
  note = {Followed recently published Bayesian re-analysis reporting guideliness of Michael Harhay et al}
}

@article{val96eva,
  title = {Evaluation of Long-Term Survival: {{Use}} of Diagnostics and Robust Estimators with {{Cox}}'s Proportional Hazards Model},
  author = {Valsecchi, M. G. and Silvestri, D. and Sasieni, P.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {2763--2780},
  citeulike-article-id = {13264991},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {assessment-of-ph,non-ph,residuals-in-cox-model},
  note = {what to do if non-PH (by downweighting outliers)}
}

@article{van14reg,
  title = {On Regression Adjustment for the Propensity Score},
  author = {Vansteelandt, S. and Daniel, R. M.},
  date = {2014-10},
  journaltitle = {Stat Med},
  volume = {33},
  number = {23},
  pages = {4053--4072},
  issn = {02776715},
  doi = {10.1002/sim.6207},
  url = {http://dx.doi.org/10.1002/sim.6207},
  abstract = {Propensity scores are widely adopted in observational research because they enable adjustment for high-dimensional confounders without requiring models for their association with the outcome of interest. The results of statistical analyses based on stratification, matching or inverse weighting by the propensity score are therefore less susceptible to model extrapolation than those based solely on outcome regression models. This is attractive because extrapolation in outcome regression models may be alarming, yet difficult to diagnose, when the exposed and unexposed individuals have very different covariate distributions. Standard regression adjustment for the propensity score forms an alternative to the aforementioned propensity score methods, but the benefits of this are less clear because it still involves modelling the outcome in addition to the propensity score. In this article, we develop novel insights into the properties of this adjustment method. We demonstrate that standard tests of the null hypothesis of no exposure effect (based on robust variance estimators), as well as particular standardised effects obtained from such adjusted regression models, are robust against misspecification of the outcome model when a propensity score model is correctly specified; they are thus not vulnerable to the aforementioned problem of extrapolation. We moreover propose efficient estimators for these standardised effects, which retain a useful causal interpretation even when the propensity score model is misspecified, provided the outcome regression model is correctly specified.},
  citeulike-article-id = {13340175},
  citeulike-attachment-1 = {van14reg.pdf; /pdf/user/harrelfe/article/13340175/982683/van14reg.pdf; 7b2d0837c91c0d47441b5588ee35f8a735dd2f7b},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6207},
  day = {15},
  posted-at = {2014-08-28 19:21:49},
  priority = {4},
  keywords = {covariate-adjustment,propensity-score},
  note = {From first author in ASA Connections discussion:I share your concerns and also tend to favour regression adjustment for the propensity score for the following additional reasons:- it adjusts for residual confounding due to imperfect matching;- it makes more efficient use of the information in the data;- adjustment for both the propensity score and covariates can result in estimators with a double robustness property: they are valid if either the propensity score is correct or the covariates in the outcome model are correctly modelled.- matching is often preferred for simplicity, but I tend to believe that regression adjustment for the propensity score is much simpler because one loses the simplicity of matching whenever one wishes to adjust for residual confounding due to imperfect matching or wishes to obtain valid standard errors.
\par
Note that, like matching methods, regression adjustment for the propensity score also prevents the dangers of model extrapolation in settings where the treated and untreated are very different in their observed covariate data, in the sense that- subjects with covariate values at which there are nearly only treated or non-treated individuals are down-weighted, as they contribute little or no information about treatment effect;- valid estimators of treatment effect can be obtained when the propensity score model is correct, even when the association between outcome and propensity score is misspecified. This follows from the aforementioned double robustness property.}
}

@article{van18nov,
  title = {Novel Diabetes Subgroups},
  author = {van Smeden, Maarten and Harrell, Frank E. and Dahly, Darren L.},
  options = {useprefix=true},
  date = {2018-06},
  journaltitle = {Lancet Diabetes Endocrinol},
  volume = {6},
  number = {6},
  eprint = {29803262},
  eprinttype = {pmid},
  pages = {439--440},
  issn = {2213-8595},
  doi = {10.1016/S2213-8587(18)30124-4},
  langid = {english},
  keywords = {ltte}
}

@article{van19cal,
  title = {Calibration: The {{Achilles}} Heel of Predictive Analytics},
  shorttitle = {Calibration},
  author = {Van Calster, Ben and McLernon, David J. and van Smeden, Maarten and Wynants, Laure and Steyerberg, Ewout W. and Bossuyt, Patrick and Collins, Gary S. and Macaskill, Petra and McLernon, David J. and Moons, Karel G. M. and Steyerberg, Ewout W. and Van~Calster, Ben and {van~Smeden}, Maarten and Vickers, Andrew~J. and {On behalf of Topic Group ‘Evaluating diagnostic tests and prediction models’ of the STRATOS initiative}},
  options = {useprefix=true},
  date = {2019-12-16},
  journaltitle = {BMC Medicine},
  volume = {17},
  number = {1},
  pages = {230},
  issn = {1741-7015},
  doi = {10.1186/s12916-019-1466-7},
  url = {https://doi.org/10.1186/s12916-019-1466-7},
  urldate = {2020-01-04},
  abstract = {The assessment of calibration performance of risk prediction models based on regression or more flexible machine learning algorithms receives little attention.},
  keywords = {calibration,rms,validation}
}

@article{van19cli,
  title = {Clinical Research Study Implementation of Case-Finding Strategies for Heart Failure and Chronic Obstructive Pulmonary Disease in the Elderly with Reduced Exercise Tolerance or Dyspnea: {{A}} Cluster Randomized Trial},
  shorttitle = {Clinical Research Study Implementation of Case-Finding Strategies for Heart Failure and Chronic Obstructive Pulmonary Disease in the Elderly with Reduced Exercise Tolerance or Dyspnea},
  author = {van Mourik, Yvonne and Rutten, Frans H. and Bertens, Loes C. M. and Cramer, Maarten J. M. and Lammers, Jan-Willem J. and Gohar, Aisha and Reitsma, Johannes B. and Moons, Karel G. M. and Hoes, Arno W.},
  options = {useprefix=true},
  date = {2019-09-01},
  journaltitle = {Am. Heart J.},
  volume = {220},
  eprint = {31790904},
  eprinttype = {pmid},
  pages = {73--81},
  issn = {1097-6744},
  doi = {10.1016/j.ahj.2019.08.021},
  abstract = {BACKGROUND: Heart failure (HF) and chronic obstructive pulmonary disease (COPD) often remain undiagnosed in older individuals, although both disorders inhibit functionality and impair health. The aim of the study was to assess the effectiveness of a case-finding strategy of these disorders. METHODS: This is a clustered randomized trial; 18 general practices from the vicinity of Utrecht, the Netherlands, were randomly allocated to a case-finding strategy or usual care. Multimorbid community subjects (≥65\,years) with dyspnea or reduced exercise tolerance were eligible for inclusion. The case-finding strategy consisted of history taking, physical examination, blood tests, electrocardiography, spirometry, and echocardiography. Subsequent treatment decisions were at the discretion of the general practitioner. Questionnaires regarding health status and functionality were filled out at baseline and after 6 months of follow-up. Information regarding changes in medication and health care use during the 6 months follow-up was extracted. RESULTS: A total of 829 participants were randomized: 389 in the case-finding strategy group and 440 in the usual care group. More patients in the case-finding group received a new diagnosis of HF or COPD than the usual care group (cumulative incidence 34\% vs 2\% and 17\% vs. 2\%, respectively). Scores for health status, functionality, and health care use were similar between the 2 strategies after 6 months of follow-up. CONCLUSIONS: A case-finding strategy applied in primary care to multimorbid older people with dyspnea or reduced exercise tolerance resulted in a number of new diagnoses of HF and COPD but did not result in short-term improvement of health status compared to usual care.},
  langid = {english},
  keywords = {clinical-prediction,cluster,impact,rct}
}

@article{van19eff,
  title = {Efficient Design and Analysis of Randomized Controlled Trials in Rare Neurological Diseases: {{An}} Example in {{Guillain-Barré}} Syndrome},
  shorttitle = {Efficient Design and Analysis of Randomized Controlled Trials in Rare Neurological Diseases},
  author = {van Leeuwen, Nikki and Walgaard, Christa and van Doorn, Pieter A. and Jacobs, Bart C. and Steyerberg, Ewout W. and Lingsma, Hester F.},
  options = {useprefix=true},
  date = {2019},
  journaltitle = {PLoS One},
  volume = {14},
  number = {2},
  eprint = {30785890},
  eprinttype = {pmid},
  pages = {e0211404},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0211404},
  abstract = {BACKGROUND: Randomized controlled trials (RCTs) pose specific challenges in rare and heterogeneous neurological diseases due to the small numbers of patients and heterogeneity in disease course. Two analytical approaches have been proposed to optimally handle these issues in RCTs: covariate adjustment and ordinal analysis. We investigated the potential gain in efficiency of these approaches in rare and heterogeneous neurological diseases, using Guillain-Barré syndrome (GBS) as an example. METHODS: We analyzed two published GBS trials with primary outcome 'at least one grade improvement' on the GBS disability scale. We estimated the treatment effect using logistic regression models with and without adjustment for prognostic factors. The difference between the unadjusted and adjusted estimates was disentangled in imbalance (random differences in baseline covariates between treatment arms) and stratification (change of the estimate due to covariate adjustment). Second, we applied proportional odds regression, which exploits the ordinal nature of the GBS disability score. The standard error of the estimated treatment effect indicated the statistical efficiency. RESULTS: Both trials were slightly imbalanced with respect to baseline characteristics, which was corrected in the adjusted analysis. Covariate adjustment increased the estimated treatment effect in the two trials by 8\% and 18\% respectively. Proportional odds analysis resulted in lower standard errors indicating more statistical power. CONCLUSION: Covariate adjustment and proportional odds analysis most efficiently use the available data and ensure balance between the treatment arms to obtain reliable and valid treatment effect estimates. These approaches merit application in future trials in rare and heterogeneous neurological diseases like GBS.},
  langid = {english},
  pmcid = {PMC6382155},
  keywords = {ordinal,po,rare-disease}
}

@article{van19how,
  title = {How Can We Make Better Graphs? {{An}} Initiative to Increase the Graphical Expertise and Productivity of Quantitative Scientists},
  shorttitle = {How Can We Make Better Graphs?},
  author = {Vandemeulebroecke, Marc and Baillie, Mark and Carr, David and Kanitra, Linda and Margolskee, Alison and Wright, Andrew and Magnusson, Baldur},
  date = {2019},
  journaltitle = {Pharmaceutical Statistics},
  volume = {18},
  number = {1},
  pages = {106--114},
  issn = {1539-1612},
  doi = {10.1002/pst.1912},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1912},
  urldate = {2019-01-26},
  abstract = {Graphics are at the core of exploring and understanding data, communicating results and conclusions, and supporting decision-making. Increasing our graphical expertise can significantly strengthen our impact as professional statisticians and quantitative scientists. In this article, we present a concerted effort to improve the way we create graphics at Novartis. We provide our vision and guiding principles, before describing seven work packages in more detail. The actions, principles, and experiences laid out in this paper are applicable generally, also beyond drug development, which is our field of work. The purpose of this article is to share our experiences and help foster the use of good graphs in pharmaceutical statistics and beyond. A Graphics Principles “Cheat Sheet” is available online at https://graphicsprinciples.github.io/.},
  langid = {english},
  keywords = {graphics}
}

@article{van20ref,
  title = {Reflection on Modern Methods: Five Myths about Measurement Error in Epidemiological Research},
  shorttitle = {Reflection on Modern Methods},
  author = {van Smeden, Maarten and Lash, Timothy L and Groenwold, Rolf H H},
  options = {useprefix=true},
  date = {2020-02-01},
  journaltitle = {International Journal of Epidemiology},
  volume = {49},
  number = {1},
  pages = {338--347},
  issn = {0300-5771},
  doi = {10.1093/ije/dyz251},
  url = {https://doi.org/10.1093/ije/dyz251},
  urldate = {2022-01-15},
  abstract = {Epidemiologists are often confronted with datasets to analyse which contain measurement error due to, for instance, mistaken data entries, inaccurate recordings and measurement instrument or procedural errors. If the effect of measurement error is misjudged, the data analyses are hampered and the validity of the study’s inferences may be affected. In this paper, we describe five myths that contribute to misjudgments about measurement error, regarding expected structure, impact and solutions to mitigate the problems resulting from mismeasurements. The aim is to clarify these measurement error misconceptions. We show that the influence of measurement error in an epidemiological data analysis can play out in ways that go beyond simple heuristics, such as heuristics about whether or not to expect attenuation of the effect estimates. Whereas we encourage epidemiologists to deliberate about the structure and potential impact of measurement error in their analyses, we also recommend exercising restraint when making claims about the magnitude or even direction of effect of measurement error if not accompanied by statistical measurement error corrections or quantitative bias analysis. Suggestions for alleviating the problems or investigating the structure and magnitude of measurement error are given.},
  keywords = {epidemiology,measurement-error}
}

@article{van22myt,
  title = {Myths {{About Linear}} and {{Monotonic Associations}}: {{Pearson}}’s r, {{Spearman}}’s ρ, and {{Kendall}}’s τ},
  shorttitle = {Myths {{About Linear}} and {{Monotonic Associations}}},
  author = {van den Heuvel, Edwin and Zhan, Zhuozhao},
  options = {useprefix=true},
  date = {2022-01-02},
  journaltitle = {The American Statistician},
  volume = {76},
  number = {1},
  pages = {44--52},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2021.2004922},
  url = {https://doi.org/10.1080/00031305.2021.2004922},
  urldate = {2022-02-07},
  abstract = {Pearson’s correlation coefficient is considered a measure of linear association between bivariate random variables X and Y. It is recommended not to use it for other forms of associations. Indeed, for nonlinear monotonic associations alternative measures like Spearman’s rank and Kendall’s tau correlation coefficients are considered more appropriate. These views or opinions on the estimation of association are strongly rooted in the statistical and other empirical sciences. After defining linear and monotonic associations, we will demonstrate that these opinions are incorrect. Pearson’s correlation coefficient should not be ruled out a priori for measuring nonlinear monotonic associations. We will provide examples of practically relevant families of bivariate distribution functions with nonlinear monotonic associations for which Pearson’s correlation is preferred over Spearman’s rank and Kendall’s tau correlation in testing the dependency between X and Y. Alternatively, we will provide a family of bivariate distributions with a linear association between X and Y for which Spearman’s rank and Kendall’s tau are preferred over Pearson’s correlation. Our examples show that existing views on linear and monotonic associations are myths.},
  keywords = {correlation,rank-correlation},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2021.2004922}
}

@article{van96evi,
  title = {Evidence-Based Medicine and “Medicine d'observation”},
  author = {Vandenbroucke, Jan P.},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {1335--1338},
  citeulike-article-id = {13264992},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {history-of-evidence-based-medicine}
}

@article{var10mix,
  title = {A Mixed Autoregressive Probit Model for Ordinal Longitudinal Data},
  author = {Varin, Cristiano and Czado, Claudia},
  date = {2010-01-01},
  journaltitle = {Biostatistics},
  volume = {11},
  number = {1},
  pages = {127--138},
  issn = {1465-4644},
  doi = {10.1093/biostatistics/kxp042},
  url = {https://doi.org/10.1093/biostatistics/kxp042},
  urldate = {2020-12-22},
  abstract = {Longitudinal data with binary and ordinal outcomes routinely appear in medical applications. Existing methods are typically designed to deal with short measurement series. In contrast, modern longitudinal data can result in large numbers of subject-specific serial observations. In this framework, we consider multivariate probit models with random effects to capture heterogeneity and autoregressive terms for describing the serial dependence. Since likelihood inference for the proposed class of models is computationally burdensome because of high-dimensional intractable integrals, a pseudolikelihood approach is followed. The methodology is motivated by the analysis of a large longitudinal study on the determinants of migraine severity.},
  keywords = {autoregressive-correlation-structure,ordinal,probit,random-effects,serial}
}

@article{var10mixa,
  title = {A Mixed Autoregressive Probit Model for Ordinal Longitudinal Data},
  author = {Varin, Cristiano and Czado, Claudia},
  date = {2010-01-01},
  journaltitle = {Biostatistics},
  volume = {11},
  number = {1},
  pages = {127--138},
  issn = {1465-4644},
  doi = {10.1093/biostatistics/kxp042},
  url = {https://doi.org/10.1093/biostatistics/kxp042},
  urldate = {2020-12-22},
  abstract = {Longitudinal data with binary and ordinal outcomes routinely appear in medical applications. Existing methods are typically designed to deal with short measurement series. In contrast, modern longitudinal data can result in large numbers of subject-specific serial observations. In this framework, we consider multivariate probit models with random effects to capture heterogeneity and autoregressive terms for describing the serial dependence. Since likelihood inference for the proposed class of models is computationally burdensome because of high-dimensional intractable integrals, a pseudolikelihood approach is followed. The methodology is motivated by the analysis of a large longitudinal study on the determinants of migraine severity.},
  keywords = {autoregressive-correlation-structure,ordinal,probit,serial}
}

@article{var14shr,
  title = {On Shrinkage and Model Extrapolation in the Evaluation of Clinical Center Performance},
  author = {Varewyck, Machteld and Goetghebeur, Els and Eriksson, Marie and Vansteelandt, Stijn},
  date = {2014-10},
  journaltitle = {Biostatistics},
  volume = {15},
  number = {4},
  eprint = {24812420},
  eprinttype = {pmid},
  pages = {651--664},
  publisher = {Oxford University Press},
  issn = {1468-4357},
  doi = {10.1093/biostatistics/kxu019},
  url = {http://dx.doi.org/10.1093/biostatistics/kxu019},
  abstract = {We consider statistical methods for benchmarking clinical centers based on a dichotomous outcome indicator. Borrowing ideas from the causal inference literature, we aim to reveal how the entire study population would have fared under the current care level of each center. To this end, we evaluate direct standardization based on fixed versus random center effects outcome models that incorporate patient-specific baseline covariates to adjust for differential case-mix. We explore fixed effects (FE) regression with Firth correction and normal mixed effects (ME) regression to maintain convergence in the presence of very small centers. Moreover, we study doubly robust FE regression to avoid outcome model extrapolation. Simulation studies show that shrinkage following standard ME modeling can result in substantial power loss relative to the considered alternatives, especially for small centers. Results are consistent with findings in the analysis of 30-day mortality risk following acute stroke across 90 centers in the Swedish Stroke Register.},
  citeulike-article-id = {13362268},
  citeulike-attachment-1 = {var14shr.pdf; /pdf/user/harrelfe/article/13362268/984896/var14shr.pdf; e6b2667cf03c461361f4c0f30fda9bec1a52e3b6},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/biostatistics/kxu019},
  citeulike-linkout-1 = {http://biostatistics.oxfordjournals.org/content/15/4/651.abstract},
  citeulike-linkout-2 = {http://biostatistics.oxfordjournals.org/content/15/4/651.full.pdf},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/24812420},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=24812420},
  day = {01},
  posted-at = {2014-09-13 16:06:52},
  priority = {2},
  keywords = {fixed-effects,provider-profiling,shrinkage}
}

@article{var87,
  title = {Letters to Editor on {{The}} Effect of Sample Size on the Meaning of Significance Tests},
  author = {letters to editor on Royall paper, Various},
  options = {useprefix=true},
  date = {1987},
  journaltitle = {Am Statistician},
  volume = {41},
  pages = {245--247},
  citeulike-article-id = {13264993},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {study-design-and-stopping-rules,teaching}
}

@incollection{varclus,
  title = {The {{VARCLUS Procedure}}},
  booktitle = {{{SAS}}/{{STAT User}}'s {{Guide}}},
  author = {Sarle, Warren},
  date = {1990},
  edition = {fourth},
  volume = {2},
  pages = {1641--1659},
  publisher = {{SAS Institute, Inc.}},
  location = {{Cary, NC}},
  url = {http://support.sas.com/documentation/onlinedoc/stat},
  chapter = {43},
  citeulike-article-id = {13264994},
  citeulike-linkout-0 = {http://support.sas.com/documentation/onlinedoc/stat},
  posted-at = {2014-07-14 14:09:47},
  priority = {0}
}

@article{vea96pse,
  title = {Pseudo-{{R}}² Measures for Some Common Limited Dependent Variable Models},
  author = {Veall, Michael R. and Zimmermann, Klaus F.},
  date = {1996},
  journaltitle = {J Econ Surv},
  volume = {10},
  number = {3},
  pages = {241--259},
  citeulike-article-id = {13265287},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  note = {points out that priority for Nagelkerke index goes to cra70dem;predictive accuracy index}
}

@article{ven16reg,
  title = {Regression Discontinuity Designs in Healthcare Research},
  author = {Venkataramani, Atheendar S. and Bor, Jacob and Jena, Anupam B.},
  date = {2016-03-14},
  journaltitle = {BMJ},
  volume = {352},
  eprint = {26977086},
  eprinttype = {pmid},
  pages = {i1216},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.i1216},
  url = {https://www.bmj.com/content/352/bmj.i1216},
  urldate = {2021-05-30},
  abstract = {{$<$}p{$>$}Clinical decisions are often driven by decision rules premised around specific thresholds. Specific laboratory measurements, dates, or policy eligibility criteria create cut-offs at which people become eligible for certain treatments or health services. The regression discontinuity design is a statistical approach that utilizes threshold based decision making to derive compelling causal estimates of different interventions. In this review, we argue that regression discontinuity is underutilized in healthcare research despite the ubiquity of threshold based decision making as well as the design’s simplicity and transparency. Moreover, regression discontinuity provides evidence of “real world” therapeutic and policy effects, circumventing a major limitation of randomized controlled trials. We discuss the implementation, strengths, and weaknesses of regression discontinuity and review several examples from clinical medicine, public health, and health policy. We conclude by discussing the wide array of open research questions for which regression discontinuity stands to provide meaningful insights to clinicians and policymakers{$<$}/p{$>$}},
  langid = {english},
  keywords = {interrupted-time-series,observational-study,observational-study-design}
}

@article{ven19bay,
  title = {Bayesian {{Uncertainty Directed Trial Designs}}},
  author = {Ventz, Steffen and Cellamare, Matteo and Bacallado, Sergio and Trippa, Lorenzo},
  date = {2019-07-03},
  journaltitle = {Journal of the American Statistical Association},
  volume = {114},
  number = {527},
  pages = {962--974},
  issn = {0162-1459},
  doi = {10.1080/01621459.2018.1497497},
  url = {https://doi.org/10.1080/01621459.2018.1497497},
  urldate = {2019-12-16},
  abstract = {Most Bayesian response-adaptive designs unbalance randomization rates toward the most promising arms with the goal of increasing the number of positive treatment outcomes during the study, even though the primary aim of the trial is different. We discuss Bayesian uncertainty directed designs (BUD), a class of Bayesian designs in which the investigator specifies an information measure tailored to the experiment. All decisions during the trial are selected to optimize the available information at the end of the study. The approach can be applied to several designs, ranging from early stage multi-arm trials to biomarker-driven and multi-endpoint studies. We discuss the asymptotic limit of the patient allocation proportion to treatments, and illustrate the finite-sample operating characteristics of BUD designs through examples, including multi-arm trials, biomarker-stratified trials, and trials with multiple co-primary endpoints. Supplementary materials for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.},
  keywords = {adaptive,bayes,experimental-design}
}

@article{ven88met,
  title = {A Method for Computing Profile-Likelihood-Based Confidence Intervals},
  author = {Venzon, D. J. and Moolgavkar, S. H.},
  date = {1988},
  journaltitle = {Appl Stat},
  volume = {37},
  pages = {87--94},
  citeulike-article-id = {13264995},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {confidence-limits,maximum-likelihood}
}

@book{ven99mod,
  title = {Modern {{Applied Statistics}} with {{S-Plus}}},
  author = {Venables, William N. and Ripley, Brian D.},
  date = {1999},
  edition = {Third},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13264996},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {modern-regression,multivariate,s-plus}
}

@book{ver00lin,
  title = {Linear {{Mixed Models}} for {{Longitudinal Data}}},
  author = {Verbeke, Geert and Molenberghs, Geert},
  date = {2000},
  publisher = {{Springer}},
  location = {{New York}},
  citeulike-article-id = {13265325},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {and-selection-models,comprehensive-information-on-missing-data,dropouts,longitudinal-data,repeated-measures,sas-proc-mixed}
}

@article{ver01pra,
  title = {The Practical Use of Different Strategies to Handle Dropout in Longitudinal Studies},
  author = {Verbeke, Geert and Lesaffre, Emmanuel and Spiessens, Bart},
  date = {2001},
  journaltitle = {Drug Info J},
  volume = {35},
  pages = {419--434},
  citeulike-article-id = {13265202},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {dropout-process,good-review-article,non-random-dropout,pattern-mixture-model,repeated-measures,serial-data}
}

@article{ver05sub,
  title = {Substantial Effective Sample Sizes Were Required for External Validation Studies of Predictive Logistic Regression Models},
  author = {Vergouwe, Yvonne and Steyerberg, Ewout W. and Eijkemans, Marinus J. C. and Habbema, J. D. F.},
  date = {2005},
  journaltitle = {J Clin Epi},
  volume = {58},
  pages = {475--483},
  citeulike-article-id = {13265423},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {external-validation,performance,prediction,predictive-accuracy,sample-size,simulation-setup,validation-criteria}
}

@article{ver15inc,
  title = {Increasing the Power of the {{Mann-Whitney}} Test in Randomized Experiments through Flexible Covariate Adjustment},
  author = {Vermeulen, Karel and Thas, Olivier and Vansteelandt, Stijn},
  date = {2015},
  journaltitle = {Statistics in Medicine},
  volume = {34},
  number = {6},
  pages = {1012--1030},
  issn = {1097-0258},
  doi = {10.1002/sim.6386},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6386},
  urldate = {2020-11-24},
  abstract = {The Mann-Whitney U test is frequently used to evaluate treatment effects in randomized experiments with skewed outcome distributions or small sample sizes. It may lack power, however, because it ignores the auxiliary baseline covariate information that is routinely collected. Wald and score tests in so-called probabilistic index models generalize the Mann-Whitney U test to enable adjustment for covariates, but these may lack robustness by demanding correct model specification and do not lend themselves to small sample inference. Using semiparametric efficiency theory, we here propose an alternative extension of the Mann-Whitney U test, which increases its power by exploiting covariate information in an objective way and which lends itself to permutation inference. Simulation studies and an application to an HIV clinical trial show that the proposed permutation test attains the nominal Type I error rate and can be drastically more powerful than the classical Mann-Whitney U test. Copyright © 2014 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {c-index,concordance,po,proportional-odds,wilcoxon-mann-whitney},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.6386},
  note = {Failed to note that the Wilcoxon test is the same as the PO model score test.~ Covariate adjustment is done through a direct model for the probability index (c-index; concordance probability) in Eq (4).~ This assumes a model that is no more likely to fit than a regular proportional odds model that automatically allows for covariate adjustment.~ If Eq (4) fits the regular PO model cannot fit, and vice-versa.}
}

@article{ver20roc,
  title = {{{ROC}} Curves for Clinical Prediction Models Part 1. {{ROC}} Plots Showed No Added Value above the {{AUC}} When Evaluating the Performance of Clinical Prediction Models},
  author = {Verbakel, Jan Y. and Steyerberg, Ewout W. and Uno, Hajime and Cock, Bavo De and Wynants, Laure and Collins, Gary S. and Calster, Ben Van},
  date = {2020-10-01},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {126},
  eprint = {32712176},
  eprinttype = {pmid},
  pages = {207--216},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2020.01.028},
  url = {https://www.jclinepi.com/article/S0895-4356(18)31004-7/abstract},
  urldate = {2020-12-08},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objectives{$<$}/h3{$><$}p{$>$}Receiver operating characteristic (ROC) curves show how well a risk prediction model discriminates between patients with and without a condition. We aim to investigate how ROC curves are presented in the literature and discuss and illustrate their potential limitations.{$<$}/p{$><$}h3{$>$}Study Design and Setting{$<$}/h3{$><$}p{$>$}We conducted a pragmatic literature review of contemporary publications that externally validated clinical prediction models. We illustrated limitations of ROC curves using a testicular cancer case study and simulated data.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Of 86 identified prediction modeling studies, 52 (60\%) presented ROC curves without thresholds and one (1\%) presented an ROC curve with only a few thresholds. We illustrate that ROC curves in their standard form withhold threshold information have an unstable shape even for the same area under the curve (AUC) and are problematic for comparing model performance conditional on threshold. We compare ROC curves with classification plots, which show sensitivity and specificity conditional on risk thresholds.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}ROC curves do not offer more information than the AUC to indicate discriminative ability. To assess the model's performance for decision-making, results should be provided conditional on risk thresholds. Therefore, if discriminatory ability must be visualized, classification plots are attractive.{$<$}/p{$>$}},
  langid = {english},
  keywords = {roc},
  note = {no added value of ROC over AUROC}
}

@article{ver93cro,
  title = {Cross-Validation in Survival Analysis},
  author = {Verweij, Pierre J. M. and van Houwelingen, Hans C.},
  options = {useprefix=true},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2305--2314},
  citeulike-article-id = {13264998},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {cross-validated-likelihood,cross-validation,jackknife,likelihood}
}

@article{ver94pen,
  title = {Penalized Likelihood in {{Cox}} Regression},
  author = {Verweij, Pierre J. and van Houwelingen, Hans C.},
  options = {useprefix=true},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {2427--2436},
  citeulike-article-id = {13264999},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {aic,categorical-predictors,cross-validation,effective-df,interaction-surfaces,parameterization,penalized-mle,ridge-regression,shrinkage}
}

@article{ver95tim,
  title = {Time-Dependent Effects of Fixed Covariates in {{Cox}} Regression},
  author = {Verweij, Pierre J. M. and van Houwelingen, Hans C.},
  options = {useprefix=true},
  date = {1995},
  journaltitle = {Biometrics},
  volume = {51},
  pages = {1550--1556},
  citeulike-article-id = {13265000},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {aic,nice-representation-of-cox-partial-likelihood,penalized-mle}
}

@article{vet06whe,
  title = {When to Use Agreement versus Reliability Measures},
  author = {de Vet, Henrica C. W. and Terwee, Caroline B. and Knol, Dirk L. and Bouter, Lex M.},
  options = {useprefix=true},
  date = {2006},
  journaltitle = {J Clin Epi},
  volume = {59},
  pages = {1033--1039},
  citeulike-article-id = {13265529},
  posted-at = {2014-07-14 14:09:58},
  priority = {0},
  keywords = {agreement,measurement-error,measurement-instruments,reliability,repeated-measurements,reproducibility,variance-components},
  note = {putting variance components on original measurement scale;ICC}
}

@article{vic01use,
  title = {The Use of Percentage Change from Baseline as an Outcome in a Controlled Trial Is Statistically Inefficient: A Simulation Study},
  author = {Vickers, A. J.},
  date = {2001},
  journaltitle = {BMC Med Res Methodol},
  volume = {1},
  pages = {6},
  doi = {10.1186/1471-2288-1-6},
  url = {http://www.biomedcentral.com/1471-2288/1/6},
  abstract = {BACKGROUND:Many randomized trials involve measuring a continuous outcome - such as pain, body weight or blood pressure - at baseline and after treatment. In this paper, I compare four possibilities for how such trials can be analyzed: post-treatment; change between baseline and post-treatment; percentage change between baseline and post-treatment and analysis of covariance (ANCOVA) with baseline score as a covariate. The statistical power of each method was determined for a hypothetical randomized trial under a range of correlations between baseline and post-treatment scores.RESULTS:ANCOVA has the highest statistical power. Change from baseline has acceptable power when correlation between baseline and post-treatment scores is high;when correlation is low, analyzing only post-treatment scores has reasonable power. Percentage change from baseline has the lowest statistical power and was highly sensitive to changes in variance. Theoretical considerations suggest that percentage change from baseline will also fail to protect from bias in the case of baseline imbalance and will lead to an excess of trials with non-normally distributed outcome data.CONCLUSIONS:Percentage change from baseline should not be used in statistical analysis. Trialists wishing to report this statistic should use another method, such as ANCOVA, and convert the results to a percentage change by using mean baseline scores.},
  citeulike-article-id = {13265731},
  citeulike-linkout-0 = {http://dx.doi.org/10.1186/1471-2288-1-6},
  citeulike-linkout-1 = {http://www.biomedcentral.com/1471-2288/1/6},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {change,change-from-baseline,change-score,measuring-change,methodology,percent-change,percentage-change,statistics,teaching-mds}
}

@article{vic08aga,
  title = {Against Diagnosis},
  author = {Vickers, Andrew J. and Basch, Ethan and Kattan, Michael W.},
  date = {2008},
  journaltitle = {Ann Int Med},
  volume = {149},
  pages = {200--203},
  citeulike-article-id = {13265872},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  note = {"The act of diagnosis requires that patients be placed in a binary category of either having or not having a certain disease. Accordingly, the diseases of particular concern for industrialized countries---such as type 2 diabetes, obesity, or depression---require that a somewhat arbitrary cut-point be chosen on a continuous scale of measurement (for example, a fasting glucose level {$>$}6.9 mmol/L [{$>$}125 mg/dL] for type 2 diabetes). These cut-points do not ade- quately reflect disease biology, may inappropriately treat patients on either side of the cut-point as 2 homogenous risk groups, fail to incorporate other risk factors, and are invariable to patient preference."}
}

@article{vic08dec,
  title = {Decision Analysis for the Evaluation of Diagnostic Tests, Prediction Models, and Molecular Markers},
  author = {Vickers, Andrew J.},
  date = {2008},
  journaltitle = {Am Statistician},
  volume = {62},
  number = {4},
  pages = {314--320},
  citeulike-article-id = {13265707},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {decision-support-techniques,decision-theory,outcome-assessment,prognosis},
  note = {limitations of accuracy metrics;incorporating clinical consequences;nice example of calculation of expected outcome;drawbacks of conventional decision analysis, especially because of the difficulty of eliciting the expected harm of a missed diagnosis;use of a threshold on the probability of disease for taking some action;decision curve;has other good references to decision analysis}
}

@article{vic20gui,
  title = {Guidelines for {{Reporting}} of {{Figures}} and {{Tables}} for {{Clinical Research}} in {{Urology}}},
  author = {Vickers, Andrew J. and Assel, Melissa J. and Sjoberg, Daniel D. and Qin, Rui and Zhao, Zhiguo and Koyama, Tatsuki and Botchway, Albert and Wang, Xuemei and Huo, Dezheng and Kattan, Michael and Zabor, Emily C. and Harrell, Frank},
  date = {2020-08},
  journaltitle = {Urology},
  volume = {142},
  eprint = {32446805},
  eprinttype = {pmid},
  pages = {1--13},
  issn = {1527-9995},
  doi = {10.1016/j.urology.2020.05.002},
  abstract = {In an effort to improve the presentation of and information within tables and figures in clinical urology research, we propose a set of appropriate guidelines. We introduce 6 principles (1) include graphs only if they improve the reader's ability to understand the study findings; (2) think through how a graph might best convey information, do not just select a graph from preselected options on statistical software; (3) do not use graphs to replace reporting key numbers in the text of a paper; (4) graphs should give an immediate visual impression of the data; (5) make it beautiful; and (6) make the labels and legend clear and complete. We present a list of quick "dos and don'ts" for both tables and figures. Investigators should feel free to break any of the guidelines if it would result in a beautiful figure or a clear table that communicates data effectively. That said, we believe that the quality of tables and figures in the medical literature would improve if these guidelines were to be followed. PATIENT SUMMARY: A set of guidelines were developed for presenting figures and tables in urology research. The guidelines were developed by a broad group of statistical experts with special interest in urology.},
  langid = {english},
  pmcid = {PMC7387170},
  keywords = {graphical-methods,tables}
}

@article{vid87fam,
  title = {Familial Occurrence of Accessory Atrioventricular Pathways (Preexcitation Syndrome)},
  author = {Vidiallet, H. J. and Pressley, J. C. and Henke, E. and Harrell, F. E. and German, L. D.},
  date = {1987},
  journaltitle = {NEJM},
  volume = {317},
  pages = {65--9},
  citeulike-article-id = {13265001},
  posted-at = {2014-07-14 14:09:47},
  priority = {0}
}

@article{vin00sim,
  title = {Simple Principal Components},
  author = {Vines, S. K.},
  date = {2000},
  journaltitle = {Appl Stat},
  volume = {49},
  pages = {441--451},
  citeulike-article-id = {13265169},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {principal-components,simplification},
  note = {principal components with constraints of integer coefficients}
}

@article{vin14pre,
  title = {Predictive Mean Matching Imputation of Semicontinuous Variables},
  author = {Vink, Gerko and Frank, Laurence E. and Pannekoek, Jeroen and van Buuren, Stef},
  options = {useprefix=true},
  date = {2014-02},
  journaltitle = {Statistica Neerlandica},
  volume = {68},
  number = {1},
  pages = {61--90},
  issn = {00390402},
  doi = {10.1111/stan.12023},
  url = {http://dx.doi.org/10.1111/stan.12023},
  citeulike-article-id = {14225792},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/stan.12023},
  posted-at = {2016-12-10 14:31:54},
  priority = {2},
  keywords = {missing-data,predictive-mean-matching}
}

@article{vir07cox,
  title = {Cox Regression Was Used to Compare the Measurement Error of Two Tests vs. a Gold Standard},
  author = {Virgili, Gianni and Angi, Mario and Molinari, Andrea and Casotto, Veronica},
  date = {2007},
  journaltitle = {J Clin Epi},
  volume = {60},
  pages = {345--349},
  citeulike-article-id = {13265569},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {accuracy,cox-model-for-absolute-difference-between-two-tests,cox-regression,diagnosis,diagnostic-test,inter-rater-reliability,observer-variability,prediction,survival-agreement-plot}
}

@article{vit06rel,
  title = {Relaxing the Rule of Ten Events per Variable in Logistic and {{Cox}} Regression},
  author = {Vittinghoff, Eric and McCulloch, Charles E.},
  date = {2006},
  journaltitle = {Am J Epi},
  volume = {165},
  pages = {710--718},
  citeulike-article-id = {13265573},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  note = {the authors may have not been quite stringent enough in their assessment of adequacy of predictions;letter to the editor submitted}
}

@article{vol20tre,
  title = {On the Treatment Effect Heterogeneity of Antidepressants in Major Depression: {{A Bayesian}} Meta-Analysis and Simulation Study},
  shorttitle = {On the Treatment Effect Heterogeneity of Antidepressants in Major Depression},
  author = {Volkmann, Constantin and Volkmann, Alexander and Müller, Christian A.},
  date = {2020-11-11},
  journaltitle = {PLOS ONE},
  volume = {15},
  number = {11},
  pages = {e0241497},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0241497},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0241497},
  urldate = {2020-11-11},
  abstract = {Background The average treatment effect of antidepressants in major depression was found to be about 2 points on the 17-item Hamilton Depression Rating Scale, which lies below clinical relevance. Here, we searched for evidence of a relevant treatment effect heterogeneity that could justify the usage of antidepressants despite their low average treatment effect. Methods Bayesian meta-analysis of 169 randomized, controlled trials including 58,687 patients. We considered the effect sizes log variability ratio (lnVR) and log coefficient of variation ratio (lnCVR) to analyze the difference in variability of active and placebo response. We used Bayesian random-effects meta-analyses (REMA) for lnVR and lnCVR and fitted a random-effects meta-regression (REMR) model to estimate the treatment effect variability between antidepressants and placebo. Results The variability ratio was found to be very close to 1 in the best fitting models (REMR: 95\% highest density interval (HDI) [0.98, 1.02], REMA: 95\% HDI [1.00, 1.02]). The between-study standard deviation τ under the REMA with respect to lnVR was found to be low (95\% HDI [0.00, 0.02]). Simulations showed that a large treatment effect heterogeneity is only compatible with the data if a strong correlation between placebo response and individual treatment effect is assumed. Conclusions The published data from RCTs on antidepressants for the treatment of major depression is compatible with a near-constant treatment effect. Although it is impossible to rule out a substantial treatment effect heterogeneity, its existence seems rather unlikely. Since the average treatment effect of antidepressants falls short of clinical relevance, the current prescribing practice should be re-evaluated.},
  langid = {english},
  keywords = {bayes,depression,hte}
}

@article{vol88,
  title = {Comparing Change in Longitudinal Studies: {{Adjusting}} for Initial Value},
  author = {Wm, Vollmer},
  date = {1988},
  journaltitle = {J Clin Epi},
  volume = {41},
  pages = {651--657},
  citeulike-article-id = {13265002},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {general,measurement,regression,research-methods}
}

@article{vol91eva,
  title = {Evaluation of Exact and Asymptotic Interval Estimators in Logistic Analysis of Matched Case-Control Studies},
  author = {Vollset, S. E. and Hirji, K. F. and Afifi, A. A.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {1311--1325},
  citeulike-article-id = {13265003},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {case-control-study,conditional-logistic-model,exact-tests}
}

@article{vol91fas,
  title = {Fast Computation of Exact Confidence Limits for the Common Odds Ratio in a Series of 2 2 Tables},
  author = {Vollset, S. E. and Hirji, K. F. and Elashoff, R. M.},
  date = {1991},
  journaltitle = {J Am Stat Assoc},
  volume = {86},
  pages = {404--409},
  citeulike-article-id = {13265004},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  note = {exact test; [network method -{$>$} algebraic method]}
}

@article{vol93con,
  title = {Confidence Intervals for a Binomial Proportion},
  author = {Vollset, Stein E.},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {809--824},
  citeulike-article-id = {13265005},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {binomial,confidence-intervals,logistic-model,maximum-likelihood}
}

@article{vol97bay,
  title = {Bayesian Model Averaging in Proportional Hazard Models: {{Assessing}} the Risk of a Stroke},
  author = {Volinsky, Chris T. and Madigan, David and Raftery, Adrian E. and Kronmal, Richard A.},
  date = {1997},
  journaltitle = {Appl Stat},
  volume = {46},
  pages = {433--448},
  citeulike-article-id = {13265006},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {bayesian-methods,cox-ph-model,model-averaging,model-uncertainty,partial-predictive-score,variable-selection}
}

@article{von96goo,
  title = {Goodness-of-Fit in Generalized Nonlinear Mixed Effects Models},
  author = {Vonesh, Edward F. and Chinchilli, Vernon M. and Pu, Kewei},
  date = {1996},
  journaltitle = {Biometrics},
  volume = {52},
  pages = {572--587},
  citeulike-article-id = {13265007},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {gof,goodness-of-fit,nonlinear-mixed-effects-models,tests-for-correlation-structure}
}

@book{VR,
  title = {Modern {{Applied Statistics}} with {{S}}},
  author = {Venables, William N. and Ripley, Brian D.},
  date = {2003},
  edition = {Fourth},
  publisher = {{Springer-Verlag}},
  location = {{New York}},
  citeulike-article-id = {13264997},
  isbn = {0-387-95457-0},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {modern-regression,multivariate,s}
}

@article{vri97com,
  title = {Comparing Compliance Patterns between Randomized Treatments},
  author = {Vrijens, Bernard and Goetghebeur, Els},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {187--203},
  citeulike-article-id = {13265008},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {compliance,medication-event-monitoring-system,summary-statistics}
}

@article{vu17rel,
  title = {Relational Event Models for Longitudinal Network Data with an Application to Interhospital Patient Transfers},
  author = {Vu, Duy and Lomi, Alessandro and Mascia, Daniele and Pallotti, Francesca},
  date = {2017},
  journaltitle = {Stat Med},
  issn = {02776715},
  doi = {10.1002/sim.7247},
  url = {http://dx.doi.org/10.1002/sim.7247},
  citeulike-article-id = {14327728},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7247},
  posted-at = {2017-04-03 14:34:07},
  priority = {2},
  keywords = {longitudinal-data,multi-state-model,multinomial,multistate-model,serial-data,transition-model}
}

@article{wag17bay1,
  title = {Bayesian Inference for Psychology. {{Part I}}: {{Theoretical}} Advantages and Practical Ramifications},
  booktitle = {Psychonomic Bulletin & Review},
  author = {Wagenmakers, Eric-Jan and Marsman, Maarten and Jamil, Tahira and Ly, Alexander and Verhagen, Josine and Love, Jonathon and Selker, Ravi and Gronau, Quentin F. and ̌Sḿıra, Martin and Epskamp, Sacha and Matzke, Dora and Rouder, Jeffrey N. and Morey, Richard D.},
  date = {2017},
  pages = {1--23},
  publisher = {Springer US},
  doi = {10.3758/s13423-017-1343-3},
  url = {http://dx.doi.org/10.3758/s13423-017-1343-3},
  citeulike-article-id = {14438461},
  citeulike-linkout-0 = {http://dx.doi.org/10.3758/s13423-017-1343-3},
  citeulike-linkout-1 = {http://link.springer.com/article/10.3758/s13423-017-1343-3},
  posted-at = {2017-09-26 18:41:53},
  priority = {0},
  keywords = {bayes,bayesian-inference,excellent-for-teaching-bayesian-methods-and-explaining-the-advantages}
}

@article{wag20cro,
  title = {Cross-{{Validation}}, {{Risk Estimation}}, and {{Model Selection}}: {{Comment}} on a {{Paper}} by {{Rosset}} and {{Tibshirani}}},
  shorttitle = {Cross-{{Validation}}, {{Risk Estimation}}, and {{Model Selection}}},
  author = {Wager, Stefan},
  date = {2020-01-02},
  journaltitle = {Journal of the American Statistical Association},
  volume = {115},
  number = {529},
  pages = {157--160},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2020.1727235},
  url = {https://doi.org/10.1080/01621459.2020.1727235},
  urldate = {2020-03-20},
  keywords = {validation},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2020.1727235}
}

@article{wag82eva,
  title = {Evaluation of a {{QRS}} Scoring System for Estimation of Myocardial Infarct Size {{I}}: {{Specificity}} and Observer Agreement},
  author = {Wagner, G. S. and Freye, C. J. and Palmeri, S. T. and Roark, S. F. and Stack, N. A. and Ideker, R. E. and Harrell, F. E. and Selvester, R. H.},
  date = {1982},
  journaltitle = {Circ},
  volume = {65},
  pages = {342--347},
  citeulike-article-id = {13265009},
  posted-at = {2014-07-14 14:09:47},
  priority = {0}
}

@inproceedings{wag85sur,
  title = {A Survey of Statistical Software for Life Data Analysis},
  booktitle = {Proceedings of the {{Statistical Computing Section}}, {{ASA}}},
  author = {Wagner, A. E. and Meeker, W. Q.},
  date = {1985},
  pages = {441--446},
  citeulike-article-id = {13265010},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {software-review}
}

@article{wag94dai,
  title = {Daily Prognostic Estimates for Critically Ill Adults in Intensive Care Units: {{Results}} from a Prospective, Multicenter, Inception Cohort Analysis},
  author = {Wagner, D. P. and Knaus, W. A. and Harrell, F. E. and Zimmerman, J. E. and Watts, C.},
  date = {1994},
  journaltitle = {Crit Care Med},
  volume = {22},
  pages = {1359--1372},
  citeulike-article-id = {13265011},
  posted-at = {2014-07-14 14:09:47},
  priority = {0}
}

@article{wah16ass,
  title = {Assessment of Predictive Performance in Incomplete Data by Combining Internal Validation and Multiple Imputation},
  author = {Wahl, Simone and Boulesteix, Anne-Laure and Zierer, Astrid and Thorand, Barbara and van de Wiel, Mark A.},
  options = {useprefix=true},
  date = {2016-10-26},
  journaltitle = {BMC Medical Research Methodology},
  volume = {16},
  number = {1},
  pages = {144},
  issn = {1471-2288},
  doi = {10.1186/s12874-016-0239-7},
  url = {https://doi.org/10.1186/s12874-016-0239-7},
  urldate = {2021-05-13},
  abstract = {Missing values are a frequent issue in human studies. In many situations, multiple imputation (MI) is an appropriate missing data handling strategy, whereby missing values are imputed multiple times, the analysis is performed in every imputed data set, and the obtained estimates are pooled. If the aim is to estimate (added) predictive performance measures, such as (change in) the area under the receiver-operating characteristic curve (AUC), internal validation strategies become desirable in order to correct for optimism. It is not fully understood how internal validation should be combined with multiple imputation.},
  keywords = {imputatation,missing,validation}
}

@article{wai06fin,
  title = {Finding What Is Not There through the Unfortunate Binning of Results: {{The Mendel}} Effect},
  author = {Wainer, Howard},
  date = {2006},
  journaltitle = {Chance},
  volume = {19},
  number = {1},
  pages = {49--56},
  citeulike-article-id = {13265473},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {bad,cutpoints,teaching-mds},
  note = {can find bins that yield either positive or negative association;especially pertinent when effects are small;"With four parameters, I can fit an elephant; with five, I can make it wiggle its trunk." - John von Neumann}
}

@article{wai07imp,
  title = {Improving Data Displays: {{Ours}} and the Media's},
  author = {Wainer, Howard},
  date = {2007},
  journaltitle = {Chance},
  volume = {20},
  number = {3},
  pages = {8--15},
  citeulike-article-id = {13265621},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {graphics},
  note = {nice examples of before and after using good graphics principles;history;Florence Nightengale}
}

@article{wai84how,
  title = {How to Display Data Badly},
  author = {Wainer, Howard},
  date = {1984},
  journaltitle = {Am Statistician},
  volume = {38},
  pages = {137--147},
  doi = {10.1080/00031305.1984.10483186},
  url = {http://dx.doi.org/10.1080/00031305.1984.10483186},
  citeulike-article-id = {13265012},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00031305.1984.10483186},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {bad,examples,graphics,teaching-mds}
}

@article{wai94thr,
  title = {Three Graphic Memorials},
  author = {Wainer, Howard},
  date = {1994},
  journaltitle = {Chance},
  volume = {7},
  pages = {52--55},
  citeulike-article-id = {13265013},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {forest-fire-plot,graphics,napolean-march-plot,teaching-mds}
}

@article{wai96dep,
  title = {Depicting Error},
  author = {Wainer, Howard},
  date = {1996},
  journaltitle = {Am Statistician},
  volume = {50},
  pages = {101--111},
  citeulike-article-id = {13265014},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {fuzzing-bars-to-indicate-interval-estimates,graphical-methods}
}

@article{wal00cho,
  title = {Choice of Effect Measure for Epidemiological Data},
  author = {Walter, S. D.},
  date = {2000},
  journaltitle = {J Clin Epi},
  volume = {53},
  pages = {931--939},
  citeulike-article-id = {13265145},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {or-better-for-data-analysis,other-measures-may-be-better-for-risk-communication}
}

@article{wal20sel,
  title = {Selection of Variables for Multivariable Models: {{Opportunities}} and Limitations in Quantifying Model Stability by Resampling},
  shorttitle = {Selection of Variables for Multivariable Models},
  author = {Wallisch, Christine and Dunkler, Daniela and Rauch, Geraldine and de Bin, Riccardo and Heinze, Georg},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8779},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8779},
  urldate = {2020-10-30},
  abstract = {Statistical models are often fitted to obtain a concise description of the association of an outcome variable with some covariates. Even if background knowledge is available to guide preselection of covariates, stepwise variable selection is commonly applied to remove irrelevant ones. This practice may introduce additional variability and selection is rarely certain. However, these issues are often ignored and model stability is not questioned. Several resampling-based measures were proposed to describe model stability, including variable inclusion frequencies (VIFs), model selection frequencies, relative conditional bias (RCB), and root mean squared difference ratio (RMSDR). The latter two were recently proposed to assess bias and variance inflation induced by variable selection. Here, we study the consistency and accuracy of resampling estimates of these measures and the optimal choice of the resampling technique. In particular, we compare subsampling and bootstrapping for assessing stability of linear, logistic, and Cox models obtained by backward elimination in a simulation study. Moreover, we exemplify the estimation and interpretation of all suggested measures in a study on cardiovascular risk. The VIF and the model selection frequency are only consistently estimated in the subsampling approach. By contrast, the bootstrap is advantageous in terms of bias and precision for estimating the RCB as well as the RMSDR. Though, unbiased estimation of the latter quantity requires independence of covariates, which is rarely encountered in practice. Our study stresses the importance of addressing model stability after variable selection and shows how to cope with it.},
  langid = {english},
  keywords = {bootstrap,stability,stepwise,variable-selection},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8779}
}

@book{wal47seq,
  title = {Sequential {{Analysis}}},
  author = {Wald, A.},
  date = {1947},
  publisher = {{Wiley and Sons}},
  location = {{New York}},
  citeulike-article-id = {13265747},
  posted-at = {2014-07-14 14:10:03},
  priority = {0}
}

@article{wal67,
  title = {Estimation of the Probability of an Event as a Function of Several Independent Variables},
  author = {Walker, S. H. and Duncan, D. B.},
  date = {1967},
  journaltitle = {Biometrika},
  volume = {54},
  pages = {167--178},
  citeulike-article-id = {13265015},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {logistic-model,ordinal-logistic-model}
}

@article{wal87cod,
  title = {Coding Ordinal Independent Variables in Multiple Regression Analyses},
  author = {Walter, A. R. and Feinstein, Alvan R. and Wells, C. K.},
  date = {1987},
  journaltitle = {Am J Epi},
  volume = {125},
  pages = {319--323},
  citeulike-article-id = {13265016},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {coding-in-terms-of-ix-vj,ordinal-predictor}
}

@article{wal90com,
  title = {A Comparison of Multivariable Mathematical Models for Predicting Survival---{{II Statistical}} Selection of Prognostic Variables.},
  author = {Walter, S. D. and Feinstein, A. R. and Wells, C. K.},
  date = {1990},
  journaltitle = {J Clin Epi},
  volume = {43},
  pages = {349--359},
  citeulike-article-id = {13265017},
  posted-at = {2014-07-14 14:09:47},
  priority = {0}
}

@book{wal96gra,
  title = {Graphing {{Statistics}} \& {{Data}}},
  author = {Wallgren, Anders and Wallgren, Britt and Persson, Rolf and Jorner, Ulf and Haaland, Jan-Aage},
  date = {1996},
  publisher = {{Sage Publications}},
  location = {{Thousand Oaks}},
  citeulike-article-id = {13265018},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {graphics,teaching-mds}
}

@article{wal97non,
  title = {A Non-Iterative Accurate Asymptotic Confidence Interval for the Difference between Two Proportions},
  author = {Wallenstein, Sylvan},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1329--1336},
  citeulike-article-id = {13265019},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {binomial-two-sample-test,comparing-proportions,continuity-correction}
}

@article{wal97var,
  title = {Variation in Baseline Risk a an Explanation of Heterogeneity in Meta-Analysis},
  author = {Walter, S. D.},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {2883--2900},
  citeulike-article-id = {13265020},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {baseline-risk,meta-analysis,regression-to-the-mean},
  annotation = {See letter to editor 18:233-239, 1999}
}

@article{wan02non,
  title = {Non-Parametric Methods for Recurrent Event Data with Informative and Non-Informative Censorings},
  author = {Wang, Mei-Cheng and Chiang, Chin-Tsang},
  date = {2002},
  journaltitle = {Stat Med},
  volume = {21},
  pages = {445--456},
  citeulike-article-id = {13265269},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {cumulative-rate-function,informative-censoring,intensity-function,repeated-events,simulation-setup-for-recurrent-events}
}

@article{wan05bay,
  title = {A {{Bayesian Approach}} on {{Sample Size Calculation}} for {{Comparing Means}}},
  author = {Wang, Hansheng and Chow, Shein-Chung and Chen, Murphy},
  date = {2005-09},
  journaltitle = {J Biopharm Stat},
  volume = {15},
  number = {5},
  pages = {799--807},
  issn = {1054-3406},
  doi = {10.1081/bip-200067789},
  url = {http://dx.doi.org/10.1081/bip-200067789},
  citeulike-article-id = {14259681},
  citeulike-attachment-1 = {wan05bay.pdf; /pdf/user/harrelfe/article/14259681/1098761/wan05bay.pdf; ad82619a73d7171f45bbc0f6a50c14c929071852},
  citeulike-linkout-0 = {http://dx.doi.org/10.1081/bip-200067789},
  day = {1},
  posted-at = {2017-01-21 20:16:54},
  priority = {2},
  keywords = {bayesian-inference,bayesian-sample-size-estimation,sample-size},
  note = {analytic form for posterior for normal t-test case}
}

@article{wan05gen,
  title = {Gene Selection for Microarray Data Analysis Using Principal Component Analysis},
  author = {Wang, Antai and Gehan, Edmund A.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {2069--2087},
  citeulike-article-id = {13265422},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {bioinformatics,data-reduction,data-visualization,exploratory-data-analysis,gene-expression-data,genomics,graphics,microarray,pca,pca-for-gene-expression-array}
}

@article{wan07uni,
  title = {Unified {{LASSO}} Estimation by Least Squares Approximation},
  author = {Wang, Hansheng and Leng, Chenlei},
  date = {2007},
  journaltitle = {J Am Stat Assoc},
  volume = {102},
  pages = {1039--1048},
  doi = {10.1198/016214507000000509},
  url = {http://dx.doi.org/10.1198/016214507000000509},
  abstract = {We propose a method of least squares approximation (LSA) for unified yet simple LASSO estimation. Our general theoretical framework includes ordinary least squares, generalized linear models, quantile regression, and many others as special cases. Specifically, LSA can transfer many different types of LASSO objective functions into their asymptotically equivalent least squares problems. Thereafter, the standard asymptotic theory can be established and the LARS algorithm can be applied. In particular, if the adaptive LASSO penalty and a Bayes information criterion–type tuning parameter selector are used, the resulting LSA estimator can be as efficient as the oracle. Extensive numerical studies confirm our theory.},
  citeulike-article-id = {13265631},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/016214507000000509},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {adaptive-lasso,bic,least-angle-regression,least-squares-approximation,microarry-data,model-approximation,oracle-property,solution-path}
}

@article{wan09hie,
  title = {Hierarchically Penalized {{Cox}} Regression with Grouped Variables},
  author = {Wang, S. and Nan, B. and Zhou, N. and Zhu, J.},
  date = {2009},
  journaltitle = {Biometrika},
  volume = {96},
  number = {2},
  pages = {307--322},
  citeulike-article-id = {13265773},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {cox-model,group-variable-selection,grouped-lasso,lasso,microarray,oracle-property,regularization,shrinkage}
}

@article{wan10est,
  title = {Estimation of the Retransformed Conditional Mean in Health Care Cost Studies},
  author = {Wang, Huixia J. and Zhou, Xiao-Hua},
  date = {2010},
  journaltitle = {Biometrika},
  volume = {97},
  number = {1},
  pages = {147--158},
  citeulike-article-id = {13265821},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {analysis-of-cost,conditional-mean,converting-quantiles-to-mean,heteroschedastic-regression-model,medical-cost,quantile-regression,skewed-data,two-part-model}
}

@article{wan10fro,
  title = {From Adaptive Design to Modern Protocol Design for Drug Development: {{Part I}}. {{Editorial}} and Summary of Adaptive Designs Session at the {{Third FDA}}/{{DIA Statistics Forum}}},
  author = {Wang, Sue-Jane and Bretz, Frank},
  date = {2010},
  journaltitle = {Drug Info J},
  volume = {44},
  pages = {325--331},
  citeulike-article-id = {13265866},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {adaptive-design,clinical-scenario-planning}
}

@article{wan15inf,
  title = {Inferring Gene–Gene Interactions and Functional Modules Using Sparse Canonical Correlation Analysis},
  author = {Wang, Y. X. Rachel and Jiang, Keni and Feldman, Lewis J. and Bickel, Peter J. and Huang, Haiyan},
  date = {2015-03},
  journaltitle = {Ann App Stat},
  volume = {9},
  number = {1},
  pages = {300--323},
  issn = {1932-6157},
  doi = {10.1214/14-aoas792},
  url = {http://dx.doi.org/10.1214/14-aoas792},
  citeulike-article-id = {13660321},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/14-aoas792},
  posted-at = {2015-06-29 20:41:19},
  priority = {2},
  keywords = {canonical-correlation,canonical-variates,interaction,sparse-data},
  note = {sparse canonical correlation analysis}
}

@article{wan16inf,
  title = {Inference in Randomized Trials with Death and Missingness},
  author = {Wang, Chenguang and Scharfstein, Daniel O. and Colantuoni, Elizabeth and Girard, Timothy D. and Yan, Ying},
  date = {2016-10},
  journaltitle = {Biometrics},
  issn = {0006341X},
  doi = {10.1111/biom.12594},
  url = {http://dx.doi.org/10.1111/biom.12594},
  citeulike-article-id = {14221599},
  citeulike-attachment-1 = {wan16inf.pdf; /pdf/user/harrelfe/article/14221599/1093884/wan16inf.pdf; f3ff86df4c0ca35ceba14772b74deec1186419e0},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/biom.12594},
  posted-at = {2016-12-06 23:30:43},
  priority = {2},
  keywords = {multiple-endpoints,rct}
}

@article{wan19ana,
  title = {Analysis of Covariance ({{ANCOVA}}) in Randomized Trials: {{More}} Precision and Valid Confidence Intervals, without Model Assumptions},
  shorttitle = {Analysis of Covariance ({{ANCOVA}}) in Randomized Trials},
  author = {Wang, Bingkai and Ogburn, Elizabeth L. and Rosenblum, Michael},
  date = {2019},
  journaltitle = {Biometrics},
  volume = {0},
  issn = {1541-0420},
  doi = {10.1111/biom.13062},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13062},
  urldate = {2019-04-23},
  abstract = {“Covariate adjustment' in the randomized trial context refers to an estimator of the average treatment effect that adjusts for chance imbalances between study arms in baseline variables (called “covariates'). The baseline variables could include, e.g., age, sex, disease severity, and biomarkers. According to two surveys of clinical trial reports, there is confusion about the statistical properties of covariate adjustment. We focus on the ANCOVA estimator, which involves fitting a linear model for the outcome given the treatment arm and baseline variables, and trials that use simple randomization with equal probability of assignment to treatment and control. We prove the following new (to the best of our knowledge) robustness property of ANCOVA to arbitrary model misspecification: Not only is the ANCOVA point estimate consistent (as proved by Yang and Tsiatis (2001)) but so is its standard error. This implies that confidence intervals and hypothesis tests conducted as if the linear model were correct are still asymptotically valid even when the linear model is arbitrarily misspecified, e.g., when the baseline variables are nonlinearly related to the outcome or there is treatment effect heterogeneity. We also give a simple, robust formula for the variance reduction (equivalently, sample size reduction) from using ANCOVA. By re-analyzing completed randomized trials for mild cognitive impairment, schizophrenia, and depression, we demonstrate how ANCOVA can achieve variance reductions of 4\% to 32\%. This article is protected by copyright. All rights reserved.},
  issue = {ja},
  langid = {english},
  keywords = {ancova,rct}
}

@article{wan19anaa,
  title = {Analysis of Covariance in Randomized Trials: {{More}} Precision and Valid Confidence Intervals, without Model Assumptions},
  shorttitle = {Analysis of Covariance in Randomized Trials},
  author = {Wang, Bingkai and Ogburn, Elizabeth L. and Rosenblum, Michael},
  date = {2019},
  journaltitle = {Biometrics},
  volume = {75},
  number = {4},
  pages = {1391--1400},
  issn = {1541-0420},
  doi = {10.1111/biom.13062},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13062},
  urldate = {2019-12-06},
  abstract = {“Covariate adjustment” in the randomized trial context refers to an estimator of the average treatment effect that adjusts for chance imbalances between study arms in baseline variables (called “covariates”). The baseline variables could include, for example, age, sex, disease severity, and biomarkers. According to two surveys of clinical trial reports, there is confusion about the statistical properties of covariate adjustment. We focus on the analysis of covariance (ANCOVA) estimator, which involves fitting a linear model for the outcome given the treatment arm and baseline variables, and trials that use simple randomization with equal probability of assignment to treatment and control. We prove the following new (to the best of our knowledge) robustness property of ANCOVA to arbitrary model misspecification: Not only is the ANCOVA point estimate consistent (as proved by Yang and Tsiatis, 2001) but so is its standard error. This implies that confidence intervals and hypothesis tests conducted as if the linear model were correct are still asymptotically valid even when the linear model is arbitrarily misspecified, for example, when the baseline variables are nonlinearly related to the outcome or there is treatment effect heterogeneity. We also give a simple, robust formula for the variance reduction (equivalently, sample size reduction) from using ANCOVA. By reanalyzing completed randomized trials for mild cognitive impairment, schizophrenia, and depression, we demonstrate how ANCOVA can achieve variance reductions of 4 to 32\%.},
  langid = {english},
  keywords = {analysis-of-covariance,ancova,rct}
}

@article{wan19mat,
  title = {Matched or Unmatched Analyses with Propensity-Score–Matched Data?},
  author = {Wan, Fei},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {38},
  number = {2},
  pages = {289--300},
  issn = {1097-0258},
  doi = {10.1002/sim.7976},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7976},
  urldate = {2018-12-17},
  abstract = {Propensity-score matching has been used widely in observational studies to balance confounders across treatment groups. However, whether matched-pairs analyses should be used as a primary approach is still in debate. We compared the statistical power and type 1 error rate for four commonly used methods of analyzing propensity-score–matched samples with continuous outcomes: (1) an unadjusted mixed-effects model, (2) an unadjusted generalized estimating method, (3) simple linear regression, and (4) multiple linear regression. Multiple linear regression had the highest statistical power among the four competing methods. We also found that the degree of intraclass correlation within matched pairs depends on the dissimilarity between the coefficient vectors of confounders in the outcome and treatment models. Multiple linear regression is superior to the unadjusted matched-pairs analyses for propensity-score–matched data.},
  langid = {english},
  keywords = {covariate-adjustment,matching,propensity}
}

@article{wan20cov,
  title = {Covariate Adjustment for Randomized Controlled Trials Revisited},
  author = {Wang, Jixian},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.1988},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1988},
  urldate = {2019-12-21},
  abstract = {Covariate adjustment for the estimation of treatment effect for randomized controlled trials (RCT) is a simple approach with a long history, hence, its pros and cons have been well-investigated and published in the literature. It is worthwhile to revisit this topic since recently there has been significant investigation and development on model assumptions, robustness to model mis-specification, in particular, regarding the Neyman-Rubin model and the average treatment effect estimand. This paper discusses key results of the investigation and development and their practical implication on pharmaceutical statistics. Accordingly, we recommend that appropriate covariate adjustment should be more widely used for RCTs for both hypothesis testing and estimation.},
  langid = {english},
  keywords = {ancova,rct}
}

@article{wan20sim,
  title = {A Simple New Approach to Variable Selection in Regression, with Application to Genetic Fine Mapping},
  author = {Wang, Gao and Sarkar, Abhishek and Carbonetto, Peter and Stephens, Matthew},
  date = {2020},
  journaltitle = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {82},
  number = {5},
  pages = {1273--1300},
  issn = {1467-9868},
  doi = {10.1111/rssb.12388},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssb.12388},
  urldate = {2020-12-08},
  abstract = {We introduce a simple new approach to variable selection in linear regression, with a particular focus on quantifying uncertainty in which variables should be selected. The approach is based on a new model—the ‘sum of single effects’ model, called ‘SuSiE’—which comes from writing the sparse vector of regression coefficients as a sum of ‘single-effect’ vectors, each with one non-zero element. We also introduce a corresponding new fitting procedure—iterative Bayesian stepwise selection (IBSS)—which is a Bayesian analogue of stepwise selection methods. IBSS shares the computational simplicity and speed of traditional stepwise methods but, instead of selecting a single variable at each step, IBSS computes a distribution on variables that captures uncertainty in which variable to select. We provide a formal justification of this intuitive algorithm by showing that it optimizes a variational approximation to the posterior distribution under SuSiE. Further, this approximate posterior distribution naturally yields convenient novel summaries of uncertainty in variable selection, providing a credible set of variables for each selection. Our methods are particularly well suited to settings where variables are highly correlated and detectable effects are sparse, both of which are characteristics of genetic fine mapping applications. We demonstrate through numerical experiments that our methods outperform existing methods for this task, and we illustrate their application to fine mapping genetic variants influencing alternative splicing in human cell lines. We also discuss the potential and challenges for applying these methods to generic variable-selection problems.},
  langid = {english},
  keywords = {bayes,rms,variable-selection},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssb.12388}
}

@article{wan21ada,
  title = {Adaptive Randomization in a Two-Stage Sequential Multiple Assignment Randomized Trial},
  author = {Wang, Junyao and Wu, Liwen and Wahed, Abdus S.},
  date = {2021-05-30},
  journaltitle = {Biostatistics},
  issn = {1465-4644},
  doi = {10.1093/biostatistics/kxab020},
  url = {https://doi.org/10.1093/biostatistics/kxab020},
  urldate = {2021-05-30},
  abstract = {Sequential multiple assignment randomized trials (SMARTs) are systematic and efficient media for comparing dynamic treatment regimes (DTRs), where each patient is involved in multiple stages of treatment with the randomization at each stage depending on the patient’s previous treatment history and interim outcomes. Generally, patients enrolled in SMARTs are randomized equally to ethically acceptable treatment options regardless of how effective those treatments were during the previous stages, which results in some undesirable consequences in practice, such as low recruitment, less retention, and lower treatment adherence. In this article, we propose a response-adaptive SMART (RA-SMART) design where the allocation probabilities are imbalanced in favor of more promising treatments based on the accumulated information on treatment efficacy from previous patients and stages. The operating characteristics of the RA-SMART design relative to SMART design, including the consistency and efficiency of estimated response rate under each DTR, the power of identifying the optimal DTR, and the number of patients treated with the optimal and the worst DTRs, are assessed through extensive simulation studies. Some practical suggestions are discussed in the conclusion.},
  issue = {kxab020},
  keywords = {adaptive,rct,smart}
}

@article{wan92sec,
  title = {Secondary Data Analysis When There Are Missing Observations},
  author = {Wang, R. and Sedransk, J. and Jinn, J. H.},
  date = {1992},
  journaltitle = {J Am Stat Assoc},
  volume = {87},
  pages = {952--961},
  citeulike-article-id = {13265021},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {missing-data}
}

@article{wan95inf,
  title = {Inference for Smooth Curves in Longitudinal Data with Application to an {{AIDS}} Clinical Trial},
  author = {Wang, Yongxiao and Taylor, Jeremy M. G.},
  date = {1995},
  journaltitle = {Stat Med},
  volume = {14},
  pages = {1205--1218},
  doi = {10.1002/sim.4780141106},
  url = {http://dx.doi.org/10.1002/sim.4780141106},
  citeulike-article-id = {13265022},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4780141106},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {bayesian-inference,penalized-mle,pmle,rct,serial-data,shrinkage}
}

@article{wan97usi,
  title = {Using Smoothing Spline {{ANOVA}} to Examine the Relation of Risk Factors to the Incidence and Progression of Diabetic Retinopathy},
  author = {Wang, Yuedong and Wahba, Grace and Gu, Chong and Klein, Ronald and Klein, Barbara},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {1357--1376},
  citeulike-article-id = {13265023},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {additive-model,anova-model,interaction-surface,smoothing-spline,tensor-spline}
}

@article{wan99non,
  title = {Nonparametric Estimation of a Recurrent Survival Function},
  author = {Wang, Mei-Cheng and Chang, Shu-Hui},
  date = {1999},
  journaltitle = {J Am Stat Assoc},
  volume = {94},
  pages = {146--153},
  citeulike-article-id = {13265024},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {kaplan-meier-estimator,repeated-events}
}

@article{war15inc,
  title = {Incidence of Emergency Department Visits for {{ST-elevation}} Myocardial Infarction in a Recent Six-Year Period in the {{United States}}.},
  author = {Ward, Michael J. and Kripalani, Sunil and Zhu, Yuwei and Storrow, Alan B. and Dittus, Robert S. and Harrell, Frank E. and Self, Wesley H.},
  date = {2015-01},
  journaltitle = {Am J Cardio},
  volume = {115},
  number = {2},
  eprint = {25465931},
  eprinttype = {pmid},
  pages = {167--170},
  issn = {1879-1913},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25465931},
  abstract = {The incidence and longitudinal trends of patients with ST-elevation myocardial infarction (STEMI) presenting to United States (US) emergency departments (EDs) are currently unknown. Efforts to use effective treatments for cardiovascular disease may decrease ED STEMI presentation. We conducted a descriptive epidemiological analysis of STEMI visits to EDs from 2006 to 2011 using the Nationwide ED Sample, the largest source of US ED data, to determine the incidence of patients with STEMIs presenting to the US EDs. We included adult ED visits with an International Classification of Diseases, Ninth Revision, Clinical Modification diagnosis of STEMI and calculated incidence rates for STEMI ED visits using US census population data. Incidence calculations were stratified by age group, geographic region, and year. From 2006 to 2011, there was a mean of 258,106 STEMIs presenting to EDs per year, decreasing from 300,466 in 2006 to 227,343 in 2011. Incidence of ED STEMI visits per 10,000 adults decreased from 10.1 (95\% confidence interval [CI] 9.8 to 10.8) in 2006 to 7.3 (95\% CI 6.8 to 7.8) in 2011. The Midwest had the highest rate of ED STEMIs at 10.0 (95\% CI 9.2 to 10.8) and the West had the lowest with 6.6 (95\% CI 6.1 to 7.0). The incidence of STEMI decreased for all age groups during the study period. In conclusion, we report the first national estimates of STEMI presentation to US EDs, which demonstrate decreasing incidence across all age groups and all geographic regions from 2006 to 2011. A decreasing STEMI incidence may affect the quality and timeliness of STEMI care. Continued national STEMI surveillance is needed to guide healthcare resource allocation. Copyright  2015 Elsevier Inc. All rights reserved.},
  citeulike-article-id = {14102495},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25465931},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25465931},
  day = {15},
  posted-at = {2016-07-26 21:24:51},
  priority = {2},
  keywords = {collaboration}
}

@article{war16rol,
  title = {Role of {{Health Insurance Status}} in {{Interfacility Transfers}} of {{Patients With ST-Elevation Myocardial Infarction}}.},
  author = {Ward, Michael J. and Kripalani, Sunil and Zhu, Yuwei and Storrow, Alan B. and Wang, Thomas J. and Speroff, Theodore and Munoz, Daniel and Dittus, Robert S. and Harrell, Frank E. and Self, Wesley H.},
  date = {2016-08},
  journaltitle = {Am J Cardio},
  volume = {118},
  number = {3},
  eprint = {27282834},
  eprinttype = {pmid},
  pages = {332--337},
  issn = {1879-1913},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/27282834},
  abstract = {Lack of health insurance is associated with interfacility transfer from emergency departments for several nonemergent conditions, but its association with transfers for ST-elevation myocardial infarction (STEMI), which requires timely definitive care for optimal outcomes, is unknown. Our objective was to determine whether insurance status is a predictor of interfacility transfer for emergency department visits with STEMI. We analyzed data from the 2006 to 2011 Nationwide Emergency Department Sample examining all emergency department visits for patients age 18~years and older with a diagnosis of STEMI and a disposition of interfacility transfer or hospitalization at the same institution. For emergency department visits with STEMI, our multivariate logistic regression model included emergency department disposition status (interfacility transfer vs hospitalization at the same institution) as the primary outcome, and insurance status (none vs any [including Medicare, Medicaid, and private insurance]) as the primary exposure. We found that among 1,377,827 emergency department STEMI visits, including 249,294 (18.1\%) transfers, patients without health insurance (adjusted odds ratio 1.6, 95\% CI 1.5 to 1.7) were more likely to be transferred than those with insurance. Lack of health insurance status was also an independent risk factor for transfer compared with each subcategory of health insurance, including Medicare, Medicaid, and private insurance. In conclusion, among patients presenting to United States emergency departments with STEMI, lack of insurance was an independent predictor of interfacility transfer. In conclusion, because interfacility transfer is associated with longer delays to definitive STEMI therapy than treatment at the same facility, lack of health insurance may lead to important health disparities among patients with STEMI. Copyright  2016 Elsevier Inc. All rights reserved.},
  citeulike-article-id = {14102478},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/27282834},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=27282834},
  day = {1},
  posted-at = {2016-07-26 20:56:12},
  priority = {2},
  keywords = {collaboration}
}

@article{war16rola,
  title = {Role of {{Health Insurance Status}} in {{Interfacility Transfers}} of {{Patients With ST-Elevation Myocardial Infarction}}},
  author = {Ward, Michael J. and Kripalani, Sunil and Zhu, Yuwei and Storrow, Alan B. and Wang, Thomas J. and Speroff, Theodore and Munoz, Daniel and Dittus, Robert S. and Harrell, Frank E. and Self, Wesley H.},
  date = {2016-08-01},
  journaltitle = {Am J Cardiol},
  volume = {118},
  number = {3},
  eprint = {27282834},
  eprinttype = {pmid},
  pages = {332--337},
  issn = {1879-1913},
  doi = {10.1016/j.amjcard.2016.05.007},
  abstract = {Lack of health insurance is associated with interfacility transfer from emergency departments for several nonemergent conditions, but its association with transfers for ST-elevation myocardial infarction (STEMI), which requires timely definitive care for optimal outcomes, is unknown. Our objective was to determine whether insurance status is a predictor of interfacility transfer for emergency department visits with STEMI. We analyzed data from the 2006 to 2011 Nationwide Emergency Department Sample examining all emergency department visits for patients age 18~years and older with a diagnosis of STEMI and a disposition of interfacility transfer or hospitalization at the same institution. For emergency department visits with STEMI, our multivariate logistic regression model included emergency department disposition status (interfacility transfer vs hospitalization at the same institution) as the primary outcome, and insurance status (none vs any [including Medicare, Medicaid, and private insurance]) as the primary exposure. We found that among 1,377,827 emergency department STEMI visits, including 249,294 (18.1\%) transfers, patients without health insurance (adjusted odds ratio 1.6, 95\% CI 1.5 to 1.7) were more likely to be transferred than those with insurance. Lack of health insurance status was also an independent risk factor for transfer compared with each subcategory of health insurance, including Medicare, Medicaid, and private insurance. In conclusion, among patients presenting to United States emergency departments with STEMI, lack of insurance was an independent predictor of interfacility transfer. In conclusion, because interfacility transfer is associated with longer delays to definitive STEMI therapy than treatment at the same facility, lack of health insurance may lead to important health disparities among patients with STEMI.},
  langid = {english},
  pmcid = {PMC4949088},
  keywords = {collaboration}
}

@article{war89inv,
  title = {Investigating Therapies of Potentially Great Benefit: {{ECMO}}},
  author = {Ware, J. H.},
  date = {1989},
  journaltitle = {Stat Sci},
  volume = {4},
  pages = {298--340},
  citeulike-article-id = {13265025},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {study-design-and-stopping-rules}
}

@article{war97equ,
  title = {Equivalence Trials ({{Editorial}})},
  author = {Ware, James H. and Antman, Elliott M.},
  date = {1997},
  journaltitle = {NEJM},
  volume = {337},
  pages = {1159--1161},
  citeulike-article-id = {13265026},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {equivalence-trials,misinterpretation-of-p-values,teaching-mds}
}

@article{wax92col,
  title = {Collinearity Diagnosis for a Relative Risk Regression Analysis: {{An}} Application to Assessment of Diet-Cancer Relationship in Epidemiological Studies},
  author = {Wax, Yohanan},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1273--1287},
  citeulike-article-id = {13265027},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {collinearity,maximum-likelihood}
}

@article{wea05pat,
  title = {Patient Satisfaction and the Curse of {{Kelvin}}},
  author = {Wears, Robert L.},
  date = {2005},
  journaltitle = {Ann Emerg Med},
  volume = {46},
  number = {1},
  pages = {11--12},
  citeulike-article-id = {13265752},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  note = {"Almost 30 years ago, Alvin Feinstein coined the phrase, `the curse of Kelvin', to refer to the unthinking and inappropriate worship of quantifiable information in medicine. Lord Kelvin (who was addressing physicists, not physicians), had been quoted as saying in effect, that if your knowledge could not be expressed in numbers, then it was of a meager and unsatisfactory kind. Health care, because of its desire to be `scientific,' has not only been stricken by the curse of Kelvin, but has positively embraced it; this despite the fact that many prominent scientists (including some of Kelvin's contemporaries, eg, Darwin or Virchow) succeeded while completely ignoring his advice. Thus, we see a proliferation of scales and measurement instruments aimed at quantifying the hitherto unquantifiable". A.R. Feinstein, On exorcizing the ghost of Gauss and the curse of Kelvin, Clinical Biostatistics, C.V. Mosby Company, St. Louis, MO (1977), pp. 229--242. See fei77cliKelvin}
}

@article{web18how,
  title = {How to Use Prior Knowledge and Still Give New Data a Chance?},
  author = {Weber, Kristina and Hemmings, Rob and Koch, Armin},
  date = {2018},
  journaltitle = {Pharmaceutical Statistics},
  volume = {17},
  number = {4},
  pages = {329--341},
  issn = {1539-1612},
  doi = {10.1002/pst.1862},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.1862},
  urldate = {2018-07-13},
  abstract = {A common challenge for the development of drugs in rare diseases and special populations, eg, paediatrics, is the small numbers of patients that can be recruited into clinical trials. Extrapolation can be used to support development and licensing in paediatrics through the structured integration of available data in adults and prospectively generated data in paediatrics to derive conclusions that support licensing decisions in the target paediatric population. In this context, Bayesian analyses have been proposed to obtain formal proof of efficacy of a new drug or therapeutic principle by using additional information (data, opinion, or expectation), expressed through a prior distribution. However, little is said about the impact of the prior assumptions on the evaluation of outcome and prespecified strategies for decision-making as required in the regulatory context. On the basis of examples, we explore the use of data-based Bayesian meta-analytic–predictive methods and compare these approaches with common frequentist and Bayesian meta-analysis models. Noninformative efficacy prior distributions usually do not change the conclusions irrespective of the chosen analysis method. However, if heterogeneity is considered, conclusions are highly dependent on the heterogeneity prior. When using informative efficacy priors based on previous study data in combination with heterogeneity priors, these may completely determine conclusions irrespective of the data generated in the target population. Thus, it is important to understand the impact of the prior assumptions and ensure that prospective trial data in the target population have an appropriate chance, to change prior belief to avoid trivial and potentially erroneous conclusions.},
  langid = {english},
  keywords = {bayes,drug-development,historical-data,pediatric,prior}
}

@article{authchk,
  title = {Checklist for Authors},
  author = {Web, Biostatistics},
  date = {2020},
  url = {https://discourse.datamethods.org/t/author-checklist}
}

@article{wed01cha,
  title = {Challenges of Subgroup Analyses in Multinational Clinical Trials: {{Experiences}} from the {{MERIT-HF}} Trial},
  author = {Wedel, Hans and DeMets, David and {Emphet Al}},
  date = {2001},
  journaltitle = {Am Heart J},
  volume = {142},
  pages = {502--511},
  doi = {10.1067/mhj.2001.117600},
  url = {http://dx.doi.org/10.1067/mhj.2001.117600},
  citeulike-article-id = {13265224},
  citeulike-linkout-0 = {http://dx.doi.org/10.1067/mhj.2001.117600},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {rct,subgroup-analysis,teaching-mds},
  note = {caution against overinterpreting negative treatment effect in some subgroups}
}

@article{wee98rel,
  title = {Relationship between Cancer Patients' Predictions of Prognosis and Their Treatment Preferences},
  author = {Weeks, J. C. and Cook, E. F. and O'Day, S. J. and Peterson, L. M. and Wenger, N. and Reding, D. and Harrell, F. E. and Kussin, P. and Dawson, N. V. and Connors, A. F. and Lynn, J. and Phillips, R. S.},
  date = {1998},
  journaltitle = {JAMA},
  volume = {279},
  pages = {1709--1714},
  citeulike-article-id = {13265028},
  posted-at = {2014-07-14 14:09:47},
  priority = {0}
}

@article{wee98sur,
  title = {Survival Analysis with Time-Varying Covariates},
  author = {Weesie, Jeroen},
  date = {1998-01},
  journaltitle = {Stata Tech Bull},
  volume = {STB-41},
  pages = {25--43},
  citeulike-article-id = {13265029},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {shaping-data-for-analysis,tdc,teaching}
}

@article{wee98win,
  title = {Windmeijer's Goodness-of-Fit Test for Logistic Regression},
  author = {Weesie, Joroen},
  date = {1998-07},
  journaltitle = {Stata Tech Bull},
  number = {44},
  pages = {22--27},
  citeulike-article-id = {13265030},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {gof,goodness-of-fit,pearson-residual-test-problems,power,simulation-setup,type-i-error,windmeijers-test}
}

@article{wei00ord,
  title = {Ordering an Echocardiogram for Evaluation of Left Ventricular Function: {{Level}} of Expertise Necessary for Efficient Use},
  author = {Weiss, J. Peter and Gruver, Carol and Kaul, Sanjiv and Harrell, Frank E. and Sklenar, Jiri and Dent, John M.},
  date = {2000},
  journaltitle = {J Am Soc Echocard},
  volume = {13},
  pages = {124--130},
  citeulike-article-id = {13265113},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {diagnosis,propensity-score,testing,used-design-library}
}

@article{wei05mod,
  title = {Model-Based Correction to the {{QT}} Interval for Heart Rate for Assessing Mean {{QT}} Interval Change Due to Drug Effect},
  author = {Wei, Greg C. G. and Chen, Josh Y. H.},
  date = {2005},
  journaltitle = {Drug Info J},
  volume = {39},
  pages = {139--148},
  citeulike-article-id = {13265414},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {analysis-of-safety-data,drug-safety,pharmaceutical-safety,qt,qt-correction},
  note = {derives change in QT interval after drug minus change in QT due to heart rate after drug;modeling is done separately by treatment group;analyses based on standard corrected QT indexes ignore interaction between drug effect on QT and effect on heart rate}
}

@article{wei06com,
  title = {Comparison of the National Emergency Department Overcrowding Scale and the Emergency Department Work Index for Quantifying Emergency Department Crowding},
  author = {Weiss, Steven J. and Ernst, Amy A. and Nick, Todd G.},
  date = {2006},
  journaltitle = {Acad Emerg Med},
  volume = {13},
  pages = {513--518},
  citeulike-article-id = {13265698},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {adequacy-index,comparing-two-predictors,crowding,emergency-medicine-research}
}

@article{wei06con,
  title = {Conditional Growth Charts (with Discussion)},
  author = {Wei, Ying and He, Xuming},
  date = {2006},
  journaltitle = {Appl Stat},
  volume = {34},
  pages = {2069--2131},
  citeulike-article-id = {13265555},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {graphics,growth-charts,penalization},
  note = {advantage of customizing growth curve by subject taking prior measurements and covariates into account;nice discussion of penalized vs. unpenalized splines by Carroll and Ruppert;nice graphics}
}

@article{wei08est,
  title = {Estimating {{Cumulative Treatment Effects}} in the {{Presence}} of {{Nonproportional Hazards}}},
  author = {Wei, Guanghui and Schaubel, Douglas E.},
  date = {2008},
  journaltitle = {Biometrics},
  volume = {64},
  number = {3},
  pages = {724--732},
  issn = {1541-0420},
  doi = {10.1111/j.1541-0420.2007.00947.x},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2007.00947.x},
  urldate = {2020-01-06},
  abstract = {Often in medical studies of time to an event, the treatment effect is not constant over time. In the context of Cox regression modeling, the most frequent solution is to apply a model that assumes the treatment effect is either piecewise constant or varies smoothly over time, i.e., the Cox nonproportional hazards model. This approach has at least two major limitations. First, it is generally difficult to assess whether the parametric form chosen for the treatment effect is correct. Second, in the presence of nonproportional hazards, investigators are usually more interested in the cumulative than the instantaneous treatment effect (e.g., determining if and when the survival functions cross). Therefore, we propose an estimator for the aggregate treatment effect in the presence of nonproportional hazards. Our estimator is based on the treatment-specific baseline cumulative hazards estimated under a stratified Cox model. No functional form for the nonproportionality need be assumed. Asymptotic properties of the proposed estimators are derived, and the finite-sample properties are assessed in simulation studies. Pointwise and simultaneous confidence bands of the estimator can be computed. The proposed method is applied to data from a national organ failure registry.},
  langid = {english},
  keywords = {non-ph,non-proportional-hazards,survival}
}

@article{wei20gen,
  title = {Generalized Accelerated Recurrence Time Model in the Presence of a Dependent Terminal Event},
  author = {Wei, Bo and Zhang, Zhumin and Lai, HuiChuan J. and Peng, Limin},
  date = {2020-06},
  journaltitle = {Ann. Appl. Stat.},
  volume = {14},
  number = {2},
  pages = {956--976},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {1932-6157, 1941-7330},
  doi = {10.1214/20-AOAS1335},
  url = {https://projecteuclid.org/euclid.aoas/1593449333},
  urldate = {2020-06-29},
  abstract = {Recurrent events are commonly encountered in longitudinal studies. The observation of recurrent events is often stopped by a dependent terminal event in practice. For this data scenario, we propose two sensible adaptations of the generalized accelerated recurrence time (GART) model (J. Amer. Statist. Assoc. 111 (2016) 145–156) to provide useful alternative analyses that can offer physical interpretations while rendering extra flexibility beyond the existing work based on the accelerated failure time model. Our modeling strategies align with the rationale underlying the use of the survivors’ rate function or the adjusted rate function to account for the presence of the dependent terminal event. For the proposed models, we identify and develop estimation and inference procedures which can be readily implemented based on existing software. We establish the asymptotic properties of the new estimator. Simulation studies demonstrate good finite-sample performance of the proposed methods. An application to a dataset from the Cystic Fibrosis Foundation Patient Registry (CFFPR) illustrates the practical utility of the new methods.},
  langid = {english},
  keywords = {recurrent-event-with-competing-risk,recurrent-events,survival,terminating-event}
}

@article{wei20sam,
  title = {Sample Size Determination for {{Bayesian}} Analysis of Small n Sequential, Multiple Assignment, Randomized Trials ({{snSMARTs}}) with Three Agents},
  author = {Wei, Boxian and Braun, Thomas M. and Tamura, Roy N. and Kidwell, Kelley},
  date = {2020-09-06},
  journaltitle = {Journal of Biopharmaceutical Statistics},
  volume = {0},
  number = {0},
  eprint = {32892710},
  eprinttype = {pmid},
  pages = {1--12},
  publisher = {{Taylor \& Francis}},
  issn = {1054-3406},
  doi = {10.1080/10543406.2020.1815032},
  url = {https://doi.org/10.1080/10543406.2020.1815032},
  urldate = {2020-09-12},
  abstract = {The small n, Sequential, Multiple Assignment, Randomized Trial (snSMART) is a two-stage clinical trial design for rare diseases motivated by the comparison of three active treatments for isolated skin vasculitis in the ongoing clinical trial ARAMIS (a randomized multicenter study for isolated skin vasculitis, NCT09239573). In Stage 1, all patients are randomized to one of three treatments. In Stage 2, patients who respond to their initial treatment receive the same treatment again, while those who fail to respond are re-randomized to one of the two remaining treatments. A Bayesian method for estimating the response rate of each individual treatment in a three-arm snSMART demonstrated efficiency gains for a given sample size relative to other existing frequentist approaches. However, these efficiency gains are dependent upon knowing how many subjects are required to determine a specific difference in the treatment response rates. Because few sample size calculation methods for snSMARTs exist, we propose a Bayesian sample size calculation for an snSMART designed to distinguish the best treatment from the second-best treatment. Although our methods are based on asymptotic approximations, we demonstrate via simulations that our proposed sample size calculation approach produces the desired statistical power, even in small samples. Moreover, our methods and applet produce sample sizes quickly, thereby saving time relative to using simulations to determine the appropriate sample size. We compare our proposed sample size to an existing frequentist method based upon a weighted Z -statistic and demonstrate that the Bayesian method requires far fewer patients than the frequentist method for a study with the same design parameters.},
  keywords = {adaptive,bayes,sample-size,smart},
  annotation = {\_eprint: https://doi.org/10.1080/10543406.2020.1815032}
}

@article{wei64,
  title = {A Significance Test for Simultaneous Quantal and Quantitative Responses},
  author = {{Weiler}},
  date = {1964},
  journaltitle = {Technometrics},
  volume = {6},
  pages = {273--285},
  citeulike-article-id = {13265031},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {general,medical,multivariate-analysis}
}

@article{wei89,
  title = {Regression Analysis of Multivariate Incomplete Failure Time Data by Modeling Marginal Distributions},
  author = {Wei, L. J. and Lin, D. Y. and Weissfeld, L.},
  date = {1989},
  journaltitle = {J Am Stat Assoc},
  volume = {84},
  pages = {1065--1073},
  citeulike-article-id = {13265032},
  posted-at = {2014-07-14 14:09:47},
  priority = {0},
  keywords = {multivariate-analysis,survival-analysis-proportional-hazards-model}
}

@article{wei90,
  title = {Linear Regression Analysis of Censored Survival Data Based on Rank Tests},
  author = {Wei LJ, Lin D. Y.},
  date = {1990},
  journaltitle = {Biometrika},
  volume = {77},
  pages = {845--851},
  citeulike-article-id = {13265033},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {censored-data,distribution-free-methods,general}
}

@article{wei91app,
  title = {Applications of Multiple Imputation to the Analysis of Censored Regression Data},
  author = {Wei, G. C. G. and Tanner, M. A.},
  date = {1991},
  journaltitle = {Biometrics},
  volume = {47},
  pages = {1297--1309},
  citeulike-article-id = {13265034},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {censored-data,general,imputation}
}

@article{wei95inf,
  title = {The Influence of Variable Selection: {{A Bayesian}} Diagnostic Perspective},
  author = {Weiss, Robert E.},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {619--625},
  citeulike-article-id = {13265035},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {bayesian-inference,influence-of-adjustment-on-point-estimates-of-effects,logistic-simulation-setup,variable-selection}
}

@article{wei96res,
  title = {Dissent: {{Hyperlipidemia}} versus Iron Overload and Coronary Artery Disease: {{Yet}} More Arguments on the Cholesterol Debate},
  author = {Weintraub, William S. and Wenger, Nanette K. and Parthasarathy, Sam and Brown, W. Virgil},
  date = {1996},
  journaltitle = {J Clin Epi},
  volume = {49},
  pages = {1353--1358},
  citeulike-article-id = {13265036},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {medical,review-of-studies-of-cholesterol-lowering}
}

@article{wel13str,
  title = {Strategies for Developing Biostatistics Resources in an Academic Health Center},
  author = {Welty, Leah J. and Carter, Rickey E. and Finkelstein, Dianne M. and Harrell, Frank E. and Lindsell, Christopher J. and Macaluso, Maurizio and Mazumdar, Madhu and Nietert, Paul J. and Oster, Robert A. and Pollock, Brad H. and Roberson, Paula K. and Ware, James H.},
  date = {2013},
  journaltitle = {Acad Med},
  volume = {88},
  number = {4},
  pages = {454--460},
  doi = {10.1097/ACM.0b013e31828578ed},
  url = {http://dx.doi.org/10.1097/ACM.0b013e31828578ed},
  abstract = {Biostatistics---the application of statistics to understanding health and biology—provides powerful tools for developing research questions, designing studies, refining measurements, analyzing data, and interpreting findings. Biostatistics plays an important role in health-related research, yet biostatistics resources are often fragmented, ad hoc, or oversubscribed within academic health centers (AHCs). Given the increasing complexity and quantity of health-related data, the emphasis on accelerating clinical and translational science, and the importance of conducting reproducible research, the need for the thoughtful development of biostatistics resources within AHCs is growing. In this article, the authors identify strategies for developing biostatistics resources in three areas: (1) recruiting and retaining biostatisticians, (2) efficiently using biostatistics resources, and (3) improving biostatistical contributions to science. AHCs should consider these three domains in building strong biostatistics resources, which they can leverage to support a broad spectrum of research. For each of the three domains, the authors describe the advantages and disadvantages of AHCs creating centralized biostatistics units rather than dispersing such resources across clinical departments or other research units. They also address the challenges that biostatisticians face in contributing to research without sacrificing their individual professional growth or the trajectory of their research teams. The authors ultimately recommend that AHCs create centralized biostatistics units because this approach offers distinct advantages both to investigators who collaborate with biostatisticians as well as to the biostatisticians themselves, and it is better suited to accomplish the research and education missions of AHCs.},
  citeulike-article-id = {13265967},
  citeulike-linkout-0 = {http://dx.doi.org/10.1097/ACM.0b013e31828578ed},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {academic-medical-center,biostatistics,resources,strategy}
}

@article{wel90,
  title = {Construction of Permutation Tests},
  author = {Wj, Welch},
  date = {1990},
  journaltitle = {J Am Stat Assoc},
  volume = {85},
  pages = {693--698},
  citeulike-article-id = {13265037},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {distribution-free-methods}
}

@article{wel93log,
  title = {A Log-Rank Test for Equivalence of Two Survivor Functions},
  author = {Wellek, Stefan},
  date = {1993},
  journaltitle = {Biometrics},
  volume = {49},
  pages = {877--881},
  citeulike-article-id = {13265038},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {maximum-survival-difference,risk-difference-vs-hazard-ratio}
}

@article{wen00wit,
  title = {Withholding versus Withdrawing Life-Sustaining Treatment: {{Patient}} Factors and Documentation Associated with Dialysis Decisions},
  author = {Wenger, Neil S. and Lynn, Joanne and Oye, Robert K. and Liu, Honghu and Teno, Joan M. and Phillips, Russell S. and Desbiens, Norman A. and Sehgal, Ashwini and Kussin, Peter and Taub, Harry and Harrell, Frank E. and Knaus, William A.},
  date = {2000},
  journaltitle = {J Am Geriatric Soc},
  volume = {48},
  pages = {S74-S83},
  citeulike-article-id = {13265129},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{wen18com,
  title = {Comparing Methods for Estimation of Heterogeneous Treatment Effects Using Observational Data from Health Care Databases},
  author = {{Wendling} and {Jung} and {Callahan} and {Schuler} and {Shah} and {Gallego}},
  journaltitle = {Stat Med},
  volume = {0},
  number = {0},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7820},
  doi = {10.1002/sim.7820},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7820},
  abstract = {There is growing interest in using routinely collected data from health care databases to study the safety and effectiveness of therapies in ” real‐world” conditions, as it can provide complementary evidence to that of randomized controlled trials. Causal inference from health care databases is challenging because the data are typically noisy, high dimensional, and most importantly, observational. It requires methods that can estimate heterogeneous treatment effects while controlling for confounding in high dimensions. Bayesian additive regression trees, causal forests, causal boosting, and causal multivariate adaptive regression splines are off‐the‐shelf methods that have shown good performance for estimation of heterogeneous treatment effects in observational studies of continuous outcomes. However, it is not clear how these methods would perform in health care database studies where outcomes are often binary and rare and data structures are complex. In this study, we evaluate these methods in simulation studies that recapitulate key characteristics of comparative effectiveness studies. We focus on the conditional average effect of a binary treatment on a binary outcome using the conditional risk difference as an estimand. To emulate health care database studies, we propose a simulation design where real covariate and treatment assignment data are used and only outcomes are simulated based on nonparametric models of the real outcomes. We apply this design to 4 published observational studies that used records from 2 major health care databases in the United States. Our results suggest that Bayesian additive regression trees and causal boosting consistently provide low bias in conditional risk difference estimates in the context of health care database studies.},
  citeulike-article-id = {14600147},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7820},
  citeulike-linkout-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7820},
  posted-at = {2018-06-06 17:09:42},
  priority = {2},
  keywords = {causal-inference,hte,machine-learning}
}

@article{wen80pro,
  title = {Procainamide Delivery to Ischemic Canine Myocardium Following Rapid Intravenous Administration},
  author = {Wenger, T. L. and Browning, D. J. and Masterton, C. E. and Abou-Donia, M. B. and Harrell, F. E. and Bache, R. J. and Strauss, H. C.},
  date = {1980},
  journaltitle = {Circ Res},
  volume = {46},
  pages = {789--795},
  citeulike-article-id = {13265039},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{wen84ven,
  title = {Ventricular Fibrillation Following Canine Coronary Reperfusion: {{Different}} Outcomes with Pentobarbital and α-Chloralose},
  author = {Wenger, T. L. and Harrell, F. E. and Brown, K. K. and Lederman, S. and Strauss, H. C.},
  date = {1984},
  journaltitle = {Can J Phys Pharm},
  volume = {62},
  pages = {224--228},
  citeulike-article-id = {13265040},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{wes10pro,
  title = {Propensity Score Estimation: Neural Networks, Support Vector Machines, Decision Trees ({{CART}}), and Meta-Classifiers as Alternatives to Logistic Regression},
  author = {Westreich, Daniel and Lessler, Justin and Funk, Michele J.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {826--833},
  citeulike-article-id = {13265826},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {logistic-regression,neural-networks,propensity-scores,recursive-partitioning,review},
  note = {use of more advanced predictive methods in developing propensity scores}
}

@article{wes17com,
  title = {A {{Comparison}} of {{Correlation Structure Selection Penalties}} for {{Generalized Estimating Equations}}},
  author = {Westgate, Philip M. and Burchett, Woodrow W.},
  date = {2017},
  journaltitle = {Am Statistician},
  volume = {71},
  number = {4},
  eprint = {https://doi.org/10.1080/00031305.2016.1200490},
  pages = {344--353},
  publisher = {Taylor & Francis},
  doi = {10.1080/00031305.2016.1200490},
  url = {https://doi.org/10.1080/00031305.2016.1200490},
  abstract = {ABSTRACTCorrelated data are commonly analyzed using models constructed using population-averaged generalized estimating equations (GEEs). The specification of a population-averaged GEE model includes selection of a structure describing the correlation of repeated measures. Accurate specification of this structure can improve efficiency, whereas the finite-sample estimation of nuisance correlation parameters can inflate the variances of regression parameter estimates. Therefore, correlation structure selection criteria should penalize, or account for, correlation parameter estimation. In this article, we compare recently proposed penalties in terms of their impacts on correlation structure selection and regression parameter estimation, and give practical considerations for data analysts. Supplementary materials for this article are available online.},
  citeulike-article-id = {14550243},
  citeulike-linkout-0 = {http://dx.doi.org/10.1080/00031305.2016.1200490},
  citeulike-linkout-1 = {https://doi.org/10.1080/00031305.2016.1200490},
  posted-at = {2018-03-16 13:36:51},
  priority = {2},
  keywords = {correlation-structure,gee,longitudinal-data,model-uncertainty,serial-data}
}

@article{wes97bay,
  title = {A {{Bayesian}} Perspective on the {{Bonferroni}} Adjustment},
  author = {Westfall, Peter H. and Johnson, Wesley O. and Utts, Jessica M.},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {419--427},
  citeulike-article-id = {13265041},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {bayesian-inference,multiple-comparisons,multiplicity},
  note = {Bonferroni adjustment is consistent with prior which assumes that the probability that all null hypotheses is true is a constant (say 0.5) no matter how many hypotheses are tested; If priors for individual parameters are well calibrated there is no need for adjusting the prior to take into account other hypotheses being tested}
}

@article{wha82sur,
  title = {Survival of Coronary Artery Disease Patients with Stable Pain and Normal Left Ventricular Function Treated Medically or Surgically at {{Duke University}}},
  author = {Whalen, R. E. and Harrell, F. E. and Lee, K. L. and Rosati, R. A.},
  date = {1982},
  journaltitle = {Circ},
  volume = {65:II},
  pages = {49--52},
  citeulike-article-id = {13265042},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{whe00hea,
  title = {Heart Transplant Center Practice Patterns Affect Access to Donors and Survival of Patients Classified as Status 1 by the {{United Network}} of {{Organ Sharing}}},
  author = {Whellan, David J. and Tudor, Gail and Denofrio, David and Abrams, Jonathan D. and Loh, Evan},
  date = {2000},
  journaltitle = {Am Heart J},
  volume = {140},
  pages = {443--450},
  citeulike-article-id = {13265144},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {transplant}
}

@article{whi01met,
  title = {Meta-Analysis of Ordinal Outcomes Using Individual Patient Data},
  author = {Whitehead, Anne and Omar, Rumana Z. and Higgins, Julian P. T. and Savaluny, Elly and Turner, Rebecca M. and Thompson, Simon G.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {2243--2260},
  citeulike-article-id = {13265214},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {bugs-code,meta-analysis,mixed-effects-model,po-assumption,proportional-odds-model,random-effects,repeated-measurements,serial-data}
}

@article{whi05adj,
  title = {Adjusting for Partially Missing Baseline Measurements in Randomized Trials},
  author = {White, Ian R. and Thompson, Simon G.},
  date = {2005},
  journaltitle = {Stat Med},
  volume = {24},
  pages = {993--1007},
  citeulike-article-id = {13265855},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {analysis-of-covariance,ancova,imputation,missing-baseline,missing-covariate,power,randomized-trials,rct,statistical-analysis-plan}
}

@article{whi05ass,
  title = {Assessing Subgroup Effects with Binary Data: Can the Use of Different Effect Measures Lead to Different Conclusions?},
  author = {White, Ian R. and Elbourne, Diana},
  date = {2005-04},
  journaltitle = {BMC Med Res Methodol},
  volume = {5},
  number = {15},
  url = {http://www.biomedcentral.com/1471-2288/5/15},
  citeulike-article-id = {13265806},
  citeulike-linkout-0 = {http://www.biomedcentral.com/1471-2288/5/15},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  note = {example of disagreement between variation in treatment effects over subgroups when using relative risks vs. odds ratio;large variation in baseline risk;"The test of interaction should therefore be applied to the effect measure which is least likely to exhibit an interaction.";doi:10.1186/1471-2288-5-15;note from Doug Altman:"I fully support the idea of using evidence as well as theoretical arguments in such situations. We have evidence that OR is not more likely to give homogeneity in meta-analysis than RR (Deeks JJ: Issues in the selection of a summary statistic for meta-analysis of clinical trials with binary outcomes. Stat Med 2002, 21:1575-1600.). It certainly is possible for RRs to be constant across a wide range of risk groups when one is heading towards zero so to speak - ie a beneficial effect gives RR{$<$}1. I agree that it is not possible when one goes the other way."}
}

@article{whi09imp,
  title = {Imputing Missing Covariate Values for the {{Cox}} Model},
  author = {White, Ian R. and Royston, Patrick},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {1982--1998},
  citeulike-article-id = {13265770},
  citeulike-attachment-1 = {whi09imp.pdf; /pdf/user/harrelfe/article/13265770/1109013/whi09imp.pdf; 50ee39d65a18045c8252b949f76ca4f35cfd5632},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {cox-model,missing-covariates,missing-data,multiple-imputation,ph,proportional-hazards-model},
  note = {approach to using event time and censoring indicator as predictors in the imputation model for missing baseline covariates;recommended an approximation using the event indicator and the cumulative hazard transformation of time, without their interaction}
}

@article{whi10bia,
  title = {Bias and Efficiency of Multiple Imputation Compared with Complete-Case Analysis for Missing Covariate Values},
  author = {White, Ian R. and Carlin, John B.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {2920--2931},
  citeulike-article-id = {13265865},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {bias-of-mi-and-complete-case-analysis,cc,mi,missing-data,multiple-imputation}
}

@article{whi10eva,
  title = {Evaluating Health Risk Models},
  author = {Whittemore, Alice S.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {29},
  number = {23},
  pages = {2438--2452},
  citeulike-article-id = {13265856},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {absolute-risk,brier-score-and-decompositions,concordance,discrimination,low-resolution-calibration,personalized-disease-prevention,precision,resolution,risk-model}
}

@article{whi11mul,
  title = {Multiple Imputation Using Chained Equations: {{Issues}} and Guidance for Practice},
  author = {White, Ian R. and Royston, Patrick and Wood, Angela M.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  number = {4},
  pages = {377--399},
  citeulike-article-id = {13265871},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {missing-data,multiple-imputation},
  note = {practical guidance for the use of multiple imputation using chained equations;MICE;imputation models for different types of target variables;PMM choosing at random from among a few closest matches;choosing number of multiple imputations by a reproducibility argument, suggesting 100f imputations when f is the fraction of cases that are incomplete}
}

@article{whi15bay,
  title = {Bayesian Sample Sizes for Exploratory Clinical Trials Comparing Multiple Experimental Treatments with a Control},
  author = {Whitehead, John and Cleary, Faye and Turner, Amanda},
  date = {2015-05},
  journaltitle = {Stat Med},
  volume = {34},
  number = {12},
  pages = {2048--2061},
  issn = {02776715},
  doi = {10.1002/sim.6469},
  url = {http://dx.doi.org/10.1002/sim.6469},
  citeulike-article-id = {14214859},
  citeulike-attachment-1 = {whi15bay.pdf; /pdf/user/harrelfe/article/14214859/1092995/whi15bay.pdf; dbda88eb5417652c66231374ae636e7eed8f1d72},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.6469},
  day = {30},
  posted-at = {2016-11-25 19:08:14},
  priority = {0},
  keywords = {bayes,bayesian-inference,bayesian-methods,bayesian-sample-size-estimation,rct,sample-size}
}

@article{whi17inf,
  title = {Against {{Inferential Statistics}}: {{How}} and {{Why Current Statistics Teaching Gets It Wrong}}},
  shorttitle = {Against {{Inferential Statistics}}},
  author = {White, Patrick and Gorard, Stephen},
  date = {2017-05},
  journaltitle = {Statistics Education Research Journal},
  volume = {16},
  number = {1},
  pages = {55--65},
  publisher = {{International Association for Statistics Education and the International Statistical Institute}},
  issn = {1570-1824},
  abstract = {Recent concerns about a shortage of capacity for statistical and numerical analysis skills among social science students and researchers have prompted a range of initiatives aiming to improve teaching in this area. However, these projects have rarely re-evaluated the content of what is taught to students and have instead focussed primarily on delivery. The emphasis has generally been on increased use of complex techniques, specialist software and, most importantly in the context of this paper, a continued focus on inferential statistical tests, often at the expense of other types of analysis. We argue that this "business as usual" approach to the content of statistics teaching is problematic for several reasons. First, the assumptions underlying inferential statistical tests are rarely met, meaning that students are being taught analyses that should only be used very rarely. Secondly, all of the most common outputs of inferential statistical tests--p-values, standard errors and confidence intervals--suffer from a similar logical problem that renders them at best useless and at worst misleading. Eliminating inferential statistical tests from statistics teaching (and practice) would avoid the creation of another generation of researchers who either do not understand, or knowingly misuse, these techniques. It would also have the benefit of removing one of the key barriers to students' understanding of statistical analysis. [For a response to this article, "A Response to White and Gorard: against Inferential Statistics: How and Why Current Statistics Teaching Gets It Wrong," see EJ1152509. For the rejoinder, "Still against Inferential Statistics: Rejoinder to Nicholson and Ridgway," see EJ1152510.]},
  langid = {english},
  keywords = {inference,teaching}
}

@unpublished{whi21cov,
  title = {Covariate Adjustment in Randomised Trials: Canonical Link Functions Protect against Model Mis-Specification},
  shorttitle = {Covariate Adjustment in Randomised Trials},
  author = {White, Ian R. and Morris, Tim P. and Williamson, Elizabeth},
  date = {2021-07-15},
  eprint = {2107.07278},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2107.07278},
  urldate = {2021-12-15},
  abstract = {Covariate adjustment has the potential to increase power in the analysis of randomised trials, but mis-specification of the adjustment model could cause error. We explore what error is possible when the adjustment model omits a covariate by randomised treatment interaction, in a setting where the covariate is perfectly balanced between randomised treatments. We use mathematical arguments and analyses of single hypothetical data sets. We show that analysis by a generalised linear model with the canonical link function leads to no error under the null -- that is, if treatment effect is truly zero under the adjusted model then it is also zero under the unadjusted model. However, using non-canonical link functions does not give this property and leads to potentially important error under the null. The error is present even in large samples and hence constitutes bias. We conclude that covariate adjustment analyses of randomised trials should avoid non-canonical links. If a marginal risk difference is the target of estimation then this should not be estimated using an identity link; alternative preferable methods include standardisation and inverse probability of treatment weighting.},
  archiveprefix = {arXiv},
  keywords = {ancova,link-function,misspecification},
  note = {Comment: 10 pages, 1 figure}
}

@unpublished{whi21cova,
  title = {Covariate Adjustment in Randomised Trials: Canonical Link Functions Protect against Model Mis-Specification},
  shorttitle = {Covariate Adjustment in Randomised Trials},
  author = {White, Ian R. and Morris, Tim P. and Williamson, Elizabeth},
  date = {2021-07-15},
  eprint = {2107.07278},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2107.07278},
  urldate = {2022-01-21},
  abstract = {Covariate adjustment has the potential to increase power in the analysis of randomised trials, but mis-specification of the adjustment model could cause error. We explore what error is possible when the adjustment model omits a covariate by randomised treatment interaction, in a setting where the covariate is perfectly balanced between randomised treatments. We use mathematical arguments and analyses of single hypothetical data sets. We show that analysis by a generalised linear model with the canonical link function leads to no error under the null -- that is, if treatment effect is truly zero under the adjusted model then it is also zero under the unadjusted model. However, using non-canonical link functions does not give this property and leads to potentially important error under the null. The error is present even in large samples and hence constitutes bias. We conclude that covariate adjustment analyses of randomised trials should avoid non-canonical links. If a marginal risk difference is the target of estimation then this should not be estimated using an identity link; alternative preferable methods include standardisation and inverse probability of treatment weighting.},
  archiveprefix = {arXiv},
  keywords = {ancova,covariate-adjustment,link-function,rct},
  note = {Comment: 10 pages, 1 figure}
}

@article{whi80het,
  title = {A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity},
  author = {White, Halbert},
  date = {1980},
  journaltitle = {Econometrica},
  volume = {48},
  pages = {817--838},
  citeulike-article-id = {13265043},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {robust-estimators}
}

@article{whi84,
  title = {Model Interpretation from the Additive Elements of the Likelihood Function},
  author = {Whittaker, Joe},
  date = {1984},
  journaltitle = {Appl Stat},
  volume = {33},
  pages = {52--64},
  citeulike-article-id = {13265044},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{whi86sur,
  title = {Survival Estimation Using Splines},
  author = {Whittemore, Alice S. and Keller, Joseph B.},
  date = {1986},
  journaltitle = {Biometrics},
  volume = {42},
  pages = {495--506},
  citeulike-article-id = {13265045},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {cox-ph-model,kaplan-meier,nelson-altshuler,nonparametric-survival-estimator,simulation-setup,splines}
}

@article{whi93sam,
  title = {Sample Size Calculations for Ordered Categorical Data},
  author = {Whitehead, John},
  date = {1993},
  journaltitle = {Stat Med},
  volume = {12},
  pages = {2257--2271},
  citeulike-article-id = {13265046},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {ordinal-logistic-model,sample-size,scales,study-design},
  annotation = {See letter to editor SM 15:1065-6 for binary case;see errata in SM 13:871 1994;see kol95com, jul96sam}
}

@article{whi96sta,
  title = {Statistical Reporting of Clinical Trials with Individual Changes from Allocated Treatment},
  author = {White, Ian R. and Pocock, Stuart J.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {249--262},
  citeulike-article-id = {13265047},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {drop-ins,dropouts,intention-to-treat,study-design,tdc,treatment-allocation}
}

@article{whi99on,
  title = {On Being the Statistician on a Data and Safety Monitoring Board},
  author = {Whitehead, John},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {3425--3434},
  citeulike-article-id = {13265086},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {blinding,dsmb},
  note = {"The reports to the DSMB should be totally unblind, identifying treatments by name. This is because, to fulfil their role of protecting the safety interests of patients, the DSMB should have access to all the facts."}
}

@article{who99bac,
  title = {Bacterial Etiology of Serious Infections in Young Infants in Developing Countries: {{Results}} of a Multicenter Study},
  author = {Margolis, Peter and Mulholland, E. Kim and Harrell, Frank E. and Gove, Sandy and {The WHO Young Infants Study Group}},
  date = {1999},
  journaltitle = {Pediatr Infect Dis J},
  volume = {18S},
  pages = {S17-S22},
  citeulike-article-id = {13265101},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{who99cli,
  title = {Clinical Prediction of Serious Bacterial Infections in Young Infants in Developing Countries},
  author = {Margolis, Peter and Mulholland, E. Kim and Harrell, Frank E. and Gove, Sandy and {the WHO Young Infants Study Group}},
  date = {1999},
  journaltitle = {Pediatr Infect Dis J},
  volume = {18S},
  pages = {S23-S31},
  citeulike-article-id = {13265098},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{who99con,
  title = {Conclusions from the {{WHO}} Multicenter Study of Serious Infections in Young Infants},
  author = {Margolis, Peter and Mulholland, E. Kim and Harrell, Frank E. and Gove, Sandy and {The WHO Young Infants Study Group}},
  date = {1999},
  journaltitle = {Pediatr Infect Dis J},
  volume = {18S},
  pages = {S32-S34},
  citeulike-article-id = {13265102},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{who99met,
  title = {Methodology for a Multicenter Study of Serious Infections in Young Infants in Developing Countries},
  author = {Margolis, Peter and Mulholland, E. Kim and Harrell, Frank E. and Gove, Sandy and {The WHO Young Infants Study Group}},
  date = {1999},
  journaltitle = {Pediatr Infect Dis J},
  volume = {18S},
  pages = {S8-S16},
  citeulike-article-id = {13265100},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{who99ser,
  title = {Serious Infections in Young Infants in Developing Countries: {{Rationale}} for a Multicenter Study},
  author = {Margolis, Peter and Mulholland, E. Kim and Harrell, Frank E. and Gove, Sandy and {The WHO Young Infants Study Group}},
  date = {1999},
  journaltitle = {Pediatr Infect Dis J},
  volume = {18S},
  pages = {S4-S7},
  citeulike-article-id = {13265099},
  posted-at = {2014-07-14 14:09:49},
  priority = {0}
}

@article{wic10lay,
  title = {A Layered Grammar of Graphics},
  author = {Wickham, Hadley},
  date = {2010},
  journaltitle = {J Comp Graph Stat},
  volume = {19},
  number = {1},
  pages = {3--28},
  citeulike-article-id = {13265824},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {advantages-of-layering,concise-specification-of-napoleons-march,ggplot,statistical-graphics}
}

@article{wie10per,
  title = {Performance of Using Multiple Stepwise Algorithms for Variable Selection},
  author = {Wiegand, Ryan E.},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {1647--1659},
  citeulike-article-id = {13265831},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {stepwise-regression,variable-selection},
  note = {fruitless to try different stepwise methods and look for agreement;the methods will agree on the wrong model}
}

@article{wie19qua,
  title = {Quantification of {{Prior Impact}} in {{Terms}} of {{Effective Current Sample Size}}},
  author = {Wiesenfarth, Manuel and Calderazzo, Silvia},
  date = {2019},
  journaltitle = {Biometrics},
  volume = {0},
  issn = {1541-0420},
  doi = {10.1111/biom.13124},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13124},
  urldate = {2019-07-31},
  abstract = {Bayesian methods allow borrowing of historical information through prior distributions. The concept of prior effective sample size (prior ESS) facilitates quantification and communication of such prior information by equating it to a sample size. Prior information can arise from historical observations, thus the traditional approach identifies the ESS with such historical sample size. However, this measure is independent from newly observed data, and thus would not capture an actual “loss of information” induced by the prior in case of prior-data conflict. We build on recent work to relate prior impact to a number of (virtual) samples from the current data model and introduce the effective current sample size (ECSS) of a prior, tailored to the application in Bayesian clinical trial designs. Special emphasis is put on robust mixture, power and commensurate priors. We apply the approach to an adaptive design in which the number of recruited patients is adjusted depending on the effective sample size at an interim analysis. We argue that the ECSS is the appropriate measure in this case, as the aim is to save current (as opposed to historical) patients from recruitment. Furthermore, the ECSS can help overcoming lack of consensus in the ESS assessment of mixture priors and can, more broadly, provide further insights into the impact of priors. An R package accompanies the paper. This article is protected by copyright. All rights reserved.},
  issue = {ja},
  langid = {english},
  keywords = {bayes,prior,sample-size}
}

@article{wie89,
  title = {A Family of Nonparametric Statistics for Comparing Diagnostic Markers with Paired or Unpaired Data},
  author = {Wieand, S. and Gail, M. H. and James, B. R. and James, K. L.},
  date = {1989},
  journaltitle = {Biometrika},
  volume = {76},
  pages = {585--592},
  citeulike-article-id = {13265048},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {diagnosis,predictive-accuracy,testing}
}

@article{wij09bay,
  title = {Bayesian Statistical Inference Enhances the Interpretation of Contemporary Randomized Controlled Trials},
  author = {Wijeysundera, Duminda N. and Austin, Peter C. and Hux, Janet E. and Beattie, W. Scott and Laupacis, Andreas},
  date = {2009},
  journaltitle = {J Clin Epi},
  volume = {62},
  pages = {13--21},
  citeulike-article-id = {13265722},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {bayesian-inference,evidence-based-medicine,rct,systematic-reviews},
  note = {Bayesian re-analysis of trials analyzed using frequentist methods}
}

@article{wik00eva,
  title = {Evaluation of the Performance of a P53 Sequencing Microarray Chip Using 140 Previously Sequenced Bladder Tumor Samples},
  author = {Wilman, Friedrik P. and Lu, Ming-Lan and Thykjaer, Thomas and Olesen, Sanne H. and Andersen, Lars D. and Cordon-Cardo, Carlos and Orntoft, Torben F.},
  date = {2000},
  journaltitle = {Clin Chem},
  volume = {46},
  pages = {1555--1561},
  citeulike-article-id = {13265162},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  note = {Affymetrix p53 Genechip's 1464 gene chip positions- need to regard "each chip position as a separate entity with its own noise and threshold characteristics"}
}

@article{wil00sta,
  title = {Statistical Review by Research Ethics Committees},
  author = {Williamson, P. and Hutton, J. L. and Bliss, J. and Blunt, J. and Campbell, M. J. and Nicholson, R.},
  date = {2000},
  journaltitle = {J Roy Stat Soc A},
  volume = {163},
  pages = {5--13},
  citeulike-article-id = {13265108},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {ethics-of-under-powered-studies,research-ethics-committee,scientific-validity,statistical-review,statistician-membership}
}

@article{wil01inc,
  title = {Incremental Net Benefit in Randomized Clinical Trials},
  author = {Willan, Andrew R. and Lin, D. Y.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1563--1574},
  citeulike-article-id = {13265205},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {c-e,incremental-net-benefit},
  note = {joint analysis of effectiveness and cost when survival time may be censored;informative censoring of cost:"... censoring is informative on the cost scale. Patients accumulate costs at different rates. Therefore, there is a positive correlation between the costs a patient accumulates until death and the costs he or she accumulates until censoring. As a result, the life-table estimate of mean cost is positively biased."}
}

@article{wil03inc,
  title = {Incremental Net Benefit in Randomized Clinical Trials with Quality-Adjusted Survival},
  author = {Willan, Andrew R. and Chen, Eric B. and Cook, Richard J. and Lin, D. Y.},
  date = {2003},
  journaltitle = {Stat Med},
  volume = {22},
  pages = {353--362},
  citeulike-article-id = {13265312},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {analysis-of-cost,c-e},
  note = {methods for estimating difference in mean costs and difference in mean effectiveness with their variances and covariances in the presence of dependent censoring;analysis of cost;cost effectiveness;incremental net benefit}
}

@book{wil05gra,
  title = {The {{Grammar}} of {{Graphics}}},
  author = {Wilkinson, Leland},
  date = {2005},
  edition = {Second},
  publisher = {{Springer}},
  location = {{New York}},
  doi = {10.1007/0-387-28695-0},
  url = {http://dx.doi.org/10.1007/0-387-28695-0},
  citeulike-article-id = {13265054},
  citeulike-linkout-0 = {http://dx.doi.org/10.1007/0-387-28695-0},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {graphics,teaching-mds}
}

@article{wil06hyb,
  title = {A Hybrid Model for Nonignorable Dropout in Longitudinal Binary Responses},
  author = {Wilkins, Kenneth J. and Fitzmaurice, Garrett M.},
  date = {2006},
  journaltitle = {Biometrics},
  volume = {62},
  pages = {168--176},
  citeulike-article-id = {13265484},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {binary-response,informative-dropout,longitudinal-data,missing-data,nonrandom-dropout,serial-data}
}

@article{wil13avo,
  title = {Avoid Lost Discoveries, Because of Violations of Standard Assumptions, by Using Modern Robust Statistical Methods},
  author = {Wilcox, Rand and Carlson, Mike and Azen, Stan and Clark, Florence},
  date = {2013-03-01},
  journaltitle = {Journal of Clinical Epidemiology},
  volume = {66},
  number = {3},
  eprint = {23195918},
  eprinttype = {pmid},
  pages = {319--329},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2012.09.003},
  url = {https://www.jclinepi.com/article/S0895-4356(12)00275-2/abstract},
  urldate = {2019-10-24},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objectives{$<$}/h3{$><$}p{$>$}Recently, there have been major advances in statistical techniques for assessing central tendency and measures of association. The practical utility of modern methods has been documented extensively in the statistics literature, but they remain underused and relatively unknown in clinical trials. Our objective was to address this issue.{$<$}/p{$><$}h3{$>$}Study Design and Purpose{$<$}/h3{$><$}p{$>$}The first purpose was to review common problems associated with standard methodologies (low power, lack of control over type I errors, and incorrect assessments of the strength of the association). The second purpose was to summarize some modern methods that can be used to circumvent such problems. The third purpose was to illustrate the practical utility of modern robust methods using data from the Well Elderly 2 randomized controlled trial.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}In multiple instances, robust methods uncovered differences among groups and associations among variables that were not detected by classic techniques. In particular, the results demonstrated that details of the nature and strength of the association were sometimes overlooked when using ordinary least squares regression and Pearson correlation.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}Modern robust methods can make a practical difference in detecting and describing differences between groups and associations between variables. Such procedures should be applied more frequently when analyzing trial-based data.{$<$}/p{$>$}},
  langid = {english},
  keywords = {clt,nonparametric,power,robust-methods,robustness}
}

@article{wil16pre,
  title = {Predicting {{Severe Pneumonia Outcomes}} in {{Children}}},
  author = {Williams, Derek J. and Zhu, Yuwei and Grijalva, Carlos G. and Self, Wesley H. and Harrell, Frank E. and Reed, Carrie and Stockmann, Chris and Arnold, Sandra R. and Ampofo, Krow K. and Anderson, Evan J. and Bramley, Anna M. and Wunderink, Richard G. and McCullers, Jonathan A. and Pavia, Andrew T. and Jain, Seema and Edwards, Kathryn M.},
  date = {2016-10},
  journaltitle = {Pediatrics},
  volume = {138},
  number = {4},
  eprint = {27688362},
  eprinttype = {pmid},
  issn = {1098-4275},
  doi = {10.1542/peds.2016-1019},
  abstract = {BACKGROUND: Substantial morbidity and excessive care variation are seen with pediatric pneumonia. Accurate risk-stratification tools to guide clinical decision-making are needed. METHODS: We developed risk models to predict severe pneumonia outcomes in children ({$<$}18 years) by using data from the Etiology of Pneumonia in the Community Study, a prospective study of community-acquired pneumonia hospitalizations conducted in 3 US cities from January 2010 to June 2012. In-hospital outcomes were organized into an ordinal severity scale encompassing severe (mechanical ventilation, shock, or death), moderate (intensive care admission only), and mild (non-intensive care hospitalization) outcomes. Twenty predictors, including patient, laboratory, and radiographic characteristics at presentation, were evaluated in 3 models: a full model included all 20 predictors, a reduced model included 10 predictors based on expert consensus, and an electronic health record (EHR) model included 9 predictors typically available as structured data within comprehensive EHRs. Ordinal regression was used for model development. Predictive accuracy was estimated by using discrimination (concordance index). RESULTS: Among the 2319 included children, 21\% had a moderate or severe outcome (14\% moderate, 7\% severe). Each of the models accurately identified risk for moderate or severe pneumonia (concordance index across models 0.78-0.81). Age, vital signs, chest indrawing, and radiologic infiltrate pattern were the strongest predictors of severity. The reduced and EHR models retained most of the strongest predictors and performed as well as the full model. CONCLUSIONS: We created 3 risk models that accurately estimate risk for severe pneumonia in children. Their use holds the potential to improve care and outcomes.},
  langid = {english},
  pmcid = {PMC5051209},
  keywords = {collaboration}
}

@article{wil20wor,
  title = {Worse {{Than Death}}: {{Survey}} of {{Public Perceptions}} of {{Disability Outcomes After Hypothetical Traumatic Brain Injury}}},
  shorttitle = {Worse {{Than Death}}},
  author = {Wilson, Jo Ellen and Shinall, Myrick C. and Leath, Taylor C. and Wang, Li and Harrell, Frank E. and Wilson, Laura D. and Nordness, Mina F. and Rakhit, Shayan and de Riesthal, Michael R. and Duff, Melissa C. and Pandharipande, Pratik P. and Patel, Mayur B.},
  options = {useprefix=true},
  date = {2020-01-14},
  journaltitle = {Ann Surg},
  eprint = {31972638},
  eprinttype = {pmid},
  issn = {1528-1140},
  doi = {10.1097/SLA.0000000000003389},
  abstract = {OBJECTIVE: The aim of this study was to determine the health utility states of the most commonly used traumatic brain injury (TBI) clinical trial endpoint, the Extended Glasgow Outcome Scale (GOSE). SUMMARY BACKGROUND DATA: Health utilities represent the strength of one's preferences under conditions of uncertainty. There are insufficient data to indicate how an individual would value levels of disability after a TBI. METHODS: This was a cross-sectional web-based online convenience sampling adaptive survey. Using a standard gamble approach, participants evaluated their preferences for GOSE health states 1 year after a hypothetical TBI. The categorical GOSE was studied from vegetative state (GOSE2) to upper good recovery (GOSE8). Median (25th percentile, 75th percentile) health utility values for different GOSE states after TBI, ranging from -1 (worse than death) to 1 (full health), with 0 as reference (death). RESULTS: Of 3508 eligible participants, 3235 (92.22\%) completed the survey. Participants rated lower GOSE states as having lower utility, with some states rated as worse than death, though the relationship was nonlinear and intervals were unequal between health states. Over 75\% of participants rated a vegetative state (GOSE2, absence of awareness and bedridden) and about 50\% rated lower severe disability (GOSE3, housebound needing all-day assistance) as conditions worse than death. CONCLUSIONS: In the largest investigation of public perceptions about post-TBI disability, we demonstrate unequally rated health states, with some states perceived as worse than death. Although limited by selection bias, these results may guide future comparative-effectiveness research and shared medical decision-making after neurologic injury.},
  langid = {english},
  keywords = {collaboration}
}

@article{wil21cos,
  title = {Costs and Staffing Resource Requirements for Adaptive Clinical Trials: Quantitative and Qualitative Results from the {{Costing Adaptive Trials}} Project},
  shorttitle = {Costs and Staffing Resource Requirements for Adaptive Clinical Trials},
  author = {Wilson, Nina and Biggs, Katie and Bowden, Sarah and Brown, Julia and Dimairo, Munyaradzi and Flight, Laura and Hall, Jamie and Hockaday, Anna and Jaki, Thomas and Lowe, Rachel and Murphy, Caroline and Pallmann, Philip and Pilling, Mark A. and Snowdon, Claire and Sydes, Matthew R. and Villar, Sofía S. and Weir, Christopher J. and Welburn, Jessica and Yap, Christina and Maier, Rebecca and Hancock, Helen and Wason, James M. S.},
  date = {2021-10-26},
  journaltitle = {BMC Medicine},
  volume = {19},
  number = {1},
  pages = {251},
  issn = {1741-7015},
  doi = {10.1186/s12916-021-02124-z},
  url = {https://doi.org/10.1186/s12916-021-02124-z},
  urldate = {2021-10-26},
  abstract = {Adaptive designs offer great promise in improving the efficiency and patient-benefit of clinical trials. An important barrier to further increased use is a lack of understanding about which additional resources are required to conduct a high-quality adaptive clinical trial, compared to a traditional fixed design.},
  keywords = {adaptive,cost,efficiency,rct}
}

@article{wil79mea,
  title = {Measuring the Effectiveness of Perinatal Medical Care},
  author = {Williams, R. L.},
  date = {1979},
  journaltitle = {Med Care},
  volume = {17},
  pages = {95--109},
  citeulike-article-id = {13265049},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  note = {observed vs. expected from logistic model (?)}
}

@article{wil86psy,
  title = {Psychosocial and Physical Predictors of Anginal Pain Relief with Medical Management},
  author = {Williams, R. B. and Haney, T. L. and McKinnis, R. A. and Harrell, F. E. and Lee, K. L. and Pryor, D. B. and Califf, R. M. and Kong, Y. and Rosati, R. A. and Blumenthal, J. A.},
  date = {1986},
  journaltitle = {Psychosom Med},
  volume = {48},
  pages = {200--210},
  citeulike-article-id = {13265050},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{wil88typ,
  title = {Type {{A}} Behavior and Angiographically Documented Coronary Atherosclerosis in a Sample of 2,289 Patients},
  author = {Williams RB, J. C. and Haney, T. L. and Harrell, F. E. and Blumenthal, J. A. and Pryor, D. B. and Peterson, B.},
  date = {1988},
  journaltitle = {Psychosom Med},
  volume = {50},
  pages = {139--152},
  citeulike-article-id = {13265051},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{wil92com,
  title = {Comparing In-Patient Classification Systems: {{A}} Problem of Non-Nested Regression Models},
  author = {Willan, Andrew R. and Ross, William and MacKenzie, Thomas A.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1321--1331},
  citeulike-article-id = {13265052},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {maximum-likelihood,nested-models,predictive-accuracy}
}

@article{wil97ben,
  title = {Benefit-Risk Ratios in the Assessment of the Clinical Evidence of a New Therapy},
  author = {Willan, Andrew R. and O'Brien, Bernie J. and Cook, Deborah},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {121--130},
  citeulike-article-id = {13265053},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {adverse-events,gusto,nnt,number-needed-to-treat,rct-interpretation,risk-benefit-ratio},
  note = {using ratio of number needed to treat to prevent one major outcome to number needed to treat to cause one adverse event}
}

@article{wil97pre,
  title = {Prevalence of Coronary Heart Disease Risk Factors among Rural Blacks: {{A}} Community-Based Study},
  author = {Willems, James P. and Saunders, J. Terry and Hunt, Dawn E. and Schorling, John B.},
  date = {1997},
  journaltitle = {So Med J},
  volume = {90},
  pages = {814--820},
  citeulike-article-id = {13265119},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  note = {source reference for diabetes dataset;see also sch97tri}
}

@article{win01not,
  title = {A Note on Scaled {{Schoenfeld}} Residuals for the Proportional Hazards Model},
  author = {Winnett, Angela and Sasieni, Peter},
  date = {2001},
  journaltitle = {Biometrika},
  volume = {88},
  pages = {565--571},
  citeulike-article-id = {13265207},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {adjusted-residual,betat,cox-model,diagnostic-plot,nonproportional-hazards,scaled-schoenfeld-residuals,smoothed-residual}
}

@article{win03ite,
  title = {Iterated Residuals and Time-Varying Covariate Effects in {{Cox}} Regression},
  author = {Winnett, Angela and Sasieni, Peter},
  date = {2003},
  journaltitle = {J Roy Stat Soc B},
  volume = {65},
  pages = {473--488},
  citeulike-article-id = {13265339},
  posted-at = {2014-07-14 14:09:54},
  priority = {0},
  keywords = {intensity-models,non-ph,nonparametric-regression,nonproportional-hazards,s-software,schoenfeld-residuals,smoothing,time-varying-coefficients,using-scaled-schoenfeld-residuals-to-iteratively-model-non-ph-effects}
}

@article{win07med,
  title = {Medicine Residents' Understanding of the Biostatistics and Results in the Medical Literature},
  author = {Windish, Donna M. and Huot, Stephen J. and Green, Michael L.},
  date = {2007},
  journaltitle = {JAMA},
  volume = {298},
  pages = {1010--1022},
  citeulike-article-id = {13265613},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {teaching-mds},
  note = {poor state of knowledge about biostat; nice quiz with answers}
}

@article{win90asy,
  title = {The Asymptotic Distribution of the Sum of Weighted Squared Residuals in Binary Choice Models},
  author = {Windmeijer, F. A. G.},
  date = {1990},
  journaltitle = {Statistica Neerlandica},
  volume = {48},
  pages = {271--283},
  citeulike-article-id = {13265055},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {gof,goodness-of-fit,logistic-model,squared-residual-test}
}

@article{wit00dat,
  title = {Data Safety Monitoring Boards: {{A}} Brief Introduction (with Discussion)},
  author = {Wittes, Janet},
  date = {2000},
  journaltitle = {Biopharm Rep ASA},
  volume = {8},
  number = {1},
  pages = {1--11},
  citeulike-article-id = {13265131},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {apprentice-statistician,blinding,dsmb,rct,safety}
}

@article{wit08tes,
  title = {Testing Significance of Features by Lassoed Principal Components},
  author = {Witten, Daniela M. and Tibshirani, Robert},
  date = {2008},
  journaltitle = {Ann Appl Stat},
  volume = {2},
  number = {3},
  pages = {986--1012},
  citeulike-article-id = {13265709},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  note = {reduction in false discovery rates over using a vector of t-statistics;borrowing strength across genes;"one would not expect a single gene to be associated with the outcome, since, in practice, many genes work together to effect a particular phenotype. LPC effectively down-weights individual genes that are associated with the outcome but that do not share an expression pattern with a larger group of genes, and instead favors large groups of genes that appear to be differentially-expressed.";regress principal components on outcome;sparse principal components}
}

@article{wit87,
  title = {The Power of the {{Mantel-Haenszel}} Test},
  author = {{Wittes}},
  date = {1987},
  journaltitle = {J Am Stat Assoc},
  volume = {82},
  pages = {1104--1109},
  citeulike-article-id = {13265056},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {logistic-model-extensions,sample-size-estimation}
}

@article{wit99int,
  title = {Internal Pilot Studies {{I}}:{{Type I}} Error Rate of the Naive t-Test},
  author = {Wittes, Janet and Schabenberger, Oliver and Zucker, David and Brittain, Erica and Proschan, Michael},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {3481--3491},
  citeulike-article-id = {13265088},
  posted-at = {2014-07-14 14:09:49},
  priority = {0},
  keywords = {extending-a-study},
  note = {ordinary t-test almost preserves type I error if final sample size is at least as large as the planned sample size}
}

@article{wol89eli,
  title = {Eliciting and Combining Subjective Judgments about Uncertainty},
  author = {Wolpert, Robert L.},
  date = {1989},
  journaltitle = {Int J Tech Assess Hlth Care},
  volume = {5},
  pages = {537--557},
  citeulike-article-id = {13265057},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {probability}
}

@article{won85hie,
  title = {The Hierarchical Logistic Regression Model for Multilevel Analysis},
  author = {Wong, G. Y. and Mason, W. M.},
  date = {1985},
  journaltitle = {J Am Stat Assoc},
  volume = {80},
  pages = {513--524},
  citeulike-article-id = {13265058},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {clustered-data,hierarchical-model,logistic-model-extensions}
}

@article{woo04are,
  title = {Are Missing Outcome Data Adequately Handled? {{A}} Review of Published Randomized Controlled Trials in Major Medical Journals},
  author = {Wood, Angela M. and White, Ian R. and Thompson, Simon G.},
  date = {2004},
  journaltitle = {Clin Trials},
  volume = {1},
  pages = {368--376},
  citeulike-article-id = {13265388},
  posted-at = {2014-07-14 14:09:55},
  priority = {0},
  keywords = {imputation,locf,missing-data},
  note = {LOCF is not to be used;nice summary table of assumptions and adequacy of 6 methods;sensitivity analysis;usually have to exclude subjects who have no response measurements;reporting missing data;missing response data inadequately handled in top medical journals;summary of distribution of fraction of missing data in articles surveyed, and the methods used;only one of 34 published trials used multiple imputation}
}

@book{woo06gen,
  title = {Generalized {{Additive Models}}: {{An Introduction}} with {{R}}},
  author = {Wood, S. N.},
  date = {2006},
  publisher = {{Chapman \& Hall/CRC}},
  location = {{Boca Raton, FL}},
  citeulike-article-id = {13265715},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  annotation = {ISBN 9781584884743}
}

@article{woo08est,
  title = {Estimation of Propensity Scores Using Generalized Additive Models},
  author = {Woo, Mi-Ja and Reiter, Jerome P. and Karr, Alan F.},
  date = {2008},
  journaltitle = {Stat Med},
  volume = {27},
  pages = {3805--3816},
  citeulike-article-id = {13265701},
  posted-at = {2014-07-14 14:10:02},
  priority = {0},
  keywords = {causal-inference,flexible-propensity-score-model,gam,generalized-additive-model,logistic-regression,matching,observational-study}
}

@article{woo20mod,
  title = {Model {{Interpretation Through Lower-Dimensional Posterior Summarization}}},
  author = {Woody, Spencer and Carvalho, Carlos M. and Murray, Jared S.},
  date = {2020-07-21},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {0},
  number = {0},
  pages = {1--9},
  publisher = {{Taylor \& Francis}},
  issn = {1061-8600},
  doi = {10.1080/10618600.2020.1796684},
  url = {https://doi.org/10.1080/10618600.2020.1796684},
  urldate = {2020-08-26},
  abstract = {Nonparametric regression models have recently surged in their power and popularity, accompanying the trend of increasing dataset size and complexity. While these models have proven their predictive ability in empirical settings, they are often difficult to interpret and do not address the underlying inferential goals of the analyst or decision maker. In this article, we propose a modular two-stage approach for creating parsimonious, interpretable summaries of complex models which allow freedom in the choice of modeling technique and the inferential target. In the first stage, a flexible model is fit which is believed to be as accurate as possible. In the second stage, lower-dimensional summaries are constructed by projecting draws from the distribution onto simpler structures. These summaries naturally come with valid Bayesian uncertainty estimates. Further, since we use the data only once to move from prior to posterior, these uncertainty estimates remain valid across multiple summaries and after iteratively refining a summary. We apply our method and demonstrate its strengths across a range of simulated and real datasets. The methods we present here are implemented in an R package available at github.com/spencerwoody/possum. Supplementary materials for this article are available online.},
  keywords = {bayes,model-approximation},
  annotation = {\_eprint: https://doi.org/10.1080/10618600.2020.1796684}
}

@article{wri92adj,
  title = {Adjusted {{P-values}} for Simultaneous Inference},
  author = {Wright, S. Paul},
  date = {1992},
  journaltitle = {Biometrics},
  volume = {48},
  pages = {1005--1013},
  citeulike-article-id = {13265059},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {adjustments,multiple-comparisons,p-values}
}

@article{wu01adj,
  title = {Adjusting for Drop-out in Clinical Trials with Repeated Measures: Design and Analysis Issues},
  author = {Wu, Margaret C. and Albert, Paul S. and Wu, Bechien U.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {93--108},
  citeulike-article-id = {13265175},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {informative-dropout,informative-missing,repeated-measurements,serial-data},
  note = {reducing bias by using as covariables the dropout time and the sum of all dropout times greater than that of the current patient;see wu99use;dropout allowed to depend on observed response}
}

@article{wu02est,
  title = {Estimates of Future Physical Functioning by Seriously Ill Hospitalized Patients, Their Families, and Their Physicians},
  author = {Wu, Albert W. and Young, Y. and Dawson, Neal V. and Brant, L. and Galanos, Anthony N. and Broste, Steven S. and Landefeld, Seth C. and Harrell, Frank E. and Lynn, Joann},
  date = {2002},
  journaltitle = {J Am Geriatric Soc},
  volume = {50},
  pages = {230--237},
  citeulike-article-id = {13265307},
  posted-at = {2014-07-14 14:09:53},
  priority = {0}
}

@article{wu07con,
  title = {Controlling Variable Selection by the Addition of Pseudovariables},
  author = {Wu, Yujun and Boos, Dennis D. and Stefanski, Leonard A.},
  date = {2007},
  journaltitle = {J Am Stat Assoc},
  volume = {102},
  pages = {235--243},
  citeulike-article-id = {13265559},
  posted-at = {2014-07-14 14:09:59},
  priority = {0},
  keywords = {bootstrap,false-selection-rate,forward-selection,model-error,stepwise,subset-selection,variable-selection},
  note = {add known number of pseudovariables to the real dataset, run variable selection, monitor proportion of pseudovariables falsely selected}
}

@article{wu17fpc,
  title = {{{FPCA-based}} Method to Select Optimal Sampling Schedules That Capture between-Subject Variability in Longitudinal Studies},
  author = {Wu, Meihua and Diez-Roux, Ana and Raghunathan, Trivellore E. and Sánchez, Brisa N.},
  date = {2017-05},
  journaltitle = {Biometrics},
  issn = {0006341X},
  doi = {10.1111/biom.12714},
  url = {http://dx.doi.org/10.1111/biom.12714},
  citeulike-article-id = {14353678},
  citeulike-linkout-0 = {http://dx.doi.org/10.1111/biom.12714},
  day = {08},
  posted-at = {2017-05-09 03:07:30},
  priority = {2},
  keywords = {longitudinal-data,sampling-design,serial-data}
}

@article{wu19opt,
  title = {Optimizing Interim Analysis Timing for {{Bayesian}} Adaptive Commensurate Designs},
  author = {Wu, Xiao and Xu, Yi and Carlin, Bradley P.},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8414},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8414},
  urldate = {2019-12-06},
  abstract = {In developing products for rare diseases, statistical challenges arise due to the limited number of patients available for participation in drug trials and other clinical research. Bayesian adaptive clinical trial designs offer the possibility of increased statistical efficiency, reduced development cost and ethical hazard prevention via their incorporation of evidence from external sources (historical data, expert opinions, and real-world evidence), and flexibility in the specification of interim looks. In this paper, we propose a novel Bayesian adaptive commensurate design that borrows adaptively from historical information and also uses a particular payoff function to optimize the timing of the study's interim analysis. The trial payoff is a function of how many samples can be saved via early stopping and the probability of making correct early decisions for either futility or efficacy. We calibrate our Bayesian algorithm to have acceptable long-run frequentist properties (Type I error and power) via simulation at the design stage. We illustrate our approach using a pediatric trial design setting testing the effect of a new drug for a rare genetic disease. The optimIA R package available at https://github.com/wxwx1993/Bayesian\_IA\_Timing provides an easy-to-use implementation of our approach.},
  langid = {english},
  keywords = {experimental-design,monitoring,rct,sequential}
}

@article{wu79use,
  title = {On the Use of Repeated Measurements in Regression Analysis with Dichotomous Responses},
  author = {Wu, M. and Ware, J. H.},
  date = {1979},
  journaltitle = {Biometrics},
  volume = {35},
  pages = {513--521},
  citeulike-article-id = {13265060},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{wu86jac,
  title = {Jackknife, Bootstrap and Other Resampling Methods in Regression Analysis},
  author = {Wu, C. F. J.},
  date = {1986},
  journaltitle = {Ann Stat},
  volume = {14},
  number = {4},
  pages = {1261--1350},
  citeulike-article-id = {13265061},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {heteroscedasticity,leave-out-many-jackknife}
}

@article{wu89,
  title = {Estimation and Comparison of Changes in the Presence of Informative Right Censoring: Conditional Linear Model},
  author = {Wu MC, Bailey K. R.},
  date = {1989},
  journaltitle = {Biometrics},
  volume = {45},
  pages = {939--955},
  citeulike-article-id = {13265062},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {general,study-design-and-stopping-rules,survival-analysis-regression}
}

@article{wu95pre,
  title = {Predicting Future Functional Status for Seriously Ill Hospitalized Adults: {{The SUPPORT}} Prognostic Model},
  author = {Wu, A. W. and Damiano, A. M. and Lynn, J. and Alzola, C. and Teno, J. and Landefeld, C. S. and {Desbiens} and Mayer-Oakes, A. and Harrell, F. E. and Knaus, W. A.},
  date = {1995},
  journaltitle = {Ann Int Med},
  volume = {122},
  pages = {342--350},
  citeulike-article-id = {13265063},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{wu99use,
  title = {Use of Summary Measures to Adjust for Informative Missingness in Repeated Measures Data with Random Effects},
  author = {Wu, Margaret C. and Follmann, Dean A.},
  date = {1999},
  journaltitle = {Biometrics},
  volume = {55},
  pages = {75--84},
  citeulike-article-id = {13265171},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {informative-missingness,non-random-dropout,repeated-measurements,serial-data},
  note = {summary measures of dropout times used as covariables}
}

@article{wur21reg,
  title = {Regularized {{Ordinal Regression}} and the {{ordinalNet R Package}}},
  author = {Wurm, Michael J. and Rathouz, Paul J. and Hanlon, Bret M.},
  date = {2021-09-08},
  journaltitle = {Journal of Statistical Software},
  volume = {99},
  number = {1},
  pages = {1--42},
  issn = {1548-7660},
  doi = {10.18637/jss.v099.i06},
  url = {https://www.jstatsoft.org/index.php/jss/article/view/v099i06},
  urldate = {2021-09-08},
  abstract = {Regularization techniques such as the lasso (Tibshirani 1996) and elastic net (Zou and Hastie 2005) can be used to improve regression model coefficient estimation and prediction accuracy, as well as to perform variable selection. Ordinal regression models are widely used in applications where the use of regularization could be beneficial; however, these models are not included in many popular software packages for regularized regression. We propose a coordinate descent algorithm to fit a broad class of ordinal regression models with an elastic net penalty. Furthermore, we demonstrate that each model in this class generalizes to a more flexible form, that can be used to model either ordered or unordered categorical response data. We call this the elementwise link multinomial-ordinal class, and it includes widely used models such as multinomial logistic regression (which also has an ordinal form) and ordinal logistic regression (which also has an unordered multinomial form). We introduce an elastic net penalty class that applies to either model form, and additionally, this penalty can be used to shrink a non-ordinal model toward its ordinal counterpart. Finally, we introduce the R package ordinalNet, which implements the algorithm for this model class.},
  issue = {1},
  langid = {english},
  keywords = {lasso,ordinal,partial-proportional-odds,penalization,penalized-maximum-likelihood,pmle,po}
}

@article{xia10boo,
  title = {Bootstrap-Based Methods for Estimating Standard Errors in {{Cox}}'s Regression Analyses of Clustered Event Times},
  author = {Xiao, Yongling and Abrahamowicz, Michal},
  date = {2010},
  journaltitle = {Stat Med},
  volume = {29},
  pages = {915--923},
  citeulike-article-id = {13265811},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {cluster-bootstrap,clustered-data,correlated-data,frailty,repeated-measurements,robust-variance-estimation,survival-analysis,two-stage-bootstrap},
  note = {two-step bootstrap overestimated variance for individual-level covariates}
}

@article{xia19non,
  title = {Nonparametric Group Sequential Methods for Recurrent and Terminal Events from Multiple Follow-up Windows},
  author = {Xia, Meng and Murray, Susan and Tayob, Nabihah},
  date = {2019-11-15},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {0277-6715},
  doi = {10.1002/sim.8389},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8389},
  urldate = {2019-11-18},
  abstract = {Few methods are currently available for group sequential analysis of recurrent events data subject to a terminal event in the clinical trial setting. This research helps fill this gap by developing a completely nonparametric group sequential monitoring procedure for use with the two-sample Tayob and Murray statistic. Advantages of the Tayob and Murray statistic include high power to detect treatment differences when there is correlation between recurrent event times or between recurrent and terminal events in an individual. This statistic does not suffer bias from dependent censoring, regardless of the correlation between event times in an individual. This manuscript briefly reviews the Tayob and Murray statistic, develops and describes how to use methods for its group sequential analysis, and through simulation, compares its operating characteristics with those of Cook and Lawless, which is currently in use as the only available nonparametric method for group sequential analysis of recurrent event data. The merits of our proposed approach are most clearly demonstrated when gap times between recurrent events are correlated; when gap times between events are independent, the Cook and Lawless method is difficult to beat. Simulations demonstrate that as correlation between recurrent event times grows, the reduction in power using the Cook and Lawless approach is substantial when compared to our method. Finally, we use our method to analyze recurrent acute exacerbation outcomes from the azithromycin in chronic obstructive pulmonary disease trial.},
  keywords = {multiple-endpoints,recurrent-events,sequential-monitoring,survival}
}

@article{xia20reg,
  title = {Regression Analysis of Recurrent-Event-Free Time from Multiple Follow-up Windows},
  author = {Xia, Meng and Murray, Susan and Tayob, Nabihah},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {39},
  number = {1},
  pages = {1--15},
  issn = {1097-0258},
  doi = {10.1002/sim.8385},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8385},
  urldate = {2019-12-08},
  abstract = {This research develops multivariable restricted time models appropriate for analysis of recurrent events data, where data is repurposed into censored longitudinal time-to-first-event outcomes in τ-length follow-up windows. We develop two approaches for addressing the censored nature of the outcomes: a pseudo-observation (PO) approach and a multiple-imputation (MI) approach. Each of these approaches allows for complete data methods, such as generalized estimating equations, to be used for the analysis of the newly constructed correlated outcomes. Through simulation, this manuscript assesses the performance of the proposed PO and MI methods. Both PO and MI approaches show attractive results with either correlated or independent gap times in an individual. We also demonstrate how to apply the proposed methods in the data from azithromycin in Chronic Obstructive Pulmonary Disease Trial.},
  langid = {english},
  keywords = {multiple-endpoints,pseudo-observations,recurrent-events}
}

@article{xie09con,
  title = {Confidence Intervals for Population Ranks in the Presence of Ties and near Ties},
  author = {Xie, Minge and Singh, Kesar and Zhang, Cun-Hui},
  date = {2009},
  journaltitle = {J Am Stat Assoc},
  volume = {104},
  number = {486},
  pages = {775--787},
  citeulike-article-id = {13265791},
  posted-at = {2014-07-14 14:10:04},
  priority = {0},
  keywords = {bootstrap-ranks,nonstandard-bootstrap-inference,rank-inference,ranking,ranks},
  note = {slow convergence rate;smooth ranks in the presence of near ties;rank inference for fixed effects risk adjustment models}
}

@article{xio10som,
  title = {Some Notes on the Nonnegative Garrote},
  author = {Xiong, Shifeng},
  date = {2010},
  journaltitle = {Technometrics},
  volume = {52},
  number = {3},
  pages = {349--361},
  citeulike-article-id = {13265841},
  posted-at = {2014-07-14 14:10:05},
  priority = {0},
  keywords = {degrees-of-freedom,multicollinearity,nonnegative-garrotte,penalization,shrinkage,variable-selection},
  note = {"... to select tuning parameters, it may be unnecessary to optimize a model selectin criterion repeatedly";natural selection of penalty function}
}

@article{xu11bay,
  title = {Bayesian Methods to Overcome the Winner's Curse in Genetic Studies},
  author = {Xu, Radu V. and Sun, Lei},
  date = {2011},
  journaltitle = {Ann Appl Stat},
  volume = {5},
  number = {1},
  pages = {201--231},
  doi = {10.1214/10-AOAS373},
  url = {http://dx.doi.org/10.1214/10-AOAS373},
  citeulike-article-id = {13265892},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/10-AOAS373},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {bayesian-model-averaging,gene-association-study,hierarchical-bayes-model,multiplicity,shrinkage,spike-and-slab-prior,winners-curse}
}

@article{xu12uni,
  title = {Unique {{DNA}} Methylome Profiles in {{CpG}} Island Methylator Phenotype Colon Cancers.},
  author = {Xu, Yaomin and Hu, Bo and Choi, Ae-Jin J. and Gopalan, Banu and Lee, Byron H. and Kalady, Matthew F. and Church, James M. and Ting, Angela H.},
  date = {2012-02},
  journaltitle = {Genome research},
  volume = {22},
  number = {2},
  eprint = {21990380},
  eprinttype = {pmid},
  pages = {283--291},
  publisher = {Cold Spring Harbor Laboratory Press},
  issn = {1549-5469},
  doi = {10.1101/gr.122788.111},
  url = {http://dx.doi.org/10.1101/gr.122788.111},
  abstract = {A subset of colorectal cancers was postulated to have the CpG island methylator phenotype (CIMP), a higher propensity for CpG island DNA methylation. The validity of CIMP, its molecular basis, and its prognostic value remain highly controversial. Using MBD-isolated genome sequencing, we mapped and compared genome-wide DNA methylation profiles of normal, non-CIMP, and CIMP colon specimens. Multidimensional scaling analysis revealed that each specimen could be clearly classified as normal, non-CIMP, and CIMP, thus signifying that these three groups have distinctly different global methylation patterns. We discovered 3780 sites in various genomic contexts that were hypermethylated in both non-CIMP and CIMP colon cancers when compared with normal colon. An additional 2026 sites were found to be hypermethylated in CIMP tumors only; and importantly, 80\% of these sites were located in CpG islands. These data demonstrate on a genome-wide level that the additional hypermethylation seen in CIMP tumors occurs almost exclusively at CpG islands and support definitively that these tumors were appropriately named. When these sites were examined more closely, we found that 25\% were adjacent to sites that were also hypermethylated in non-CIMP tumors. Thus, CIMP is also characterized by more extensive methylation of sites that are already prone to be hypermethylated in colon cancer. These observations indicate that CIMP tumors have specific defects in controlling both DNA methylation seeding and spreading and serve as an important first step in delineating molecular mechanisms that control these processes.},
  citeulike-article-id = {9896819},
  citeulike-linkout-0 = {http://dx.doi.org/10.1101/gr.122788.111},
  citeulike-linkout-1 = {http://genome.cshlp.org/content/22/2/283.abstract},
  citeulike-linkout-2 = {http://genome.cshlp.org/content/22/2/283.full.pdf},
  citeulike-linkout-3 = {http://genome.cshlp.org/cgi/content/abstract/22/2/283},
  citeulike-linkout-4 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3266035/},
  citeulike-linkout-5 = {http://view.ncbi.nlm.nih.gov/pubmed/21990380},
  citeulike-linkout-6 = {http://www.hubmed.org/display.cgi?uids=21990380},
  day = {01},
  pmcid = {PMC3266035},
  posted-at = {2016-05-11 21:21:18},
  priority = {2},
  keywords = {ctsafac}
}

@article{xu15sno,
  title = {Snowball: Resampling Combined with Distance-Based Regression to Discover Transcriptional Consequences of a Driver Mutation.},
  author = {Xu, Yaomin and Guo, Xingyi and Sun, Jiayang and Zhao, Zhongming},
  date = {2015-01},
  journaltitle = {Bioinformatics},
  volume = {31},
  number = {1},
  eprint = {25192743},
  eprinttype = {pmid},
  pages = {84--93},
  publisher = {Oxford University Press},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btu603},
  url = {http://dx.doi.org/10.1093/bioinformatics/btu603},
  abstract = {Large-scale cancer genomic studies, such as The Cancer Genome Atlas (TCGA), have profiled multidimensional genomic data, including mutation and expression profiles on a variety of cancer cell types, to uncover the molecular mechanism of cancerogenesis. More than a hundred driver mutations have been characterized that confer the advantage of cell growth. However, how driver mutations regulate the transcriptome to affect cellular functions remains largely unexplored. Differential analysis of gene expression relative to a driver mutation on patient samples could provide us with new insights in understanding driver mutation dysregulation in tumor genome and developing personalized treatment strategies. Here, we introduce the Snowball approach as a highly sensitive statistical analysis method to identify transcriptional signatures that are affected by a recurrent driver mutation. Snowball utilizes a resampling-based approach and combines a distance-based regression framework to assign a robust ranking index of genes based on their aggregated association with the presence of the mutation, and further selects the top significant genes for downstream data analyses or experiments. In our application of the Snowball approach to both synthesized and TCGA data, we demonstrated that it outperforms the standard methods and provides more accurate inferences to the functional effects and transcriptional dysregulation of driver mutations. R package and source code are available from CRAN at http://cran.r-project.org/web/packages/DESnowball, and also available at http://bioinfo.mc.vanderbilt.edu/DESnowball/.},
  citeulike-article-id = {13465595},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/bioinformatics/btu603},
  citeulike-linkout-1 = {http://bioinformatics.oxfordjournals.org/content/31/1/84.abstract},
  citeulike-linkout-2 = {http://bioinformatics.oxfordjournals.org/content/31/1/84.full.pdf},
  citeulike-linkout-3 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4271146/},
  citeulike-linkout-4 = {http://view.ncbi.nlm.nih.gov/pubmed/25192743},
  citeulike-linkout-5 = {http://www.hubmed.org/display.cgi?uids=25192743},
  day = {1},
  pmcid = {PMC4271146},
  posted-at = {2016-05-11 21:20:34},
  priority = {2},
  keywords = {ctsafac}
}

@article{xu17sem,
  title = {Semiparametric Estimation of Time-Varying Intervention Effects Using Recurrent Event Data},
  author = {Xu, Jiajun and Lam, K. F. and Chen, Feng and Milligan, Paul and Cheung, Yin B.},
  date = {2017},
  journaltitle = {Stat Med},
  issn = {02776715},
  doi = {10.1002/sim.7319},
  url = {http://dx.doi.org/10.1002/sim.7319},
  citeulike-article-id = {14349814},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.7319},
  posted-at = {2017-05-03 14:28:33},
  priority = {2},
  keywords = {observational-study,recurrent-events,tdc}
}

@article{yad20com,
  title = {Comparison of Statistical Methods for Recurrent Event Analysis Using Pediatrics Asthma Data},
  author = {Yadav, C. P. and Lodha, Rakesh and Kabra, S. K. and Sreenivas, V. and Sinha, Abhinav and Khan, M. A. and Pandey, R. M.},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {n/a},
  number = {n/a},
  issn = {1539-1612},
  doi = {10.1002/pst.2032},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2032},
  urldate = {2020-06-04},
  abstract = {When the same type of event is experienced by a subject more than once it is called recurrent event, which possess two important characteristics, namely “within-subject correlation” and “time-varying covariate.” As a result, the traditional statistical methods do not work well on recurrent event data. Over the past few decades, many alternatives methods have been proposed for the analysis of recurrent event data. In this article, the six most prominent methods for recurrent event analysis have been compared on pediatric asthma data. Three variance corrected models (viz “Anderson and Gill [AG] model,” “Prentice, William, and Peterson-Counting Process [PWP-CP] model,” and “Prentice, William, and Peterson-Gap Time [PWP-GT] model”) and three corresponding frailty variants (AG-frailty, PWP-CP-frailty, and PWP-GT-frailty) were compared using three mathematical criterion (AIC, BIC, and log-likelihood) and one graphical criteria (Cox-Snell goodness of fit, visual test). All model comparison indices showed the PWP-GT model as the most appropriate model on asthma data over other models. By using PWP-GT model, seven predictors of asthma exacerbation (viz “abdominal pain at previous visit,” “Z5 (\%) at previous visit,” “diagnosis of asthma at previous visit,” “calendar month of exacerbation,” “history of maternal asthma,” “monthly per capita income,” and “emotional stress”) were identified. The PWP-GT model was identified as the most appropriate model over other models on pediatrics asthma data.},
  langid = {english},
  keywords = {recurrent-events,survival-analysis},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2032}
}

@article{yad20coma,
  title = {Comparison of Statistical Methods for Recurrent Event Analysis Using Pediatrics Asthma Data},
  author = {Yadav, C. P. and Lodha, Rakesh and Kabra, S. K. and Sreenivas, V. and Sinha, Abhinav and Khan, M. A. and Pandey, R. M.},
  date = {2020},
  journaltitle = {Pharmaceutical Statistics},
  volume = {19},
  number = {6},
  pages = {803--813},
  issn = {1539-1612},
  doi = {10.1002/pst.2032},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2032},
  urldate = {2020-12-08},
  abstract = {When the same type of event is experienced by a subject more than once it is called recurrent event, which possess two important characteristics, namely “within-subject correlation” and “time-varying covariate.” As a result, the traditional statistical methods do not work well on recurrent event data. Over the past few decades, many alternatives methods have been proposed for the analysis of recurrent event data. In this article, the six most prominent methods for recurrent event analysis have been compared on pediatric asthma data. Three variance corrected models (viz “Anderson and Gill [AG] model,” “Prentice, William, and Peterson-Counting Process [PWP-CP] model,” and “Prentice, William, and Peterson-Gap Time [PWP-GT] model”) and three corresponding frailty variants (AG-frailty, PWP-CP-frailty, and PWP-GT-frailty) were compared using three mathematical criterion (AIC, BIC, and log-likelihood) and one graphical criteria (Cox-Snell goodness of fit, visual test). All model comparison indices showed the PWP-GT model as the most appropriate model on asthma data over other models. By using PWP-GT model, seven predictors of asthma exacerbation (viz “abdominal pain at previous visit,” “Z5 (\%) at previous visit,” “diagnosis of asthma at previous visit,” “calendar month of exacerbation,” “history of maternal asthma,” “monthly per capita income,” and “emotional stress”) were identified. The PWP-GT model was identified as the most appropriate model over other models on pediatrics asthma data.},
  langid = {english},
  keywords = {recurrent-events,survival},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/pst.2032}
}

@article{yam22mul,
  title = {Multiple Imputation for Longitudinal Data Using {{Bayesian}} Lasso Imputation Model},
  author = {Yamaguchi, Yusuke and Yoshida, Satoshi and Misumi, Toshihiro and Maruo, Kazushi},
  date = {2022},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9315},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9315},
  urldate = {2022-01-22},
  abstract = {Multiple imputation is a promising approach to handle missing data and is widely used in analysis of longitudinal clinical studies. A key consideration in the implementation of multiple imputation is to obtain accurate imputed values by specifying an imputation model that incorporates auxiliary variables potentially associated with missing variables. The use of informative auxiliary variables is known to be beneficial to make the missing at random assumption more plausible and help to reduce uncertainty of the imputations; however, it is not straightforward to pre-specify them in many cases. We propose a data-driven specification of the imputation model using Bayesian lasso in the context of longitudinal clinical study, and develop a built-in function of the Bayesian lasso imputation model which is performed within the framework of multiple imputation using chained equations. A simulation study suggested that the Bayesian lasso imputation model worked well in a variety of longitudinal study settings, providing unbiased treatment effect estimates with well-controlled type I error rates and coverage probabilities of the confidence interval; in contrast, ignorance of the informative auxiliary variables led to serious bias and inflation of type I error rate. Moreover, the Bayesian lasso imputation model offered higher statistical powers compared with conventional imputation methods. In our simulation study, the gains in statistical power were remarkable when the sample size was small relative to the number of auxiliary variables. An illustration through a real example also suggested that the Bayesian lasso imputation model could give smaller standard errors of the treatment effect estimate.},
  langid = {english},
  keywords = {bayes,imputatation,lasso,longitudinal,multiple-imputation,serial},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9315}
}

@book{yam91eve,
  title = {Event {{History Analysis}}},
  author = {Yamaguchi, K.},
  date = {1991},
  publisher = {{Sage}},
  location = {{Newbury Park}},
  citeulike-article-id = {13265064},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{yam96par,
  title = {Parametric Event Sequence Analysis: {{An}} Application to an Analysis of Gender and Racial/Ethnic Differences in Patterns of Drug-Use Progression},
  author = {Yamaguchi, Kazuo and Kandel, Denise B.},
  date = {1996},
  journaltitle = {J Am Stat Assoc},
  volume = {91},
  pages = {1388--1399},
  citeulike-article-id = {13265065},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {event-history-analysis,log-linear-models,multiple-events,repeated-events,sequences-of-events}
}

@article{yam99inv,
  title = {Investigating Centre Effects in a Multi-Centre Clinical Trial of Superficial Bladder Cancer},
  author = {Yamaguchi, Takuhiro and Ohashi, Yasuo},
  date = {1999},
  journaltitle = {Stat Med},
  volume = {18},
  pages = {1961--1971},
  citeulike-article-id = {13265066},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {cox-random-effects-model,mixed-effects,multi-center-rct,multi-site-rct,penalized-partial-likelihood,treatment-by-center-interaction}
}

@article{yan03pro,
  title = {Proteomic {{Patterns}} of {{Tumor Subsets}} in {{Non-small-cell Lung Cancer}}},
  author = {Yanagisawa, K. and Shyr, Y. and Xu, B. J. and Massion, P. P. and Larsen, P. H. and Roberts, J. R. and Edgerton, M. and Gonzalez, A. and Nadaf, S. and Moore, J. H. and Caprioli, R. M. and Carbone, D. P.},
  date = {2003},
  journaltitle = {Lancet},
  volume = {362},
  pages = {433--439},
  citeulike-article-id = {13265501},
  posted-at = {2014-07-14 14:09:58},
  priority = {0}
}

@article{yan10com,
  title = {Common {{SNPs}} Explain a Large Proportion of the Heritability for Human Height},
  author = {Yang, Jian and Benyamin, Beben and McEvoy, Brian P. and Gordon, Scott and Henders, Anjali K. and {Others}},
  date = {2010},
  journaltitle = {Nat Gen},
  volume = {42},
  number = {7},
  pages = {565--569},
  abstract = {SNPs discovered by genome-wide association studies (GWASs) account for only a small fraction of the genetic variation of complex traits in human populations. Where is the remaining heritability? We estimated the proportion of variance for human height explained by 294,831 SNPs genotyped on 3,925 unrelated individuals using a linear model analysis, and validated the estimation method with simulations based on the observed genotype data. We show that 45\% of variance can be explained by considering all SNPs simultaneously. Thus, most of the heritability is not missing but has not previously been detected because the individual effects are too small to pass stringent significance tests. We provide evidence that the remaining heritability is due to incomplete linkage disequilibrium between causal variants and genotyped SNPs, exacerbated by causal variants having lower minor allele frequency than the SNPs explored to date.},
  citeulike-article-id = {13265750},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  note = {see gol09com}
}

@article{yan15ind,
  title = {Independence Test for High Dimensional Data Based on Regularized Canonical Correlation Coefficients},
  author = {Yang, Yanrong and Pan, Guangming},
  date = {2015-04},
  journaltitle = {Ann Stat},
  volume = {43},
  number = {2},
  pages = {467--500},
  issn = {0090-5364},
  doi = {10.1214/14-aos1284},
  url = {http://dx.doi.org/10.1214/14-aos1284},
  citeulike-article-id = {13660323},
  citeulike-linkout-0 = {http://dx.doi.org/10.1214/14-aos1284},
  posted-at = {2015-06-29 20:45:58},
  priority = {2},
  keywords = {canonical-correlation,canonical-variates,penalization}
}

@article{yan19non,
  title = {Nonparametric {{Estimation}} of {{Copula Regression Models With Discrete Outcomes}}},
  author = {Yang, Lu and Frees, Edward W. and Zhang, Zhengjun},
  date = {2019-01-15},
  journaltitle = {Journal of the American Statistical Association},
  volume = {0},
  number = {0},
  pages = {1--25},
  issn = {0162-1459},
  doi = {10.1080/01621459.2018.1546586},
  url = {https://doi.org/10.1080/01621459.2018.1546586},
  urldate = {2019-04-14},
  abstract = {Multivariate discrete outcomes are common in a wide range of areas including insurance, finance, and biology. When the interplay between outcomes is significant, quantifying dependencies among interrelated variables is of great importance. Due to their ability to accommodate dependence flexibly, copulas are being applied increasingly. Yet, the application of copulas on discrete data is still in its infancy; one of the biggest barriers is the nonuniqueness of copulas, calling into question model interpretations and predictions. In this article, we study copula estimation with discrete outcomes in a regression context. As the marginal distributions vary with covariates, inclusion of continuous regressors expands the region of support for consistent estimation of copulas. Because some properties of continuous outcomes do not carry over to discrete outcomes, specification of a copula model has been a problem. We propose a nonparametric estimator of copulas to identify the “hidden” dependence structure for discrete outcomes and develop its asymptotic properties. The proposed nonparametric estimator can also serve as a diagnostic tool for selecting a parametric form for copulas. In the simulation study, we explore the performance of the proposed estimator under different scenarios and provide guidance on when the choice of copulas is important. The performance of the estimator improves as discreteness diminishes. A practical bandwidth selector is also proposed. An empirical analysis examines a dataset from the Local Government Property Insurance Fund (LGPIF) in the state of Wisconsin. We apply the nonparametric estimator to model the dependence among claim frequencies from different types of insurance coverage. Supplementary materials for this article are available online.},
  keywords = {copula,multiple-endpoints}
}

@article{yan21eve,
  title = {Event-Specific Win Ratios for Inference with Terminal and Non-Terminal Events},
  author = {Yang, Song and Troendle, James and Pak, Daewoo and Leifer, Eric},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9266},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9266},
  urldate = {2021-11-24},
  abstract = {For semi-competing risks data involving a non-terminal event and a terminal event we derive the asymptotic distributions of the event-specific win ratios under proportional hazards (PH) assumptions for the relevant cause-specific hazard functions of the non-terminal and terminal event, respectively. The win ratios converge to the respective hazard ratios under the PH assumptions and therefore are censoring-free, whether or not the censoring distributions in the two treatment arms are the same. With the asymptotic bivariate normal distributions of the win ratios, confidence intervals and testing procedures are obtained. Through extensive simulation studies and data analysis, we identified proper transformations of the win ratios that yield good control of the type one error rate for various testing procedures while maintaining competitive power. The confidence intervals also have good coverage probabilities. Furthermore, a test for the PH assumptions and a test of equal hazard ratios are developed. The new procedures are illustrated in the clinical trial Aldosterone Antagonist Therapy for Adults With Heart Failure and Preserved Systolic Function, which evaluated the effects of spironolactone in patients with heart failure and a preserved left ventricular ejection fraction.},
  langid = {english},
  keywords = {competing-risks,multiple-endpoints,rct,semicompeting-risks-data,win-ratio},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9266}
}

@article{yao98ana,
  title = {Analysis of Incomplete Repeated Measurements with Dependent Censoring Times},
  author = {Yao, Q. and Wei, L. J. and Hogan, J. W.},
  date = {1998},
  journaltitle = {Biometrika},
  volume = {85},
  pages = {139--149},
  citeulike-article-id = {13265067},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {generalization-of-wilcoxon-test,informative-censoring,informative-dropout,longitudinal-data,missing-data,separating-uninformative-and-informative-censoring-distributions,serial-data,u-statistic}
}

@article{yat92sam,
  title = {Sample Sizes for Proportional Hazards Survival Studies with Arbitrary Patient Entry and Loss to Follow-up Distributions},
  author = {Yateman, N. A. and Skene, A. M.},
  date = {1992},
  journaltitle = {Stat Med},
  volume = {11},
  pages = {1103--1113},
  citeulike-article-id = {13265068},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@online{ye20bay,
  title = {A {{Bayesian}} Approach in Design and Analysis of Pediatric Cancer Clinical Trials},
  author = {Ye, Jingjing and Reaman, Gregory and De Claro, R Angelo and Sridhara, Rajeshwari},
  date = {2020},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/pst.2039?af=R},
  urldate = {2020-06-21},
  abstract = {It is well recognized that cancer drug development for children and adolescents has many challenges, from biological and societal to economic. Pediatric cancer consists of a diverse group of rare diseases, and the relatively small population of children with multiple, disparate tumor types across various age groups presents a significant challenge for drug development programs as compared to oncology drug development programs for adults. Due to the different types of cancers, limited opportunities exist for extrapolation of efficacy from adult cancer indications to children. Thus, innovative study designs including Bayesian statistical approaches should be considered. A Bayesian approach can be a flexible tool to formally leverage prior knowledge of adult or external controls in pediatric cancer trials. In this article, we provide in a case example of how Bayesian approaches can be used to design, monitor, and analyze pediatric trials. Particularly, Bayesian sequential monitoring can be useful to monitor pediatric trial results as data accumulate. In addition, designing a pediatric trial with both skeptical and enthusiastic priors with Bayesian sequential monitoring can be an efficient mechanism for early trial cessation for both efficacy and futility. The interpretation of efficacy using a Bayesian approach is based on posterior probability and is intuitive and interpretable for patients, parents and prescribers given limited data.},
  keywords = {bayes,borrow-information,pediatric,prior,prior-elicitation}
}

@article{ye98mea,
  title = {On Measuring and Correcting the Effects of Data Mining and Model Selection},
  author = {Ye, Jianming},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {120--131},
  citeulike-article-id = {13265069},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {cart,data-mining,effective-degrees-of-freedom,gdf,generalized-degrees-of-freedom,model-selection,model-uncertainty,nonparametric-regression,overfitting,simulation-setup}
}

@article{yee96vec,
  title = {Vector Generalized Additive Models},
  author = {Yee, T. W. and Wild, C. J.},
  date = {1996},
  journaltitle = {J Roy Stat Soc B},
  volume = {58},
  pages = {481--493},
  citeulike-article-id = {13265070},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {checking-assumptions-of-proportional-odds-model,multivariate-response,non-proportional-odds,ordinal-logistic-regression,smoothing}
}

@article{yi02est,
  title = {Estimating Sample Size for Tests on Trends across Repeated Measurements with Missing Data Based on the Interaction Term in a Mixed Model},
  author = {Yi, Qilong and Panzarella, Tony},
  date = {2002-10-01},
  journaltitle = {Controlled Clinical Trials},
  volume = {23},
  number = {5},
  pages = {481--496},
  issn = {0197-2456},
  doi = {10.1016/S0197-2456(02)00223-4},
  url = {http://www.sciencedirect.com/science/article/pii/S0197245602002234},
  urldate = {2020-12-11},
  abstract = {A formula to estimate the required sample size for a study with repeated measurements was constructed based on the test of an interaction term in a mixed model. It covers both random effects and serial correlation and allows for missing data. This formula indicates that the method suggested by Dawson is conservative. A simulation study further verified the accuracy of the formula. Factors that influence the required sample size, such as the number of repeated measurements, the structure of the within-subject correlation, and their interaction, were investigated in detail.},
  langid = {english},
  keywords = {rct,sample-size,serial}
}

@article{yia18ran,
  title = {Randomised Controlled Pragmatic Clinical Trial Evaluating the Effectiveness of a Discharge Follow-up Phone Call on 30-Day Hospital Readmissions: Balancing Pragmatic and Explanatory Design Considerations},
  shorttitle = {Randomised Controlled Pragmatic Clinical Trial Evaluating the Effectiveness of a Discharge Follow-up Phone Call on 30-Day Hospital Readmissions},
  author = {Yiadom, Maame Yaa A. B. and Domenico, Henry and Byrne, Daniel and Hasselblad, Michele Marie and Gatto, Cheryl L. and Kripalani, Sunil and Choma, Neesha and Tucker, Sarah and Wang, Li and Bhatia, Monisha C. and Morrison, Johnston and Harrell, Frank E. and Hartert, Tina and Bernard, Gordon},
  date = {2018-02-14},
  journaltitle = {BMJ Open},
  volume = {8},
  number = {2},
  eprint = {29444787},
  eprinttype = {pmid},
  pages = {e019600},
  issn = {2044-6055},
  doi = {10.1136/bmjopen-2017-019600},
  abstract = {INTRODUCTION: Hospital readmissions within 30\,days are a healthcare quality problem associated with increased costs and poor health outcomes. Identifying interventions to improve patients' successful transition from inpatient to outpatient care is a continued challenge. METHODS AND ANALYSIS: This is a single-centre pragmatic randomised and controlled clinical trial examining the effectiveness of a discharge follow-up phone call to reduce 30-day inpatient readmissions. Our primary endpoint is inpatient readmission within 30\,days of hospital discharge censored for death analysed with an intention-to-treat approach. Secondary endpoints included observation status readmission within 30\,days, time to readmission, all-cause emergency department revisits within 30\,days, patient satisfaction (measured as mean Hospital Consumer Assessment of Healthcare Providers and Systems scores) and 30-day mortality. Exploratory endpoints include the need for assistance with discharge plan implementation among those randomised to the intervention arm and reached by the study nurse, and the number of call attempts to achieve successful intervention delivery. Consistent with the Learning Healthcare System model for clinical research, timeliness is a critical quality for studies to most effectively inform hospital clinical practice. We are challenged to apply pragmatic design elements in order to maintain a high-quality practicable study providing timely results. This type of prospective pragmatic trial empowers the advancement of hospital-wide evidence-based practice directly affecting patients. ETHICS AND DISSEMINATION: Study results will inform the structure, objective and function of future iterations of the hospital's discharge follow-up phone call programme and be submitted for publication in the literature. TRIAL REGISTRATION NUMBER: NCT03050918; Pre-results.},
  langid = {english},
  pmcid = {PMC5829894},
  keywords = {hsr}
}

@article{yia20imp,
  title = {Impact of a {{Follow-up Telephone Call Program}} on 30-{{Day Readmissions}} ({{FUTR-30}}): {{A Pragmatic Randomized Controlled Real-world Effectiveness Trial}}},
  shorttitle = {Impact of a {{Follow-up Telephone Call Program}} on 30-{{Day Readmissions}} ({{FUTR-30}})},
  author = {Yiadom, Maame Yaa A. B. and Domenico, Henry J. and Byrne, Daniel W. and Hasselblad, Michele and Kripalani, Sunil and Choma, Neesha and Tucker-Marlow, Sarah and Gatto, Cheryl L. and Wang, Li and Bhatia, Monisha C. and Morrison, Johnston and Harrell, Frank E. and Hartert, Tina V. and Lindsell, Christopher J. and Bernard, Gordon R.},
  date = {2020-09},
  journaltitle = {Med Care},
  volume = {58},
  number = {9},
  eprint = {32732787},
  eprinttype = {pmid},
  pages = {785--792},
  issn = {1537-1948},
  doi = {10.1097/MLR.0000000000001353},
  abstract = {BACKGROUND: Telephone call programs are a common intervention used to improve patients' transition to outpatient care after hospital discharge. OBJECTIVE: To examine the impact of a follow-up telephone call program as a readmission reduction initiative. RESEARCH DESIGN: Pragmatic randomized controlled real-world effectiveness trial. SUBJECTS: We enrolled and randomized all patients discharged home from a hospital general medicine service to a follow-up telephone call program or usual care discharge. Patients discharged against medical advice were excluded. The intervention was a hospital program, delivering a semistructured follow-up telephone call from a nurse within 3-7 days of discharge, designed to assess understanding and provide education, and assistance to support discharge plan implementation. MEASURES: Our primary endpoint was hospital inpatient readmission within 30 days identified by the electronic health record. Secondary endpoints included observation readmission, emergency department revisit, and mortality within 30 days, and patient experience ratings. RESULTS: All 3054 patients discharged home were enrolled and randomized to the telephone call program (n=1534) or usual care discharge (n=1520). Using a prespecified intention-to-treat analysis, we found no evidence supporting differences in 30-day inpatient readmissions [14.9\% vs. 15.3\%; difference -0.4 (95\% confidence interval, 95\% CI), -2.9 to 2.1; P=0.76], observation readmissions [3.8\% vs. 3.6\%; difference 0.2 (95\% CI, -1.1 to 1.6); P=0.74], emergency department revisits [6.1\% vs. 5.4\%; difference 0.7 (95\% CI, -1.0 to 2.3); P=0.43], or mortality [4.4\% vs. 4.9\%; difference -0.5 (95\% CI, -2.0 to 1.0); P=0.51] between telephone call and usual care groups. CONCLUSIONS: We found no evidence of an impact on 30-day readmissions or mortality due to the postdischarge telephone call program.},
  langid = {english},
  keywords = {hsr}
}

@article{yor18bty,
  title = {B-{{Type Natriuretic Peptide Levels}} and~{{Mortality}} in {{Patients With}} and {{Without Heart Failure}}},
  author = {York, Michelle K. and Gupta, Deepak K. and Reynolds, Cassandra F. and Farber-Eger, Eric and Wells, Quinn S. and Bachmann, Katherine N. and Xu, Meng and Harrell, Frank E. and Wang, Thomas J.},
  date = {2018-05-15},
  journaltitle = {J Am Coll Cardiol},
  volume = {71},
  number = {19},
  eprint = {29747827},
  eprinttype = {pmid},
  pages = {2079--2088},
  issn = {1558-3597},
  doi = {10.1016/j.jacc.2018.02.071},
  abstract = {BACKGROUND: Circulating B-type natriuretic peptide (BNP) concentrations strongly predict mortality in patients with heart failure (HF). Both cardiac and extracardiac stimuli influence BNP levels, suggesting that BNP might have similar prognostic value in patients without HF. OBJECTIVES: The aim of this study was to compare the prognostic value of BNP between patients with and those without HF. METHODS: Using the Vanderbilt University Medical Center electronic health record, 30,487 patients (median age 63 years, 50\% men, 17\% black, 38\% with HF) who had a first plasma BNP measurement between 2002 and 2013, with follow-up through 2015, were studied. The risk for death according to BNP level was quantified using multivariate Cox proportional hazards models. RESULTS: BNP levels were lower in patients without HF (median 89 pg/ml; interquartile range: 34 to 238 pg/ml) compared with those with HF (median 388 pg/ml; interquartile range: 150 to 940 pg/ml) (p~{$<$} 0.0001). Over 90,898 person-years of follow-up, 5,903 patients without HF (31\%) and 6,181 patients with HF (53\%) died. In multivariate models including demographic and clinical characteristics, BNP and age were the strongest predictors of death in both patients with and those without HF. In acute care settings and even among outpatients with modestly elevated BNP, the risk for death according to BNP was similar between patients with and those without HF. For instance, a BNP level of 400 pg/ml was associated with a 3-year risk for death of 21\% (95\% confidence interval: 20\% to 23\%) and 19\% (95\% confidence interval: 17\% to 20\%) in patients with and those without HF, respectively. CONCLUSIONS: Among patients without HF, plasma BNP level is a stronger predictor of death than traditional risk factors. The risk for death associated with any given BNP level is similar between patients with and those without HF,~particularly in the acute care setting.},
  langid = {english},
  pmcid = {PMC5951190},
  keywords = {collaboration,cv}
}

@article{you15hig,
  title = {Higher Achieved Mean Arterial Pressure during Therapeutic Hypothermia Is Not Associated with Neurologically Intact Survival Following Cardiac Arrest.},
  author = {Young, Michael N. and Hollenbeck, Ryan D. and Pollock, Jeremy S. and Giuseffi, Jennifer L. and Wang, Li and Harrell, Frank E. and McPherson, John A.},
  date = {2015-03},
  journaltitle = {Resuscitation},
  volume = {88},
  eprint = {25541429},
  eprinttype = {pmid},
  pages = {158--164},
  issn = {1873-1570},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/25541429},
  abstract = {To determine if higher achieved mean arterial blood pressure (MAP) during treatment with therapeutic hypothermia (TH) is associated with neurologically intact survival following cardiac arrest. Retrospective analysis of a prospectively collected cohort of 188 consecutive patients treated with TH in the cardiovascular intensive care unit of an academic tertiary care hospital. Neurologically intact survival was observed in 73/188 (38.8\%) patients at hospital discharge and in 48/162 (29.6\%) patients at a median follow up interval of 3 months. Patients in shock at the time of admission had lower baseline MAP at the initiation of TH (81 versus 87mmHg; p=0.002), but had similar achieved MAP during TH (80.3 versus 83.7mmHg; p=0.11). Shock on admission was associated with poor survival (18\% versus 52\%; p{$<$}0.001). Vasopressor use among all patients was common (84.6\%) and was not associated with increased mortality. A multivariable analysis including age, initial rhythm, time to return of spontaneous circulation, baseline MAP and achieved MAP did not demonstrate a relationship between MAP achieved during TH and poor neurological outcome at hospital discharge (OR 1.28, 95\% CI 0.40-4.06; p=0.87) or at outpatient follow up (OR 1.09, 95\% CI 0.32-3.75; p=0.976). We did not observe a relationship between higher achieved MAP during TH and neurologically intact survival. However, shock at the time of admission was clearly associated with poor outcomes in our study population. These data do not support the use of vasopressors to artificially increase MAP in the absence of shock. There is a need for prospective, randomized trials to further define the optimum blood pressure target during treatment with TH. Copyright  2014 Elsevier Ireland Ltd. All rights reserved.},
  citeulike-article-id = {14102494},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/25541429},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=25541429},
  posted-at = {2016-07-26 21:22:06},
  priority = {2},
  keywords = {collaboration}
}

@article{you78,
  title = {The Principal Components of Mixed Measurement Level Multivariate Data: {{An}} Alternating Least Squares Method with Optimal Scaling Features},
  author = {Young, F. W. and Takane, Y. and de Leeuw, J.},
  options = {useprefix=true},
  date = {1978},
  journaltitle = {Psychometrika},
  volume = {43},
  pages = {279--281},
  citeulike-article-id = {13265071},
  posted-at = {2014-07-14 14:09:48},
  priority = {0}
}

@article{yu03use,
  title = {Use of a {{Markov}} Transition Model to Analyse Longitudinal Low-Back Pain Data},
  author = {Yu, Fei and Morgenstern, Hal and Hurwitz, Eric and Berlin, Thomas R},
  date = {2003-08-01},
  journaltitle = {Stat Methods Med Res},
  volume = {12},
  number = {4},
  pages = {321--331},
  publisher = {{SAGE Publications Ltd STM}},
  issn = {0962-2802},
  doi = {10.1191/0962280203sm321ra},
  url = {https://doi.org/10.1191/0962280203sm321ra},
  urldate = {2021-01-03},
  abstract = {In a randomized clinical trial to assess the effectiveness of different strategies for treating low-back pain in a managed-care setting, 681 adult patients presenting with low-back pain were randomized to four treatment groups: medical care with and without physical therapy; and chiropractic care with and without physical modalities. Follow-up information was obtained by questionnaires at two and six weeks, six, 12 and 18 months and by a telephone interview at four weeks. One outcome measurement at each follow-up is the patient’s self-report on the perception of low-back pain improvement from the previous survey, recorded as ‘A lot better,’ ‘A little better,’ ‘About the same’ and ‘Worse.’ Since the patient’s perception of improvement may be influenced by past experience, the outcome is analysed using a transition (first-order Markov) model. Although one could collapse categories to the point that logistic regression analysis with repeated measurements could be used, here we allow for multiple categories by relating transition probabilities to covariates and previous outcomes through a polytomous logistic regression model with Markov structure. This approach allows us to assess not only the effects of treatment assignment and baseline characteristics but also the effects of past outcomes in analysing longitudinal categorical data.},
  langid = {english},
  keywords = {markov,ordinal,polytomous-logistic-model,serial,transition-model},
  note = {Polytomous Markov logistic model; made no use of the ordinal nature of Y.~ Shows how to use Cox or Poisson regression to do polytomous regression.}
}

@article{yu22sam,
  title = {Sample Size Formula for a Win Ratio Endpoint},
  author = {Yu, Ron Xiaolong and Ganju, Jitendra},
  date = {2022},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9297},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9297},
  urldate = {2022-01-28},
  abstract = {The win ratio composite endpoint, which organizes the components of the composite hierarchically, is becoming popular in late-stage clinical trials. The method involves comparing data in a pair-wise manner starting with the endpoint highest in priority (eg, cardiovascular death). If the comparison is a tie, the endpoint next highest in priority (eg, hospitalizations for heart failure) is compared, and so on. Its sample size is usually calculated through complex simulations because there does not exist in the literature a simple sample size formula. This article provides a formula that depends on the probability that a randomly selected patient from one group does better than a randomly selected patient from another group, and on the probability of a tie. We compare the published 95\% confidence intervals, which require patient-level data, with that calculated from the formula, requiring only summary-level data, for 17 composite or single win ratio endpoints. The two sets of results are similar. Simulations show the sample size formula performs well. The formula provides important insights. It shows when adding an endpoint to the hierarchy can increase power even if the added endpoint has low power by itself. It provides relevant information to modify an on-going blinded trial if necessary. The formula allows a non-specialist to quickly determine the size of the trial with a win ratio endpoint whose use is expected to increase over time.},
  langid = {english},
  keywords = {multiple-endpoints,sample-size,win-ratio}
}

@article{yua12var,
  title = {Variable Selection for Covariate-Adjusted Semiparametric Inference in Randomized Clinical Trials},
  author = {Yuan, Shuai and Zhang, Hao H. and Davidian, Marie},
  date = {2012},
  journaltitle = {Stat Med},
  volume = {31},
  number = {29},
  pages = {3789--3804},
  doi = {10.1002/sim.5433},
  url = {http://dx.doi.org/10.1002/sim.5433},
  abstract = {Extensive baseline covariate information is routinely collected on participants in randomized clinical trials, and it is well recognized that a proper covariate-adjusted analysis can improve the efficiency of inference on the treatment effect. However, such covariate adjustment has engendered considerable controversy, as post hoc selection of covariates may involve subjectivity and may lead to biased inference, whereas prior specification of the adjustment may exclude important variables from consideration. Accordingly, how to select covariates objectively to gain maximal efficiency is of broad interest. We propose and study the use of modern variable selection methods for this purpose in the context of a semiparametric framework, under which variable selection in modeling the relationship between outcome and covariates is separated from estimation of the treatment effect, circumventing the potential for selection bias associated with standard analysis of covariance methods. We demonstrate that such objective variable selection techniques combined with this framework can identify key variables and lead to unbiased and efficient inference on the treatment effect. A critical issue in finite samples is validity of estimators of uncertainty, such as standard errors and confidence intervals for the treatment effect. We propose an approach to estimation of sampling variation of estimated treatment effect and show its superior performance relative to that of existing methods.},
  citeulike-article-id = {13265951},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.5433},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {covariate-adjustment,false-selection-rate-control,oracle-property,semiparametric-treatment-effect-estimation,shrinkage-in-ancova,shrinkage-methods,variable-selection}
}

@article{yuc08usi,
  title = {Using Calibration to Improve Rounding in Imputation},
  author = {Yucel, Recai M. and Zaslavsky, Alan M.},
  date = {2008},
  journaltitle = {Am Statistician},
  volume = {62},
  number = {2},
  pages = {125--129},
  citeulike-article-id = {13265671},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  keywords = {categorical-data-imputation,imputation,missing-data,multiple-imputation,multivariate-normal,posterior-predictive-check,rounding,software},
  note = {using rounding to impute binary variables using techniques for continuous data;uses the method to solve for the cutpoint for a continuous estimate to be converted into a binary value;method should be useful in more general situations;idea is to duplicate the entire dataset and in the second half of the new datasets to set all non-missing values of the target variable to missing;multiply impute these now-missing values and compare them to the actual values}
}

@article{yuk13oro,
  title = {An Oropharyngeal {{pH}} Monitoring Device to Evaluate Patients with Chronic Laryngitis.},
  author = {Yuksel, E. S. and Slaughter, J. C. and Mukhtar, N. and Ochieng, M. and Sun, G. and Goutte, M. and Muddana, S. and Gaelyn Garrett, C. and Vaezi, M. F.},
  date = {2013-05},
  journaltitle = {Neurogastro Motility},
  volume = {25},
  number = {5},
  eprint = {23495894},
  eprinttype = {pmid},
  issn = {1365-2982},
  url = {http://view.ncbi.nlm.nih.gov/pubmed/23495894},
  abstract = {Diagnostics for gastro-esophageal reflux disease (GERD) are suboptimal because of limited sensitivity. We performed in vitro and in vivo studies to systematically assess the performance characteristics of an oropharyngeal pH probe. In vitro studies compared the oropharyngeal probe with a standard pH catheter in liquid and aerosolized solutions, pH 1-7. The accuracy of measurements, deviation from target pH, and time to equilibrium pH were determined. Simultaneous distal esophageal pH measurements were obtained in 11 patients with GERD. Oropharyngeal and distal esophageal reflux parameters were measured for controls (n = 20), patients with GERD (n = 17), and patients with chronic laryngitis (n = 10). In the liquid phase, at pH 4-5, the oropharyngeal probe had less deviation from the target value than the standard catheter; deviation in the vapor phase was similar (0.4 pH units). Median (interquartile) time to reach equilibrium pH was significantly (P {$<$} 0.001) faster with the oropharyngeal than the standard probe. In comparing simultaneous distal esophageal pH characteristics, 96\% of recordings with the new and standard probes were in agreement to within ± 1.0 pH unit; 71\% of recordings were in agreement within ± 0.5 pH units. Patients with chronic laryngitis had significantly higher levels of oropharyngeal acid exposure at pH {$<$}4, {$<$}5, and {$<$}6, in the upright position than patients with GERD or controls (P {$<$} .001). Oropharyngeal pH monitoring appears to be more sensitive than traditional pH monitoring in evaluation of patients with extraesophageal reflux. It is a promising tool in evaluation of this difficult group of patients.  2013 Blackwell Publishing Ltd.},
  citeulike-article-id = {13508600},
  citeulike-linkout-0 = {http://view.ncbi.nlm.nih.gov/pubmed/23495894},
  citeulike-linkout-1 = {http://www.hubmed.org/display.cgi?uids=23495894},
  posted-at = {2015-02-04 13:35:02},
  priority = {2},
  keywords = {measurement-instruments,smooth-bland-altman-plots,teaching}
}

@article{yus91ana,
  title = {Analysis and Interpretation of Treatment Effects in Subgroups of Patients in Randomized Clinical Trials},
  author = {Yusef, S. and Wittes, J. and Probstfield, J. and Tyroler, H. A.},
  date = {1991},
  journaltitle = {JAMA},
  volume = {266},
  pages = {93--98},
  doi = {10.1001/jama.266.1.93},
  url = {http://dx.doi.org/10.1001/jama.266.1.93},
  citeulike-article-id = {13265072},
  citeulike-linkout-0 = {http://dx.doi.org/10.1001/jama.266.1.93},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {multiple-comparisons,subgroup-analysis,teaching-mds}
}

@article{zam20usi,
  title = {Using {{Bayesian Methods}} to {{Augment}} the {{Interpretation}} of {{Critical Care Trials}}. {{An Overview}} of {{Theory}} and {{Example Reanalysis}} of the {{Alveolar Recruitment}} for {{Acute Respiratory Distress Syndrome Trial}}},
  author = {Zampieri, Fernando G. and Casey, Jonathan D. and Shankar-Hari, Manu and Harrell, Frank E. and Harhay, Michael O.},
  date = {2020-12-03},
  journaltitle = {Am J Respir Crit Care Med},
  volume = {203},
  number = {5},
  pages = {543--552},
  publisher = {{American Thoracic Society - AJRCCM}},
  issn = {1073-449X},
  doi = {10.1164/rccm.202006-2381CP},
  url = {https://www.atsjournals.org/doi/10.1164/rccm.202006-2381CP},
  urldate = {2021-03-01},
  abstract = {Most randomized trials are designed and analyzed using frequentist statistical approaches such as null hypothesis testing and P values. Conceptually, P values are cumbersome to understand, as they provide evidence of data incompatibility with a null hypothesis (e.g., no clinical benefit) and not direct evidence of the alternative hypothesis (e.g., clinical benefit). This counterintuitive framework may contribute to the misinterpretation that the absence of evidence is equal to evidence of absence and may cause the discounting of potentially informative data. Bayesian methods provide an alternative, probabilistic interpretation of data. The reanalysis of completed trials using Bayesian methods is becoming increasingly common, particularly for trials with effect estimates that appear clinically significant despite P values above the traditional threshold of 0.05. Statistical inference using Bayesian methods produces a distribution of effect sizes that would be compatible with observed trial data, interpreted in the context of prior assumptions about an intervention (called “priors”). These priors are chosen by investigators to reflect existing beliefs and past empirical evidence regarding the effect of an intervention. By calculating the likelihood of clinical benefit, a Bayesian reanalysis can augment the interpretation of a trial. However, if priors are not defined a priori, there is a legitimate concern that priors could be constructed in a manner that produces biased results. Therefore, some standardization of priors for Bayesian reanalysis of clinical trials may be desirable for the critical care community. In this Critical Care Perspective, we discuss both frequentist and Bayesian approaches to clinical trial analysis, introduce a framework that researchers can use to select priors for a Bayesian reanalysis, and demonstrate how to apply our proposal by conducting a novel Bayesian trial reanalysis.},
  keywords = {basic,bayes,rct,teaching-mds}
}

@article{zha01est,
  title = {On Estimating Medical Cost and Incremental Cost-Effectiveness Ratios with Censored Data},
  author = {Zhao, Hongwei and Tian, Lili},
  date = {2001},
  journaltitle = {Biometrics},
  volume = {57},
  pages = {1002--1008},
  citeulike-article-id = {13265244},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {analysis-of-cost,confidence-interval-for-icer,cost-effectiveness,health-care-cost,right-censored-cost-and-surival-time}
}

@article{zha03est,
  title = {Estimation of Causal Effects via Principal Stratification When Some Outcomes Are Truncated by “Death”},
  author = {Zhang, J. L. and Rubin, D. B.},
  date = {2003},
  journaltitle = {J Edu Behav Stat},
  volume = {28},
  pages = {353--368},
  citeulike-article-id = {13265755},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {truncation-by-death},
  note = {non-fatal endpoint unobserved because of truncation by death}
}

@article{zha07ada,
  title = {Adaptive Lasso for {{Cox}}'s Proportional Hazards Model},
  author = {Zhang, Hao H. and Lu, Wenbin},
  date = {2007},
  journaltitle = {Biometrika},
  volume = {94},
  pages = {691--703},
  citeulike-article-id = {13265627},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {adaptive-lasso,penalized-partial-likelihood,ph,proportional-hazards-model,variable-selection},
  note = {penalty function has ratios against original MLE;scale-free lasso}
}

@article{zha07equ,
  title = {On the Equivalence of Some Medical Cost Estimators with Censored Data},
  author = {Zhao, Hongwei and Bang, Heejung and Wang, Hongkun and Pfeifer, Phillip E.},
  date = {2007},
  journaltitle = {Stat Med},
  volume = {26},
  pages = {4520--4530},
  citeulike-article-id = {13265632},
  posted-at = {2014-07-14 14:10:00},
  priority = {0},
  keywords = {analysis-of-cost-data,censoring,cost-analysis,health-economics,inverse-probability-weighting,survival-analysis}
}

@article{zha09non,
  title = {Nonparametric Methods for Measurements below Detection Limit},
  author = {Zhang, Donghui and Fan, Chunpeng and Zhang, Juan and Zhang, Cun-Hui},
  date = {2009},
  journaltitle = {Stat Med},
  volume = {28},
  pages = {700--715},
  citeulike-article-id = {13265732},
  posted-at = {2014-07-14 14:10:03},
  priority = {0},
  keywords = {gehan-test,left-censoring,location-shift-model,log-rank-test,lower-limit-of-detection,peto-peto-test,superiority-of-nonparametric-methods,tobit-model,wilcoxon-test}
}

@article{zha11gen,
  title = {On Fitting Generalized Linear Mixed-Effects Models for Binary Responses Using Different Statistical Packages.},
  author = {Zhang, Hui and Lu, Naiji and Feng, Changyong and Thurston, Sally W. and Xia, Yinglin and Zhu, Liang and Tu, Xin M.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  pages = {2562--2572},
  doi = {10.1002/sim.4265},
  url = {http://dx.doi.org/10.1002/sim.4265},
  abstract = {The generalized linear mixed-effects model (GLMM) is a popular paradigm to extend models for cross-sectional data to a longitudinal setting. When applied to modeling binary responses, different software packages and even different procedures within a package may give quite different results. In this report, we describe the statistical approaches that underlie these different procedures and discuss their strengths and weaknesses when applied to fit correlated binary responses. We then illustrate these considerations by applying these procedures implemented in some popular software packages to simulated and real study data. Our simulation results indicate a lack of reliability for most of the procedures considered, which carries significant implications for applying such popular software packages in practice.},
  citeulike-article-id = {13265908},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4265},
  posted-at = {2014-07-14 14:10:07},
  priority = {0}
}

@article{zha11ins,
  title = {Some Insights on Censored Cost Estimators},
  author = {Zhao, H. and Cheng, Y. and Bang, H.},
  date = {2011},
  journaltitle = {Stat Med},
  volume = {30},
  pages = {2381--2388},
  doi = {10.1002/sim.4295},
  url = {http://dx.doi.org/10.1002/sim.4295},
  citeulike-article-id = {13265891},
  citeulike-linkout-0 = {http://dx.doi.org/10.1002/sim.4295},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {analysis-of-cost,inverse-probability-weighting,marked-process,medical-cost,redistribute-to-the-right,replacement-from-the-right,survival-analysis}
}

@article{zha17kcn,
  title = {Kcnj11 {{Ablation Is Associated With Increased Nitro-Oxidative Stress During Ischemia-Reperfusion Injury}}: {{Implications}} for {{Human Ischemic Cardiomyopathy}}},
  shorttitle = {Kcnj11 {{Ablation Is Associated With Increased Nitro-Oxidative Stress During Ischemia-Reperfusion Injury}}},
  author = {Zhang, Bo and Novitskaya, Tatiana and Wheeler, Debra G. and Xu, Zhaobin and Chepurko, Elena and Huttinger, Ryan and He, Heng and Varadharaj, Saradhadevi and Zweier, Jay L. and Song, Yanna and Xu, Meng and Harrell, Frank E. and Su, Yan Ru and Absi, Tarek and Kohr, Mark J. and Ziolo, Mark T. and Roden, Dan M. and Shaffer, Christian M. and Galindo, Cristi L. and Wells, Quinn S. and Gumina, Richard J.},
  date = {2017-02},
  journaltitle = {Circ Heart Fail},
  volume = {10},
  number = {2},
  eprint = {28209764},
  eprinttype = {pmid},
  issn = {1941-3297},
  doi = {10.1161/CIRCHEARTFAILURE.116.003523},
  abstract = {BACKGROUND: Despite increased secondary cardiovascular events in patients with ischemic cardiomyopathy (ICM), the expression of innate cardiac protective molecules in the hearts of patients with ICM is incompletely characterized. Therefore, we used a nonbiased RNAseq approach to determine whether differences in cardiac protective molecules occur with ICM. METHODS AND RESULTS: RNAseq analysis of human control and ICM left ventricular samples demonstrated a significant decrease in KCNJ11 expression with ICM. KCNJ11 encodes the Kir6.2 subunit of the cardioprotective KATP channel. Using wild-type mice and kcnj11-deficient (kcnj11-null) mice, we examined the effect of kcnj11 expression on cardiac function during ischemia-reperfusion injury. Reactive oxygen species generation increased in kcnj11-null hearts above that found in wild-type mice hearts after ischemia-reperfusion injury. Continuous left ventricular pressure measurement during ischemia and reperfusion demonstrated a more compromised diastolic function in kcnj11-null compared with wild-type mice during reperfusion. Analysis of key calcium-regulating proteins revealed significant differences in kcnj11-null mice. Despite impaired relaxation, kcnj11-null hearts increased phospholamban Ser16 phosphorylation, a modification that results in the dissociation of phospholamban from sarcoendoplasmic reticulum Ca2+, thereby increasing sarcoendoplasmic reticulum Ca2+-mediated calcium reuptake. However, kcnj11-null mice also had increased 3-nitrotyrosine modification of the sarcoendoplasmic reticulum Ca2+-ATPase, a modification that irreversibly impairs sarcoendoplasmic reticulum Ca2+ function, thereby contributing to diastolic dysfunction. CONCLUSIONS: KCNJ11 expression is decreased in human ICM. Lack of kcnj11 expression increases peroxynitrite-mediated modification of the key calcium-handling protein sarcoendoplasmic reticulum Ca2+-ATPase after myocardial ischemia-reperfusion injury, contributing to impaired diastolic function. These data suggest a mechanism for ischemia-induced diastolic dysfunction in patients with ICM.},
  langid = {english},
  pmcid = {PMC5319711},
  keywords = {collaboration,cv}
}

@article{zha19fre,
  title = {Frequentist Operating Characteristics of {{Bayesian}} Optimal Designs via Simulation},
  author = {Zhang, Yifan and Trippa, Lorenzo and Parmigiani, Giovanni},
  date = {2019},
  journaltitle = {Statistics in Medicine},
  volume = {0},
  number = {0},
  issn = {1097-0258},
  doi = {10.1002/sim.8279},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8279},
  urldate = {2019-06-20},
  abstract = {Bayesian adaptive designs have become popular because of the possibility of increasing the number of patients treated with more beneficial treatments, while still providing sufficient evidence for treatment efficacy comparisons. It can be essential, for regulatory and other purposes, to conduct frequentist analyses both before and after a Bayesian adaptive trial, and these remain challenging. In this paper, we propose a general simulation-based approach to compare frequentist designs with Bayesian adaptive designs based on frequentist criteria such as power and to compute valid frequentist p-values. We illustrate our approach by comparing the power of an equal randomization (ER) design with that of an optimal Bayesian adaptive (OBA) design. The Bayesian design considered here is the dynamic programming solution of the optimization of a specific utility function defined by the number of successes in a patient horizon, including patients whose treatment will be affected by the trial's results after the end of the trial. While the power of an ER design depends on treatment efficacy and the sample size, the power of the OBA design also depends on the patient horizon size. Our results quantify the trade-off between power and the optimal assignment of patients to treatments within the trial. We show that, for large patient horizons, the two criteria are in agreement, while for small horizons, differences can be substantial. This has implications for precision medicine, where patient horizons are decreasing as a result of increasing stratification of patients into subpopulations defined by molecular markers.},
  langid = {english},
  keywords = {bayes,simulation,simulation-setup}
}

@article{zha20int,
  title = {Interaction Analysis under Misspecification of Main Effects: {{Some}} Common Mistakes and Simple Solutions},
  shorttitle = {Interaction Analysis under Misspecification of Main Effects},
  author = {Zhang, Min and Yu, Youfei and Wang, Shikun and Salvatore, Maxwell and Fritsche, Lars G. and He, Zihuai and Mukherjee, Bhramar},
  date = {2020},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.8505},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8505},
  urldate = {2020-02-27},
  abstract = {The statistical practice of modeling interaction with two linear main effects and a product term is ubiquitous in the statistical and epidemiological literature. Most data modelers are aware that the misspecification of main effects can potentially cause severe type I error inflation in tests for interactions, leading to spurious detection of interactions. However, modeling practice has not changed. In this article, we focus on the specific situation where the main effects in the model are misspecified as linear terms and characterize its impact on common tests for statistical interaction. We then propose some simple alternatives that fix the issue of potential type I error inflation in testing interaction due to main effect misspecification. We show that when using the sandwich variance estimator for a linear regression model with a quantitative outcome and two independent factors, both the Wald and score tests asymptotically maintain the correct type I error rate. However, if the independence assumption does not hold or the outcome is binary, using the sandwich estimator does not fix the problem. We further demonstrate that flexibly modeling the main effect under a generalized additive model can largely reduce or often remove bias in the estimates and maintain the correct type I error rate for both quantitative and binary outcomes regardless of the independence assumption. We show, under the independence assumption and for a continuous outcome, overfitting and flexibly modeling the main effects does not lead to power loss asymptotically relative to a correctly specified main effect model. Our simulation study further demonstrates the empirical fact that using flexible models for the main effects does not result in a significant loss of power for testing interaction in general. Our results provide an improved understanding of the strengths and limitations for tests of interaction in the presence of main effect misspecification. Using data from a large biobank study “The Michigan Genomics Initiative”, we present two examples of interaction analysis in support of our results.},
  langid = {english},
  keywords = {interaction,rms},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8505}
}

@article{zha21reg,
  title = {A {{Regression Modeling Approach}} to {{Structured Shrinkage Estimation}}},
  author = {Zhao, Sihai Dave and Biscarri, William},
  date = {2021-01-19},
  journaltitle = {Journal of the American Statistical Association},
  volume = {0},
  number = {0},
  pages = {1--11},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2021.1875838},
  url = {https://doi.org/10.1080/01621459.2021.1875838},
  urldate = {2021-03-09},
  abstract = {Problems involving the simultaneous estimation of multiple parameters arise in many areas of theoretical and applied statistics. A canonical example is the estimation of a vector of normal means. Frequently, structural information about relationships between the parameters of interest is available. For example, in a gene expression denoising problem, genes with similar functions may have similar expression levels. Despite its importance, structural information has not been well-studied in the simultaneous estimation literature, perhaps in part because it poses challenges to the usual geometric or empirical Bayes shrinkage estimation paradigms. This article proposes that some of these challenges can be resolved by adopting an alternate paradigm, based on regression modeling. This approach can naturally incorporate structural information and also motivates new shrinkage estimation and inference procedures. As an illustration, this regression paradigm is used to develop a class of estimators with asymptotic risk optimality properties that perform well in simulations and in denoising gene expression data from a single cell RNA-sequencing experiment.},
  keywords = {mle,penalization,penalized-mle,rms,shrinkage,strategy},
  annotation = {\_eprint: https://doi.org/10.1080/01621459.2021.1875838}
}

@article{zha21res,
  title = {Restricted Survival Benefit with Right-Censored Data},
  author = {Zhang, Shixiao and LeBlanc, Michael L. and Zhao, Ying-Qi},
  date = {2021},
  journaltitle = {Biometrical Journal},
  volume = {n/a},
  number = {n/a},
  issn = {1521-4036},
  doi = {10.1002/bimj.202000392},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.202000392},
  urldate = {2022-01-01},
  abstract = {The hazard ratio is widely used to quantify treatment effects. However, it may be difficult to interpret for patients and practitioners, especially when the hazard ratio is not constant over time. Alternative measures of the treatment effects have been proposed such as the difference of the restricted mean survival times, the difference in survival proportions at some fixed follow-up time, or the net chance of a longer survival. In this paper, we propose the restricted survival benefit (RSB), a quantity that can incorporate multiple useful measurements of treatment effects. Hence, it provides a framework for a comprehensive assessment of the treatment effects. We provide estimation and inference procedures for the RSB that accommodate censored survival outcomes, using methods of the inverse-probability-censoring-weighted -statistic and the jackknife empirical likelihood. We conduct extensive simulation studies to examine the numerical performance of the proposed method, and we analyze data from a randomized Phase III clinical trial (SWOG S0777) using the proposed method.},
  langid = {english},
  keywords = {mean-restricted-life,non-ph,non-proportional-hazards,survival},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.202000392}
}

@article{zha22bay,
  title = {Bayesian Nonparametric Analysis of Restricted Mean Survival Time},
  author = {Zhang, Chenyang and Yin, Guosheng},
  date = {2022},
  journaltitle = {Biometrics},
  volume = {n/a},
  number = {n/a},
  issn = {1541-0420},
  doi = {10.1111/biom.13622},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13622},
  urldate = {2022-01-17},
  abstract = {The restricted mean survival time (RMST) evaluates the expectation of survival time truncated by a prespecified time point, because the mean survival time in presence of censoring is typically not estimable. The frequentist inference procedure for RMST has been widely advocated for comparison of two survival curves, while research from the Bayesian perspective is rather limited. For the RMST of both right- and interval-censored data, we propose Bayesian nonparametric estimation and inference procedures. By assigning a mixture of Dirichlet processes (MDP) prior to the distribution function, we can estimate the posterior distribution of RMST. We also explore another Bayesian nonparametric approach using the Dirichlet process mixture model and make comparisons with the frequentist nonparametric method. Simulation studies demonstrate that the Bayesian nonparametric RMST under diffuse MDP priors leads to robust estimation and under informative priors it can incorporate prior knowledge into the nonparametric estimator. Analysis of real trial examples demonstrates the flexibility and interpretability of the Bayesian nonparametric RMST for both right- and interval-censored data. This article is protected by copyright. All rights reserved},
  langid = {english},
  keywords = {bayes,non-ph,nonparametric,restricted-mean-life,survival-analysis}
}

@article{zha96tre,
  title = {A Tree-Based Method of Analysis for Prospective Studies},
  author = {Zhang, Heping and Holford, Theodore and Bracken, Michael B.},
  date = {1996},
  journaltitle = {Stat Med},
  volume = {15},
  pages = {37--49},
  citeulike-article-id = {13265074},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {cart,handling-missing-predictors,surrogate-splits,tree-models}
}

@article{zha97con,
  title = {A Consistent Estimator for the Distribution of Quality Adjusted Survival Time},
  author = {Zhao, Hongwei and Tsiatis, Anastasios A.},
  date = {1997},
  journaltitle = {Biometrika},
  volume = {84},
  pages = {339--348},
  citeulike-article-id = {13265073},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {analysis-of-cost-data,consistent-estimator,informative-censoring,patient-utility,qaly,quality-adjusted-survival-time,quality-of-life,twist,utilities},
  note = {see she99est,etz99use}
}

@article{zha97met,
  title = {Methods for Comparing the Means of Two Independent Log-Normal Samples},
  author = {Zhao, Xiao-Hua and Gao, Sujuan and Hui, Liu L.},
  date = {1997},
  journaltitle = {Biometrics},
  volume = {53},
  pages = {1129--1135},
  citeulike-article-id = {13265075},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {analysis-of-cost-data,bootstrap,log-normal}
}

@article{zha97som,
  title = {Some Statistical Methods for Multiple Endpoints in Clinical Trials},
  author = {Zhang, Ji and Quan, Hui and Ng, Jennifer and Stepanavage, Michael E.},
  date = {1997},
  journaltitle = {Controlled Clin Trials},
  volume = {18},
  pages = {204--221},
  citeulike-article-id = {13265076},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {closed-procedures,composite-endpoint,experimentwise-error-rate,multiple-endpoints,study-design}
}

@article{zha98cla,
  title = {Classification Trees for Multiple Binary Responses},
  author = {Zhang, Heping},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {180--193},
  citeulike-article-id = {13265077},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {cart,multivariate-binary-response}
}

@article{zha98sin,
  title = {Single or Double Data Entry: {{Considerations}} Based on a Simple Binomial Model},
  author = {Zhang, J. and Hu, W.},
  date = {1998},
  journaltitle = {Controlled Clin Trials},
  volume = {19},
  pages = {56--58},
  citeulike-article-id = {13265266},
  posted-at = {2014-07-14 14:09:53},
  priority = {0},
  keywords = {clinical-trials,data-management,double-data-entry,rct}
}

@article{zhe00sum,
  title = {Summarizing the Predictive Power of a Generalized Linear Model},
  author = {Zheng, Beiyao and Agresti, Alan},
  date = {2000},
  journaltitle = {Stat Med},
  volume = {19},
  pages = {1771--1781},
  citeulike-article-id = {13265137},
  posted-at = {2014-07-14 14:09:50},
  priority = {0},
  keywords = {glm,predictive-accuracy,predictive-power,r2},
  note = {advantages of correlation between predictive and observed;fraction of explained variation does not in general equal R² computed on predicted and observed;explained variation}
}

@article{zhe05dat,
  title = {Data from a Study of Effectiveness Suggested Potential Prognostic Factors Related to the Patterns of Shoulder Pain},
  author = {Zheng, Xiaohong and Simpson, Julie A. and var der Windt, Danielle A. W. M. and Elliott, Alison M.},
  options = {useprefix=true},
  date = {2005},
  journaltitle = {J Clin Epi},
  volume = {58},
  pages = {823--830},
  citeulike-article-id = {13265435},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {data-reduction,graphics,longitudinal-data,orthopedics,principal-components,serial-data,shoulder},
  note = {nice graphics;representative curves;typical profiles using cluster on principal component scores}
}

@article{zhe05par,
  title = {Partly Conditional Survival Models for Longitudinal Data},
  author = {Zheng, Yingye and Heagerty, Patrick J.},
  date = {2005},
  journaltitle = {Biometrics},
  volume = {61},
  pages = {379--391},
  citeulike-article-id = {13265419},
  posted-at = {2014-07-14 14:09:56},
  priority = {0},
  keywords = {combining-survival-and-longitudinal-data,estimating-equation,joint-model,landmark,multivariate-survival},
  note = {based on conditional hazard for cascading subsets;landmark analysis}
}

@article{zhe95con,
  title = {Consistent Variable Selection in Linear Models},
  author = {Zheng, Xiaodong and Loh, Wei-Lin},
  date = {1995},
  journaltitle = {J Am Stat Assoc},
  volume = {90},
  pages = {151--156},
  citeulike-article-id = {13265078},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {aic,bic,penalty,variable-selection}
}

@article{zho01mul,
  title = {Multiple Imputation in Public Health Research},
  author = {Zhou, Xiao-Hua and Eckert, George J. and Tierney, William M.},
  date = {2001},
  journaltitle = {Stat Med},
  volume = {20},
  pages = {1541--1549},
  citeulike-article-id = {13265195},
  posted-at = {2014-07-14 14:09:51},
  priority = {0},
  keywords = {good-examples,missing-data,multiple-imputation},
  note = {biased caused by not using all available covariables for matching;better standard deviation estimates for multiple imputation than for single mean imputation}
}

@article{zho01reg,
  title = {Regression Analysis of Health Care Charges with Heteroscedasticity},
  author = {Zhou, Xiao-Hua and Stroupe, Kevin T. and Tierney, William M.},
  date = {2001},
  journaltitle = {Appl Stat},
  volume = {50},
  pages = {303--312},
  citeulike-article-id = {13265212},
  posted-at = {2014-07-14 14:09:52},
  priority = {0},
  keywords = {analysis-of-cost,health-care-cost,heteroscedasticity,hypertension,log-normal-data,skewed-data}
}

@article{zho19var,
  title = {A Varying-Coefficient Generalized Odds Rate Model with Time-Varying Exposure: {{An}} Application to Fitness and Cardiovascular Disease Mortality},
  shorttitle = {A Varying-Coefficient Generalized Odds Rate Model with Time-Varying Exposure},
  author = {Zhou, Jie and Zhang, Jiajia and Mclain, Alexander C. and Lu, Wenbin and Sui, Xuemei and Hardin, James W.},
  date = {2019},
  journaltitle = {Biometrics},
  volume = {75},
  number = {3},
  pages = {853--863},
  issn = {1541-0420},
  doi = {10.1111/biom.13057},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.13057},
  urldate = {2019-10-10},
  abstract = {Varying-coefficient models have become a common tool to determine whether and how the association between an exposure and an outcome changes over a continuous measure. These models are complicated when the exposure itself is time-varying and subjected to measurement error. For example, it is well known that longitudinal physical fitness has an impact on cardiovascular disease (CVD) mortality. It is not known, however, how the effect of longitudinal physical fitness on CVD mortality varies with age. In this paper, we propose a varying-coefficient generalized odds rate model that allows flexible estimation of age-modified effects of longitudinal physical fitness on CVD mortality. In our model, the longitudinal physical fitness is measured with error and modeled using a mixed-effects model, and its associated age-varying coefficient function is represented by cubic B-splines. An expectation-maximization algorithm is developed to estimate the parameters in the joint models of longitudinal physical fitness and CVD mortality. A modified pseudoadaptive Gaussian-Hermite quadrature method is adopted to compute the integrals with respect to random effects involved in the E-step. The performance of the proposed method is evaluated through extensive simulation studies and is further illustrated with an application to cohort data from the Aerobic Center Longitudinal Study.},
  langid = {english},
  keywords = {time-varying-coefficients,time-varying-effect,time-varying-exposure}
}

@article{zho21sem,
  title = {Semiparametric Recurrent Event vs Time-to-First-Event Analyses in Randomized Trials: {{Estimands}} and Model Misspecification},
  shorttitle = {Semiparametric Recurrent Event vs Time-to-First-Event Analyses in Randomized Trials},
  author = {Zhong, Yujie and Cook, Richard J.},
  date = {2021},
  journaltitle = {Statistics in Medicine},
  volume = {n/a},
  number = {n/a},
  issn = {1097-0258},
  doi = {10.1002/sim.9002},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.9002},
  urldate = {2021-04-21},
  abstract = {Insights regarding the merits of recurrent event and time-to-first-event analyses are needed to provide guidance on strategies for analyzing intervention effects in randomized trials involving recurrent event responses. Using established asymptotic results we introduce a framework for studying the large sample properties of estimators arising from semiparametric proportional rate function models and Cox regression under model misspecification. The asymptotic biases and power implications are investigated for different data generating models, and we study the impact of dependent censoring on these findings. Illustrative applications are given involving data from a cystic fibrosis trial and a carcinogenicity experiment, following which we summarize findings and discuss implications for clinical trial design.},
  langid = {english},
  keywords = {estimand,multiple-endpoints,rct,recurrent-events},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.9002}
}

@article{zho94eff,
  title = {Effect of Verification Bias on Positive and Negative Predictive Values},
  author = {Zhou, Xiao-Hua},
  date = {1994},
  journaltitle = {Stat Med},
  volume = {13},
  pages = {1737--1745},
  citeulike-article-id = {13265079},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {diagnosis,verification-bias,workup-bias}
}

@article{zho97con,
  title = {Confidence Intervals for the Log-Normal Mean},
  author = {Zhou, Xiao-Hua and Gao, Sujuan},
  date = {1997},
  journaltitle = {Stat Med},
  volume = {16},
  pages = {783--790},
  citeulike-article-id = {13265080},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {analysis-of-costs,economic-analysis,log-transform}
}

@article{zhu11gro,
  title = {Group Sequential Methods and Software Applications},
  author = {Zhu, Li and Ni, Liyun and Yao, Bin},
  date = {2011},
  journaltitle = {Am Statistician},
  volume = {65},
  number = {2},
  pages = {127--135},
  doi = {10.1198/tast.2011.10213},
  url = {http://dx.doi.org/10.1198/tast.2011.10213},
  citeulike-article-id = {13265889},
  citeulike-linkout-0 = {http://dx.doi.org/10.1198/tast.2011.10213},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {futility-boundaries,statistical-software-comparison},
  note = {nice overview of group sequential methods}
}

@article{zhu18lan,
  title = {Landmark Linear Transformation Model for Dynamic Prediction with Application to a Longitudinal Cohort Study of Chronic Disease},
  author = {Zhu, Yayuan and Li, Liang and Huang, Xuelin},
  date = {2018},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume = {0},
  number = {0},
  issn = {1467-9876},
  doi = {10.1111/rssc.12334},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssc.12334},
  urldate = {2018-12-25},
  abstract = {Dynamic prediction of the risk of a clinical event by using longitudinally measured biomarkers or other prognostic information is important in clinical practice. We propose a new class of landmark survival models. The model takes the form of a linear transformation model but allows all the model parameters to vary with the landmark time. This model includes many published landmark prediction models as special cases. We propose a unified local linear estimation framework to estimate time varying model parameters. Simulation studies are conducted to evaluate the finite sample performance of the method proposed. We apply the methodology to a data set from the African American Study of Kidney Disease and Hypertension and predict individual patients’ risk of an adverse clinical event.},
  langid = {english},
  keywords = {dynamic-prediction,landmark}
}

@article{zig16cen,
  title = {The {{Central Role}} of {{Bayes}}’ {{Theorem}} for {{Joint Estimation}} of {{Causal Effects}} and {{Propensity Scores}}},
  author = {Zigler, Corwin Matthew},
  date = {2016-01-02},
  journaltitle = {The American Statistician},
  volume = {70},
  number = {1},
  eprint = {27482121},
  eprinttype = {pmid},
  pages = {47--54},
  issn = {0003-1305},
  doi = {10.1080/00031305.2015.1111260},
  url = {https://doi.org/10.1080/00031305.2015.1111260},
  urldate = {2019-11-25},
  abstract = {Although propensity scores have been central to the estimation of causal effects for over 30 years, only recently has the statistical literature begun to consider in detail methods for Bayesian estimation of propensity scores and causal effects. Underlying this recent body of literature on Bayesian propensity score estimation is an implicit discordance between the goal of the propensity score and the use of Bayes’ theorem. The propensity score condenses multivariate covariate information into a scalar to allow estimation of causal effects without specifying a model for how each covariate relates to the outcome. Avoiding specification of a detailed model for the outcome response surface is valuable for robust estimation of causal effects, but this strategy is at odds with the use of Bayes’ theorem, which presupposes a full probability model for the observed data that adheres to the likelihood principle. The goal of this article is to explicate this fundamental feature of Bayesian estimation of causal effects with propensity scores to provide context for the existing literature and for future work on this important topic.[Received June 2014. Revised September 2015.]},
  keywords = {bayes,causal-inference,causality,propensity}
}

@article{zil98sta,
  title = {A Statistical Method for Quantitative Evaluation of the Progression of Chronic Diseases: {{The}} Mean Score Graph ({{MSG}})},
  author = {Zilber, N. and Manor, O. and Inzelberg, R. and Kahana, E. and Korczyn, A. D.},
  date = {1998},
  journaltitle = {Stat Med},
  volume = {17},
  pages = {2395--2403},
  citeulike-article-id = {13265081},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {chronic-disease,deterioration,disease-progression}
}

@article{zim21pse,
  title = {Pseudo-{{Ranks}}: {{The Better Way}} of {{Ranking}}?},
  shorttitle = {Pseudo-{{Ranks}}},
  author = {Zimmermann, Georg and Brunner, Edgar and Brannath, Werner and Happ, Martin and Bathke, Arne C.},
  date = {2021-09-03},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--7},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2021.1972836},
  url = {https://doi.org/10.1080/00031305.2021.1972836},
  urldate = {2021-10-07},
  abstract = {Rank-based methods are frequently used in the life sciences, and in the empirical sciences in general. Among the best-known examples of nonparametric rank-based tests are the Wilcoxon-Mann-Whitney test and the Kruskal–Wallis test. However, recently, potential pitfalls and paradoxical results pertaining to the use of traditional rank-based procedures for more than two samples have been highlighted, and the so-called pseudo-ranks have been proposed as a remedy for this type of problems. The aim of the present article is twofold: First, we show that pseudo-ranks might also behave counterintuitively when splitting up groups. Second, since the use of pseudo-ranks leads to a slightly different interpretation of the results, we provide some guidance regarding the decision for one or the other approach, in particular with respect to interpretability and generalizability of the findings. It turns out that the choice of the reference distribution, to which the individual groups are compared, is crucial. The practically relevant implications of these aspects are illustrated by a discussion of a dataset from epilepsy research. Summing up, one should decide based on thorough case-by-case considerations whether ranks or pseudo-ranks are appropriate.},
  keywords = {kruskalwallis-test,nonparametric,transitivity,wilcoxon-test},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2021.1972836}
}

@article{zou05reg,
  title = {Regularization and Variable Selection via the Elastic Net},
  author = {Zou, Hui and Hastie, Trevor},
  date = {2005},
  journaltitle = {J Roy Stat Soc B},
  volume = {67},
  number = {2},
  pages = {301--320},
  citeulike-article-id = {13265713},
  posted-at = {2014-07-14 14:10:02},
  priority = {0}
}

@article{zou06spa,
  title = {Sparse Principal Component Analysis},
  author = {Zhou, Hui and Hastie, Trevor and Tibshirani, Robert},
  date = {2006},
  journaltitle = {J Comp Graph Stat},
  volume = {15},
  pages = {265--286},
  citeulike-article-id = {13265474},
  posted-at = {2014-07-14 14:09:57},
  priority = {0},
  keywords = {data-reduction,elastic-net,gene-microarray,lasso,multivariate-analysis,singular-value-decomposition,thresholding},
  note = {principal components analysis that shrinks some loadings to zero}
}

@article{zou07deg,
  title = {On the “Degrees of Freedom” of the Lasso},
  author = {Zou, Hui and Hastie, Trevor and Tibshirani, Robert},
  date = {2007},
  journaltitle = {Ann Stat},
  volume = {35},
  pages = {2173--2192},
  citeulike-article-id = {13265644},
  posted-at = {2014-07-14 14:10:01},
  priority = {0},
  note = {an unbiased estimate of the effective number of degrees of freeom for the lasso is the number of nonzero regression coefficients; note this only applies to p {$<$} n; generalization in RJ Tibshirani and J Taylor Ann Stat 40:1198-1232, 2012}
}

@article{zou08com,
  title = {Composite Quantile Regression and the Oracle Model Selection Theory},
  author = {Zou, Hui and Yuan, Ming},
  date = {2008},
  journaltitle = {Ann Stat},
  volume = {36},
  number = {3},
  pages = {1108--1126},
  citeulike-article-id = {13265976},
  posted-at = {2014-07-14 14:10:08},
  priority = {0},
  keywords = {quantile-regression}
}

@article{zuc10ind,
  title = {Individual ({{N-of-1}}) Trials Can Be Combined to Give Population Comparative Treatment Effect Estimates: Methodologic Considerations},
  author = {Zucker, Deborah R. and Ruthazer, Robin and Schmid, Christopher H.},
  date = {2010},
  journaltitle = {J Clin Epi},
  volume = {63},
  pages = {1312--1323},
  citeulike-article-id = {13265859},
  posted-at = {2014-07-14 14:10:06},
  priority = {0},
  keywords = {cer,combining-trials,meta-analysis,n-of-1-trial,n-of-one-trial}
}

@article{zuc92eff,
  title = {The Efficiency of a Weighted Log-Rank Test under a Percent Error Misspecification Model for the Log Hazard Ratio},
  author = {Zucker, David M.},
  date = {1992},
  journaltitle = {Biometrics},
  volume = {48},
  pages = {893--899},
  citeulike-article-id = {13265082},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {non-proportional-hazards}
}

@article{zuc97com,
  title = {Combining Single Patient ({{N-of-1}}) Trials to Estimate Population Treatment Effects and to Evaluate Individual Patient Responses to Treatment},
  author = {Zucker, D. R. and Schmid, C. H. and McIntosh, M. W. and D'Agostino, R. B. and Selker, H. P. and Lau, J.},
  date = {1997},
  journaltitle = {J Clin Epi},
  volume = {50},
  pages = {401--410},
  citeulike-article-id = {13265083},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {bayesian-inference,hierarchical-model,multi-level-model,n-of-1-trials}
}

@article{zuc98res,
  title = {Restricted Mean Life with Covariates: {{Modification}} and Extension of a Useful Survival Analysis Method},
  author = {Zucker, David M.},
  date = {1998},
  journaltitle = {J Am Stat Assoc},
  volume = {93},
  pages = {702--709},
  citeulike-article-id = {13265084},
  posted-at = {2014-07-14 14:09:48},
  priority = {0},
  keywords = {covariable-adjusted-version-of-area-under-the-kaplan-meier-curve,restricted-mean-life}
}

@article{zuk18ove,
  title = {Overcoming {{Translational Barriers}} in {{Acute Kidney Injury}}: {{A Report}} from an {{NIDDK Workshop}}},
  shorttitle = {Overcoming {{Translational Barriers}} in {{Acute Kidney Injury}}},
  author = {Zuk, Anna and Palevsky, Paul M. and Fried, Linda and Harrell, Frank E. and Khan, Samina and McKay, Dianne B. and Devey, Luke and Chawla, Lakhmir and de Caestecker, Mark and Kaufman, James S. and Thompson, B. Taylor and Agarwal, Anupam and Greene, Tom and Okusa, Mark Douglas and Bonventre, Joseph V. and Dember, Laura M. and Liu, Kathleen D. and Humphreys, Benjamin D. and Gossett, Daniel and Xie, Yining and Norton, Jenna M. and Kimmel, Paul L. and Star, Robert A.},
  options = {useprefix=true},
  date = {2018-07-06},
  journaltitle = {Clin J Am Soc Nephrol},
  volume = {13},
  number = {7},
  eprint = {29523680},
  eprinttype = {pmid},
  pages = {1113--1123},
  issn = {1555-905X},
  doi = {10.2215/CJN.06820617},
  abstract = {AKI is a complex clinical condition associated with high mortality, morbidity, and health care costs. Despite improvements in methodology and design of clinical trials, and advances in understanding the underlying pathophysiology of rodent AKI, no pharmacologic agent exists for the prevention or treatment of AKI in humans. To address the barriers that affect successful clinical translation of drug targets identified and validated in preclinical animal models of AKI in this patient population, the National Institute of Diabetes and Digestive and Kidney Diseases convened the "AKI Outcomes: Overcoming Barriers in AKI" workshop on February 10-12, 2015. The workshop used a reverse translational medicine approach to identify steps necessary to achieve clinical success. During the workshop, breakout groups were charged first to design feasible, phase 2, proof-of-concept clinical trials for delayed transplant graft function, prevention of AKI (primary prevention), and treatment of AKI (secondary prevention and recovery). Breakout groups then were responsible for identification of preclinical animal models that would replicate the pathophysiology of the phase 2 proof-of-concept patient population, including primary and secondary end points. Breakout groups identified considerable gaps in knowledge regarding human AKI, our understanding of the pathophysiology of AKI in preclinical animal models, and the fidelity of cellular and molecular targets that have been evaluated preclinically to provide information regarding human AKI of various etiologies. The workshop concluded with attendees defining a new path forward to a better understanding of the etiology, pathology, and pathophysiology of human AKI.},
  langid = {english},
  pmcid = {PMC6032575}
}

@article{zuo21var,
  title = {Variable {{Selection With Second-Generation P-Values}}},
  author = {Zuo, Yi and Stewart, Thomas G. and Blume, Jeffrey D.},
  date = {2021-06-30},
  journaltitle = {The American Statistician},
  volume = {0},
  number = {0},
  pages = {1--11},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2021.1946150},
  url = {https://doi.org/10.1080/00031305.2021.1946150},
  urldate = {2021-07-27},
  abstract = {Many statistical methods have been proposed for variable selection in the past century, but few balance inference and prediction tasks well. Here, we report on a novel variable selection approach called penalized regression with second-generation p-values (ProSGPV). It captures the true model at the best rate achieved by current standards, is easy to implement in practice, and often yields the smallest parameter estimation error. The idea is to use an l0 penalization scheme with second-generation p-values (SGPV), instead of traditional ones, to determine which variables remain in a model. The approach yields tangible advantages for balancing support recovery, parameter estimation, and prediction tasks. The ProSGPV algorithm can maintain its good performance even when there is strong collinearity among features or when a high-dimensional feature space with p {$>$} n is considered. We present extensive simulations and a real-world application comparing the ProSGPV approach with smoothly clipped absolute deviation (SCAD), adaptive lasso (AL), and minimax concave penalty with penalized linear unbiased selection (MC+). While the last three algorithms are among the current standards for variable selection, ProSGPV has superior inference performance and comparable prediction performance in certain scenarios.},
  keywords = {penalization,variable-selection},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2021.1946150}
}

@preamble{ "\ifdefined\DeclarePrefChars\DeclarePrefChars{'’-}\else\fi " }

